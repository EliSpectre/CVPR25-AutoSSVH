2025-03-02 11:36:40,584 - INFO - Self Supervised Video Hashing Training: AutoSSVH
2025-03-02 11:36:40,584 - INFO - set seed: 1
2025-03-02 11:36:40,747 - INFO - used gpu: 5
2025-03-02 11:36:40,747 - INFO - PARAMETER ......
2025-03-02 11:36:40,747 - INFO - Config (path: /data2/lianniu/CVPR25-AutoSSVH/configs/AutoSSVH_fcv.py): {'model_name': 'AutoSSVH', 'use_checkpoint': None, 'feature_size': 4096, 'hidden_size': 256, 'max_frames': 25, 'nbits': 16, 'AutoSSVH_type': 'small', 'dataset': 'fcv', 'workers': 1, 'batch_size': 512, 'mask_prob': 0.75, 'seed': 1, 'num_epochs': 805, 'a': 1.0, 'temperature': 0.5, 'tau_plus': 0.1, 'train_num_sample': 45585, 'CVH': True, 'num_cluster': [250, 400, 600], 'warmup_epoch': 100, 'kmeans_temperature': 0.2, 'b': 0.01, 'data_drop_rate': 0.0, 'test_batch_size': 128, 'test_num_sample': 45600, 'optimizer_name': 'Adam', 'schedule': 'StepLR', 'lr': 0.0001, 'min_lr': 1e-05, 'lr_decay_rate': 20, 'lr_decay_gamma': 0.9, 'weight_decay': 0.0, 'data_root': 'data/fcv/', 'home_root': './', 'train_feat_path': ['data/fcv/fcv_train_feats.h5'], 'test_feat_path': ['data/fcv/fcv_test_feats.h5'], 'label_path': ['data/fcv/fcv_test_labels.mat'], 'save_dir': './checkpoint/fcv', 'file_path': './checkpoint/fcv/AutoSSVH_16bit', 'log_path': './logs/fcvS5VH_16bit'}
2025-03-02 11:36:40,747 - INFO - loading model ......
2025-03-02 11:36:42,325 - INFO - encoder param:10672290
2025-03-02 11:36:42,326 - INFO - loading train data ......
2025-03-02 11:36:54,146 - INFO - loading eval data ......
2025-03-02 11:37:06,083 - INFO - begin training stage: [1/805]
2025-03-02 11:37:06,083 - INFO - begin training stage: [1/805]
2025-03-02 11:37:11,862 - INFO - Epoch:[1/805] Step:[10/90] reconstruction_loss: 1.99 loss_vc: 5.01 loss_cvh: 0.00
2025-03-02 11:37:15,019 - INFO - Epoch:[1/805] Step:[20/90] reconstruction_loss: 1.86 loss_vc: 4.92 loss_cvh: 0.00
2025-03-02 11:37:18,225 - INFO - Epoch:[1/805] Step:[30/90] reconstruction_loss: 1.70 loss_vc: 4.87 loss_cvh: 0.00
2025-03-02 11:37:21,421 - INFO - Epoch:[1/805] Step:[40/90] reconstruction_loss: 1.69 loss_vc: 4.87 loss_cvh: 0.00
2025-03-02 11:37:24,578 - INFO - Epoch:[1/805] Step:[50/90] reconstruction_loss: 1.63 loss_vc: 4.79 loss_cvh: 0.00
2025-03-02 11:37:27,697 - INFO - Epoch:[1/805] Step:[60/90] reconstruction_loss: 1.59 loss_vc: 4.77 loss_cvh: 0.00
2025-03-02 11:37:30,868 - INFO - Epoch:[1/805] Step:[70/90] reconstruction_loss: 1.59 loss_vc: 4.79 loss_cvh: 0.00
2025-03-02 11:37:33,977 - INFO - Epoch:[1/805] Step:[80/90] reconstruction_loss: 1.59 loss_vc: 4.78 loss_cvh: 0.00
2025-03-02 11:37:36,883 - INFO - Epoch:[1/805] Step:[90/90] reconstruction_loss: 1.41 loss_vc: 1.45 loss_cvh: 0.00
2025-03-02 11:37:37,745 - INFO - now the learning rate is: 0.0001
2025-03-02 11:37:37,746 - INFO - begin training stage: [2/805]
2025-03-02 11:37:37,746 - INFO - begin training stage: [2/805]
2025-03-02 11:37:42,377 - INFO - Epoch:[2/805] Step:[10/90] reconstruction_loss: 1.58 loss_vc: 4.75 loss_cvh: 0.00
2025-03-02 11:37:45,975 - INFO - Epoch:[2/805] Step:[20/90] reconstruction_loss: 1.60 loss_vc: 4.76 loss_cvh: 0.00
2025-03-02 11:37:49,294 - INFO - Epoch:[2/805] Step:[30/90] reconstruction_loss: 1.59 loss_vc: 4.72 loss_cvh: 0.00
2025-03-02 11:37:52,708 - INFO - Epoch:[2/805] Step:[40/90] reconstruction_loss: 1.55 loss_vc: 4.70 loss_cvh: 0.00
2025-03-02 11:37:56,251 - INFO - Epoch:[2/805] Step:[50/90] reconstruction_loss: 1.58 loss_vc: 4.72 loss_cvh: 0.00
2025-03-02 11:37:59,839 - INFO - Epoch:[2/805] Step:[60/90] reconstruction_loss: 1.57 loss_vc: 4.74 loss_cvh: 0.00
2025-03-02 11:38:03,482 - INFO - Epoch:[2/805] Step:[70/90] reconstruction_loss: 1.54 loss_vc: 4.72 loss_cvh: 0.00
2025-03-02 11:38:06,926 - INFO - Epoch:[2/805] Step:[80/90] reconstruction_loss: 1.49 loss_vc: 4.70 loss_cvh: 0.00
2025-03-02 11:38:10,137 - INFO - Epoch:[2/805] Step:[90/90] reconstruction_loss: 1.44 loss_vc: 1.55 loss_cvh: 0.00
2025-03-02 11:38:11,358 - INFO - now the learning rate is: 0.0001
2025-03-02 11:38:11,359 - INFO - begin training stage: [3/805]
2025-03-02 11:38:11,359 - INFO - begin training stage: [3/805]
2025-03-02 11:38:15,844 - INFO - Epoch:[3/805] Step:[10/90] reconstruction_loss: 1.51 loss_vc: 4.67 loss_cvh: 0.00
2025-03-02 11:38:19,252 - INFO - Epoch:[3/805] Step:[20/90] reconstruction_loss: 1.47 loss_vc: 4.69 loss_cvh: 0.00
2025-03-02 11:38:22,686 - INFO - Epoch:[3/805] Step:[30/90] reconstruction_loss: 1.46 loss_vc: 4.66 loss_cvh: 0.00
2025-03-02 11:38:26,030 - INFO - Epoch:[3/805] Step:[40/90] reconstruction_loss: 1.44 loss_vc: 4.71 loss_cvh: 0.00
2025-03-02 11:38:29,506 - INFO - Epoch:[3/805] Step:[50/90] reconstruction_loss: 1.42 loss_vc: 4.67 loss_cvh: 0.00
2025-03-02 11:38:32,919 - INFO - Epoch:[3/805] Step:[60/90] reconstruction_loss: 1.40 loss_vc: 4.70 loss_cvh: 0.00
2025-03-02 11:38:36,302 - INFO - Epoch:[3/805] Step:[70/90] reconstruction_loss: 1.40 loss_vc: 4.69 loss_cvh: 0.00
2025-03-02 11:38:39,699 - INFO - Epoch:[3/805] Step:[80/90] reconstruction_loss: 1.37 loss_vc: 4.68 loss_cvh: 0.00
2025-03-02 11:38:42,793 - INFO - Epoch:[3/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.39 loss_cvh: 0.00
2025-03-02 11:38:43,845 - INFO - now the learning rate is: 0.0001
2025-03-02 11:38:43,845 - INFO - begin training stage: [4/805]
2025-03-02 11:38:43,846 - INFO - begin training stage: [4/805]
2025-03-02 11:38:47,727 - INFO - Epoch:[4/805] Step:[10/90] reconstruction_loss: 1.43 loss_vc: 4.67 loss_cvh: 0.00
2025-03-02 11:38:50,765 - INFO - Epoch:[4/805] Step:[20/90] reconstruction_loss: 1.42 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:38:53,885 - INFO - Epoch:[4/805] Step:[30/90] reconstruction_loss: 1.41 loss_vc: 4.66 loss_cvh: 0.00
2025-03-02 11:38:57,002 - INFO - Epoch:[4/805] Step:[40/90] reconstruction_loss: 1.39 loss_vc: 4.66 loss_cvh: 0.00
2025-03-02 11:39:00,090 - INFO - Epoch:[4/805] Step:[50/90] reconstruction_loss: 1.37 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:39:03,390 - INFO - Epoch:[4/805] Step:[60/90] reconstruction_loss: 1.39 loss_vc: 4.67 loss_cvh: 0.00
2025-03-02 11:39:06,752 - INFO - Epoch:[4/805] Step:[70/90] reconstruction_loss: 1.34 loss_vc: 4.67 loss_cvh: 0.00
2025-03-02 11:39:09,941 - INFO - Epoch:[4/805] Step:[80/90] reconstruction_loss: 1.35 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:39:12,913 - INFO - Epoch:[4/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.61 loss_cvh: 0.00
2025-03-02 11:39:13,864 - INFO - now the learning rate is: 0.0001
2025-03-02 11:39:13,865 - INFO - begin training stage: [5/805]
2025-03-02 11:39:13,865 - INFO - begin training stage: [5/805]
2025-03-02 11:39:17,930 - INFO - Epoch:[5/805] Step:[10/90] reconstruction_loss: 1.39 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:39:21,091 - INFO - Epoch:[5/805] Step:[20/90] reconstruction_loss: 1.41 loss_vc: 4.66 loss_cvh: 0.00
2025-03-02 11:39:24,495 - INFO - Epoch:[5/805] Step:[30/90] reconstruction_loss: 1.39 loss_vc: 4.66 loss_cvh: 0.00
2025-03-02 11:39:28,359 - INFO - Epoch:[5/805] Step:[40/90] reconstruction_loss: 1.36 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:39:32,548 - INFO - Epoch:[5/805] Step:[50/90] reconstruction_loss: 1.32 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:39:36,959 - INFO - Epoch:[5/805] Step:[60/90] reconstruction_loss: 1.36 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:39:41,384 - INFO - Epoch:[5/805] Step:[70/90] reconstruction_loss: 1.35 loss_vc: 4.67 loss_cvh: 0.00
2025-03-02 11:39:46,113 - INFO - Epoch:[5/805] Step:[80/90] reconstruction_loss: 1.32 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:39:50,260 - INFO - Epoch:[5/805] Step:[90/90] reconstruction_loss: 1.48 loss_vc: 1.47 loss_cvh: 0.00
2025-03-02 11:39:51,663 - INFO - now the learning rate is: 0.0001
2025-03-02 11:39:51,663 - INFO - begin training stage: [6/805]
2025-03-02 11:39:51,663 - INFO - begin training stage: [6/805]
2025-03-02 11:39:57,397 - INFO - Epoch:[6/805] Step:[10/90] reconstruction_loss: 1.34 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:40:01,639 - INFO - Epoch:[6/805] Step:[20/90] reconstruction_loss: 1.35 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:40:05,636 - INFO - Epoch:[6/805] Step:[30/90] reconstruction_loss: 1.34 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:40:09,991 - INFO - Epoch:[6/805] Step:[40/90] reconstruction_loss: 1.37 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:40:14,144 - INFO - Epoch:[6/805] Step:[50/90] reconstruction_loss: 1.38 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:40:18,420 - INFO - Epoch:[6/805] Step:[60/90] reconstruction_loss: 1.32 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:40:22,728 - INFO - Epoch:[6/805] Step:[70/90] reconstruction_loss: 1.37 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:40:27,024 - INFO - Epoch:[6/805] Step:[80/90] reconstruction_loss: 1.35 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:40:31,241 - INFO - Epoch:[6/805] Step:[90/90] reconstruction_loss: 1.29 loss_vc: 1.50 loss_cvh: 0.00
2025-03-02 11:40:32,603 - INFO - now the learning rate is: 0.0001
2025-03-02 11:40:32,603 - INFO - begin training stage: [7/805]
2025-03-02 11:40:32,604 - INFO - begin training stage: [7/805]
2025-03-02 11:40:38,056 - INFO - Epoch:[7/805] Step:[10/90] reconstruction_loss: 1.33 loss_vc: 4.67 loss_cvh: 0.00
2025-03-02 11:40:42,435 - INFO - Epoch:[7/805] Step:[20/90] reconstruction_loss: 1.37 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:40:46,691 - INFO - Epoch:[7/805] Step:[30/90] reconstruction_loss: 1.33 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:40:50,808 - INFO - Epoch:[7/805] Step:[40/90] reconstruction_loss: 1.36 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:40:55,056 - INFO - Epoch:[7/805] Step:[50/90] reconstruction_loss: 1.37 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:40:58,136 - INFO - Epoch:[7/805] Step:[60/90] reconstruction_loss: 1.30 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:41:01,191 - INFO - Epoch:[7/805] Step:[70/90] reconstruction_loss: 1.32 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:41:04,366 - INFO - Epoch:[7/805] Step:[80/90] reconstruction_loss: 1.31 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:41:07,228 - INFO - Epoch:[7/805] Step:[90/90] reconstruction_loss: 1.42 loss_vc: 1.25 loss_cvh: 0.00
2025-03-02 11:41:08,217 - INFO - now the learning rate is: 0.0001
2025-03-02 11:41:08,217 - INFO - begin training stage: [8/805]
2025-03-02 11:41:08,217 - INFO - begin training stage: [8/805]
2025-03-02 11:41:12,093 - INFO - Epoch:[8/805] Step:[10/90] reconstruction_loss: 1.33 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:41:14,969 - INFO - Epoch:[8/805] Step:[20/90] reconstruction_loss: 1.35 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:41:17,965 - INFO - Epoch:[8/805] Step:[30/90] reconstruction_loss: 1.33 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:41:20,892 - INFO - Epoch:[8/805] Step:[40/90] reconstruction_loss: 1.31 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:41:23,790 - INFO - Epoch:[8/805] Step:[50/90] reconstruction_loss: 1.32 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:41:26,716 - INFO - Epoch:[8/805] Step:[60/90] reconstruction_loss: 1.30 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:41:29,644 - INFO - Epoch:[8/805] Step:[70/90] reconstruction_loss: 1.33 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:41:32,579 - INFO - Epoch:[8/805] Step:[80/90] reconstruction_loss: 1.32 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:41:35,410 - INFO - Epoch:[8/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.38 loss_cvh: 0.00
2025-03-02 11:41:36,364 - INFO - now the learning rate is: 0.0001
2025-03-02 11:41:36,364 - INFO - begin training stage: [9/805]
2025-03-02 11:41:36,364 - INFO - begin training stage: [9/805]
2025-03-02 11:41:40,282 - INFO - Epoch:[9/805] Step:[10/90] reconstruction_loss: 1.34 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:41:43,318 - INFO - Epoch:[9/805] Step:[20/90] reconstruction_loss: 1.31 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:41:46,756 - INFO - Epoch:[9/805] Step:[30/90] reconstruction_loss: 1.29 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:41:50,051 - INFO - Epoch:[9/805] Step:[40/90] reconstruction_loss: 1.30 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:41:53,628 - INFO - Epoch:[9/805] Step:[50/90] reconstruction_loss: 1.32 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:41:58,132 - INFO - Epoch:[9/805] Step:[60/90] reconstruction_loss: 1.29 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:42:03,036 - INFO - Epoch:[9/805] Step:[70/90] reconstruction_loss: 1.32 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:42:07,359 - INFO - Epoch:[9/805] Step:[80/90] reconstruction_loss: 1.32 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:42:11,430 - INFO - Epoch:[9/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.43 loss_cvh: 0.00
2025-03-02 11:42:12,708 - INFO - now the learning rate is: 0.0001
2025-03-02 11:42:12,710 - INFO - begin training stage: [10/805]
2025-03-02 11:42:12,710 - INFO - begin training stage: [10/805]
2025-03-02 11:42:18,640 - INFO - Epoch:[10/805] Step:[10/90] reconstruction_loss: 1.29 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:42:23,276 - INFO - Epoch:[10/805] Step:[20/90] reconstruction_loss: 1.30 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:42:28,160 - INFO - Epoch:[10/805] Step:[30/90] reconstruction_loss: 1.30 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:42:32,608 - INFO - Epoch:[10/805] Step:[40/90] reconstruction_loss: 1.31 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:42:36,953 - INFO - Epoch:[10/805] Step:[50/90] reconstruction_loss: 1.33 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:42:41,288 - INFO - Epoch:[10/805] Step:[60/90] reconstruction_loss: 1.31 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:42:45,723 - INFO - Epoch:[10/805] Step:[70/90] reconstruction_loss: 1.31 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:42:50,313 - INFO - Epoch:[10/805] Step:[80/90] reconstruction_loss: 1.31 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:42:54,472 - INFO - Epoch:[10/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.36 loss_cvh: 0.00
2025-03-02 11:42:55,763 - INFO - now the learning rate is: 0.0001
2025-03-02 11:42:55,764 - INFO - begin training stage: [11/805]
2025-03-02 11:42:55,765 - INFO - eval data number: 45600
2025-03-02 11:42:55,765 - INFO - loading eval data ......
2025-03-02 11:43:32,718 - INFO - retrieval costs: 21.78248357772827
2025-03-02 11:44:55,584 - INFO - hamming distance computation costs: 82.86571264266968
2025-03-02 11:45:03,845 - INFO - hamming ranking costs: 8.261412143707275
2025-03-02 11:45:03,845 - INFO - labels shape: (45600, 239)
2025-03-02 11:45:41,282 - INFO - similarity labels generation costs: 37.4370391368866
2025-03-02 11:45:41,355 - INFO - topK: 5:, map: 0.195085
2025-03-02 11:45:41,618 - INFO - topK: 20:, map: 0.11215662035247173
2025-03-02 11:45:42,154 - INFO - topK: 40:, map: 0.08827121545981975
2025-03-02 11:45:42,943 - INFO - topK: 60:, map: 0.07700871511560024
2025-03-02 11:45:44,026 - INFO - topK: 80:, map: 0.06952720605161662
2025-03-02 11:45:45,303 - INFO - topK: 100:, map: 0.06396162409614327
2025-03-02 11:45:46,444 - INFO - begin training stage: [11/805]
2025-03-02 11:45:50,927 - INFO - Epoch:[11/805] Step:[10/90] reconstruction_loss: 1.35 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:45:54,426 - INFO - Epoch:[11/805] Step:[20/90] reconstruction_loss: 1.31 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:45:57,801 - INFO - Epoch:[11/805] Step:[30/90] reconstruction_loss: 1.32 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:46:01,272 - INFO - Epoch:[11/805] Step:[40/90] reconstruction_loss: 1.26 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:46:04,835 - INFO - Epoch:[11/805] Step:[50/90] reconstruction_loss: 1.29 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:46:08,598 - INFO - Epoch:[11/805] Step:[60/90] reconstruction_loss: 1.30 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:46:12,117 - INFO - Epoch:[11/805] Step:[70/90] reconstruction_loss: 1.30 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:46:15,599 - INFO - Epoch:[11/805] Step:[80/90] reconstruction_loss: 1.29 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:46:18,801 - INFO - Epoch:[11/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.20 loss_cvh: 0.00
2025-03-02 11:46:19,743 - INFO - now the learning rate is: 0.0001
2025-03-02 11:46:19,743 - INFO - begin training stage: [12/805]
2025-03-02 11:46:19,743 - INFO - begin training stage: [12/805]
2025-03-02 11:46:24,226 - INFO - Epoch:[12/805] Step:[10/90] reconstruction_loss: 1.29 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:46:27,976 - INFO - Epoch:[12/805] Step:[20/90] reconstruction_loss: 1.32 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:46:31,699 - INFO - Epoch:[12/805] Step:[30/90] reconstruction_loss: 1.29 loss_vc: 4.65 loss_cvh: 0.00
2025-03-02 11:46:35,339 - INFO - Epoch:[12/805] Step:[40/90] reconstruction_loss: 1.30 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:46:39,023 - INFO - Epoch:[12/805] Step:[50/90] reconstruction_loss: 1.31 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:46:42,656 - INFO - Epoch:[12/805] Step:[60/90] reconstruction_loss: 1.28 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:46:46,450 - INFO - Epoch:[12/805] Step:[70/90] reconstruction_loss: 1.28 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:46:50,123 - INFO - Epoch:[12/805] Step:[80/90] reconstruction_loss: 1.30 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:46:53,480 - INFO - Epoch:[12/805] Step:[90/90] reconstruction_loss: 1.30 loss_vc: 1.47 loss_cvh: 0.00
2025-03-02 11:46:54,356 - INFO - now the learning rate is: 0.0001
2025-03-02 11:46:54,357 - INFO - begin training stage: [13/805]
2025-03-02 11:46:54,357 - INFO - begin training stage: [13/805]
2025-03-02 11:46:58,682 - INFO - Epoch:[13/805] Step:[10/90] reconstruction_loss: 1.32 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:47:02,312 - INFO - Epoch:[13/805] Step:[20/90] reconstruction_loss: 1.28 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:47:05,786 - INFO - Epoch:[13/805] Step:[30/90] reconstruction_loss: 1.32 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:47:09,088 - INFO - Epoch:[13/805] Step:[40/90] reconstruction_loss: 1.26 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:47:12,454 - INFO - Epoch:[13/805] Step:[50/90] reconstruction_loss: 1.27 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:47:15,790 - INFO - Epoch:[13/805] Step:[60/90] reconstruction_loss: 1.34 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:47:19,461 - INFO - Epoch:[13/805] Step:[70/90] reconstruction_loss: 1.30 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:47:23,175 - INFO - Epoch:[13/805] Step:[80/90] reconstruction_loss: 1.26 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:47:26,280 - INFO - Epoch:[13/805] Step:[90/90] reconstruction_loss: 1.32 loss_vc: 1.32 loss_cvh: 0.00
2025-03-02 11:47:27,188 - INFO - now the learning rate is: 0.0001
2025-03-02 11:47:27,189 - INFO - begin training stage: [14/805]
2025-03-02 11:47:27,189 - INFO - begin training stage: [14/805]
2025-03-02 11:47:31,278 - INFO - Epoch:[14/805] Step:[10/90] reconstruction_loss: 1.29 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:47:34,640 - INFO - Epoch:[14/805] Step:[20/90] reconstruction_loss: 1.28 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:47:38,087 - INFO - Epoch:[14/805] Step:[30/90] reconstruction_loss: 1.27 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:47:41,615 - INFO - Epoch:[14/805] Step:[40/90] reconstruction_loss: 1.33 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:47:44,891 - INFO - Epoch:[14/805] Step:[50/90] reconstruction_loss: 1.27 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:47:48,364 - INFO - Epoch:[14/805] Step:[60/90] reconstruction_loss: 1.29 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:47:51,658 - INFO - Epoch:[14/805] Step:[70/90] reconstruction_loss: 1.28 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:47:55,026 - INFO - Epoch:[14/805] Step:[80/90] reconstruction_loss: 1.31 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:47:58,459 - INFO - Epoch:[14/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.31 loss_cvh: 0.00
2025-03-02 11:47:59,379 - INFO - now the learning rate is: 0.0001
2025-03-02 11:47:59,380 - INFO - begin training stage: [15/805]
2025-03-02 11:47:59,380 - INFO - begin training stage: [15/805]
2025-03-02 11:48:03,516 - INFO - Epoch:[15/805] Step:[10/90] reconstruction_loss: 1.29 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:48:06,882 - INFO - Epoch:[15/805] Step:[20/90] reconstruction_loss: 1.26 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:48:10,175 - INFO - Epoch:[15/805] Step:[30/90] reconstruction_loss: 1.29 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:48:13,558 - INFO - Epoch:[15/805] Step:[40/90] reconstruction_loss: 1.28 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:48:16,998 - INFO - Epoch:[15/805] Step:[50/90] reconstruction_loss: 1.26 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:48:21,952 - INFO - Epoch:[15/805] Step:[60/90] reconstruction_loss: 1.28 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:48:27,153 - INFO - Epoch:[15/805] Step:[70/90] reconstruction_loss: 1.30 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:48:31,865 - INFO - Epoch:[15/805] Step:[80/90] reconstruction_loss: 1.26 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:48:36,322 - INFO - Epoch:[15/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.42 loss_cvh: 0.00
2025-03-02 11:48:37,515 - INFO - now the learning rate is: 0.0001
2025-03-02 11:48:37,515 - INFO - begin training stage: [16/805]
2025-03-02 11:48:37,515 - INFO - begin training stage: [16/805]
2025-03-02 11:48:43,696 - INFO - Epoch:[16/805] Step:[10/90] reconstruction_loss: 1.26 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:48:48,516 - INFO - Epoch:[16/805] Step:[20/90] reconstruction_loss: 1.26 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:48:52,932 - INFO - Epoch:[16/805] Step:[30/90] reconstruction_loss: 1.29 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:48:57,579 - INFO - Epoch:[16/805] Step:[40/90] reconstruction_loss: 1.25 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:49:02,284 - INFO - Epoch:[16/805] Step:[50/90] reconstruction_loss: 1.27 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:49:07,611 - INFO - Epoch:[16/805] Step:[60/90] reconstruction_loss: 1.28 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:49:12,276 - INFO - Epoch:[16/805] Step:[70/90] reconstruction_loss: 1.27 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:49:17,060 - INFO - Epoch:[16/805] Step:[80/90] reconstruction_loss: 1.25 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:49:21,364 - INFO - Epoch:[16/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.52 loss_cvh: 0.00
2025-03-02 11:49:22,517 - INFO - now the learning rate is: 0.0001
2025-03-02 11:49:22,519 - INFO - begin training stage: [17/805]
2025-03-02 11:49:22,519 - INFO - begin training stage: [17/805]
2025-03-02 11:49:28,576 - INFO - Epoch:[17/805] Step:[10/90] reconstruction_loss: 1.29 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:49:33,596 - INFO - Epoch:[17/805] Step:[20/90] reconstruction_loss: 1.28 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:49:38,354 - INFO - Epoch:[17/805] Step:[30/90] reconstruction_loss: 1.32 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:49:42,737 - INFO - Epoch:[17/805] Step:[40/90] reconstruction_loss: 1.27 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 11:49:45,927 - INFO - Epoch:[17/805] Step:[50/90] reconstruction_loss: 1.29 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:49:49,317 - INFO - Epoch:[17/805] Step:[60/90] reconstruction_loss: 1.28 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:49:52,714 - INFO - Epoch:[17/805] Step:[70/90] reconstruction_loss: 1.26 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:49:56,070 - INFO - Epoch:[17/805] Step:[80/90] reconstruction_loss: 1.25 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:49:59,066 - INFO - Epoch:[17/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.39 loss_cvh: 0.00
2025-03-02 11:49:59,928 - INFO - now the learning rate is: 0.0001
2025-03-02 11:49:59,928 - INFO - begin training stage: [18/805]
2025-03-02 11:49:59,928 - INFO - begin training stage: [18/805]
2025-03-02 11:50:04,059 - INFO - Epoch:[18/805] Step:[10/90] reconstruction_loss: 1.25 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:50:07,742 - INFO - Epoch:[18/805] Step:[20/90] reconstruction_loss: 1.27 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:50:11,158 - INFO - Epoch:[18/805] Step:[30/90] reconstruction_loss: 1.24 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:50:14,446 - INFO - Epoch:[18/805] Step:[40/90] reconstruction_loss: 1.26 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:50:17,577 - INFO - Epoch:[18/805] Step:[50/90] reconstruction_loss: 1.27 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:50:20,743 - INFO - Epoch:[18/805] Step:[60/90] reconstruction_loss: 1.26 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 11:50:24,008 - INFO - Epoch:[18/805] Step:[70/90] reconstruction_loss: 1.25 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:50:27,400 - INFO - Epoch:[18/805] Step:[80/90] reconstruction_loss: 1.27 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:50:30,612 - INFO - Epoch:[18/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.31 loss_cvh: 0.00
2025-03-02 11:50:31,519 - INFO - now the learning rate is: 0.0001
2025-03-02 11:50:31,519 - INFO - begin training stage: [19/805]
2025-03-02 11:50:31,520 - INFO - begin training stage: [19/805]
2025-03-02 11:50:35,736 - INFO - Epoch:[19/805] Step:[10/90] reconstruction_loss: 1.28 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:50:39,165 - INFO - Epoch:[19/805] Step:[20/90] reconstruction_loss: 1.28 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:50:42,741 - INFO - Epoch:[19/805] Step:[30/90] reconstruction_loss: 1.29 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:50:46,329 - INFO - Epoch:[19/805] Step:[40/90] reconstruction_loss: 1.25 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:50:49,665 - INFO - Epoch:[19/805] Step:[50/90] reconstruction_loss: 1.23 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:50:52,924 - INFO - Epoch:[19/805] Step:[60/90] reconstruction_loss: 1.25 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 11:50:57,259 - INFO - Epoch:[19/805] Step:[70/90] reconstruction_loss: 1.26 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:51:01,672 - INFO - Epoch:[19/805] Step:[80/90] reconstruction_loss: 1.27 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:51:05,943 - INFO - Epoch:[19/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.36 loss_cvh: 0.00
2025-03-02 11:51:07,186 - INFO - now the learning rate is: 0.0001
2025-03-02 11:51:07,187 - INFO - begin training stage: [20/805]
2025-03-02 11:51:07,187 - INFO - begin training stage: [20/805]
2025-03-02 11:51:12,928 - INFO - Epoch:[20/805] Step:[10/90] reconstruction_loss: 1.26 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:51:17,199 - INFO - Epoch:[20/805] Step:[20/90] reconstruction_loss: 1.27 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:51:21,741 - INFO - Epoch:[20/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:51:26,330 - INFO - Epoch:[20/805] Step:[40/90] reconstruction_loss: 1.27 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:51:31,490 - INFO - Epoch:[20/805] Step:[50/90] reconstruction_loss: 1.26 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:51:36,319 - INFO - Epoch:[20/805] Step:[60/90] reconstruction_loss: 1.25 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:51:41,047 - INFO - Epoch:[20/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:51:45,664 - INFO - Epoch:[20/805] Step:[80/90] reconstruction_loss: 1.26 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:51:50,155 - INFO - Epoch:[20/805] Step:[90/90] reconstruction_loss: 1.44 loss_vc: 1.38 loss_cvh: 0.00
2025-03-02 11:51:51,327 - INFO - now the learning rate is: 9e-05
2025-03-02 11:51:51,328 - INFO - begin training stage: [21/805]
2025-03-02 11:51:51,329 - INFO - eval data number: 45600
2025-03-02 11:51:51,329 - INFO - loading eval data ......
2025-03-02 11:52:27,819 - INFO - retrieval costs: 22.579338312149048
2025-03-02 11:53:43,908 - INFO - hamming distance computation costs: 76.08911371231079
2025-03-02 11:53:50,407 - INFO - hamming ranking costs: 6.498703956604004
2025-03-02 11:53:50,407 - INFO - labels shape: (45600, 239)
2025-03-02 11:54:27,385 - INFO - similarity labels generation costs: 36.97761368751526
2025-03-02 11:54:27,460 - INFO - topK: 5:, map: 0.2060241666666667
2025-03-02 11:54:27,723 - INFO - topK: 20:, map: 0.12685574055164178
2025-03-02 11:54:28,235 - INFO - topK: 40:, map: 0.1042030844123671
2025-03-02 11:54:28,985 - INFO - topK: 60:, map: 0.09317155769457199
2025-03-02 11:54:29,984 - INFO - topK: 80:, map: 0.0857785428944066
2025-03-02 11:54:31,225 - INFO - topK: 100:, map: 0.08018083987326657
2025-03-02 11:54:32,444 - INFO - begin training stage: [21/805]
2025-03-02 11:54:36,929 - INFO - Epoch:[21/805] Step:[10/90] reconstruction_loss: 1.25 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:54:40,434 - INFO - Epoch:[21/805] Step:[20/90] reconstruction_loss: 1.28 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:54:43,903 - INFO - Epoch:[21/805] Step:[30/90] reconstruction_loss: 1.24 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:54:47,424 - INFO - Epoch:[21/805] Step:[40/90] reconstruction_loss: 1.25 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:54:50,745 - INFO - Epoch:[21/805] Step:[50/90] reconstruction_loss: 1.27 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:54:54,199 - INFO - Epoch:[21/805] Step:[60/90] reconstruction_loss: 1.26 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 11:54:57,581 - INFO - Epoch:[21/805] Step:[70/90] reconstruction_loss: 1.26 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:55:01,101 - INFO - Epoch:[21/805] Step:[80/90] reconstruction_loss: 1.25 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:55:04,324 - INFO - Epoch:[21/805] Step:[90/90] reconstruction_loss: 1.28 loss_vc: 1.28 loss_cvh: 0.00
2025-03-02 11:55:05,193 - INFO - now the learning rate is: 9e-05
2025-03-02 11:55:05,193 - INFO - begin training stage: [22/805]
2025-03-02 11:55:05,193 - INFO - begin training stage: [22/805]
2025-03-02 11:55:09,345 - INFO - Epoch:[22/805] Step:[10/90] reconstruction_loss: 1.26 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:55:12,737 - INFO - Epoch:[22/805] Step:[20/90] reconstruction_loss: 1.25 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:55:16,168 - INFO - Epoch:[22/805] Step:[30/90] reconstruction_loss: 1.26 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:55:19,652 - INFO - Epoch:[22/805] Step:[40/90] reconstruction_loss: 1.24 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:55:23,045 - INFO - Epoch:[22/805] Step:[50/90] reconstruction_loss: 1.25 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:55:26,345 - INFO - Epoch:[22/805] Step:[60/90] reconstruction_loss: 1.24 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:55:29,784 - INFO - Epoch:[22/805] Step:[70/90] reconstruction_loss: 1.26 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:55:33,174 - INFO - Epoch:[22/805] Step:[80/90] reconstruction_loss: 1.28 loss_vc: 4.63 loss_cvh: 0.00
2025-03-02 11:55:36,455 - INFO - Epoch:[22/805] Step:[90/90] reconstruction_loss: 1.32 loss_vc: 1.31 loss_cvh: 0.00
2025-03-02 11:55:37,323 - INFO - now the learning rate is: 9e-05
2025-03-02 11:55:37,324 - INFO - begin training stage: [23/805]
2025-03-02 11:55:37,324 - INFO - begin training stage: [23/805]
2025-03-02 11:55:41,575 - INFO - Epoch:[23/805] Step:[10/90] reconstruction_loss: 1.27 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:55:44,892 - INFO - Epoch:[23/805] Step:[20/90] reconstruction_loss: 1.27 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:55:48,397 - INFO - Epoch:[23/805] Step:[30/90] reconstruction_loss: 1.25 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:55:51,864 - INFO - Epoch:[23/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:55:55,393 - INFO - Epoch:[23/805] Step:[50/90] reconstruction_loss: 1.25 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:55:58,831 - INFO - Epoch:[23/805] Step:[60/90] reconstruction_loss: 1.23 loss_vc: 4.62 loss_cvh: 0.00
2025-03-02 11:56:02,182 - INFO - Epoch:[23/805] Step:[70/90] reconstruction_loss: 1.26 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 11:56:05,546 - INFO - Epoch:[23/805] Step:[80/90] reconstruction_loss: 1.26 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:56:08,712 - INFO - Epoch:[23/805] Step:[90/90] reconstruction_loss: 1.32 loss_vc: 1.28 loss_cvh: 0.00
2025-03-02 11:56:09,561 - INFO - now the learning rate is: 9e-05
2025-03-02 11:56:09,562 - INFO - begin training stage: [24/805]
2025-03-02 11:56:09,562 - INFO - begin training stage: [24/805]
2025-03-02 11:56:13,994 - INFO - Epoch:[24/805] Step:[10/90] reconstruction_loss: 1.23 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:56:17,379 - INFO - Epoch:[24/805] Step:[20/90] reconstruction_loss: 1.27 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:56:20,714 - INFO - Epoch:[24/805] Step:[30/90] reconstruction_loss: 1.24 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:56:24,086 - INFO - Epoch:[24/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:56:27,492 - INFO - Epoch:[24/805] Step:[50/90] reconstruction_loss: 1.26 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:56:31,094 - INFO - Epoch:[24/805] Step:[60/90] reconstruction_loss: 1.25 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:56:34,486 - INFO - Epoch:[24/805] Step:[70/90] reconstruction_loss: 1.26 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:56:37,781 - INFO - Epoch:[24/805] Step:[80/90] reconstruction_loss: 1.25 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 11:56:40,832 - INFO - Epoch:[24/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.40 loss_cvh: 0.00
2025-03-02 11:56:41,715 - INFO - now the learning rate is: 9e-05
2025-03-02 11:56:41,715 - INFO - begin training stage: [25/805]
2025-03-02 11:56:41,715 - INFO - begin training stage: [25/805]
2025-03-02 11:56:46,079 - INFO - Epoch:[25/805] Step:[10/90] reconstruction_loss: 1.27 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:56:49,580 - INFO - Epoch:[25/805] Step:[20/90] reconstruction_loss: 1.23 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:56:53,048 - INFO - Epoch:[25/805] Step:[30/90] reconstruction_loss: 1.27 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:56:56,385 - INFO - Epoch:[25/805] Step:[40/90] reconstruction_loss: 1.24 loss_vc: 4.64 loss_cvh: 0.00
2025-03-02 11:56:59,816 - INFO - Epoch:[25/805] Step:[50/90] reconstruction_loss: 1.26 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:57:03,347 - INFO - Epoch:[25/805] Step:[60/90] reconstruction_loss: 1.24 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:57:08,547 - INFO - Epoch:[25/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 11:57:13,332 - INFO - Epoch:[25/805] Step:[80/90] reconstruction_loss: 1.25 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:57:17,493 - INFO - Epoch:[25/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.24 loss_cvh: 0.00
2025-03-02 11:57:18,751 - INFO - now the learning rate is: 9e-05
2025-03-02 11:57:18,751 - INFO - begin training stage: [26/805]
2025-03-02 11:57:18,751 - INFO - begin training stage: [26/805]
2025-03-02 11:57:24,667 - INFO - Epoch:[26/805] Step:[10/90] reconstruction_loss: 1.26 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:57:29,280 - INFO - Epoch:[26/805] Step:[20/90] reconstruction_loss: 1.23 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:57:34,332 - INFO - Epoch:[26/805] Step:[30/90] reconstruction_loss: 1.25 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:57:39,233 - INFO - Epoch:[26/805] Step:[40/90] reconstruction_loss: 1.25 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:57:43,831 - INFO - Epoch:[26/805] Step:[50/90] reconstruction_loss: 1.25 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:57:48,745 - INFO - Epoch:[26/805] Step:[60/90] reconstruction_loss: 1.27 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:57:53,239 - INFO - Epoch:[26/805] Step:[70/90] reconstruction_loss: 1.26 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 11:57:58,146 - INFO - Epoch:[26/805] Step:[80/90] reconstruction_loss: 1.23 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:58:02,797 - INFO - Epoch:[26/805] Step:[90/90] reconstruction_loss: 1.44 loss_vc: 1.29 loss_cvh: 0.00
2025-03-02 11:58:03,991 - INFO - now the learning rate is: 9e-05
2025-03-02 11:58:03,992 - INFO - begin training stage: [27/805]
2025-03-02 11:58:03,992 - INFO - begin training stage: [27/805]
2025-03-02 11:58:09,876 - INFO - Epoch:[27/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:58:14,596 - INFO - Epoch:[27/805] Step:[20/90] reconstruction_loss: 1.23 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:58:19,632 - INFO - Epoch:[27/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:58:24,628 - INFO - Epoch:[27/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:58:29,526 - INFO - Epoch:[27/805] Step:[50/90] reconstruction_loss: 1.26 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:58:32,968 - INFO - Epoch:[27/805] Step:[60/90] reconstruction_loss: 1.24 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:58:36,446 - INFO - Epoch:[27/805] Step:[70/90] reconstruction_loss: 1.25 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 11:58:39,834 - INFO - Epoch:[27/805] Step:[80/90] reconstruction_loss: 1.23 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 11:58:43,054 - INFO - Epoch:[27/805] Step:[90/90] reconstruction_loss: 1.28 loss_vc: 1.44 loss_cvh: 0.00
2025-03-02 11:58:43,931 - INFO - now the learning rate is: 9e-05
2025-03-02 11:58:43,932 - INFO - begin training stage: [28/805]
2025-03-02 11:58:43,932 - INFO - begin training stage: [28/805]
2025-03-02 11:58:48,523 - INFO - Epoch:[28/805] Step:[10/90] reconstruction_loss: 1.24 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:58:51,832 - INFO - Epoch:[28/805] Step:[20/90] reconstruction_loss: 1.24 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:58:55,245 - INFO - Epoch:[28/805] Step:[30/90] reconstruction_loss: 1.24 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:58:58,712 - INFO - Epoch:[28/805] Step:[40/90] reconstruction_loss: 1.24 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:59:02,125 - INFO - Epoch:[28/805] Step:[50/90] reconstruction_loss: 1.26 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 11:59:05,592 - INFO - Epoch:[28/805] Step:[60/90] reconstruction_loss: 1.23 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:59:08,897 - INFO - Epoch:[28/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 11:59:12,286 - INFO - Epoch:[28/805] Step:[80/90] reconstruction_loss: 1.24 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 11:59:15,318 - INFO - Epoch:[28/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.44 loss_cvh: 0.00
2025-03-02 11:59:16,144 - INFO - now the learning rate is: 9e-05
2025-03-02 11:59:16,144 - INFO - begin training stage: [29/805]
2025-03-02 11:59:16,144 - INFO - begin training stage: [29/805]
2025-03-02 11:59:20,259 - INFO - Epoch:[29/805] Step:[10/90] reconstruction_loss: 1.24 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 11:59:23,468 - INFO - Epoch:[29/805] Step:[20/90] reconstruction_loss: 1.24 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 11:59:26,696 - INFO - Epoch:[29/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:59:30,014 - INFO - Epoch:[29/805] Step:[40/90] reconstruction_loss: 1.25 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:59:33,507 - INFO - Epoch:[29/805] Step:[50/90] reconstruction_loss: 1.23 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 11:59:36,972 - INFO - Epoch:[29/805] Step:[60/90] reconstruction_loss: 1.23 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 11:59:40,511 - INFO - Epoch:[29/805] Step:[70/90] reconstruction_loss: 1.25 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 11:59:43,908 - INFO - Epoch:[29/805] Step:[80/90] reconstruction_loss: 1.24 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 11:59:47,190 - INFO - Epoch:[29/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.57 loss_cvh: 0.00
2025-03-02 11:59:48,424 - INFO - now the learning rate is: 9e-05
2025-03-02 11:59:48,425 - INFO - begin training stage: [30/805]
2025-03-02 11:59:48,425 - INFO - begin training stage: [30/805]
2025-03-02 11:59:53,924 - INFO - Epoch:[30/805] Step:[10/90] reconstruction_loss: 1.26 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 11:59:58,666 - INFO - Epoch:[30/805] Step:[20/90] reconstruction_loss: 1.28 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:00:03,323 - INFO - Epoch:[30/805] Step:[30/90] reconstruction_loss: 1.27 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:00:08,005 - INFO - Epoch:[30/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 12:00:12,562 - INFO - Epoch:[30/805] Step:[50/90] reconstruction_loss: 1.23 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:00:17,313 - INFO - Epoch:[30/805] Step:[60/90] reconstruction_loss: 1.24 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:00:21,879 - INFO - Epoch:[30/805] Step:[70/90] reconstruction_loss: 1.26 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:00:26,502 - INFO - Epoch:[30/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:00:30,629 - INFO - Epoch:[30/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.43 loss_cvh: 0.00
2025-03-02 12:00:31,831 - INFO - now the learning rate is: 9e-05
2025-03-02 12:00:31,832 - INFO - begin training stage: [31/805]
2025-03-02 12:00:31,833 - INFO - eval data number: 45600
2025-03-02 12:00:31,833 - INFO - loading eval data ......
2025-03-02 12:01:10,836 - INFO - retrieval costs: 25.34167170524597
2025-03-02 12:02:29,523 - INFO - hamming distance computation costs: 78.68708777427673
2025-03-02 12:02:36,237 - INFO - hamming ranking costs: 6.713737487792969
2025-03-02 12:02:36,237 - INFO - labels shape: (45600, 239)
2025-03-02 12:03:13,066 - INFO - similarity labels generation costs: 36.82895112037659
2025-03-02 12:03:13,143 - INFO - topK: 5:, map: 0.22508666666666668
2025-03-02 12:03:13,406 - INFO - topK: 20:, map: 0.14177412943990778
2025-03-02 12:03:13,913 - INFO - topK: 40:, map: 0.11817823567567416
2025-03-02 12:03:14,728 - INFO - topK: 60:, map: 0.10647550314444076
2025-03-02 12:03:15,804 - INFO - topK: 80:, map: 0.09867370631547931
2025-03-02 12:03:17,058 - INFO - topK: 100:, map: 0.09262594062487081
2025-03-02 12:03:18,102 - INFO - begin training stage: [31/805]
2025-03-02 12:03:22,531 - INFO - Epoch:[31/805] Step:[10/90] reconstruction_loss: 1.25 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 12:03:26,006 - INFO - Epoch:[31/805] Step:[20/90] reconstruction_loss: 1.24 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:03:29,477 - INFO - Epoch:[31/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:03:32,863 - INFO - Epoch:[31/805] Step:[40/90] reconstruction_loss: 1.26 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:03:36,146 - INFO - Epoch:[31/805] Step:[50/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:03:39,514 - INFO - Epoch:[31/805] Step:[60/90] reconstruction_loss: 1.25 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:03:42,929 - INFO - Epoch:[31/805] Step:[70/90] reconstruction_loss: 1.25 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 12:03:46,410 - INFO - Epoch:[31/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:03:49,576 - INFO - Epoch:[31/805] Step:[90/90] reconstruction_loss: 1.28 loss_vc: 1.47 loss_cvh: 0.00
2025-03-02 12:03:50,452 - INFO - now the learning rate is: 9e-05
2025-03-02 12:03:50,453 - INFO - begin training stage: [32/805]
2025-03-02 12:03:50,453 - INFO - begin training stage: [32/805]
2025-03-02 12:03:54,754 - INFO - Epoch:[32/805] Step:[10/90] reconstruction_loss: 1.23 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:03:58,056 - INFO - Epoch:[32/805] Step:[20/90] reconstruction_loss: 1.28 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:04:01,529 - INFO - Epoch:[32/805] Step:[30/90] reconstruction_loss: 1.27 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:04:05,110 - INFO - Epoch:[32/805] Step:[40/90] reconstruction_loss: 1.24 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:04:08,515 - INFO - Epoch:[32/805] Step:[50/90] reconstruction_loss: 1.26 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:04:11,873 - INFO - Epoch:[32/805] Step:[60/90] reconstruction_loss: 1.24 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 12:04:15,396 - INFO - Epoch:[32/805] Step:[70/90] reconstruction_loss: 1.25 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:04:18,763 - INFO - Epoch:[32/805] Step:[80/90] reconstruction_loss: 1.24 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:04:22,046 - INFO - Epoch:[32/805] Step:[90/90] reconstruction_loss: 1.42 loss_vc: 1.51 loss_cvh: 0.00
2025-03-02 12:04:22,948 - INFO - now the learning rate is: 9e-05
2025-03-02 12:04:22,949 - INFO - begin training stage: [33/805]
2025-03-02 12:04:22,949 - INFO - begin training stage: [33/805]
2025-03-02 12:04:27,179 - INFO - Epoch:[33/805] Step:[10/90] reconstruction_loss: 1.25 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:04:30,655 - INFO - Epoch:[33/805] Step:[20/90] reconstruction_loss: 1.24 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:04:34,026 - INFO - Epoch:[33/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:04:37,470 - INFO - Epoch:[33/805] Step:[40/90] reconstruction_loss: 1.25 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:04:41,107 - INFO - Epoch:[33/805] Step:[50/90] reconstruction_loss: 1.24 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:04:44,586 - INFO - Epoch:[33/805] Step:[60/90] reconstruction_loss: 1.22 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:04:47,980 - INFO - Epoch:[33/805] Step:[70/90] reconstruction_loss: 1.25 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:04:51,398 - INFO - Epoch:[33/805] Step:[80/90] reconstruction_loss: 1.25 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:04:54,488 - INFO - Epoch:[33/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.34 loss_cvh: 0.00
2025-03-02 12:04:55,356 - INFO - now the learning rate is: 9e-05
2025-03-02 12:04:55,356 - INFO - begin training stage: [34/805]
2025-03-02 12:04:55,357 - INFO - begin training stage: [34/805]
2025-03-02 12:04:59,803 - INFO - Epoch:[34/805] Step:[10/90] reconstruction_loss: 1.27 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 12:05:03,287 - INFO - Epoch:[34/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:05:06,720 - INFO - Epoch:[34/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:05:10,126 - INFO - Epoch:[34/805] Step:[40/90] reconstruction_loss: 1.25 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:05:13,645 - INFO - Epoch:[34/805] Step:[50/90] reconstruction_loss: 1.23 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:05:17,117 - INFO - Epoch:[34/805] Step:[60/90] reconstruction_loss: 1.23 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:05:20,681 - INFO - Epoch:[34/805] Step:[70/90] reconstruction_loss: 1.24 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:05:24,034 - INFO - Epoch:[34/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:05:27,120 - INFO - Epoch:[34/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.40 loss_cvh: 0.00
2025-03-02 12:05:27,984 - INFO - now the learning rate is: 9e-05
2025-03-02 12:05:27,985 - INFO - begin training stage: [35/805]
2025-03-02 12:05:27,985 - INFO - begin training stage: [35/805]
2025-03-02 12:05:32,215 - INFO - Epoch:[35/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:05:35,891 - INFO - Epoch:[35/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:05:39,493 - INFO - Epoch:[35/805] Step:[30/90] reconstruction_loss: 1.26 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:05:42,995 - INFO - Epoch:[35/805] Step:[40/90] reconstruction_loss: 1.26 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:05:46,471 - INFO - Epoch:[35/805] Step:[50/90] reconstruction_loss: 1.23 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:05:49,896 - INFO - Epoch:[35/805] Step:[60/90] reconstruction_loss: 1.22 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:05:53,459 - INFO - Epoch:[35/805] Step:[70/90] reconstruction_loss: 1.24 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:05:57,728 - INFO - Epoch:[35/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:06:02,271 - INFO - Epoch:[35/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.44 loss_cvh: 0.00
2025-03-02 12:06:03,961 - INFO - now the learning rate is: 9e-05
2025-03-02 12:06:03,962 - INFO - begin training stage: [36/805]
2025-03-02 12:06:03,962 - INFO - begin training stage: [36/805]
2025-03-02 12:06:10,140 - INFO - Epoch:[36/805] Step:[10/90] reconstruction_loss: 1.24 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:06:15,178 - INFO - Epoch:[36/805] Step:[20/90] reconstruction_loss: 1.25 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:06:20,157 - INFO - Epoch:[36/805] Step:[30/90] reconstruction_loss: 1.26 loss_vc: 4.61 loss_cvh: 0.00
2025-03-02 12:06:25,153 - INFO - Epoch:[36/805] Step:[40/90] reconstruction_loss: 1.25 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:06:29,835 - INFO - Epoch:[36/805] Step:[50/90] reconstruction_loss: 1.23 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:06:34,500 - INFO - Epoch:[36/805] Step:[60/90] reconstruction_loss: 1.23 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:06:39,659 - INFO - Epoch:[36/805] Step:[70/90] reconstruction_loss: 1.22 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:06:44,569 - INFO - Epoch:[36/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:06:49,035 - INFO - Epoch:[36/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.52 loss_cvh: 0.00
2025-03-02 12:06:50,243 - INFO - now the learning rate is: 9e-05
2025-03-02 12:06:50,243 - INFO - begin training stage: [37/805]
2025-03-02 12:06:50,243 - INFO - begin training stage: [37/805]
2025-03-02 12:06:56,417 - INFO - Epoch:[37/805] Step:[10/90] reconstruction_loss: 1.24 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:07:00,867 - INFO - Epoch:[37/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 12:07:05,771 - INFO - Epoch:[37/805] Step:[30/90] reconstruction_loss: 1.25 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:07:10,696 - INFO - Epoch:[37/805] Step:[40/90] reconstruction_loss: 1.26 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:07:15,523 - INFO - Epoch:[37/805] Step:[50/90] reconstruction_loss: 1.22 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:07:19,925 - INFO - Epoch:[37/805] Step:[60/90] reconstruction_loss: 1.24 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:07:23,353 - INFO - Epoch:[37/805] Step:[70/90] reconstruction_loss: 1.26 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:07:26,894 - INFO - Epoch:[37/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:07:30,175 - INFO - Epoch:[37/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.39 loss_cvh: 0.00
2025-03-02 12:07:31,075 - INFO - now the learning rate is: 9e-05
2025-03-02 12:07:31,075 - INFO - begin training stage: [38/805]
2025-03-02 12:07:31,075 - INFO - begin training stage: [38/805]
2025-03-02 12:07:35,399 - INFO - Epoch:[38/805] Step:[10/90] reconstruction_loss: 1.27 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:07:38,810 - INFO - Epoch:[38/805] Step:[20/90] reconstruction_loss: 1.23 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:07:42,352 - INFO - Epoch:[38/805] Step:[30/90] reconstruction_loss: 1.25 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:07:45,824 - INFO - Epoch:[38/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:07:49,329 - INFO - Epoch:[38/805] Step:[50/90] reconstruction_loss: 1.24 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:07:52,720 - INFO - Epoch:[38/805] Step:[60/90] reconstruction_loss: 1.22 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:07:56,101 - INFO - Epoch:[38/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:07:59,490 - INFO - Epoch:[38/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:08:02,641 - INFO - Epoch:[38/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.12 loss_cvh: 0.00
2025-03-02 12:08:03,558 - INFO - now the learning rate is: 9e-05
2025-03-02 12:08:03,558 - INFO - begin training stage: [39/805]
2025-03-02 12:08:03,559 - INFO - begin training stage: [39/805]
2025-03-02 12:08:09,693 - INFO - Epoch:[39/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:08:14,251 - INFO - Epoch:[39/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:08:17,777 - INFO - Epoch:[39/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:08:21,081 - INFO - Epoch:[39/805] Step:[40/90] reconstruction_loss: 1.26 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:08:24,611 - INFO - Epoch:[39/805] Step:[50/90] reconstruction_loss: 1.25 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:08:29,697 - INFO - Epoch:[39/805] Step:[60/90] reconstruction_loss: 1.23 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 12:08:33,511 - INFO - Epoch:[39/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:08:37,913 - INFO - Epoch:[39/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:08:42,747 - INFO - Epoch:[39/805] Step:[90/90] reconstruction_loss: 1.30 loss_vc: 1.36 loss_cvh: 0.00
2025-03-02 12:08:44,045 - INFO - now the learning rate is: 9e-05
2025-03-02 12:08:44,046 - INFO - begin training stage: [40/805]
2025-03-02 12:08:44,046 - INFO - begin training stage: [40/805]
2025-03-02 12:08:49,716 - INFO - Epoch:[40/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.60 loss_cvh: 0.00
2025-03-02 12:08:54,812 - INFO - Epoch:[40/805] Step:[20/90] reconstruction_loss: 1.24 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:08:59,852 - INFO - Epoch:[40/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:09:04,556 - INFO - Epoch:[40/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:09:09,315 - INFO - Epoch:[40/805] Step:[50/90] reconstruction_loss: 1.22 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:09:14,013 - INFO - Epoch:[40/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:09:18,504 - INFO - Epoch:[40/805] Step:[70/90] reconstruction_loss: 1.22 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:09:23,135 - INFO - Epoch:[40/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:09:27,465 - INFO - Epoch:[40/805] Step:[90/90] reconstruction_loss: 1.36 loss_vc: 1.45 loss_cvh: 0.00
2025-03-02 12:09:28,903 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:09:28,903 - INFO - begin training stage: [41/805]
2025-03-02 12:09:28,904 - INFO - eval data number: 45600
2025-03-02 12:09:28,904 - INFO - loading eval data ......
2025-03-02 12:10:09,202 - INFO - retrieval costs: 26.447993993759155
2025-03-02 12:11:28,854 - INFO - hamming distance computation costs: 79.65196204185486
2025-03-02 12:11:35,214 - INFO - hamming ranking costs: 6.359962224960327
2025-03-02 12:11:35,214 - INFO - labels shape: (45600, 239)
2025-03-02 12:12:12,744 - INFO - similarity labels generation costs: 37.53003287315369
2025-03-02 12:12:12,819 - INFO - topK: 5:, map: 0.23777416666666668
2025-03-02 12:12:13,086 - INFO - topK: 20:, map: 0.1543565766738851
2025-03-02 12:12:13,613 - INFO - topK: 40:, map: 0.12900784150125089
2025-03-02 12:12:14,400 - INFO - topK: 60:, map: 0.11685930179657274
2025-03-02 12:12:15,429 - INFO - topK: 80:, map: 0.10763251991485139
2025-03-02 12:12:16,713 - INFO - topK: 100:, map: 0.10062885146734378
2025-03-02 12:12:17,828 - INFO - begin training stage: [41/805]
2025-03-02 12:12:22,533 - INFO - Epoch:[41/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:12:26,306 - INFO - Epoch:[41/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:12:29,910 - INFO - Epoch:[41/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:12:33,576 - INFO - Epoch:[41/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:12:37,288 - INFO - Epoch:[41/805] Step:[50/90] reconstruction_loss: 1.24 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:12:40,897 - INFO - Epoch:[41/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:12:44,574 - INFO - Epoch:[41/805] Step:[70/90] reconstruction_loss: 1.24 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:12:48,169 - INFO - Epoch:[41/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:12:51,726 - INFO - Epoch:[41/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.44 loss_cvh: 0.00
2025-03-02 12:12:52,722 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:12:52,722 - INFO - begin training stage: [42/805]
2025-03-02 12:12:52,722 - INFO - begin training stage: [42/805]
2025-03-02 12:12:58,206 - INFO - Epoch:[42/805] Step:[10/90] reconstruction_loss: 1.23 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:13:02,906 - INFO - Epoch:[42/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:13:07,318 - INFO - Epoch:[42/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:13:11,779 - INFO - Epoch:[42/805] Step:[40/90] reconstruction_loss: 1.22 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:13:16,187 - INFO - Epoch:[42/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:13:20,632 - INFO - Epoch:[42/805] Step:[60/90] reconstruction_loss: 1.24 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:13:24,875 - INFO - Epoch:[42/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:13:29,111 - INFO - Epoch:[42/805] Step:[80/90] reconstruction_loss: 1.23 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:13:32,954 - INFO - Epoch:[42/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.31 loss_cvh: 0.00
2025-03-02 12:13:33,866 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:13:33,866 - INFO - begin training stage: [43/805]
2025-03-02 12:13:33,867 - INFO - begin training stage: [43/805]
2025-03-02 12:13:38,147 - INFO - Epoch:[43/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:13:41,641 - INFO - Epoch:[43/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:13:44,861 - INFO - Epoch:[43/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:13:48,083 - INFO - Epoch:[43/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:13:51,430 - INFO - Epoch:[43/805] Step:[50/90] reconstruction_loss: 1.23 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:13:54,813 - INFO - Epoch:[43/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:13:58,594 - INFO - Epoch:[43/805] Step:[70/90] reconstruction_loss: 1.24 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:14:02,048 - INFO - Epoch:[43/805] Step:[80/90] reconstruction_loss: 1.25 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:14:05,126 - INFO - Epoch:[43/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.42 loss_cvh: 0.00
2025-03-02 12:14:06,100 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:14:06,100 - INFO - begin training stage: [44/805]
2025-03-02 12:14:06,100 - INFO - begin training stage: [44/805]
2025-03-02 12:14:12,021 - INFO - Epoch:[44/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:14:16,506 - INFO - Epoch:[44/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:14:20,898 - INFO - Epoch:[44/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:14:25,332 - INFO - Epoch:[44/805] Step:[40/90] reconstruction_loss: 1.24 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:14:29,672 - INFO - Epoch:[44/805] Step:[50/90] reconstruction_loss: 1.22 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:14:34,183 - INFO - Epoch:[44/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:14:38,646 - INFO - Epoch:[44/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:14:43,703 - INFO - Epoch:[44/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:14:48,033 - INFO - Epoch:[44/805] Step:[90/90] reconstruction_loss: 1.44 loss_vc: 1.25 loss_cvh: 0.00
2025-03-02 12:14:49,290 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:14:49,291 - INFO - begin training stage: [45/805]
2025-03-02 12:14:49,291 - INFO - begin training stage: [45/805]
2025-03-02 12:14:54,700 - INFO - Epoch:[45/805] Step:[10/90] reconstruction_loss: 1.25 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:14:59,399 - INFO - Epoch:[45/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:15:04,083 - INFO - Epoch:[45/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:15:08,688 - INFO - Epoch:[45/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:15:13,396 - INFO - Epoch:[45/805] Step:[50/90] reconstruction_loss: 1.22 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:15:18,179 - INFO - Epoch:[45/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:15:22,897 - INFO - Epoch:[45/805] Step:[70/90] reconstruction_loss: 1.22 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:15:27,389 - INFO - Epoch:[45/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:15:31,541 - INFO - Epoch:[45/805] Step:[90/90] reconstruction_loss: 1.30 loss_vc: 1.27 loss_cvh: 0.00
2025-03-02 12:15:33,128 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:15:33,129 - INFO - begin training stage: [46/805]
2025-03-02 12:15:33,129 - INFO - begin training stage: [46/805]
2025-03-02 12:15:39,056 - INFO - Epoch:[46/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:15:43,644 - INFO - Epoch:[46/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:15:48,309 - INFO - Epoch:[46/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:15:52,891 - INFO - Epoch:[46/805] Step:[40/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:15:57,696 - INFO - Epoch:[46/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:16:02,352 - INFO - Epoch:[46/805] Step:[60/90] reconstruction_loss: 1.24 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:16:06,822 - INFO - Epoch:[46/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:16:11,612 - INFO - Epoch:[46/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:16:16,044 - INFO - Epoch:[46/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.45 loss_cvh: 0.00
2025-03-02 12:16:17,547 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:16:17,547 - INFO - begin training stage: [47/805]
2025-03-02 12:16:17,547 - INFO - begin training stage: [47/805]
2025-03-02 12:16:22,676 - INFO - Epoch:[47/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:16:26,034 - INFO - Epoch:[47/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:16:29,520 - INFO - Epoch:[47/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:16:33,062 - INFO - Epoch:[47/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:16:36,550 - INFO - Epoch:[47/805] Step:[50/90] reconstruction_loss: 1.23 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:16:40,088 - INFO - Epoch:[47/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:16:43,455 - INFO - Epoch:[47/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:16:47,073 - INFO - Epoch:[47/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:16:50,354 - INFO - Epoch:[47/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.33 loss_cvh: 0.00
2025-03-02 12:16:51,654 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:16:51,655 - INFO - begin training stage: [48/805]
2025-03-02 12:16:51,655 - INFO - begin training stage: [48/805]
2025-03-02 12:16:56,106 - INFO - Epoch:[48/805] Step:[10/90] reconstruction_loss: 1.24 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:16:59,566 - INFO - Epoch:[48/805] Step:[20/90] reconstruction_loss: 1.24 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:17:03,027 - INFO - Epoch:[48/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:17:06,376 - INFO - Epoch:[48/805] Step:[40/90] reconstruction_loss: 1.22 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:17:09,846 - INFO - Epoch:[48/805] Step:[50/90] reconstruction_loss: 1.23 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:17:13,270 - INFO - Epoch:[48/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:17:16,542 - INFO - Epoch:[48/805] Step:[70/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:17:19,957 - INFO - Epoch:[48/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:17:23,154 - INFO - Epoch:[48/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.26 loss_cvh: 0.00
2025-03-02 12:17:24,208 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:17:24,209 - INFO - begin training stage: [49/805]
2025-03-02 12:17:24,209 - INFO - begin training stage: [49/805]
2025-03-02 12:17:28,665 - INFO - Epoch:[49/805] Step:[10/90] reconstruction_loss: 1.23 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:17:31,898 - INFO - Epoch:[49/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:17:35,124 - INFO - Epoch:[49/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:17:38,198 - INFO - Epoch:[49/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:17:41,267 - INFO - Epoch:[49/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:17:44,335 - INFO - Epoch:[49/805] Step:[60/90] reconstruction_loss: 1.24 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:17:47,646 - INFO - Epoch:[49/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:17:51,006 - INFO - Epoch:[49/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:17:54,057 - INFO - Epoch:[49/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.37 loss_cvh: 0.00
2025-03-02 12:17:55,125 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:17:55,125 - INFO - begin training stage: [50/805]
2025-03-02 12:17:55,125 - INFO - begin training stage: [50/805]
2025-03-02 12:17:59,351 - INFO - Epoch:[50/805] Step:[10/90] reconstruction_loss: 1.23 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:18:02,524 - INFO - Epoch:[50/805] Step:[20/90] reconstruction_loss: 1.23 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:18:06,125 - INFO - Epoch:[50/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:18:10,363 - INFO - Epoch:[50/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:18:14,624 - INFO - Epoch:[50/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:18:18,900 - INFO - Epoch:[50/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:18:23,121 - INFO - Epoch:[50/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:18:27,308 - INFO - Epoch:[50/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:18:31,449 - INFO - Epoch:[50/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.47 loss_cvh: 0.00
2025-03-02 12:18:33,019 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:18:33,019 - INFO - begin training stage: [51/805]
2025-03-02 12:18:33,020 - INFO - eval data number: 45600
2025-03-02 12:18:33,020 - INFO - loading eval data ......
2025-03-02 12:19:13,765 - INFO - retrieval costs: 26.60629367828369
2025-03-02 12:20:49,397 - INFO - hamming distance computation costs: 95.6320915222168
2025-03-02 12:20:55,246 - INFO - hamming ranking costs: 5.84835958480835
2025-03-02 12:20:55,246 - INFO - labels shape: (45600, 239)
2025-03-02 12:21:32,432 - INFO - similarity labels generation costs: 37.18633556365967
2025-03-02 12:21:32,506 - INFO - topK: 5:, map: 0.24930916666666667
2025-03-02 12:21:32,764 - INFO - topK: 20:, map: 0.16440480621787268
2025-03-02 12:21:33,268 - INFO - topK: 40:, map: 0.13765897242038624
2025-03-02 12:21:34,028 - INFO - topK: 60:, map: 0.12346397475926184
2025-03-02 12:21:35,036 - INFO - topK: 80:, map: 0.11378128042146766
2025-03-02 12:21:36,351 - INFO - topK: 100:, map: 0.10683676448920576
2025-03-02 12:21:37,573 - INFO - begin training stage: [51/805]
2025-03-02 12:21:42,847 - INFO - Epoch:[51/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:21:47,014 - INFO - Epoch:[51/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.58 loss_cvh: 0.00
2025-03-02 12:21:51,010 - INFO - Epoch:[51/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:21:55,077 - INFO - Epoch:[51/805] Step:[40/90] reconstruction_loss: 1.24 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:21:59,163 - INFO - Epoch:[51/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:22:03,421 - INFO - Epoch:[51/805] Step:[60/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:22:07,469 - INFO - Epoch:[51/805] Step:[70/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:22:11,492 - INFO - Epoch:[51/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:22:14,991 - INFO - Epoch:[51/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.35 loss_cvh: 0.00
2025-03-02 12:22:16,146 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:22:16,147 - INFO - begin training stage: [52/805]
2025-03-02 12:22:16,147 - INFO - begin training stage: [52/805]
2025-03-02 12:22:20,914 - INFO - Epoch:[52/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:22:24,887 - INFO - Epoch:[52/805] Step:[20/90] reconstruction_loss: 1.23 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:22:28,784 - INFO - Epoch:[52/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:22:32,798 - INFO - Epoch:[52/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:22:36,662 - INFO - Epoch:[52/805] Step:[50/90] reconstruction_loss: 1.23 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:22:40,519 - INFO - Epoch:[52/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:22:44,369 - INFO - Epoch:[52/805] Step:[70/90] reconstruction_loss: 1.25 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:22:48,134 - INFO - Epoch:[52/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:22:51,747 - INFO - Epoch:[52/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.23 loss_cvh: 0.00
2025-03-02 12:22:52,795 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:22:52,795 - INFO - begin training stage: [53/805]
2025-03-02 12:22:52,796 - INFO - begin training stage: [53/805]
2025-03-02 12:22:58,645 - INFO - Epoch:[53/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:23:03,111 - INFO - Epoch:[53/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:23:07,592 - INFO - Epoch:[53/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:23:12,112 - INFO - Epoch:[53/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:23:16,354 - INFO - Epoch:[53/805] Step:[50/90] reconstruction_loss: 1.25 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:23:20,404 - INFO - Epoch:[53/805] Step:[60/90] reconstruction_loss: 1.22 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:23:24,929 - INFO - Epoch:[53/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:23:29,367 - INFO - Epoch:[53/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:23:32,973 - INFO - Epoch:[53/805] Step:[90/90] reconstruction_loss: 1.42 loss_vc: 1.33 loss_cvh: 0.00
2025-03-02 12:23:34,103 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:23:34,103 - INFO - begin training stage: [54/805]
2025-03-02 12:23:34,103 - INFO - begin training stage: [54/805]
2025-03-02 12:23:39,161 - INFO - Epoch:[54/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:23:42,826 - INFO - Epoch:[54/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:23:46,732 - INFO - Epoch:[54/805] Step:[30/90] reconstruction_loss: 1.24 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:23:50,712 - INFO - Epoch:[54/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:23:55,368 - INFO - Epoch:[54/805] Step:[50/90] reconstruction_loss: 1.22 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:23:58,896 - INFO - Epoch:[54/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:24:02,246 - INFO - Epoch:[54/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.59 loss_cvh: 0.00
2025-03-02 12:24:05,896 - INFO - Epoch:[54/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:24:10,053 - INFO - Epoch:[54/805] Step:[90/90] reconstruction_loss: 1.30 loss_vc: 1.32 loss_cvh: 0.00
2025-03-02 12:24:11,762 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:24:11,763 - INFO - begin training stage: [55/805]
2025-03-02 12:24:11,763 - INFO - begin training stage: [55/805]
2025-03-02 12:24:18,796 - INFO - Epoch:[55/805] Step:[10/90] reconstruction_loss: 1.23 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:24:24,380 - INFO - Epoch:[55/805] Step:[20/90] reconstruction_loss: 1.24 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:24:30,302 - INFO - Epoch:[55/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:24:35,652 - INFO - Epoch:[55/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:24:41,380 - INFO - Epoch:[55/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:24:47,147 - INFO - Epoch:[55/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:24:52,909 - INFO - Epoch:[55/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:24:58,272 - INFO - Epoch:[55/805] Step:[80/90] reconstruction_loss: 1.23 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:25:03,045 - INFO - Epoch:[55/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.50 loss_cvh: 0.00
2025-03-02 12:25:04,952 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:25:04,952 - INFO - begin training stage: [56/805]
2025-03-02 12:25:04,953 - INFO - begin training stage: [56/805]
2025-03-02 12:25:11,133 - INFO - Epoch:[56/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:25:15,740 - INFO - Epoch:[56/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:25:20,267 - INFO - Epoch:[56/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:25:24,704 - INFO - Epoch:[56/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:25:29,525 - INFO - Epoch:[56/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:25:33,832 - INFO - Epoch:[56/805] Step:[60/90] reconstruction_loss: 1.23 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:25:37,650 - INFO - Epoch:[56/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:25:40,911 - INFO - Epoch:[56/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:25:43,871 - INFO - Epoch:[56/805] Step:[90/90] reconstruction_loss: 1.29 loss_vc: 1.31 loss_cvh: 0.00
2025-03-02 12:25:44,883 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:25:44,884 - INFO - begin training stage: [57/805]
2025-03-02 12:25:44,884 - INFO - begin training stage: [57/805]
2025-03-02 12:25:49,002 - INFO - Epoch:[57/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:25:52,191 - INFO - Epoch:[57/805] Step:[20/90] reconstruction_loss: 1.26 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:25:55,410 - INFO - Epoch:[57/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:25:58,561 - INFO - Epoch:[57/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:26:01,751 - INFO - Epoch:[57/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:26:04,829 - INFO - Epoch:[57/805] Step:[60/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:26:08,069 - INFO - Epoch:[57/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:26:11,231 - INFO - Epoch:[57/805] Step:[80/90] reconstruction_loss: 1.23 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:26:14,077 - INFO - Epoch:[57/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.15 loss_cvh: 0.00
2025-03-02 12:26:15,116 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:26:15,117 - INFO - begin training stage: [58/805]
2025-03-02 12:26:15,117 - INFO - begin training stage: [58/805]
2025-03-02 12:26:19,421 - INFO - Epoch:[58/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:26:22,629 - INFO - Epoch:[58/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:26:25,884 - INFO - Epoch:[58/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:26:28,985 - INFO - Epoch:[58/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:26:32,165 - INFO - Epoch:[58/805] Step:[50/90] reconstruction_loss: 1.22 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:26:35,428 - INFO - Epoch:[58/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:26:38,721 - INFO - Epoch:[58/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:26:41,882 - INFO - Epoch:[58/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:26:44,956 - INFO - Epoch:[58/805] Step:[90/90] reconstruction_loss: 1.35 loss_vc: 1.37 loss_cvh: 0.00
2025-03-02 12:26:46,068 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:26:46,069 - INFO - begin training stage: [59/805]
2025-03-02 12:26:46,069 - INFO - begin training stage: [59/805]
2025-03-02 12:26:50,548 - INFO - Epoch:[59/805] Step:[10/90] reconstruction_loss: 1.24 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:26:54,012 - INFO - Epoch:[59/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:26:57,356 - INFO - Epoch:[59/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:27:00,664 - INFO - Epoch:[59/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:27:03,915 - INFO - Epoch:[59/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:27:07,264 - INFO - Epoch:[59/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:27:10,572 - INFO - Epoch:[59/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:27:13,690 - INFO - Epoch:[59/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:27:16,657 - INFO - Epoch:[59/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.43 loss_cvh: 0.00
2025-03-02 12:27:17,778 - INFO - now the learning rate is: 8.1e-05
2025-03-02 12:27:17,778 - INFO - begin training stage: [60/805]
2025-03-02 12:27:17,778 - INFO - begin training stage: [60/805]
2025-03-02 12:27:21,870 - INFO - Epoch:[60/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:27:25,117 - INFO - Epoch:[60/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:27:28,435 - INFO - Epoch:[60/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:27:31,842 - INFO - Epoch:[60/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:27:35,151 - INFO - Epoch:[60/805] Step:[50/90] reconstruction_loss: 1.24 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:27:38,548 - INFO - Epoch:[60/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:27:41,825 - INFO - Epoch:[60/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:27:45,707 - INFO - Epoch:[60/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:27:49,550 - INFO - Epoch:[60/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.27 loss_cvh: 0.00
2025-03-02 12:27:51,118 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:27:51,119 - INFO - begin training stage: [61/805]
2025-03-02 12:27:51,120 - INFO - eval data number: 45600
2025-03-02 12:27:51,120 - INFO - loading eval data ......
2025-03-02 12:28:32,221 - INFO - retrieval costs: 27.069258451461792
2025-03-02 12:30:26,481 - INFO - hamming distance computation costs: 114.26048135757446
2025-03-02 12:30:32,640 - INFO - hamming ranking costs: 6.158473491668701
2025-03-02 12:30:32,640 - INFO - labels shape: (45600, 239)
2025-03-02 12:31:09,544 - INFO - similarity labels generation costs: 36.904585123062134
2025-03-02 12:31:09,620 - INFO - topK: 5:, map: 0.25703666666666664
2025-03-02 12:31:09,910 - INFO - topK: 20:, map: 0.17331134154464597
2025-03-02 12:31:10,630 - INFO - topK: 40:, map: 0.14700661933083786
2025-03-02 12:31:11,405 - INFO - topK: 60:, map: 0.13331618255339214
2025-03-02 12:31:12,440 - INFO - topK: 80:, map: 0.12306123744407065
2025-03-02 12:31:13,743 - INFO - topK: 100:, map: 0.1152049531674039
2025-03-02 12:31:14,886 - INFO - begin training stage: [61/805]
2025-03-02 12:31:19,623 - INFO - Epoch:[61/805] Step:[10/90] reconstruction_loss: 1.24 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:31:23,394 - INFO - Epoch:[61/805] Step:[20/90] reconstruction_loss: 1.24 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:31:26,962 - INFO - Epoch:[61/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:31:30,719 - INFO - Epoch:[61/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:31:34,374 - INFO - Epoch:[61/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:31:37,912 - INFO - Epoch:[61/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:31:41,946 - INFO - Epoch:[61/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:31:45,450 - INFO - Epoch:[61/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:31:48,808 - INFO - Epoch:[61/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.33 loss_cvh: 0.00
2025-03-02 12:31:49,963 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:31:49,964 - INFO - begin training stage: [62/805]
2025-03-02 12:31:49,964 - INFO - begin training stage: [62/805]
2025-03-02 12:31:55,596 - INFO - Epoch:[62/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:32:00,348 - INFO - Epoch:[62/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:32:04,763 - INFO - Epoch:[62/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:32:08,934 - INFO - Epoch:[62/805] Step:[40/90] reconstruction_loss: 1.23 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:32:13,194 - INFO - Epoch:[62/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:32:17,799 - INFO - Epoch:[62/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:32:22,184 - INFO - Epoch:[62/805] Step:[70/90] reconstruction_loss: 1.22 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:32:26,392 - INFO - Epoch:[62/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:32:30,155 - INFO - Epoch:[62/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.18 loss_cvh: 0.00
2025-03-02 12:32:31,178 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:32:31,178 - INFO - begin training stage: [63/805]
2025-03-02 12:32:31,179 - INFO - begin training stage: [63/805]
2025-03-02 12:32:35,778 - INFO - Epoch:[63/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:32:39,317 - INFO - Epoch:[63/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:32:42,719 - INFO - Epoch:[63/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:32:46,018 - INFO - Epoch:[63/805] Step:[40/90] reconstruction_loss: 1.22 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:32:49,361 - INFO - Epoch:[63/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:32:52,589 - INFO - Epoch:[63/805] Step:[60/90] reconstruction_loss: 1.23 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:32:56,271 - INFO - Epoch:[63/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:32:59,934 - INFO - Epoch:[63/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:33:03,082 - INFO - Epoch:[63/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.29 loss_cvh: 0.00
2025-03-02 12:33:04,118 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:33:04,118 - INFO - begin training stage: [64/805]
2025-03-02 12:33:04,118 - INFO - begin training stage: [64/805]
2025-03-02 12:33:08,523 - INFO - Epoch:[64/805] Step:[10/90] reconstruction_loss: 1.23 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:33:11,894 - INFO - Epoch:[64/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:33:15,335 - INFO - Epoch:[64/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:33:18,543 - INFO - Epoch:[64/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:33:21,798 - INFO - Epoch:[64/805] Step:[50/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:33:25,789 - INFO - Epoch:[64/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:33:30,584 - INFO - Epoch:[64/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:33:35,438 - INFO - Epoch:[64/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:33:40,023 - INFO - Epoch:[64/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.31 loss_cvh: 0.00
2025-03-02 12:33:41,466 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:33:41,468 - INFO - begin training stage: [65/805]
2025-03-02 12:33:41,468 - INFO - begin training stage: [65/805]
2025-03-02 12:33:47,632 - INFO - Epoch:[65/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:33:52,305 - INFO - Epoch:[65/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:33:56,961 - INFO - Epoch:[65/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:34:01,664 - INFO - Epoch:[65/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:34:06,553 - INFO - Epoch:[65/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:34:11,407 - INFO - Epoch:[65/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:34:16,036 - INFO - Epoch:[65/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:34:20,645 - INFO - Epoch:[65/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:34:24,708 - INFO - Epoch:[65/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.41 loss_cvh: 0.00
2025-03-02 12:34:26,115 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:34:26,115 - INFO - begin training stage: [66/805]
2025-03-02 12:34:26,115 - INFO - begin training stage: [66/805]
2025-03-02 12:34:32,432 - INFO - Epoch:[66/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:34:37,152 - INFO - Epoch:[66/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:34:41,883 - INFO - Epoch:[66/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:34:46,219 - INFO - Epoch:[66/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:34:50,878 - INFO - Epoch:[66/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:34:55,064 - INFO - Epoch:[66/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:34:58,445 - INFO - Epoch:[66/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:35:01,830 - INFO - Epoch:[66/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:35:04,900 - INFO - Epoch:[66/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.23 loss_cvh: 0.00
2025-03-02 12:35:05,947 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:35:05,948 - INFO - begin training stage: [67/805]
2025-03-02 12:35:05,948 - INFO - begin training stage: [67/805]
2025-03-02 12:35:10,484 - INFO - Epoch:[67/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:35:13,986 - INFO - Epoch:[67/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:35:17,312 - INFO - Epoch:[67/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:35:20,527 - INFO - Epoch:[67/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:35:23,887 - INFO - Epoch:[67/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:35:27,540 - INFO - Epoch:[67/805] Step:[60/90] reconstruction_loss: 1.22 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:35:31,077 - INFO - Epoch:[67/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:35:34,472 - INFO - Epoch:[67/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:35:37,456 - INFO - Epoch:[67/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.37 loss_cvh: 0.00
2025-03-02 12:35:38,462 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:35:38,462 - INFO - begin training stage: [68/805]
2025-03-02 12:35:38,463 - INFO - begin training stage: [68/805]
2025-03-02 12:35:42,647 - INFO - Epoch:[68/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:35:46,034 - INFO - Epoch:[68/805] Step:[20/90] reconstruction_loss: 1.23 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:35:49,436 - INFO - Epoch:[68/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:35:52,821 - INFO - Epoch:[68/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:35:56,119 - INFO - Epoch:[68/805] Step:[50/90] reconstruction_loss: 1.22 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:35:59,370 - INFO - Epoch:[68/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:36:02,796 - INFO - Epoch:[68/805] Step:[70/90] reconstruction_loss: 1.22 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:36:06,156 - INFO - Epoch:[68/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:36:09,331 - INFO - Epoch:[68/805] Step:[90/90] reconstruction_loss: 1.32 loss_vc: 1.14 loss_cvh: 0.00
2025-03-02 12:36:10,327 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:36:10,327 - INFO - begin training stage: [69/805]
2025-03-02 12:36:10,327 - INFO - begin training stage: [69/805]
2025-03-02 12:36:14,609 - INFO - Epoch:[69/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:36:17,773 - INFO - Epoch:[69/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:36:21,136 - INFO - Epoch:[69/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:36:24,509 - INFO - Epoch:[69/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:36:27,947 - INFO - Epoch:[69/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:36:31,353 - INFO - Epoch:[69/805] Step:[60/90] reconstruction_loss: 1.23 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:36:34,647 - INFO - Epoch:[69/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.57 loss_cvh: 0.00
2025-03-02 12:36:37,892 - INFO - Epoch:[69/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:36:41,006 - INFO - Epoch:[69/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.30 loss_cvh: 0.00
2025-03-02 12:36:42,002 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:36:42,002 - INFO - begin training stage: [70/805]
2025-03-02 12:36:42,002 - INFO - begin training stage: [70/805]
2025-03-02 12:36:46,239 - INFO - Epoch:[70/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:36:49,544 - INFO - Epoch:[70/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:36:52,819 - INFO - Epoch:[70/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:36:56,368 - INFO - Epoch:[70/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:36:59,858 - INFO - Epoch:[70/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:37:03,300 - INFO - Epoch:[70/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:37:06,735 - INFO - Epoch:[70/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:37:09,954 - INFO - Epoch:[70/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:37:12,987 - INFO - Epoch:[70/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.29 loss_cvh: 0.00
2025-03-02 12:37:14,082 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:37:14,082 - INFO - begin training stage: [71/805]
2025-03-02 12:37:14,084 - INFO - eval data number: 45600
2025-03-02 12:37:14,084 - INFO - loading eval data ......
2025-03-02 12:37:53,156 - INFO - retrieval costs: 26.959660530090332
2025-03-02 12:40:08,386 - INFO - hamming distance computation costs: 135.22997975349426
2025-03-02 12:40:14,466 - INFO - hamming ranking costs: 6.07987117767334
2025-03-02 12:40:14,466 - INFO - labels shape: (45600, 239)
2025-03-02 12:40:50,722 - INFO - similarity labels generation costs: 36.25573968887329
2025-03-02 12:40:50,798 - INFO - topK: 5:, map: 0.26309000000000005
2025-03-02 12:40:51,065 - INFO - topK: 20:, map: 0.1799496927474293
2025-03-02 12:40:51,593 - INFO - topK: 40:, map: 0.15361384842577808
2025-03-02 12:40:52,376 - INFO - topK: 60:, map: 0.13834540921745025
2025-03-02 12:40:53,396 - INFO - topK: 80:, map: 0.12773990128534202
2025-03-02 12:40:54,652 - INFO - topK: 100:, map: 0.11994220376323758
2025-03-02 12:40:56,003 - INFO - begin training stage: [71/805]
2025-03-02 12:41:00,575 - INFO - Epoch:[71/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:41:04,240 - INFO - Epoch:[71/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:41:07,815 - INFO - Epoch:[71/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:41:11,303 - INFO - Epoch:[71/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:41:14,705 - INFO - Epoch:[71/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:41:18,112 - INFO - Epoch:[71/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:41:21,668 - INFO - Epoch:[71/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:41:25,450 - INFO - Epoch:[71/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:41:28,799 - INFO - Epoch:[71/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.41 loss_cvh: 0.00
2025-03-02 12:41:29,844 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:41:29,845 - INFO - begin training stage: [72/805]
2025-03-02 12:41:29,845 - INFO - begin training stage: [72/805]
2025-03-02 12:41:34,289 - INFO - Epoch:[72/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:41:37,763 - INFO - Epoch:[72/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:41:41,874 - INFO - Epoch:[72/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:41:45,553 - INFO - Epoch:[72/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:41:49,391 - INFO - Epoch:[72/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:41:52,904 - INFO - Epoch:[72/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:41:56,506 - INFO - Epoch:[72/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:42:00,040 - INFO - Epoch:[72/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:42:03,200 - INFO - Epoch:[72/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.32 loss_cvh: 0.00
2025-03-02 12:42:04,175 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:42:04,175 - INFO - begin training stage: [73/805]
2025-03-02 12:42:04,175 - INFO - begin training stage: [73/805]
2025-03-02 12:42:08,656 - INFO - Epoch:[73/805] Step:[10/90] reconstruction_loss: 1.23 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:42:11,970 - INFO - Epoch:[73/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:42:15,468 - INFO - Epoch:[73/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:42:18,970 - INFO - Epoch:[73/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:42:22,647 - INFO - Epoch:[73/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:42:26,177 - INFO - Epoch:[73/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.46 loss_cvh: 0.00
2025-03-02 12:42:29,596 - INFO - Epoch:[73/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:42:33,018 - INFO - Epoch:[73/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:42:36,322 - INFO - Epoch:[73/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.41 loss_cvh: 0.00
2025-03-02 12:42:37,316 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:42:37,317 - INFO - begin training stage: [74/805]
2025-03-02 12:42:37,317 - INFO - begin training stage: [74/805]
2025-03-02 12:42:43,629 - INFO - Epoch:[74/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:42:48,459 - INFO - Epoch:[74/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:42:53,023 - INFO - Epoch:[74/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:42:57,936 - INFO - Epoch:[74/805] Step:[40/90] reconstruction_loss: 1.24 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:43:02,354 - INFO - Epoch:[74/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:43:07,216 - INFO - Epoch:[74/805] Step:[60/90] reconstruction_loss: 1.22 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:43:12,167 - INFO - Epoch:[74/805] Step:[70/90] reconstruction_loss: 1.24 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:43:16,907 - INFO - Epoch:[74/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:43:21,067 - INFO - Epoch:[74/805] Step:[90/90] reconstruction_loss: 1.36 loss_vc: 1.19 loss_cvh: 0.00
2025-03-02 12:43:22,543 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:43:22,544 - INFO - begin training stage: [75/805]
2025-03-02 12:43:22,544 - INFO - begin training stage: [75/805]
2025-03-02 12:43:29,033 - INFO - Epoch:[75/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:43:34,255 - INFO - Epoch:[75/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:43:38,999 - INFO - Epoch:[75/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:43:43,709 - INFO - Epoch:[75/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:43:48,441 - INFO - Epoch:[75/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:43:53,213 - INFO - Epoch:[75/805] Step:[60/90] reconstruction_loss: 1.22 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:43:57,872 - INFO - Epoch:[75/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:44:02,767 - INFO - Epoch:[75/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:44:07,053 - INFO - Epoch:[75/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.55 loss_cvh: 0.00
2025-03-02 12:44:08,489 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:44:08,489 - INFO - begin training stage: [76/805]
2025-03-02 12:44:08,489 - INFO - begin training stage: [76/805]
2025-03-02 12:44:14,329 - INFO - Epoch:[76/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:44:17,857 - INFO - Epoch:[76/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:44:21,430 - INFO - Epoch:[76/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:44:25,013 - INFO - Epoch:[76/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:44:28,487 - INFO - Epoch:[76/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:44:31,785 - INFO - Epoch:[76/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:44:35,420 - INFO - Epoch:[76/805] Step:[70/90] reconstruction_loss: 1.23 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:44:39,066 - INFO - Epoch:[76/805] Step:[80/90] reconstruction_loss: 1.23 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:44:42,623 - INFO - Epoch:[76/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.17 loss_cvh: 0.00
2025-03-02 12:44:43,595 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:44:43,595 - INFO - begin training stage: [77/805]
2025-03-02 12:44:43,595 - INFO - begin training stage: [77/805]
2025-03-02 12:44:47,861 - INFO - Epoch:[77/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:44:51,202 - INFO - Epoch:[77/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:44:54,608 - INFO - Epoch:[77/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:44:58,144 - INFO - Epoch:[77/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:45:01,807 - INFO - Epoch:[77/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:45:05,433 - INFO - Epoch:[77/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:45:08,786 - INFO - Epoch:[77/805] Step:[70/90] reconstruction_loss: 1.22 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:45:12,113 - INFO - Epoch:[77/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:45:15,493 - INFO - Epoch:[77/805] Step:[90/90] reconstruction_loss: 1.29 loss_vc: 1.32 loss_cvh: 0.00
2025-03-02 12:45:16,436 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:45:16,436 - INFO - begin training stage: [78/805]
2025-03-02 12:45:16,437 - INFO - begin training stage: [78/805]
2025-03-02 12:45:21,114 - INFO - Epoch:[78/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:45:24,664 - INFO - Epoch:[78/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:45:28,083 - INFO - Epoch:[78/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 12:45:31,568 - INFO - Epoch:[78/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:45:35,072 - INFO - Epoch:[78/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:45:38,672 - INFO - Epoch:[78/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:45:42,199 - INFO - Epoch:[78/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:45:45,777 - INFO - Epoch:[78/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:45:49,032 - INFO - Epoch:[78/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.29 loss_cvh: 0.00
2025-03-02 12:45:50,101 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:45:50,101 - INFO - begin training stage: [79/805]
2025-03-02 12:45:50,101 - INFO - begin training stage: [79/805]
2025-03-02 12:45:54,734 - INFO - Epoch:[79/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:45:58,355 - INFO - Epoch:[79/805] Step:[20/90] reconstruction_loss: 1.23 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:46:01,801 - INFO - Epoch:[79/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:46:05,142 - INFO - Epoch:[79/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:46:08,611 - INFO - Epoch:[79/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:46:12,127 - INFO - Epoch:[79/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:46:15,742 - INFO - Epoch:[79/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:46:19,217 - INFO - Epoch:[79/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:46:22,262 - INFO - Epoch:[79/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.38 loss_cvh: 0.00
2025-03-02 12:46:23,294 - INFO - now the learning rate is: 7.290000000000001e-05
2025-03-02 12:46:23,294 - INFO - begin training stage: [80/805]
2025-03-02 12:46:23,295 - INFO - begin training stage: [80/805]
2025-03-02 12:46:27,964 - INFO - Epoch:[80/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:46:31,692 - INFO - Epoch:[80/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:46:35,244 - INFO - Epoch:[80/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:46:38,661 - INFO - Epoch:[80/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:46:42,099 - INFO - Epoch:[80/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:46:45,576 - INFO - Epoch:[80/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:46:48,997 - INFO - Epoch:[80/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:46:52,525 - INFO - Epoch:[80/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:46:55,788 - INFO - Epoch:[80/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.37 loss_cvh: 0.00
2025-03-02 12:46:56,744 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 12:46:56,744 - INFO - begin training stage: [81/805]
2025-03-02 12:46:56,746 - INFO - eval data number: 45600
2025-03-02 12:46:56,746 - INFO - loading eval data ......
2025-03-02 12:47:32,105 - INFO - retrieval costs: 23.307116508483887
2025-03-02 12:50:03,419 - INFO - hamming distance computation costs: 151.31397080421448
2025-03-02 12:50:10,006 - INFO - hamming ranking costs: 6.586267948150635
2025-03-02 12:50:10,006 - INFO - labels shape: (45600, 239)
2025-03-02 12:50:47,132 - INFO - similarity labels generation costs: 37.126266956329346
2025-03-02 12:50:47,207 - INFO - topK: 5:, map: 0.2700841666666666
2025-03-02 12:50:47,470 - INFO - topK: 20:, map: 0.18389519546151945
2025-03-02 12:50:47,986 - INFO - topK: 40:, map: 0.15678435236785537
2025-03-02 12:50:48,751 - INFO - topK: 60:, map: 0.14232225510647964
2025-03-02 12:50:49,774 - INFO - topK: 80:, map: 0.13134068440847346
2025-03-02 12:50:51,107 - INFO - topK: 100:, map: 0.12325103750924572
2025-03-02 12:50:52,402 - INFO - begin training stage: [81/805]
2025-03-02 12:50:57,003 - INFO - Epoch:[81/805] Step:[10/90] reconstruction_loss: 1.24 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:51:00,615 - INFO - Epoch:[81/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:51:04,073 - INFO - Epoch:[81/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:51:07,579 - INFO - Epoch:[81/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:51:10,979 - INFO - Epoch:[81/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:51:14,535 - INFO - Epoch:[81/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:51:18,100 - INFO - Epoch:[81/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:51:21,744 - INFO - Epoch:[81/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:51:24,987 - INFO - Epoch:[81/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.46 loss_cvh: 0.00
2025-03-02 12:51:26,041 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 12:51:26,041 - INFO - begin training stage: [82/805]
2025-03-02 12:51:26,041 - INFO - begin training stage: [82/805]
2025-03-02 12:51:30,439 - INFO - Epoch:[82/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 12:51:34,052 - INFO - Epoch:[82/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:51:37,671 - INFO - Epoch:[82/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:51:41,124 - INFO - Epoch:[82/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 12:51:44,545 - INFO - Epoch:[82/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:51:47,900 - INFO - Epoch:[82/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:51:51,510 - INFO - Epoch:[82/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:51:55,379 - INFO - Epoch:[82/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:51:59,033 - INFO - Epoch:[82/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.31 loss_cvh: 0.00
2025-03-02 12:52:00,470 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 12:52:00,471 - INFO - begin training stage: [83/805]
2025-03-02 12:52:00,471 - INFO - begin training stage: [83/805]
2025-03-02 12:52:06,684 - INFO - Epoch:[83/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:52:11,276 - INFO - Epoch:[83/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 0.00
2025-03-02 12:52:16,468 - INFO - Epoch:[83/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:52:21,491 - INFO - Epoch:[83/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 12:52:26,075 - INFO - Epoch:[83/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:52:30,756 - INFO - Epoch:[83/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:52:35,824 - INFO - Epoch:[83/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:52:40,748 - INFO - Epoch:[83/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:52:45,504 - INFO - Epoch:[83/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.20 loss_cvh: 0.00
2025-03-02 12:52:46,963 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 12:52:46,963 - INFO - begin training stage: [84/805]
2025-03-02 12:52:46,964 - INFO - begin training stage: [84/805]
2025-03-02 12:52:53,469 - INFO - Epoch:[84/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.56 loss_cvh: 0.00
2025-03-02 12:52:58,492 - INFO - Epoch:[84/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:53:03,523 - INFO - Epoch:[84/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:53:08,484 - INFO - Epoch:[84/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:53:13,462 - INFO - Epoch:[84/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:53:18,228 - INFO - Epoch:[84/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:53:23,072 - INFO - Epoch:[84/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:53:27,758 - INFO - Epoch:[84/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:53:32,467 - INFO - Epoch:[84/805] Step:[90/90] reconstruction_loss: 1.30 loss_vc: 1.26 loss_cvh: 0.00
2025-03-02 12:53:33,584 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 12:53:33,585 - INFO - begin training stage: [85/805]
2025-03-02 12:53:33,585 - INFO - begin training stage: [85/805]
2025-03-02 12:53:37,969 - INFO - Epoch:[85/805] Step:[10/90] reconstruction_loss: 1.23 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:53:41,304 - INFO - Epoch:[85/805] Step:[20/90] reconstruction_loss: 1.23 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:53:44,596 - INFO - Epoch:[85/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:53:48,090 - INFO - Epoch:[85/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:53:51,715 - INFO - Epoch:[85/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 12:53:55,187 - INFO - Epoch:[85/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:53:58,551 - INFO - Epoch:[85/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:54:01,810 - INFO - Epoch:[85/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:54:05,138 - INFO - Epoch:[85/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.44 loss_cvh: 0.00
2025-03-02 12:54:06,435 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 12:54:06,435 - INFO - begin training stage: [86/805]
2025-03-02 12:54:06,435 - INFO - begin training stage: [86/805]
2025-03-02 12:54:11,121 - INFO - Epoch:[86/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:54:14,604 - INFO - Epoch:[86/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:54:17,984 - INFO - Epoch:[86/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:54:21,459 - INFO - Epoch:[86/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 0.00
2025-03-02 12:54:24,980 - INFO - Epoch:[86/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:54:28,528 - INFO - Epoch:[86/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:54:32,109 - INFO - Epoch:[86/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 12:54:35,501 - INFO - Epoch:[86/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:54:38,723 - INFO - Epoch:[86/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.33 loss_cvh: 0.00
2025-03-02 12:54:39,860 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 12:54:39,861 - INFO - begin training stage: [87/805]
2025-03-02 12:54:39,861 - INFO - begin training stage: [87/805]
2025-03-02 12:54:44,391 - INFO - Epoch:[87/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:54:48,002 - INFO - Epoch:[87/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:54:51,531 - INFO - Epoch:[87/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:54:54,929 - INFO - Epoch:[87/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 12:54:58,381 - INFO - Epoch:[87/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:55:01,887 - INFO - Epoch:[87/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:55:05,587 - INFO - Epoch:[87/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:55:09,236 - INFO - Epoch:[87/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:55:12,471 - INFO - Epoch:[87/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.40 loss_cvh: 0.00
2025-03-02 12:55:13,534 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 12:55:13,535 - INFO - begin training stage: [88/805]
2025-03-02 12:55:13,535 - INFO - begin training stage: [88/805]
2025-03-02 12:55:17,922 - INFO - Epoch:[88/805] Step:[10/90] reconstruction_loss: 1.23 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:55:21,360 - INFO - Epoch:[88/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:55:24,931 - INFO - Epoch:[88/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 12:55:28,471 - INFO - Epoch:[88/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:55:32,205 - INFO - Epoch:[88/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:55:35,852 - INFO - Epoch:[88/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:55:39,476 - INFO - Epoch:[88/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:55:42,843 - INFO - Epoch:[88/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:55:45,900 - INFO - Epoch:[88/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.34 loss_cvh: 0.00
2025-03-02 12:55:46,925 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 12:55:46,926 - INFO - begin training stage: [89/805]
2025-03-02 12:55:46,926 - INFO - begin training stage: [89/805]
2025-03-02 12:55:51,465 - INFO - Epoch:[89/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:55:55,351 - INFO - Epoch:[89/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 12:55:59,057 - INFO - Epoch:[89/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 12:56:02,707 - INFO - Epoch:[89/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:56:06,158 - INFO - Epoch:[89/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:56:09,659 - INFO - Epoch:[89/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:56:13,566 - INFO - Epoch:[89/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:56:17,320 - INFO - Epoch:[89/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:56:20,830 - INFO - Epoch:[89/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.37 loss_cvh: 0.00
2025-03-02 12:56:22,232 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 12:56:22,232 - INFO - begin training stage: [90/805]
2025-03-02 12:56:22,233 - INFO - begin training stage: [90/805]
2025-03-02 12:56:26,734 - INFO - Epoch:[90/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 12:56:30,273 - INFO - Epoch:[90/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:56:33,981 - INFO - Epoch:[90/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:56:37,598 - INFO - Epoch:[90/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 12:56:41,096 - INFO - Epoch:[90/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 12:56:44,426 - INFO - Epoch:[90/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 0.00
2025-03-02 12:56:48,099 - INFO - Epoch:[90/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 12:56:51,776 - INFO - Epoch:[90/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 12:56:55,012 - INFO - Epoch:[90/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.42 loss_cvh: 0.00
2025-03-02 12:56:55,999 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 12:56:55,999 - INFO - begin training stage: [91/805]
2025-03-02 12:56:56,001 - INFO - eval data number: 45600
2025-03-02 12:56:56,001 - INFO - loading eval data ......
2025-03-02 12:57:32,857 - INFO - retrieval costs: 24.59121799468994
2025-03-02 13:00:04,824 - INFO - hamming distance computation costs: 151.96686053276062
2025-03-02 13:00:11,291 - INFO - hamming ranking costs: 6.467559099197388
2025-03-02 13:00:11,292 - INFO - labels shape: (45600, 239)
2025-03-02 13:00:48,171 - INFO - similarity labels generation costs: 36.88022327423096
2025-03-02 13:00:48,247 - INFO - topK: 5:, map: 0.27885000000000004
2025-03-02 13:00:48,511 - INFO - topK: 20:, map: 0.19260297375821417
2025-03-02 13:00:49,023 - INFO - topK: 40:, map: 0.16417551779013204
2025-03-02 13:00:49,788 - INFO - topK: 60:, map: 0.14911029027468953
2025-03-02 13:00:50,801 - INFO - topK: 80:, map: 0.13800868532644223
2025-03-02 13:00:52,068 - INFO - topK: 100:, map: 0.1292359680759418
2025-03-02 13:00:53,368 - INFO - begin training stage: [91/805]
2025-03-02 13:00:57,871 - INFO - Epoch:[91/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:01:01,387 - INFO - Epoch:[91/805] Step:[20/90] reconstruction_loss: 1.22 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:01:04,856 - INFO - Epoch:[91/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:01:08,361 - INFO - Epoch:[91/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:01:11,882 - INFO - Epoch:[91/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:01:15,666 - INFO - Epoch:[91/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:01:19,385 - INFO - Epoch:[91/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:01:22,748 - INFO - Epoch:[91/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:01:25,906 - INFO - Epoch:[91/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.37 loss_cvh: 0.00
2025-03-02 13:01:26,883 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 13:01:26,883 - INFO - begin training stage: [92/805]
2025-03-02 13:01:26,883 - INFO - begin training stage: [92/805]
2025-03-02 13:01:31,322 - INFO - Epoch:[92/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.55 loss_cvh: 0.00
2025-03-02 13:01:34,995 - INFO - Epoch:[92/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:01:38,513 - INFO - Epoch:[92/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:01:41,970 - INFO - Epoch:[92/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:01:45,349 - INFO - Epoch:[92/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:01:48,778 - INFO - Epoch:[92/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:01:53,091 - INFO - Epoch:[92/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:01:57,969 - INFO - Epoch:[92/805] Step:[80/90] reconstruction_loss: 1.22 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:02:02,323 - INFO - Epoch:[92/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.39 loss_cvh: 0.00
2025-03-02 13:02:03,775 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 13:02:03,775 - INFO - begin training stage: [93/805]
2025-03-02 13:02:03,775 - INFO - begin training stage: [93/805]
2025-03-02 13:02:10,168 - INFO - Epoch:[93/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:02:14,644 - INFO - Epoch:[93/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:02:19,369 - INFO - Epoch:[93/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:02:24,063 - INFO - Epoch:[93/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:02:28,600 - INFO - Epoch:[93/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 13:02:33,643 - INFO - Epoch:[93/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:02:38,900 - INFO - Epoch:[93/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:02:43,665 - INFO - Epoch:[93/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:02:47,881 - INFO - Epoch:[93/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.47 loss_cvh: 0.00
2025-03-02 13:02:49,359 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 13:02:49,359 - INFO - begin training stage: [94/805]
2025-03-02 13:02:49,359 - INFO - begin training stage: [94/805]
2025-03-02 13:02:55,344 - INFO - Epoch:[94/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:03:00,473 - INFO - Epoch:[94/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 13:03:05,093 - INFO - Epoch:[94/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:03:10,448 - INFO - Epoch:[94/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:03:15,381 - INFO - Epoch:[94/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:03:20,435 - INFO - Epoch:[94/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:03:25,175 - INFO - Epoch:[94/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:03:29,349 - INFO - Epoch:[94/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:03:32,678 - INFO - Epoch:[94/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.19 loss_cvh: 0.00
2025-03-02 13:03:33,655 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 13:03:33,656 - INFO - begin training stage: [95/805]
2025-03-02 13:03:33,656 - INFO - begin training stage: [95/805]
2025-03-02 13:03:38,106 - INFO - Epoch:[95/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:03:41,507 - INFO - Epoch:[95/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:03:44,838 - INFO - Epoch:[95/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:03:48,409 - INFO - Epoch:[95/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:03:51,976 - INFO - Epoch:[95/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 13:03:55,689 - INFO - Epoch:[95/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:03:59,202 - INFO - Epoch:[95/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:04:02,595 - INFO - Epoch:[95/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:04:05,840 - INFO - Epoch:[95/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.24 loss_cvh: 0.00
2025-03-02 13:04:06,766 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 13:04:06,767 - INFO - begin training stage: [96/805]
2025-03-02 13:04:06,767 - INFO - begin training stage: [96/805]
2025-03-02 13:04:11,500 - INFO - Epoch:[96/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:04:14,966 - INFO - Epoch:[96/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.54 loss_cvh: 0.00
2025-03-02 13:04:18,433 - INFO - Epoch:[96/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.53 loss_cvh: 0.00
2025-03-02 13:04:22,029 - INFO - Epoch:[96/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:04:25,611 - INFO - Epoch:[96/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:04:29,301 - INFO - Epoch:[96/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:04:32,832 - INFO - Epoch:[96/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 13:04:36,224 - INFO - Epoch:[96/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:04:39,328 - INFO - Epoch:[96/805] Step:[90/90] reconstruction_loss: 1.33 loss_vc: 1.23 loss_cvh: 0.00
2025-03-02 13:04:40,400 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 13:04:40,401 - INFO - begin training stage: [97/805]
2025-03-02 13:04:40,401 - INFO - begin training stage: [97/805]
2025-03-02 13:04:44,866 - INFO - Epoch:[97/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:04:48,374 - INFO - Epoch:[97/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:04:51,897 - INFO - Epoch:[97/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:04:55,304 - INFO - Epoch:[97/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:04:58,736 - INFO - Epoch:[97/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 0.00
2025-03-02 13:05:02,287 - INFO - Epoch:[97/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:05:05,716 - INFO - Epoch:[97/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:05:09,282 - INFO - Epoch:[97/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 13:05:12,530 - INFO - Epoch:[97/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.29 loss_cvh: 0.00
2025-03-02 13:05:13,505 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 13:05:13,506 - INFO - begin training stage: [98/805]
2025-03-02 13:05:13,506 - INFO - begin training stage: [98/805]
2025-03-02 13:05:17,856 - INFO - Epoch:[98/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:05:21,228 - INFO - Epoch:[98/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:05:24,755 - INFO - Epoch:[98/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 0.00
2025-03-02 13:05:28,490 - INFO - Epoch:[98/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:05:31,907 - INFO - Epoch:[98/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:05:35,371 - INFO - Epoch:[98/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:05:38,828 - INFO - Epoch:[98/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:05:42,222 - INFO - Epoch:[98/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:05:45,523 - INFO - Epoch:[98/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.33 loss_cvh: 0.00
2025-03-02 13:05:46,556 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 13:05:46,556 - INFO - begin training stage: [99/805]
2025-03-02 13:05:46,556 - INFO - begin training stage: [99/805]
2025-03-02 13:05:50,935 - INFO - Epoch:[99/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:05:54,642 - INFO - Epoch:[99/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:05:58,302 - INFO - Epoch:[99/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:06:01,919 - INFO - Epoch:[99/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:06:05,369 - INFO - Epoch:[99/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 13:06:08,823 - INFO - Epoch:[99/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 0.00
2025-03-02 13:06:12,258 - INFO - Epoch:[99/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:06:15,828 - INFO - Epoch:[99/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 13:06:19,124 - INFO - Epoch:[99/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.40 loss_cvh: 0.00
2025-03-02 13:06:20,097 - INFO - now the learning rate is: 6.561000000000002e-05
2025-03-02 13:06:20,098 - INFO - begin training stage: [100/805]
2025-03-02 13:06:20,098 - INFO - begin training stage: [100/805]
2025-03-02 13:06:24,736 - INFO - Epoch:[100/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:06:28,146 - INFO - Epoch:[100/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 0.00
2025-03-02 13:06:31,739 - INFO - Epoch:[100/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.51 loss_cvh: 0.00
2025-03-02 13:06:35,492 - INFO - Epoch:[100/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:06:39,341 - INFO - Epoch:[100/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:06:42,962 - INFO - Epoch:[100/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 0.00
2025-03-02 13:06:46,512 - INFO - Epoch:[100/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 0.00
2025-03-02 13:06:49,971 - INFO - Epoch:[100/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.52 loss_cvh: 0.00
2025-03-02 13:06:53,109 - INFO - Epoch:[100/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.32 loss_cvh: 0.00
2025-03-02 13:06:54,142 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:07:29,060 - INFO - begin training stage: [101/805]
2025-03-02 13:07:29,061 - INFO - eval data number: 45600
2025-03-02 13:07:29,061 - INFO - loading eval data ......
2025-03-02 13:08:04,639 - INFO - retrieval costs: 23.27260971069336
2025-03-02 13:10:45,307 - INFO - hamming distance computation costs: 160.66809940338135
2025-03-02 13:10:51,575 - INFO - hamming ranking costs: 6.268681764602661
2025-03-02 13:10:51,576 - INFO - labels shape: (45600, 239)
2025-03-02 13:11:28,521 - INFO - similarity labels generation costs: 36.94561696052551
2025-03-02 13:11:28,595 - INFO - topK: 5:, map: 0.27856333333333333
2025-03-02 13:11:28,854 - INFO - topK: 20:, map: 0.1965367369387256
2025-03-02 13:11:29,363 - INFO - topK: 40:, map: 0.1680398259674481
2025-03-02 13:11:30,134 - INFO - topK: 60:, map: 0.15395313106782654
2025-03-02 13:11:31,157 - INFO - topK: 80:, map: 0.142853713457928
2025-03-02 13:11:32,563 - INFO - topK: 100:, map: 0.13370727772668636
2025-03-02 13:11:33,661 - INFO - begin training stage: [101/805]
2025-03-02 13:11:38,201 - INFO - Epoch:[101/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.48 loss_cvh: 3.17
2025-03-02 13:11:41,836 - INFO - Epoch:[101/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.51 loss_cvh: 3.20
2025-03-02 13:11:45,299 - INFO - Epoch:[101/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 3.22
2025-03-02 13:11:48,700 - INFO - Epoch:[101/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.23
2025-03-02 13:11:52,360 - INFO - Epoch:[101/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 3.17
2025-03-02 13:11:55,968 - INFO - Epoch:[101/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.19
2025-03-02 13:11:59,555 - INFO - Epoch:[101/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 3.22
2025-03-02 13:12:03,008 - INFO - Epoch:[101/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.53 loss_cvh: 3.27
2025-03-02 13:12:06,232 - INFO - Epoch:[101/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.13 loss_cvh: 0.38
2025-03-02 13:12:07,242 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:12:41,879 - INFO - begin training stage: [102/805]
2025-03-02 13:12:41,879 - INFO - begin training stage: [102/805]
2025-03-02 13:12:46,186 - INFO - Epoch:[102/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.46 loss_cvh: 3.17
2025-03-02 13:12:49,584 - INFO - Epoch:[102/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.17
2025-03-02 13:12:53,219 - INFO - Epoch:[102/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.50 loss_cvh: 3.17
2025-03-02 13:12:56,818 - INFO - Epoch:[102/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.13
2025-03-02 13:13:00,417 - INFO - Epoch:[102/805] Step:[50/90] reconstruction_loss: 1.22 loss_vc: 4.51 loss_cvh: 3.24
2025-03-02 13:13:04,103 - INFO - Epoch:[102/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 3.17
2025-03-02 13:13:07,565 - INFO - Epoch:[102/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.20
2025-03-02 13:13:11,149 - INFO - Epoch:[102/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.49 loss_cvh: 3.18
2025-03-02 13:13:14,648 - INFO - Epoch:[102/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.64 loss_cvh: 1.03
2025-03-02 13:13:15,644 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:13:50,144 - INFO - begin training stage: [103/805]
2025-03-02 13:13:50,145 - INFO - begin training stage: [103/805]
2025-03-02 13:13:54,674 - INFO - Epoch:[103/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.50 loss_cvh: 3.17
2025-03-02 13:13:58,143 - INFO - Epoch:[103/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 3.19
2025-03-02 13:14:01,566 - INFO - Epoch:[103/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 13:14:05,034 - INFO - Epoch:[103/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.17
2025-03-02 13:14:08,592 - INFO - Epoch:[103/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 3.19
2025-03-02 13:14:12,411 - INFO - Epoch:[103/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 3.21
2025-03-02 13:14:16,001 - INFO - Epoch:[103/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.23
2025-03-02 13:14:19,438 - INFO - Epoch:[103/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.48 loss_cvh: 3.17
2025-03-02 13:14:22,674 - INFO - Epoch:[103/805] Step:[90/90] reconstruction_loss: 1.28 loss_vc: 1.36 loss_cvh: 0.96
2025-03-02 13:14:23,719 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:14:58,880 - INFO - begin training stage: [104/805]
2025-03-02 13:14:58,880 - INFO - begin training stage: [104/805]
2025-03-02 13:15:03,455 - INFO - Epoch:[104/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.50 loss_cvh: 3.22
2025-03-02 13:15:07,110 - INFO - Epoch:[104/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.20
2025-03-02 13:15:10,634 - INFO - Epoch:[104/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.52 loss_cvh: 3.28
2025-03-02 13:15:14,063 - INFO - Epoch:[104/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.17
2025-03-02 13:15:17,628 - INFO - Epoch:[104/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.19
2025-03-02 13:15:21,229 - INFO - Epoch:[104/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.18
2025-03-02 13:15:24,789 - INFO - Epoch:[104/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.48 loss_cvh: 3.18
2025-03-02 13:15:28,390 - INFO - Epoch:[104/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.51 loss_cvh: 3.20
2025-03-02 13:15:31,538 - INFO - Epoch:[104/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.46 loss_cvh: 0.91
2025-03-02 13:15:32,544 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:16:07,884 - INFO - begin training stage: [105/805]
2025-03-02 13:16:07,885 - INFO - begin training stage: [105/805]
2025-03-02 13:16:12,251 - INFO - Epoch:[105/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.19
2025-03-02 13:16:16,062 - INFO - Epoch:[105/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 3.24
2025-03-02 13:16:19,660 - INFO - Epoch:[105/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.51 loss_cvh: 3.25
2025-03-02 13:16:23,460 - INFO - Epoch:[105/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 3.23
2025-03-02 13:16:27,063 - INFO - Epoch:[105/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 3.20
2025-03-02 13:16:30,468 - INFO - Epoch:[105/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 3.24
2025-03-02 13:16:34,023 - INFO - Epoch:[105/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.52 loss_cvh: 3.23
2025-03-02 13:16:37,689 - INFO - Epoch:[105/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.14
2025-03-02 13:16:40,993 - INFO - Epoch:[105/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.46 loss_cvh: 0.85
2025-03-02 13:16:42,063 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:17:17,047 - INFO - begin training stage: [106/805]
2025-03-02 13:17:17,048 - INFO - begin training stage: [106/805]
2025-03-02 13:17:22,601 - INFO - Epoch:[106/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 3.29
2025-03-02 13:17:27,640 - INFO - Epoch:[106/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 3.28
2025-03-02 13:17:32,733 - INFO - Epoch:[106/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.48 loss_cvh: 3.25
2025-03-02 13:17:37,571 - INFO - Epoch:[106/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 3.19
2025-03-02 13:17:42,476 - INFO - Epoch:[106/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.27
2025-03-02 13:17:47,408 - INFO - Epoch:[106/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.18
2025-03-02 13:17:52,472 - INFO - Epoch:[106/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.47 loss_cvh: 3.24
2025-03-02 13:17:57,631 - INFO - Epoch:[106/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 3.17
2025-03-02 13:18:02,007 - INFO - Epoch:[106/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.30 loss_cvh: 0.94
2025-03-02 13:18:03,743 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:18:49,004 - INFO - begin training stage: [107/805]
2025-03-02 13:18:49,004 - INFO - begin training stage: [107/805]
2025-03-02 13:18:53,907 - INFO - Epoch:[107/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 3.18
2025-03-02 13:18:57,691 - INFO - Epoch:[107/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.19
2025-03-02 13:19:01,218 - INFO - Epoch:[107/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 13:19:04,827 - INFO - Epoch:[107/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 3.20
2025-03-02 13:19:08,461 - INFO - Epoch:[107/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.14
2025-03-02 13:19:12,214 - INFO - Epoch:[107/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.51 loss_cvh: 3.17
2025-03-02 13:19:15,873 - INFO - Epoch:[107/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 3.19
2025-03-02 13:19:19,377 - INFO - Epoch:[107/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 3.22
2025-03-02 13:19:22,720 - INFO - Epoch:[107/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.35 loss_cvh: 0.61
2025-03-02 13:19:23,748 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:19:58,500 - INFO - begin training stage: [108/805]
2025-03-02 13:19:58,500 - INFO - begin training stage: [108/805]
2025-03-02 13:20:02,769 - INFO - Epoch:[108/805] Step:[10/90] reconstruction_loss: 1.22 loss_vc: 4.51 loss_cvh: 3.29
2025-03-02 13:20:06,153 - INFO - Epoch:[108/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.50 loss_cvh: 3.21
2025-03-02 13:20:09,865 - INFO - Epoch:[108/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 3.22
2025-03-02 13:20:13,618 - INFO - Epoch:[108/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 13:20:16,977 - INFO - Epoch:[108/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.22
2025-03-02 13:20:20,328 - INFO - Epoch:[108/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.18
2025-03-02 13:20:23,920 - INFO - Epoch:[108/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.20
2025-03-02 13:20:27,683 - INFO - Epoch:[108/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.48 loss_cvh: 3.25
2025-03-02 13:20:30,981 - INFO - Epoch:[108/805] Step:[90/90] reconstruction_loss: 1.05 loss_vc: 1.26 loss_cvh: 0.72
2025-03-02 13:20:32,020 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:21:06,870 - INFO - begin training stage: [109/805]
2025-03-02 13:21:06,870 - INFO - begin training stage: [109/805]
2025-03-02 13:21:11,225 - INFO - Epoch:[109/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 3.29
2025-03-02 13:21:14,667 - INFO - Epoch:[109/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 13:21:18,139 - INFO - Epoch:[109/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.46 loss_cvh: 3.20
2025-03-02 13:21:22,046 - INFO - Epoch:[109/805] Step:[40/90] reconstruction_loss: 1.22 loss_vc: 4.51 loss_cvh: 3.23
2025-03-02 13:21:25,778 - INFO - Epoch:[109/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.19
2025-03-02 13:21:29,193 - INFO - Epoch:[109/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.51 loss_cvh: 3.15
2025-03-02 13:21:32,570 - INFO - Epoch:[109/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.51 loss_cvh: 3.20
2025-03-02 13:21:36,023 - INFO - Epoch:[109/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.24
2025-03-02 13:21:39,410 - INFO - Epoch:[109/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.23 loss_cvh: 0.79
2025-03-02 13:21:40,502 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:22:15,386 - INFO - begin training stage: [110/805]
2025-03-02 13:22:15,386 - INFO - begin training stage: [110/805]
2025-03-02 13:22:20,006 - INFO - Epoch:[110/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.20
2025-03-02 13:22:23,405 - INFO - Epoch:[110/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.22
2025-03-02 13:22:26,841 - INFO - Epoch:[110/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.47 loss_cvh: 3.20
2025-03-02 13:22:30,531 - INFO - Epoch:[110/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.15
2025-03-02 13:22:34,185 - INFO - Epoch:[110/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.17
2025-03-02 13:22:38,087 - INFO - Epoch:[110/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 3.20
2025-03-02 13:22:41,528 - INFO - Epoch:[110/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.16
2025-03-02 13:22:44,920 - INFO - Epoch:[110/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.23
2025-03-02 13:22:48,297 - INFO - Epoch:[110/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.39 loss_cvh: 0.69
2025-03-02 13:22:49,308 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:23:23,899 - INFO - begin training stage: [111/805]
2025-03-02 13:23:23,900 - INFO - eval data number: 45600
2025-03-02 13:23:23,900 - INFO - loading eval data ......
2025-03-02 13:23:56,674 - INFO - retrieval costs: 20.60197114944458
2025-03-02 13:26:42,678 - INFO - hamming distance computation costs: 166.00340056419373
2025-03-02 13:26:49,910 - INFO - hamming ranking costs: 7.232572793960571
2025-03-02 13:26:49,911 - INFO - labels shape: (45600, 239)
2025-03-02 13:27:26,767 - INFO - similarity labels generation costs: 36.85686254501343
2025-03-02 13:27:26,844 - INFO - topK: 5:, map: 0.28826666666666667
2025-03-02 13:27:27,105 - INFO - topK: 20:, map: 0.20160908527687696
2025-03-02 13:27:27,682 - INFO - topK: 40:, map: 0.1735733171876127
2025-03-02 13:27:28,503 - INFO - topK: 60:, map: 0.1577278975278926
2025-03-02 13:27:29,516 - INFO - topK: 80:, map: 0.1461399965269712
2025-03-02 13:27:30,769 - INFO - topK: 100:, map: 0.13688760347228385
2025-03-02 13:27:32,016 - INFO - begin training stage: [111/805]
2025-03-02 13:27:36,504 - INFO - Epoch:[111/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.52 loss_cvh: 3.24
2025-03-02 13:27:40,051 - INFO - Epoch:[111/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.22
2025-03-02 13:27:43,436 - INFO - Epoch:[111/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 3.18
2025-03-02 13:27:47,245 - INFO - Epoch:[111/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.24
2025-03-02 13:27:50,875 - INFO - Epoch:[111/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.49 loss_cvh: 3.19
2025-03-02 13:27:54,621 - INFO - Epoch:[111/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.45 loss_cvh: 3.18
2025-03-02 13:27:58,361 - INFO - Epoch:[111/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 3.20
2025-03-02 13:28:02,062 - INFO - Epoch:[111/805] Step:[80/90] reconstruction_loss: 1.23 loss_vc: 4.48 loss_cvh: 3.18
2025-03-02 13:28:05,435 - INFO - Epoch:[111/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.21 loss_cvh: 0.57
2025-03-02 13:28:06,486 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:28:40,305 - INFO - begin training stage: [112/805]
2025-03-02 13:28:40,306 - INFO - begin training stage: [112/805]
2025-03-02 13:28:44,987 - INFO - Epoch:[112/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.18
2025-03-02 13:28:48,560 - INFO - Epoch:[112/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 13:28:52,254 - INFO - Epoch:[112/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.12
2025-03-02 13:28:55,849 - INFO - Epoch:[112/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.12
2025-03-02 13:28:59,245 - INFO - Epoch:[112/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.17
2025-03-02 13:29:02,652 - INFO - Epoch:[112/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.52 loss_cvh: 3.25
2025-03-02 13:29:06,250 - INFO - Epoch:[112/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.17
2025-03-02 13:29:09,732 - INFO - Epoch:[112/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 13:29:13,102 - INFO - Epoch:[112/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.29 loss_cvh: 0.97
2025-03-02 13:29:14,120 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:29:49,545 - INFO - begin training stage: [113/805]
2025-03-02 13:29:49,545 - INFO - begin training stage: [113/805]
2025-03-02 13:29:54,117 - INFO - Epoch:[113/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.46 loss_cvh: 3.22
2025-03-02 13:29:57,548 - INFO - Epoch:[113/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.22
2025-03-02 13:30:00,966 - INFO - Epoch:[113/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 3.28
2025-03-02 13:30:04,585 - INFO - Epoch:[113/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 3.15
2025-03-02 13:30:08,355 - INFO - Epoch:[113/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.20
2025-03-02 13:30:11,717 - INFO - Epoch:[113/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 3.13
2025-03-02 13:30:15,215 - INFO - Epoch:[113/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 3.23
2025-03-02 13:30:18,843 - INFO - Epoch:[113/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.15
2025-03-02 13:30:22,182 - INFO - Epoch:[113/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.20 loss_cvh: 0.86
2025-03-02 13:30:23,189 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:30:57,727 - INFO - begin training stage: [114/805]
2025-03-02 13:30:57,727 - INFO - begin training stage: [114/805]
2025-03-02 13:31:02,380 - INFO - Epoch:[114/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 13:31:05,944 - INFO - Epoch:[114/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.52 loss_cvh: 3.20
2025-03-02 13:31:09,674 - INFO - Epoch:[114/805] Step:[30/90] reconstruction_loss: 1.23 loss_vc: 4.49 loss_cvh: 3.22
2025-03-02 13:31:13,077 - INFO - Epoch:[114/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.48 loss_cvh: 3.22
2025-03-02 13:31:16,474 - INFO - Epoch:[114/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 3.18
2025-03-02 13:31:20,075 - INFO - Epoch:[114/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.19
2025-03-02 13:31:23,543 - INFO - Epoch:[114/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.17
2025-03-02 13:31:27,012 - INFO - Epoch:[114/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.14
2025-03-02 13:31:30,321 - INFO - Epoch:[114/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.45 loss_cvh: 0.88
2025-03-02 13:31:31,288 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:32:05,616 - INFO - begin training stage: [115/805]
2025-03-02 13:32:05,616 - INFO - begin training stage: [115/805]
2025-03-02 13:32:10,080 - INFO - Epoch:[115/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.26
2025-03-02 13:32:13,576 - INFO - Epoch:[115/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 3.19
2025-03-02 13:32:17,335 - INFO - Epoch:[115/805] Step:[30/90] reconstruction_loss: 1.22 loss_vc: 4.46 loss_cvh: 3.22
2025-03-02 13:32:20,879 - INFO - Epoch:[115/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.21
2025-03-02 13:32:24,391 - INFO - Epoch:[115/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 3.24
2025-03-02 13:32:27,918 - INFO - Epoch:[115/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 3.20
2025-03-02 13:32:31,373 - INFO - Epoch:[115/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.15
2025-03-02 13:32:34,877 - INFO - Epoch:[115/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 13:32:38,321 - INFO - Epoch:[115/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.40 loss_cvh: 1.10
2025-03-02 13:32:39,299 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:33:43,281 - INFO - begin training stage: [116/805]
2025-03-02 13:33:43,281 - INFO - begin training stage: [116/805]
2025-03-02 13:33:49,436 - INFO - Epoch:[116/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 3.20
2025-03-02 13:33:54,056 - INFO - Epoch:[116/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.51 loss_cvh: 3.19
2025-03-02 13:33:58,996 - INFO - Epoch:[116/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.19
2025-03-02 13:34:04,084 - INFO - Epoch:[116/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.13
2025-03-02 13:34:08,894 - INFO - Epoch:[116/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.17
2025-03-02 13:34:13,504 - INFO - Epoch:[116/805] Step:[60/90] reconstruction_loss: 1.22 loss_vc: 4.48 loss_cvh: 3.16
2025-03-02 13:34:18,307 - INFO - Epoch:[116/805] Step:[70/90] reconstruction_loss: 1.22 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 13:34:23,059 - INFO - Epoch:[116/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 3.16
2025-03-02 13:34:27,342 - INFO - Epoch:[116/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.31 loss_cvh: 0.59
2025-03-02 13:34:28,313 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:35:02,301 - INFO - begin training stage: [117/805]
2025-03-02 13:35:02,301 - INFO - begin training stage: [117/805]
2025-03-02 13:35:06,720 - INFO - Epoch:[117/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.51 loss_cvh: 3.28
2025-03-02 13:35:10,310 - INFO - Epoch:[117/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.19
2025-03-02 13:35:13,928 - INFO - Epoch:[117/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.20
2025-03-02 13:35:17,643 - INFO - Epoch:[117/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.16
2025-03-02 13:35:21,407 - INFO - Epoch:[117/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 3.22
2025-03-02 13:35:25,042 - INFO - Epoch:[117/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.46 loss_cvh: 3.21
2025-03-02 13:35:28,460 - INFO - Epoch:[117/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 13:35:31,825 - INFO - Epoch:[117/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 3.17
2025-03-02 13:35:34,892 - INFO - Epoch:[117/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.21 loss_cvh: 0.82
2025-03-02 13:35:35,991 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:36:10,022 - INFO - begin training stage: [118/805]
2025-03-02 13:36:10,022 - INFO - begin training stage: [118/805]
2025-03-02 13:36:14,447 - INFO - Epoch:[118/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.20
2025-03-02 13:36:18,039 - INFO - Epoch:[118/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.23
2025-03-02 13:36:22,018 - INFO - Epoch:[118/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 13:36:25,506 - INFO - Epoch:[118/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.50 loss_cvh: 3.23
2025-03-02 13:36:28,925 - INFO - Epoch:[118/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.48 loss_cvh: 3.19
2025-03-02 13:36:32,383 - INFO - Epoch:[118/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.50 loss_cvh: 3.26
2025-03-02 13:36:35,824 - INFO - Epoch:[118/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.21
2025-03-02 13:36:39,414 - INFO - Epoch:[118/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 3.22
2025-03-02 13:36:42,594 - INFO - Epoch:[118/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.40 loss_cvh: 0.79
2025-03-02 13:36:43,582 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:37:18,004 - INFO - begin training stage: [119/805]
2025-03-02 13:37:18,005 - INFO - begin training stage: [119/805]
2025-03-02 13:37:22,495 - INFO - Epoch:[119/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 3.26
2025-03-02 13:37:26,029 - INFO - Epoch:[119/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 3.19
2025-03-02 13:37:29,477 - INFO - Epoch:[119/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.18
2025-03-02 13:37:33,217 - INFO - Epoch:[119/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 3.18
2025-03-02 13:37:36,948 - INFO - Epoch:[119/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.49 loss_cvh: 3.21
2025-03-02 13:37:40,472 - INFO - Epoch:[119/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.18
2025-03-02 13:37:43,981 - INFO - Epoch:[119/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 3.20
2025-03-02 13:37:47,512 - INFO - Epoch:[119/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 3.23
2025-03-02 13:37:50,734 - INFO - Epoch:[119/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.22 loss_cvh: 0.93
2025-03-02 13:37:51,782 - INFO - now the learning rate is: 5.904900000000002e-05
2025-03-02 13:38:26,286 - INFO - begin training stage: [120/805]
2025-03-02 13:38:26,286 - INFO - begin training stage: [120/805]
2025-03-02 13:38:30,738 - INFO - Epoch:[120/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.18
2025-03-02 13:38:34,318 - INFO - Epoch:[120/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.47 loss_cvh: 3.21
2025-03-02 13:38:37,903 - INFO - Epoch:[120/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.26
2025-03-02 13:38:41,356 - INFO - Epoch:[120/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.50 loss_cvh: 3.24
2025-03-02 13:38:44,878 - INFO - Epoch:[120/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 13:38:48,480 - INFO - Epoch:[120/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.48 loss_cvh: 3.19
2025-03-02 13:38:52,051 - INFO - Epoch:[120/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.20
2025-03-02 13:38:55,566 - INFO - Epoch:[120/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.18
2025-03-02 13:38:59,039 - INFO - Epoch:[120/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.12 loss_cvh: 0.81
2025-03-02 13:39:00,104 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 13:39:35,902 - INFO - begin training stage: [121/805]
2025-03-02 13:39:35,903 - INFO - eval data number: 45600
2025-03-02 13:39:35,903 - INFO - loading eval data ......
2025-03-02 13:40:11,743 - INFO - retrieval costs: 23.498576164245605
2025-03-02 13:42:23,535 - INFO - hamming distance computation costs: 131.79194593429565
2025-03-02 13:42:32,235 - INFO - hamming ranking costs: 8.700896739959717
2025-03-02 13:42:32,236 - INFO - labels shape: (45600, 239)
2025-03-02 13:43:18,146 - INFO - similarity labels generation costs: 45.91070342063904
2025-03-02 13:43:18,255 - INFO - topK: 5:, map: 0.2916583333333333
2025-03-02 13:43:18,597 - INFO - topK: 20:, map: 0.2056268112042541
2025-03-02 13:43:19,269 - INFO - topK: 40:, map: 0.1773750888322354
2025-03-02 13:43:20,460 - INFO - topK: 60:, map: 0.161630061083325
2025-03-02 13:43:21,987 - INFO - topK: 80:, map: 0.15016773386597018
2025-03-02 13:43:23,621 - INFO - topK: 100:, map: 0.1407526281360962
2025-03-02 13:43:25,082 - INFO - begin training stage: [121/805]
2025-03-02 13:43:29,776 - INFO - Epoch:[121/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.15
2025-03-02 13:43:33,285 - INFO - Epoch:[121/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.15
2025-03-02 13:43:36,969 - INFO - Epoch:[121/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 13:43:40,508 - INFO - Epoch:[121/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.21
2025-03-02 13:43:44,212 - INFO - Epoch:[121/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.20
2025-03-02 13:43:47,872 - INFO - Epoch:[121/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.20
2025-03-02 13:43:51,518 - INFO - Epoch:[121/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.16
2025-03-02 13:43:55,161 - INFO - Epoch:[121/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.12
2025-03-02 13:43:58,545 - INFO - Epoch:[121/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.09 loss_cvh: 0.68
2025-03-02 13:43:59,529 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 13:44:34,547 - INFO - begin training stage: [122/805]
2025-03-02 13:44:34,547 - INFO - begin training stage: [122/805]
2025-03-02 13:44:38,985 - INFO - Epoch:[122/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 13:44:42,361 - INFO - Epoch:[122/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.23
2025-03-02 13:44:45,775 - INFO - Epoch:[122/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.22
2025-03-02 13:44:49,484 - INFO - Epoch:[122/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 3.15
2025-03-02 13:44:53,154 - INFO - Epoch:[122/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.21
2025-03-02 13:44:56,629 - INFO - Epoch:[122/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.15
2025-03-02 13:45:00,115 - INFO - Epoch:[122/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.21
2025-03-02 13:45:03,510 - INFO - Epoch:[122/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.48 loss_cvh: 3.21
2025-03-02 13:45:06,871 - INFO - Epoch:[122/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.17 loss_cvh: 0.69
2025-03-02 13:45:07,955 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 13:45:43,485 - INFO - begin training stage: [123/805]
2025-03-02 13:45:43,485 - INFO - begin training stage: [123/805]
2025-03-02 13:45:48,128 - INFO - Epoch:[123/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.13
2025-03-02 13:45:51,705 - INFO - Epoch:[123/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 13:45:55,104 - INFO - Epoch:[123/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 3.15
2025-03-02 13:45:58,515 - INFO - Epoch:[123/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.14
2025-03-02 13:46:02,054 - INFO - Epoch:[123/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.49 loss_cvh: 3.23
2025-03-02 13:46:05,625 - INFO - Epoch:[123/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 3.20
2025-03-02 13:46:09,212 - INFO - Epoch:[123/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 13:46:12,583 - INFO - Epoch:[123/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 13:46:15,748 - INFO - Epoch:[123/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.31 loss_cvh: 1.04
2025-03-02 13:46:16,767 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 13:46:51,359 - INFO - begin training stage: [124/805]
2025-03-02 13:46:51,359 - INFO - begin training stage: [124/805]
2025-03-02 13:46:56,036 - INFO - Epoch:[124/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.28
2025-03-02 13:46:59,625 - INFO - Epoch:[124/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.49 loss_cvh: 3.19
2025-03-02 13:47:03,321 - INFO - Epoch:[124/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.19
2025-03-02 13:47:06,947 - INFO - Epoch:[124/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.18
2025-03-02 13:47:10,549 - INFO - Epoch:[124/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 13:47:14,086 - INFO - Epoch:[124/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.20
2025-03-02 13:47:17,827 - INFO - Epoch:[124/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.14
2025-03-02 13:47:21,652 - INFO - Epoch:[124/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.18
2025-03-02 13:47:24,991 - INFO - Epoch:[124/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.27 loss_cvh: 0.82
2025-03-02 13:47:25,981 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 13:48:00,894 - INFO - begin training stage: [125/805]
2025-03-02 13:48:00,895 - INFO - begin training stage: [125/805]
2025-03-02 13:48:05,533 - INFO - Epoch:[125/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.23
2025-03-02 13:48:09,131 - INFO - Epoch:[125/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 13:48:13,140 - INFO - Epoch:[125/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 13:48:17,857 - INFO - Epoch:[125/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 13:48:23,002 - INFO - Epoch:[125/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.44 loss_cvh: 3.21
2025-03-02 13:48:28,094 - INFO - Epoch:[125/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.50 loss_cvh: 3.11
2025-03-02 13:48:33,108 - INFO - Epoch:[125/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.18
2025-03-02 13:48:38,055 - INFO - Epoch:[125/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.16
2025-03-02 13:48:42,836 - INFO - Epoch:[125/805] Step:[90/90] reconstruction_loss: 1.35 loss_vc: 1.26 loss_cvh: 0.84
2025-03-02 13:48:44,295 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 13:49:45,975 - INFO - begin training stage: [126/805]
2025-03-02 13:49:45,975 - INFO - begin training stage: [126/805]
2025-03-02 13:49:50,425 - INFO - Epoch:[126/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 3.22
2025-03-02 13:49:53,969 - INFO - Epoch:[126/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.51 loss_cvh: 3.23
2025-03-02 13:49:57,556 - INFO - Epoch:[126/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 13:50:01,121 - INFO - Epoch:[126/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.20
2025-03-02 13:50:04,568 - INFO - Epoch:[126/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 13:50:07,973 - INFO - Epoch:[126/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 13:50:11,682 - INFO - Epoch:[126/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.21
2025-03-02 13:50:15,370 - INFO - Epoch:[126/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.20
2025-03-02 13:50:18,659 - INFO - Epoch:[126/805] Step:[90/90] reconstruction_loss: 1.05 loss_vc: 1.25 loss_cvh: 0.88
2025-03-02 13:50:19,693 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 13:50:54,179 - INFO - begin training stage: [127/805]
2025-03-02 13:50:54,179 - INFO - begin training stage: [127/805]
2025-03-02 13:50:58,679 - INFO - Epoch:[127/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 13:51:02,096 - INFO - Epoch:[127/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 13:51:05,529 - INFO - Epoch:[127/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 13:51:09,116 - INFO - Epoch:[127/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 13:51:12,570 - INFO - Epoch:[127/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.20
2025-03-02 13:51:16,075 - INFO - Epoch:[127/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 13:51:19,672 - INFO - Epoch:[127/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.46 loss_cvh: 3.20
2025-03-02 13:51:23,092 - INFO - Epoch:[127/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.17
2025-03-02 13:51:26,292 - INFO - Epoch:[127/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.34 loss_cvh: 1.04
2025-03-02 13:51:27,266 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 13:52:01,780 - INFO - begin training stage: [128/805]
2025-03-02 13:52:01,780 - INFO - begin training stage: [128/805]
2025-03-02 13:52:06,382 - INFO - Epoch:[128/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.45 loss_cvh: 3.20
2025-03-02 13:52:09,862 - INFO - Epoch:[128/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.21
2025-03-02 13:52:13,568 - INFO - Epoch:[128/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.23
2025-03-02 13:52:17,083 - INFO - Epoch:[128/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.15
2025-03-02 13:52:20,709 - INFO - Epoch:[128/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.50 loss_cvh: 3.22
2025-03-02 13:52:24,413 - INFO - Epoch:[128/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.20
2025-03-02 13:52:28,009 - INFO - Epoch:[128/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 13:52:31,602 - INFO - Epoch:[128/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.48 loss_cvh: 3.18
2025-03-02 13:52:34,789 - INFO - Epoch:[128/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.23 loss_cvh: 0.73
2025-03-02 13:52:35,777 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 13:53:10,716 - INFO - begin training stage: [129/805]
2025-03-02 13:53:10,716 - INFO - begin training stage: [129/805]
2025-03-02 13:53:15,295 - INFO - Epoch:[129/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 13:53:18,722 - INFO - Epoch:[129/805] Step:[20/90] reconstruction_loss: 1.21 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 13:53:22,178 - INFO - Epoch:[129/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.16
2025-03-02 13:53:25,766 - INFO - Epoch:[129/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.16
2025-03-02 13:53:29,503 - INFO - Epoch:[129/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 13:53:33,094 - INFO - Epoch:[129/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.17
2025-03-02 13:53:36,773 - INFO - Epoch:[129/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.16
2025-03-02 13:53:40,308 - INFO - Epoch:[129/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 13:53:43,620 - INFO - Epoch:[129/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.38 loss_cvh: 0.81
2025-03-02 13:53:44,693 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 13:54:18,590 - INFO - begin training stage: [130/805]
2025-03-02 13:54:18,590 - INFO - begin training stage: [130/805]
2025-03-02 13:54:23,202 - INFO - Epoch:[130/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.13
2025-03-02 13:54:26,802 - INFO - Epoch:[130/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.24
2025-03-02 13:54:30,492 - INFO - Epoch:[130/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.21
2025-03-02 13:54:33,990 - INFO - Epoch:[130/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.20
2025-03-02 13:54:37,652 - INFO - Epoch:[130/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.45 loss_cvh: 3.12
2025-03-02 13:54:41,586 - INFO - Epoch:[130/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.16
2025-03-02 13:54:45,352 - INFO - Epoch:[130/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 13:54:48,950 - INFO - Epoch:[130/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.19
2025-03-02 13:54:52,277 - INFO - Epoch:[130/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.32 loss_cvh: 0.89
2025-03-02 13:54:53,276 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 13:55:28,405 - INFO - begin training stage: [131/805]
2025-03-02 13:55:28,406 - INFO - eval data number: 45600
2025-03-02 13:55:28,406 - INFO - loading eval data ......
2025-03-02 13:56:01,062 - INFO - retrieval costs: 20.36672878265381
2025-03-02 13:58:11,509 - INFO - hamming distance computation costs: 130.4468548297882
2025-03-02 13:58:19,858 - INFO - hamming ranking costs: 8.348343133926392
2025-03-02 13:58:19,858 - INFO - labels shape: (45600, 239)
2025-03-02 13:59:09,600 - INFO - similarity labels generation costs: 49.74184989929199
2025-03-02 13:59:09,675 - INFO - topK: 5:, map: 0.3007016666666667
2025-03-02 13:59:09,942 - INFO - topK: 20:, map: 0.21054751409538172
2025-03-02 13:59:10,462 - INFO - topK: 40:, map: 0.17978965424240492
2025-03-02 13:59:11,230 - INFO - topK: 60:, map: 0.16317608605470707
2025-03-02 13:59:12,281 - INFO - topK: 80:, map: 0.15142375378767667
2025-03-02 13:59:13,654 - INFO - topK: 100:, map: 0.1413430969258213
2025-03-02 13:59:15,365 - INFO - begin training stage: [131/805]
2025-03-02 13:59:20,526 - INFO - Epoch:[131/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.20
2025-03-02 13:59:24,315 - INFO - Epoch:[131/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.23
2025-03-02 13:59:28,023 - INFO - Epoch:[131/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.48 loss_cvh: 3.19
2025-03-02 13:59:31,617 - INFO - Epoch:[131/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.49 loss_cvh: 3.19
2025-03-02 13:59:35,161 - INFO - Epoch:[131/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.16
2025-03-02 13:59:38,973 - INFO - Epoch:[131/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.46 loss_cvh: 3.19
2025-03-02 13:59:42,655 - INFO - Epoch:[131/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.15
2025-03-02 13:59:46,445 - INFO - Epoch:[131/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.17
2025-03-02 13:59:50,101 - INFO - Epoch:[131/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.28 loss_cvh: 0.92
2025-03-02 13:59:51,469 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 14:00:28,135 - INFO - begin training stage: [132/805]
2025-03-02 14:00:28,136 - INFO - begin training stage: [132/805]
2025-03-02 14:00:33,169 - INFO - Epoch:[132/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.21
2025-03-02 14:00:36,894 - INFO - Epoch:[132/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:00:40,609 - INFO - Epoch:[132/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.16
2025-03-02 14:00:44,234 - INFO - Epoch:[132/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 14:00:48,089 - INFO - Epoch:[132/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 14:00:51,768 - INFO - Epoch:[132/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.13
2025-03-02 14:00:55,417 - INFO - Epoch:[132/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 14:00:59,115 - INFO - Epoch:[132/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 14:01:02,625 - INFO - Epoch:[132/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.19 loss_cvh: 0.56
2025-03-02 14:01:03,655 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 14:01:38,326 - INFO - begin training stage: [133/805]
2025-03-02 14:01:38,326 - INFO - begin training stage: [133/805]
2025-03-02 14:01:42,766 - INFO - Epoch:[133/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 14:01:46,208 - INFO - Epoch:[133/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 3.21
2025-03-02 14:01:49,810 - INFO - Epoch:[133/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 14:01:53,312 - INFO - Epoch:[133/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.18
2025-03-02 14:01:56,991 - INFO - Epoch:[133/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 14:02:00,595 - INFO - Epoch:[133/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 3.19
2025-03-02 14:02:04,091 - INFO - Epoch:[133/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.16
2025-03-02 14:02:07,723 - INFO - Epoch:[133/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 14:02:11,060 - INFO - Epoch:[133/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.42 loss_cvh: 0.88
2025-03-02 14:02:12,010 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 14:02:46,396 - INFO - begin training stage: [134/805]
2025-03-02 14:02:46,396 - INFO - begin training stage: [134/805]
2025-03-02 14:02:50,765 - INFO - Epoch:[134/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.51 loss_cvh: 3.18
2025-03-02 14:02:54,230 - INFO - Epoch:[134/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.16
2025-03-02 14:02:57,871 - INFO - Epoch:[134/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 14:03:01,237 - INFO - Epoch:[134/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.49 loss_cvh: 3.22
2025-03-02 14:03:04,767 - INFO - Epoch:[134/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 3.21
2025-03-02 14:03:08,204 - INFO - Epoch:[134/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 14:03:11,795 - INFO - Epoch:[134/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.16
2025-03-02 14:03:15,221 - INFO - Epoch:[134/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:03:18,429 - INFO - Epoch:[134/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.18 loss_cvh: 0.75
2025-03-02 14:03:19,420 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 14:04:23,287 - INFO - begin training stage: [135/805]
2025-03-02 14:04:23,287 - INFO - begin training stage: [135/805]
2025-03-02 14:04:29,477 - INFO - Epoch:[135/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.16
2025-03-02 14:04:34,472 - INFO - Epoch:[135/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 14:04:39,195 - INFO - Epoch:[135/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.17
2025-03-02 14:04:44,126 - INFO - Epoch:[135/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 14:04:48,924 - INFO - Epoch:[135/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.45 loss_cvh: 3.16
2025-03-02 14:04:53,727 - INFO - Epoch:[135/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 14:04:58,428 - INFO - Epoch:[135/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.47 loss_cvh: 3.13
2025-03-02 14:05:02,340 - INFO - Epoch:[135/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.14
2025-03-02 14:05:05,661 - INFO - Epoch:[135/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.28 loss_cvh: 0.90
2025-03-02 14:05:06,624 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 14:05:40,686 - INFO - begin training stage: [136/805]
2025-03-02 14:05:40,686 - INFO - begin training stage: [136/805]
2025-03-02 14:05:45,682 - INFO - Epoch:[136/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.22
2025-03-02 14:05:49,246 - INFO - Epoch:[136/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.21
2025-03-02 14:05:52,922 - INFO - Epoch:[136/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:05:56,583 - INFO - Epoch:[136/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.19
2025-03-02 14:06:00,284 - INFO - Epoch:[136/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 14:06:03,944 - INFO - Epoch:[136/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.13
2025-03-02 14:06:07,397 - INFO - Epoch:[136/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.12
2025-03-02 14:06:11,000 - INFO - Epoch:[136/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.45 loss_cvh: 3.10
2025-03-02 14:06:14,386 - INFO - Epoch:[136/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.32 loss_cvh: 0.85
2025-03-02 14:06:15,359 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 14:06:50,032 - INFO - begin training stage: [137/805]
2025-03-02 14:06:50,032 - INFO - begin training stage: [137/805]
2025-03-02 14:06:54,599 - INFO - Epoch:[137/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.17
2025-03-02 14:06:58,059 - INFO - Epoch:[137/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 14:07:01,657 - INFO - Epoch:[137/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.18
2025-03-02 14:07:05,139 - INFO - Epoch:[137/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 14:07:08,651 - INFO - Epoch:[137/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.19
2025-03-02 14:07:12,140 - INFO - Epoch:[137/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 14:07:15,617 - INFO - Epoch:[137/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.20
2025-03-02 14:07:19,196 - INFO - Epoch:[137/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 14:07:22,435 - INFO - Epoch:[137/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.18 loss_cvh: 0.71
2025-03-02 14:07:23,383 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 14:07:57,452 - INFO - begin training stage: [138/805]
2025-03-02 14:07:57,452 - INFO - begin training stage: [138/805]
2025-03-02 14:08:01,995 - INFO - Epoch:[138/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.20
2025-03-02 14:08:05,509 - INFO - Epoch:[138/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.20
2025-03-02 14:08:08,991 - INFO - Epoch:[138/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 14:08:12,741 - INFO - Epoch:[138/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 14:08:16,251 - INFO - Epoch:[138/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.46 loss_cvh: 3.15
2025-03-02 14:08:19,709 - INFO - Epoch:[138/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.46 loss_cvh: 3.16
2025-03-02 14:08:23,225 - INFO - Epoch:[138/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:08:26,656 - INFO - Epoch:[138/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 14:08:29,924 - INFO - Epoch:[138/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.55 loss_cvh: 0.94
2025-03-02 14:08:30,978 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 14:09:05,129 - INFO - begin training stage: [139/805]
2025-03-02 14:09:05,129 - INFO - begin training stage: [139/805]
2025-03-02 14:09:09,601 - INFO - Epoch:[139/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.20
2025-03-02 14:09:13,071 - INFO - Epoch:[139/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 14:09:16,523 - INFO - Epoch:[139/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.16
2025-03-02 14:09:19,980 - INFO - Epoch:[139/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.18
2025-03-02 14:09:23,618 - INFO - Epoch:[139/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.12
2025-03-02 14:09:27,107 - INFO - Epoch:[139/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 3.15
2025-03-02 14:09:30,618 - INFO - Epoch:[139/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.49 loss_cvh: 3.20
2025-03-02 14:09:34,080 - INFO - Epoch:[139/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:09:37,263 - INFO - Epoch:[139/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.51 loss_cvh: 1.00
2025-03-02 14:09:38,243 - INFO - now the learning rate is: 5.314410000000002e-05
2025-03-02 14:10:12,911 - INFO - begin training stage: [140/805]
2025-03-02 14:10:12,911 - INFO - begin training stage: [140/805]
2025-03-02 14:10:17,480 - INFO - Epoch:[140/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 14:10:20,955 - INFO - Epoch:[140/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:10:24,475 - INFO - Epoch:[140/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.22
2025-03-02 14:10:27,980 - INFO - Epoch:[140/805] Step:[40/90] reconstruction_loss: 1.21 loss_vc: 4.46 loss_cvh: 3.16
2025-03-02 14:10:31,500 - INFO - Epoch:[140/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.20
2025-03-02 14:10:35,004 - INFO - Epoch:[140/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 14:10:38,575 - INFO - Epoch:[140/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.21
2025-03-02 14:10:42,163 - INFO - Epoch:[140/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 3.26
2025-03-02 14:10:45,441 - INFO - Epoch:[140/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.28 loss_cvh: 0.67
2025-03-02 14:10:46,423 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:11:20,571 - INFO - begin training stage: [141/805]
2025-03-02 14:11:20,572 - INFO - eval data number: 45600
2025-03-02 14:11:20,572 - INFO - loading eval data ......
2025-03-02 14:11:53,127 - INFO - retrieval costs: 20.33449077606201
2025-03-02 14:14:01,385 - INFO - hamming distance computation costs: 128.25795459747314
2025-03-02 14:14:09,110 - INFO - hamming ranking costs: 7.724998474121094
2025-03-02 14:14:09,110 - INFO - labels shape: (45600, 239)
2025-03-02 14:14:56,751 - INFO - similarity labels generation costs: 47.641257524490356
2025-03-02 14:14:56,826 - INFO - topK: 5:, map: 0.2976325000000001
2025-03-02 14:14:57,088 - INFO - topK: 20:, map: 0.21216773621996335
2025-03-02 14:14:57,594 - INFO - topK: 40:, map: 0.1817277594051493
2025-03-02 14:14:58,358 - INFO - topK: 60:, map: 0.1656171658108235
2025-03-02 14:14:59,374 - INFO - topK: 80:, map: 0.15405284933464516
2025-03-02 14:15:00,639 - INFO - topK: 100:, map: 0.1440916002880427
2025-03-02 14:15:01,847 - INFO - begin training stage: [141/805]
2025-03-02 14:15:06,633 - INFO - Epoch:[141/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 14:15:10,404 - INFO - Epoch:[141/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.49 loss_cvh: 3.18
2025-03-02 14:15:13,945 - INFO - Epoch:[141/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.47 loss_cvh: 3.14
2025-03-02 14:15:17,630 - INFO - Epoch:[141/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.18
2025-03-02 14:15:21,281 - INFO - Epoch:[141/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.25
2025-03-02 14:15:25,044 - INFO - Epoch:[141/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 14:15:28,636 - INFO - Epoch:[141/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.21
2025-03-02 14:15:32,261 - INFO - Epoch:[141/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 14:15:35,572 - INFO - Epoch:[141/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.39 loss_cvh: 0.91
2025-03-02 14:15:36,594 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:16:11,029 - INFO - begin training stage: [142/805]
2025-03-02 14:16:11,030 - INFO - begin training stage: [142/805]
2025-03-02 14:16:15,482 - INFO - Epoch:[142/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 14:16:18,963 - INFO - Epoch:[142/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:16:22,228 - INFO - Epoch:[142/805] Step:[30/90] reconstruction_loss: 1.21 loss_vc: 4.48 loss_cvh: 3.17
2025-03-02 14:16:25,509 - INFO - Epoch:[142/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.46 loss_cvh: 3.14
2025-03-02 14:16:28,848 - INFO - Epoch:[142/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 3.14
2025-03-02 14:16:32,213 - INFO - Epoch:[142/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.21
2025-03-02 14:16:35,540 - INFO - Epoch:[142/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:16:38,851 - INFO - Epoch:[142/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 14:16:41,951 - INFO - Epoch:[142/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.24 loss_cvh: 0.92
2025-03-02 14:16:42,881 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:17:15,331 - INFO - begin training stage: [143/805]
2025-03-02 14:17:15,331 - INFO - begin training stage: [143/805]
2025-03-02 14:17:19,449 - INFO - Epoch:[143/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.13
2025-03-02 14:17:22,725 - INFO - Epoch:[143/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.10
2025-03-02 14:17:25,979 - INFO - Epoch:[143/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:17:29,218 - INFO - Epoch:[143/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 14:17:32,536 - INFO - Epoch:[143/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 14:17:35,920 - INFO - Epoch:[143/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.11
2025-03-02 14:17:39,216 - INFO - Epoch:[143/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.12
2025-03-02 14:17:42,491 - INFO - Epoch:[143/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.20
2025-03-02 14:17:45,576 - INFO - Epoch:[143/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.32 loss_cvh: 0.73
2025-03-02 14:17:46,474 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:18:18,788 - INFO - begin training stage: [144/805]
2025-03-02 14:18:18,788 - INFO - begin training stage: [144/805]
2025-03-02 14:18:22,940 - INFO - Epoch:[144/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 14:18:26,496 - INFO - Epoch:[144/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 14:18:31,166 - INFO - Epoch:[144/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.15
2025-03-02 14:18:35,764 - INFO - Epoch:[144/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.11
2025-03-02 14:18:40,203 - INFO - Epoch:[144/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 14:18:44,928 - INFO - Epoch:[144/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 14:18:49,462 - INFO - Epoch:[144/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.23
2025-03-02 14:18:54,203 - INFO - Epoch:[144/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 14:18:58,372 - INFO - Epoch:[144/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.32 loss_cvh: 0.92
2025-03-02 14:18:59,756 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:19:51,160 - INFO - begin training stage: [145/805]
2025-03-02 14:19:51,160 - INFO - begin training stage: [145/805]
2025-03-02 14:19:55,420 - INFO - Epoch:[145/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.22
2025-03-02 14:19:58,697 - INFO - Epoch:[145/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 14:20:02,008 - INFO - Epoch:[145/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 14:20:05,279 - INFO - Epoch:[145/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:20:08,550 - INFO - Epoch:[145/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.16
2025-03-02 14:20:12,106 - INFO - Epoch:[145/805] Step:[60/90] reconstruction_loss: 1.21 loss_vc: 4.47 loss_cvh: 3.15
2025-03-02 14:20:15,536 - INFO - Epoch:[145/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 14:20:18,947 - INFO - Epoch:[145/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 14:20:22,191 - INFO - Epoch:[145/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.15 loss_cvh: 0.85
2025-03-02 14:20:23,145 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:20:56,105 - INFO - begin training stage: [146/805]
2025-03-02 14:20:56,106 - INFO - begin training stage: [146/805]
2025-03-02 14:21:00,302 - INFO - Epoch:[146/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.16
2025-03-02 14:21:03,614 - INFO - Epoch:[146/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.12
2025-03-02 14:21:06,946 - INFO - Epoch:[146/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.21
2025-03-02 14:21:10,249 - INFO - Epoch:[146/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.10
2025-03-02 14:21:13,632 - INFO - Epoch:[146/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 14:21:17,000 - INFO - Epoch:[146/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.15
2025-03-02 14:21:20,394 - INFO - Epoch:[146/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.46 loss_cvh: 3.20
2025-03-02 14:21:23,720 - INFO - Epoch:[146/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.17
2025-03-02 14:21:26,899 - INFO - Epoch:[146/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.28 loss_cvh: 0.66
2025-03-02 14:21:27,925 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:22:01,124 - INFO - begin training stage: [147/805]
2025-03-02 14:22:01,124 - INFO - begin training stage: [147/805]
2025-03-02 14:22:05,454 - INFO - Epoch:[147/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.49 loss_cvh: 3.25
2025-03-02 14:22:08,912 - INFO - Epoch:[147/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 14:22:12,366 - INFO - Epoch:[147/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.17
2025-03-02 14:22:15,711 - INFO - Epoch:[147/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.17
2025-03-02 14:22:19,063 - INFO - Epoch:[147/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 14:22:22,409 - INFO - Epoch:[147/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.20
2025-03-02 14:22:25,832 - INFO - Epoch:[147/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.18
2025-03-02 14:22:29,127 - INFO - Epoch:[147/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:22:32,208 - INFO - Epoch:[147/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.37 loss_cvh: 0.99
2025-03-02 14:22:33,208 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:23:06,268 - INFO - begin training stage: [148/805]
2025-03-02 14:23:06,269 - INFO - begin training stage: [148/805]
2025-03-02 14:23:10,527 - INFO - Epoch:[148/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 14:23:13,852 - INFO - Epoch:[148/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.22
2025-03-02 14:23:17,197 - INFO - Epoch:[148/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.12
2025-03-02 14:23:20,634 - INFO - Epoch:[148/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 14:23:23,907 - INFO - Epoch:[148/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.16
2025-03-02 14:23:27,266 - INFO - Epoch:[148/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.23
2025-03-02 14:23:30,639 - INFO - Epoch:[148/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.21
2025-03-02 14:23:33,948 - INFO - Epoch:[148/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 14:23:37,173 - INFO - Epoch:[148/805] Step:[90/90] reconstruction_loss: 1.29 loss_vc: 1.25 loss_cvh: 0.87
2025-03-02 14:23:38,236 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:24:11,693 - INFO - begin training stage: [149/805]
2025-03-02 14:24:11,694 - INFO - begin training stage: [149/805]
2025-03-02 14:24:15,950 - INFO - Epoch:[149/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.22
2025-03-02 14:24:19,580 - INFO - Epoch:[149/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 14:24:22,988 - INFO - Epoch:[149/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.11
2025-03-02 14:24:26,700 - INFO - Epoch:[149/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.21
2025-03-02 14:24:30,305 - INFO - Epoch:[149/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:24:33,789 - INFO - Epoch:[149/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 14:24:37,253 - INFO - Epoch:[149/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 14:24:40,985 - INFO - Epoch:[149/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 14:24:44,242 - INFO - Epoch:[149/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.15 loss_cvh: 0.75
2025-03-02 14:24:45,308 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:25:19,050 - INFO - begin training stage: [150/805]
2025-03-02 14:25:19,050 - INFO - begin training stage: [150/805]
2025-03-02 14:25:23,357 - INFO - Epoch:[150/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.24
2025-03-02 14:25:26,868 - INFO - Epoch:[150/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.19
2025-03-02 14:25:30,321 - INFO - Epoch:[150/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 14:25:33,714 - INFO - Epoch:[150/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.46 loss_cvh: 3.15
2025-03-02 14:25:37,080 - INFO - Epoch:[150/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 14:25:40,452 - INFO - Epoch:[150/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.18
2025-03-02 14:25:43,853 - INFO - Epoch:[150/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.21
2025-03-02 14:25:47,228 - INFO - Epoch:[150/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.26
2025-03-02 14:25:50,404 - INFO - Epoch:[150/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.10 loss_cvh: 0.85
2025-03-02 14:25:51,355 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:26:24,649 - INFO - begin training stage: [151/805]
2025-03-02 14:26:24,650 - INFO - eval data number: 45600
2025-03-02 14:26:24,650 - INFO - loading eval data ......
2025-03-02 14:26:55,376 - INFO - retrieval costs: 19.11039710044861
2025-03-02 14:28:30,525 - INFO - hamming distance computation costs: 95.14895248413086
2025-03-02 14:28:38,328 - INFO - hamming ranking costs: 7.803177118301392
2025-03-02 14:28:38,328 - INFO - labels shape: (45600, 239)
2025-03-02 14:29:39,730 - INFO - similarity labels generation costs: 61.40214657783508
2025-03-02 14:29:39,811 - INFO - topK: 5:, map: 0.3032991666666667
2025-03-02 14:29:40,069 - INFO - topK: 20:, map: 0.21584215377877627
2025-03-02 14:29:40,684 - INFO - topK: 40:, map: 0.18593856764011504
2025-03-02 14:29:41,429 - INFO - topK: 60:, map: 0.17000292124057012
2025-03-02 14:29:42,409 - INFO - topK: 80:, map: 0.1577992204142237
2025-03-02 14:29:43,640 - INFO - topK: 100:, map: 0.14761932052094823
2025-03-02 14:29:44,960 - INFO - begin training stage: [151/805]
2025-03-02 14:29:49,509 - INFO - Epoch:[151/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.20
2025-03-02 14:29:52,931 - INFO - Epoch:[151/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 14:29:56,340 - INFO - Epoch:[151/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:29:59,694 - INFO - Epoch:[151/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.16
2025-03-02 14:30:03,026 - INFO - Epoch:[151/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.17
2025-03-02 14:30:06,463 - INFO - Epoch:[151/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 14:30:09,836 - INFO - Epoch:[151/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.47 loss_cvh: 3.17
2025-03-02 14:30:13,166 - INFO - Epoch:[151/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.15
2025-03-02 14:30:16,300 - INFO - Epoch:[151/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.48 loss_cvh: 0.71
2025-03-02 14:30:17,215 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:30:51,098 - INFO - begin training stage: [152/805]
2025-03-02 14:30:51,098 - INFO - begin training stage: [152/805]
2025-03-02 14:30:55,389 - INFO - Epoch:[152/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:30:58,795 - INFO - Epoch:[152/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.12
2025-03-02 14:31:02,195 - INFO - Epoch:[152/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.20
2025-03-02 14:31:05,611 - INFO - Epoch:[152/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.18
2025-03-02 14:31:08,948 - INFO - Epoch:[152/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:31:12,340 - INFO - Epoch:[152/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 14:31:15,768 - INFO - Epoch:[152/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 14:31:19,167 - INFO - Epoch:[152/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 14:31:22,303 - INFO - Epoch:[152/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.18 loss_cvh: 0.67
2025-03-02 14:31:23,268 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:31:57,252 - INFO - begin training stage: [153/805]
2025-03-02 14:31:57,253 - INFO - begin training stage: [153/805]
2025-03-02 14:32:01,839 - INFO - Epoch:[153/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.12
2025-03-02 14:32:05,333 - INFO - Epoch:[153/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.48 loss_cvh: 3.14
2025-03-02 14:32:08,723 - INFO - Epoch:[153/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 14:32:12,168 - INFO - Epoch:[153/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.17
2025-03-02 14:32:15,700 - INFO - Epoch:[153/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 14:32:19,098 - INFO - Epoch:[153/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 14:32:22,599 - INFO - Epoch:[153/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.17
2025-03-02 14:32:26,097 - INFO - Epoch:[153/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.14
2025-03-02 14:32:29,168 - INFO - Epoch:[153/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.13 loss_cvh: 0.72
2025-03-02 14:32:30,249 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:33:26,174 - INFO - begin training stage: [154/805]
2025-03-02 14:33:26,174 - INFO - begin training stage: [154/805]
2025-03-02 14:33:32,232 - INFO - Epoch:[154/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 14:33:37,066 - INFO - Epoch:[154/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:33:41,627 - INFO - Epoch:[154/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.09
2025-03-02 14:33:46,126 - INFO - Epoch:[154/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.12
2025-03-02 14:33:50,712 - INFO - Epoch:[154/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.47 loss_cvh: 3.11
2025-03-02 14:33:55,412 - INFO - Epoch:[154/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:34:00,181 - INFO - Epoch:[154/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 14:34:05,048 - INFO - Epoch:[154/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.21
2025-03-02 14:34:09,376 - INFO - Epoch:[154/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.34 loss_cvh: 0.86
2025-03-02 14:34:10,955 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:34:47,660 - INFO - begin training stage: [155/805]
2025-03-02 14:34:47,660 - INFO - begin training stage: [155/805]
2025-03-02 14:34:51,988 - INFO - Epoch:[155/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.15
2025-03-02 14:34:55,396 - INFO - Epoch:[155/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.18
2025-03-02 14:34:58,808 - INFO - Epoch:[155/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.48 loss_cvh: 3.14
2025-03-02 14:35:02,136 - INFO - Epoch:[155/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 14:35:05,512 - INFO - Epoch:[155/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:35:08,882 - INFO - Epoch:[155/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.14
2025-03-02 14:35:12,356 - INFO - Epoch:[155/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:35:15,772 - INFO - Epoch:[155/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.10
2025-03-02 14:35:19,002 - INFO - Epoch:[155/805] Step:[90/90] reconstruction_loss: 1.00 loss_vc: 1.38 loss_cvh: 0.83
2025-03-02 14:35:19,970 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:35:53,335 - INFO - begin training stage: [156/805]
2025-03-02 14:35:53,335 - INFO - begin training stage: [156/805]
2025-03-02 14:35:57,890 - INFO - Epoch:[156/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.27
2025-03-02 14:36:01,518 - INFO - Epoch:[156/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.21
2025-03-02 14:36:05,222 - INFO - Epoch:[156/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.16
2025-03-02 14:36:08,685 - INFO - Epoch:[156/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.18
2025-03-02 14:36:12,166 - INFO - Epoch:[156/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.20
2025-03-02 14:36:15,772 - INFO - Epoch:[156/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.21
2025-03-02 14:36:19,498 - INFO - Epoch:[156/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 14:36:22,939 - INFO - Epoch:[156/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.19
2025-03-02 14:36:26,105 - INFO - Epoch:[156/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.28 loss_cvh: 0.86
2025-03-02 14:36:27,059 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:37:00,518 - INFO - begin training stage: [157/805]
2025-03-02 14:37:00,518 - INFO - begin training stage: [157/805]
2025-03-02 14:37:04,995 - INFO - Epoch:[157/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 14:37:08,470 - INFO - Epoch:[157/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.21
2025-03-02 14:37:11,916 - INFO - Epoch:[157/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.21
2025-03-02 14:37:15,373 - INFO - Epoch:[157/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.18
2025-03-02 14:37:18,807 - INFO - Epoch:[157/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.18
2025-03-02 14:37:22,372 - INFO - Epoch:[157/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.19
2025-03-02 14:37:26,146 - INFO - Epoch:[157/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 14:37:29,457 - INFO - Epoch:[157/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.19
2025-03-02 14:37:32,573 - INFO - Epoch:[157/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.31 loss_cvh: 0.79
2025-03-02 14:37:33,536 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:38:06,854 - INFO - begin training stage: [158/805]
2025-03-02 14:38:06,854 - INFO - begin training stage: [158/805]
2025-03-02 14:38:11,203 - INFO - Epoch:[158/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 14:38:14,542 - INFO - Epoch:[158/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.20
2025-03-02 14:38:18,061 - INFO - Epoch:[158/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.21
2025-03-02 14:38:21,396 - INFO - Epoch:[158/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 14:38:24,781 - INFO - Epoch:[158/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 14:38:28,175 - INFO - Epoch:[158/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.20
2025-03-02 14:38:31,574 - INFO - Epoch:[158/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.18
2025-03-02 14:38:35,145 - INFO - Epoch:[158/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.20
2025-03-02 14:38:38,367 - INFO - Epoch:[158/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.28 loss_cvh: 0.87
2025-03-02 14:38:39,301 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:39:12,925 - INFO - begin training stage: [159/805]
2025-03-02 14:39:12,926 - INFO - begin training stage: [159/805]
2025-03-02 14:39:17,191 - INFO - Epoch:[159/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.15
2025-03-02 14:39:20,630 - INFO - Epoch:[159/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.18
2025-03-02 14:39:24,023 - INFO - Epoch:[159/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:39:27,424 - INFO - Epoch:[159/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.19
2025-03-02 14:39:30,968 - INFO - Epoch:[159/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 14:39:34,415 - INFO - Epoch:[159/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 14:39:37,825 - INFO - Epoch:[159/805] Step:[70/90] reconstruction_loss: 1.21 loss_vc: 4.45 loss_cvh: 3.18
2025-03-02 14:39:41,297 - INFO - Epoch:[159/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 14:39:44,455 - INFO - Epoch:[159/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.35 loss_cvh: 0.89
2025-03-02 14:39:45,417 - INFO - now the learning rate is: 4.782969000000002e-05
2025-03-02 14:40:19,314 - INFO - begin training stage: [160/805]
2025-03-02 14:40:19,314 - INFO - begin training stage: [160/805]
2025-03-02 14:40:23,598 - INFO - Epoch:[160/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.12
2025-03-02 14:40:27,039 - INFO - Epoch:[160/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.48 loss_cvh: 3.18
2025-03-02 14:40:30,436 - INFO - Epoch:[160/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.18
2025-03-02 14:40:33,872 - INFO - Epoch:[160/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 14:40:37,350 - INFO - Epoch:[160/805] Step:[50/90] reconstruction_loss: 1.21 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 14:40:41,084 - INFO - Epoch:[160/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 14:40:44,522 - INFO - Epoch:[160/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.46 loss_cvh: 3.19
2025-03-02 14:40:47,850 - INFO - Epoch:[160/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 14:40:51,022 - INFO - Epoch:[160/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.28 loss_cvh: 1.01
2025-03-02 14:40:51,978 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 14:41:25,321 - INFO - begin training stage: [161/805]
2025-03-02 14:41:25,322 - INFO - eval data number: 45600
2025-03-02 14:41:25,322 - INFO - loading eval data ......
2025-03-02 14:41:56,280 - INFO - retrieval costs: 19.52883219718933
2025-03-02 14:43:18,349 - INFO - hamming distance computation costs: 82.06851172447205
2025-03-02 14:43:26,399 - INFO - hamming ranking costs: 8.050033569335938
2025-03-02 14:43:26,399 - INFO - labels shape: (45600, 239)
2025-03-02 14:44:27,990 - INFO - similarity labels generation costs: 61.590713024139404
2025-03-02 14:44:28,119 - INFO - topK: 5:, map: 0.3001174999999999
2025-03-02 14:44:28,570 - INFO - topK: 20:, map: 0.21425597049971226
2025-03-02 14:44:29,450 - INFO - topK: 40:, map: 0.18472346582975574
2025-03-02 14:44:30,757 - INFO - topK: 60:, map: 0.16870406538977256
2025-03-02 14:44:32,373 - INFO - topK: 80:, map: 0.15654254036893914
2025-03-02 14:44:33,647 - INFO - topK: 100:, map: 0.14608614480147947
2025-03-02 14:44:34,886 - INFO - begin training stage: [161/805]
2025-03-02 14:44:39,457 - INFO - Epoch:[161/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:44:43,097 - INFO - Epoch:[161/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 14:44:46,537 - INFO - Epoch:[161/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.17
2025-03-02 14:44:49,963 - INFO - Epoch:[161/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 14:44:53,412 - INFO - Epoch:[161/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 14:44:56,972 - INFO - Epoch:[161/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:45:00,578 - INFO - Epoch:[161/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 14:45:04,081 - INFO - Epoch:[161/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.46 loss_cvh: 3.14
2025-03-02 14:45:07,192 - INFO - Epoch:[161/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.15 loss_cvh: 0.63
2025-03-02 14:45:08,512 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 14:45:42,149 - INFO - begin training stage: [162/805]
2025-03-02 14:45:42,149 - INFO - begin training stage: [162/805]
2025-03-02 14:45:46,678 - INFO - Epoch:[162/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.15
2025-03-02 14:45:50,087 - INFO - Epoch:[162/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 14:45:53,503 - INFO - Epoch:[162/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 14:45:57,059 - INFO - Epoch:[162/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 14:46:00,368 - INFO - Epoch:[162/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.49 loss_cvh: 3.21
2025-03-02 14:46:03,809 - INFO - Epoch:[162/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 14:46:07,214 - INFO - Epoch:[162/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 14:46:10,613 - INFO - Epoch:[162/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.45 loss_cvh: 3.18
2025-03-02 14:46:13,759 - INFO - Epoch:[162/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.43 loss_cvh: 0.95
2025-03-02 14:46:14,683 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 14:46:49,162 - INFO - begin training stage: [163/805]
2025-03-02 14:46:49,162 - INFO - begin training stage: [163/805]
2025-03-02 14:46:53,554 - INFO - Epoch:[163/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:46:57,038 - INFO - Epoch:[163/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 14:47:00,447 - INFO - Epoch:[163/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.14
2025-03-02 14:47:03,984 - INFO - Epoch:[163/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 14:47:07,437 - INFO - Epoch:[163/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 14:47:11,003 - INFO - Epoch:[163/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 14:47:14,575 - INFO - Epoch:[163/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 3.10
2025-03-02 14:47:18,053 - INFO - Epoch:[163/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.49 loss_cvh: 3.19
2025-03-02 14:47:21,430 - INFO - Epoch:[163/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.03 loss_cvh: 0.77
2025-03-02 14:47:22,788 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 14:48:30,736 - INFO - begin training stage: [164/805]
2025-03-02 14:48:30,737 - INFO - begin training stage: [164/805]
2025-03-02 14:48:36,852 - INFO - Epoch:[164/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.20
2025-03-02 14:48:41,892 - INFO - Epoch:[164/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 14:48:46,394 - INFO - Epoch:[164/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 14:48:49,902 - INFO - Epoch:[164/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 14:48:53,269 - INFO - Epoch:[164/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 14:48:56,682 - INFO - Epoch:[164/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 14:49:00,222 - INFO - Epoch:[164/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 14:49:03,599 - INFO - Epoch:[164/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:49:06,774 - INFO - Epoch:[164/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.35 loss_cvh: 1.05
2025-03-02 14:49:07,701 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 14:49:42,452 - INFO - begin training stage: [165/805]
2025-03-02 14:49:42,452 - INFO - begin training stage: [165/805]
2025-03-02 14:49:46,811 - INFO - Epoch:[165/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 14:49:50,174 - INFO - Epoch:[165/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 14:49:53,674 - INFO - Epoch:[165/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.17
2025-03-02 14:49:57,051 - INFO - Epoch:[165/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.09
2025-03-02 14:50:00,482 - INFO - Epoch:[165/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.08
2025-03-02 14:50:03,979 - INFO - Epoch:[165/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 14:50:07,384 - INFO - Epoch:[165/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.18
2025-03-02 14:50:10,853 - INFO - Epoch:[165/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 14:50:13,993 - INFO - Epoch:[165/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.32 loss_cvh: 0.88
2025-03-02 14:50:14,966 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 14:50:49,141 - INFO - begin training stage: [166/805]
2025-03-02 14:50:49,141 - INFO - begin training stage: [166/805]
2025-03-02 14:50:53,449 - INFO - Epoch:[166/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.16
2025-03-02 14:50:56,843 - INFO - Epoch:[166/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.46 loss_cvh: 3.16
2025-03-02 14:51:00,303 - INFO - Epoch:[166/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 14:51:03,730 - INFO - Epoch:[166/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 14:51:07,184 - INFO - Epoch:[166/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.08
2025-03-02 14:51:10,613 - INFO - Epoch:[166/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 14:51:14,020 - INFO - Epoch:[166/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 14:51:17,414 - INFO - Epoch:[166/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.12
2025-03-02 14:51:20,659 - INFO - Epoch:[166/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.24 loss_cvh: 0.83
2025-03-02 14:51:21,669 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 14:51:56,288 - INFO - begin training stage: [167/805]
2025-03-02 14:51:56,288 - INFO - begin training stage: [167/805]
2025-03-02 14:52:00,641 - INFO - Epoch:[167/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.17
2025-03-02 14:52:04,210 - INFO - Epoch:[167/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.13
2025-03-02 14:52:07,600 - INFO - Epoch:[167/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.19
2025-03-02 14:52:10,964 - INFO - Epoch:[167/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 14:52:14,353 - INFO - Epoch:[167/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 14:52:17,796 - INFO - Epoch:[167/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 14:52:21,230 - INFO - Epoch:[167/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.48 loss_cvh: 3.17
2025-03-02 14:52:24,616 - INFO - Epoch:[167/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 14:52:27,833 - INFO - Epoch:[167/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.39 loss_cvh: 1.00
2025-03-02 14:52:28,803 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 14:53:02,857 - INFO - begin training stage: [168/805]
2025-03-02 14:53:02,858 - INFO - begin training stage: [168/805]
2025-03-02 14:53:07,301 - INFO - Epoch:[168/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.22
2025-03-02 14:53:10,798 - INFO - Epoch:[168/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 14:53:14,225 - INFO - Epoch:[168/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.12
2025-03-02 14:53:17,602 - INFO - Epoch:[168/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 14:53:21,024 - INFO - Epoch:[168/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.15
2025-03-02 14:53:24,532 - INFO - Epoch:[168/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.19
2025-03-02 14:53:27,991 - INFO - Epoch:[168/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 14:53:31,464 - INFO - Epoch:[168/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 14:53:34,647 - INFO - Epoch:[168/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.32 loss_cvh: 0.94
2025-03-02 14:53:35,594 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 14:54:10,087 - INFO - begin training stage: [169/805]
2025-03-02 14:54:10,087 - INFO - begin training stage: [169/805]
2025-03-02 14:54:14,427 - INFO - Epoch:[169/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 14:54:17,947 - INFO - Epoch:[169/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 14:54:21,381 - INFO - Epoch:[169/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.14
2025-03-02 14:54:24,784 - INFO - Epoch:[169/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 14:54:28,331 - INFO - Epoch:[169/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 14:54:31,800 - INFO - Epoch:[169/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 14:54:35,264 - INFO - Epoch:[169/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.47 loss_cvh: 3.21
2025-03-02 14:54:38,674 - INFO - Epoch:[169/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 14:54:41,809 - INFO - Epoch:[169/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.30 loss_cvh: 0.78
2025-03-02 14:54:42,758 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 14:55:16,539 - INFO - begin training stage: [170/805]
2025-03-02 14:55:16,539 - INFO - begin training stage: [170/805]
2025-03-02 14:55:20,803 - INFO - Epoch:[170/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.15
2025-03-02 14:55:24,211 - INFO - Epoch:[170/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.48 loss_cvh: 3.16
2025-03-02 14:55:27,766 - INFO - Epoch:[170/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 14:55:31,310 - INFO - Epoch:[170/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 14:55:34,681 - INFO - Epoch:[170/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.10
2025-03-02 14:55:38,098 - INFO - Epoch:[170/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.23
2025-03-02 14:55:41,509 - INFO - Epoch:[170/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 14:55:45,138 - INFO - Epoch:[170/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 14:55:48,316 - INFO - Epoch:[170/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.44 loss_cvh: 1.00
2025-03-02 14:55:49,373 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 14:56:23,334 - INFO - begin training stage: [171/805]
2025-03-02 14:56:23,335 - INFO - eval data number: 45600
2025-03-02 14:56:23,335 - INFO - loading eval data ......
2025-03-02 14:56:57,242 - INFO - retrieval costs: 22.20771598815918
2025-03-02 14:58:32,467 - INFO - hamming distance computation costs: 95.22467112541199
2025-03-02 14:58:40,141 - INFO - hamming ranking costs: 7.673931121826172
2025-03-02 14:58:40,141 - INFO - labels shape: (45600, 239)
2025-03-02 14:59:39,271 - INFO - similarity labels generation costs: 59.13080835342407
2025-03-02 14:59:39,348 - INFO - topK: 5:, map: 0.31201750000000006
2025-03-02 14:59:39,618 - INFO - topK: 20:, map: 0.2225393091598911
2025-03-02 14:59:40,142 - INFO - topK: 40:, map: 0.19153336717506414
2025-03-02 14:59:41,005 - INFO - topK: 60:, map: 0.1747196078529668
2025-03-02 14:59:42,321 - INFO - topK: 80:, map: 0.1616761244537501
2025-03-02 14:59:43,945 - INFO - topK: 100:, map: 0.151515502412349
2025-03-02 14:59:45,413 - INFO - begin training stage: [171/805]
2025-03-02 14:59:49,782 - INFO - Epoch:[171/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.12
2025-03-02 14:59:53,194 - INFO - Epoch:[171/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 14:59:56,613 - INFO - Epoch:[171/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 15:00:00,087 - INFO - Epoch:[171/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 15:00:03,507 - INFO - Epoch:[171/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.21
2025-03-02 15:00:06,936 - INFO - Epoch:[171/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.10
2025-03-02 15:00:10,357 - INFO - Epoch:[171/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 15:00:13,733 - INFO - Epoch:[171/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 15:00:16,988 - INFO - Epoch:[171/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.36 loss_cvh: 0.69
2025-03-02 15:00:17,897 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 15:00:52,399 - INFO - begin training stage: [172/805]
2025-03-02 15:00:52,400 - INFO - begin training stage: [172/805]
2025-03-02 15:00:57,153 - INFO - Epoch:[172/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.12
2025-03-02 15:01:00,864 - INFO - Epoch:[172/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.19
2025-03-02 15:01:04,513 - INFO - Epoch:[172/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.17
2025-03-02 15:01:08,319 - INFO - Epoch:[172/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 15:01:11,769 - INFO - Epoch:[172/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 15:01:15,291 - INFO - Epoch:[172/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 15:01:18,767 - INFO - Epoch:[172/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.09
2025-03-02 15:01:22,189 - INFO - Epoch:[172/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 15:01:25,400 - INFO - Epoch:[172/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.19 loss_cvh: 0.62
2025-03-02 15:01:27,023 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 15:02:00,583 - INFO - begin training stage: [173/805]
2025-03-02 15:02:00,584 - INFO - begin training stage: [173/805]
2025-03-02 15:02:04,911 - INFO - Epoch:[173/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 15:02:08,412 - INFO - Epoch:[173/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 15:02:12,602 - INFO - Epoch:[173/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.19
2025-03-02 15:02:17,337 - INFO - Epoch:[173/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.18
2025-03-02 15:02:22,017 - INFO - Epoch:[173/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.17
2025-03-02 15:02:26,702 - INFO - Epoch:[173/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.46 loss_cvh: 3.10
2025-03-02 15:02:31,587 - INFO - Epoch:[173/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 15:02:36,228 - INFO - Epoch:[173/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 15:02:40,915 - INFO - Epoch:[173/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.31 loss_cvh: 0.94
2025-03-02 15:02:42,328 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 15:03:33,449 - INFO - begin training stage: [174/805]
2025-03-02 15:03:33,449 - INFO - begin training stage: [174/805]
2025-03-02 15:03:37,742 - INFO - Epoch:[174/805] Step:[10/90] reconstruction_loss: 1.21 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 15:03:41,134 - INFO - Epoch:[174/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.21
2025-03-02 15:03:44,506 - INFO - Epoch:[174/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 15:03:47,878 - INFO - Epoch:[174/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.45 loss_cvh: 3.16
2025-03-02 15:03:51,232 - INFO - Epoch:[174/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.18
2025-03-02 15:03:54,755 - INFO - Epoch:[174/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 15:03:58,273 - INFO - Epoch:[174/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.16
2025-03-02 15:04:01,715 - INFO - Epoch:[174/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 15:04:04,904 - INFO - Epoch:[174/805] Step:[90/90] reconstruction_loss: 0.99 loss_vc: 1.21 loss_cvh: 0.89
2025-03-02 15:04:05,831 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 15:04:39,276 - INFO - begin training stage: [175/805]
2025-03-02 15:04:39,276 - INFO - begin training stage: [175/805]
2025-03-02 15:04:43,613 - INFO - Epoch:[175/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 15:04:46,985 - INFO - Epoch:[175/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 15:04:50,426 - INFO - Epoch:[175/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 15:04:53,901 - INFO - Epoch:[175/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 15:04:57,404 - INFO - Epoch:[175/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 15:05:00,750 - INFO - Epoch:[175/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 15:05:04,168 - INFO - Epoch:[175/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.14
2025-03-02 15:05:07,583 - INFO - Epoch:[175/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.14
2025-03-02 15:05:10,864 - INFO - Epoch:[175/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.12 loss_cvh: 0.64
2025-03-02 15:05:12,186 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 15:05:45,944 - INFO - begin training stage: [176/805]
2025-03-02 15:05:45,944 - INFO - begin training stage: [176/805]
2025-03-02 15:05:50,290 - INFO - Epoch:[176/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.12
2025-03-02 15:05:53,695 - INFO - Epoch:[176/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 15:05:57,052 - INFO - Epoch:[176/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.17
2025-03-02 15:06:00,505 - INFO - Epoch:[176/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.21
2025-03-02 15:06:03,936 - INFO - Epoch:[176/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 15:06:07,338 - INFO - Epoch:[176/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 15:06:10,718 - INFO - Epoch:[176/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 15:06:14,096 - INFO - Epoch:[176/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.19
2025-03-02 15:06:17,231 - INFO - Epoch:[176/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.15 loss_cvh: 0.77
2025-03-02 15:06:18,162 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 15:06:53,234 - INFO - begin training stage: [177/805]
2025-03-02 15:06:53,234 - INFO - begin training stage: [177/805]
2025-03-02 15:06:57,481 - INFO - Epoch:[177/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 15:07:00,960 - INFO - Epoch:[177/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 15:07:04,341 - INFO - Epoch:[177/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 15:07:07,722 - INFO - Epoch:[177/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 15:07:11,079 - INFO - Epoch:[177/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 15:07:14,480 - INFO - Epoch:[177/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 15:07:17,875 - INFO - Epoch:[177/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 15:07:21,266 - INFO - Epoch:[177/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 15:07:24,471 - INFO - Epoch:[177/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.18 loss_cvh: 0.82
2025-03-02 15:07:25,418 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 15:07:59,282 - INFO - begin training stage: [178/805]
2025-03-02 15:07:59,282 - INFO - begin training stage: [178/805]
2025-03-02 15:08:03,702 - INFO - Epoch:[178/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.18
2025-03-02 15:08:07,201 - INFO - Epoch:[178/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.19
2025-03-02 15:08:10,595 - INFO - Epoch:[178/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.17
2025-03-02 15:08:13,998 - INFO - Epoch:[178/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.09
2025-03-02 15:08:17,399 - INFO - Epoch:[178/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 15:08:20,887 - INFO - Epoch:[178/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 15:08:24,316 - INFO - Epoch:[178/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 15:08:27,563 - INFO - Epoch:[178/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.09
2025-03-02 15:08:30,703 - INFO - Epoch:[178/805] Step:[90/90] reconstruction_loss: 1.04 loss_vc: 1.41 loss_cvh: 0.67
2025-03-02 15:08:31,614 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 15:09:05,659 - INFO - begin training stage: [179/805]
2025-03-02 15:09:05,659 - INFO - begin training stage: [179/805]
2025-03-02 15:09:10,112 - INFO - Epoch:[179/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.20
2025-03-02 15:09:13,527 - INFO - Epoch:[179/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.18
2025-03-02 15:09:16,980 - INFO - Epoch:[179/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.12
2025-03-02 15:09:20,434 - INFO - Epoch:[179/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.47 loss_cvh: 3.16
2025-03-02 15:09:23,798 - INFO - Epoch:[179/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 15:09:27,276 - INFO - Epoch:[179/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 15:09:30,689 - INFO - Epoch:[179/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.14
2025-03-02 15:09:34,124 - INFO - Epoch:[179/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 15:09:37,272 - INFO - Epoch:[179/805] Step:[90/90] reconstruction_loss: 1.29 loss_vc: 1.19 loss_cvh: 0.88
2025-03-02 15:09:38,193 - INFO - now the learning rate is: 4.304672100000002e-05
2025-03-02 15:10:11,598 - INFO - begin training stage: [180/805]
2025-03-02 15:10:11,599 - INFO - begin training stage: [180/805]
2025-03-02 15:10:15,880 - INFO - Epoch:[180/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.19
2025-03-02 15:10:19,361 - INFO - Epoch:[180/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.44 loss_cvh: 3.12
2025-03-02 15:10:22,743 - INFO - Epoch:[180/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 15:10:26,290 - INFO - Epoch:[180/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 15:10:29,664 - INFO - Epoch:[180/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 15:10:33,115 - INFO - Epoch:[180/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 15:10:36,548 - INFO - Epoch:[180/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.10
2025-03-02 15:10:39,939 - INFO - Epoch:[180/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 15:10:43,136 - INFO - Epoch:[180/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.22 loss_cvh: 0.80
2025-03-02 15:10:44,121 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:11:17,447 - INFO - begin training stage: [181/805]
2025-03-02 15:11:17,448 - INFO - eval data number: 45600
2025-03-02 15:11:17,448 - INFO - loading eval data ......
2025-03-02 15:11:51,357 - INFO - retrieval costs: 22.208237171173096
2025-03-02 15:14:19,250 - INFO - hamming distance computation costs: 147.89274048805237
2025-03-02 15:14:30,341 - INFO - hamming ranking costs: 11.091365575790405
2025-03-02 15:14:30,341 - INFO - labels shape: (45600, 239)
2025-03-02 15:15:38,712 - INFO - similarity labels generation costs: 68.3706226348877
2025-03-02 15:15:38,867 - INFO - topK: 5:, map: 0.3106741666666667
2025-03-02 15:15:39,414 - INFO - topK: 20:, map: 0.22129877951581656
2025-03-02 15:15:40,380 - INFO - topK: 40:, map: 0.1901115551647711
2025-03-02 15:15:41,745 - INFO - topK: 60:, map: 0.17410638167431564
2025-03-02 15:15:43,564 - INFO - topK: 80:, map: 0.16118617199337976
2025-03-02 15:15:45,798 - INFO - topK: 100:, map: 0.15057462327792712
2025-03-02 15:15:47,071 - INFO - begin training stage: [181/805]
2025-03-02 15:15:52,351 - INFO - Epoch:[181/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.17
2025-03-02 15:15:56,986 - INFO - Epoch:[181/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 15:16:00,601 - INFO - Epoch:[181/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.21
2025-03-02 15:16:04,080 - INFO - Epoch:[181/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 15:16:07,548 - INFO - Epoch:[181/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.07
2025-03-02 15:16:10,999 - INFO - Epoch:[181/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 15:16:14,559 - INFO - Epoch:[181/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 15:16:18,871 - INFO - Epoch:[181/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 15:16:23,070 - INFO - Epoch:[181/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.18 loss_cvh: 0.81
2025-03-02 15:16:24,521 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:17:04,611 - INFO - begin training stage: [182/805]
2025-03-02 15:17:04,612 - INFO - begin training stage: [182/805]
2025-03-02 15:17:09,250 - INFO - Epoch:[182/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 15:17:13,246 - INFO - Epoch:[182/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 15:17:17,500 - INFO - Epoch:[182/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.47 loss_cvh: 3.15
2025-03-02 15:17:21,466 - INFO - Epoch:[182/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 15:17:26,089 - INFO - Epoch:[182/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.07
2025-03-02 15:17:31,353 - INFO - Epoch:[182/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 15:17:36,676 - INFO - Epoch:[182/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 15:17:41,392 - INFO - Epoch:[182/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.18
2025-03-02 15:17:45,923 - INFO - Epoch:[182/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.18 loss_cvh: 0.77
2025-03-02 15:17:47,355 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:19:02,314 - INFO - begin training stage: [183/805]
2025-03-02 15:19:02,314 - INFO - begin training stage: [183/805]
2025-03-02 15:19:10,592 - INFO - Epoch:[183/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 15:19:15,804 - INFO - Epoch:[183/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 15:19:20,945 - INFO - Epoch:[183/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 15:19:26,558 - INFO - Epoch:[183/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 15:19:32,350 - INFO - Epoch:[183/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 15:19:37,330 - INFO - Epoch:[183/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 15:19:41,176 - INFO - Epoch:[183/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 15:19:45,332 - INFO - Epoch:[183/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 15:19:49,105 - INFO - Epoch:[183/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.09 loss_cvh: 0.90
2025-03-02 15:19:50,194 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:20:27,515 - INFO - begin training stage: [184/805]
2025-03-02 15:20:27,516 - INFO - begin training stage: [184/805]
2025-03-02 15:20:33,611 - INFO - Epoch:[184/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 15:20:40,013 - INFO - Epoch:[184/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 15:20:44,617 - INFO - Epoch:[184/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 15:20:48,292 - INFO - Epoch:[184/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 15:20:52,001 - INFO - Epoch:[184/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 15:20:55,776 - INFO - Epoch:[184/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 15:20:59,398 - INFO - Epoch:[184/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.21
2025-03-02 15:21:02,910 - INFO - Epoch:[184/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.18
2025-03-02 15:21:06,193 - INFO - Epoch:[184/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.29 loss_cvh: 0.90
2025-03-02 15:21:07,239 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:21:52,892 - INFO - begin training stage: [185/805]
2025-03-02 15:21:52,892 - INFO - begin training stage: [185/805]
2025-03-02 15:21:57,309 - INFO - Epoch:[185/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 15:22:00,919 - INFO - Epoch:[185/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 15:22:04,684 - INFO - Epoch:[185/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 15:22:08,920 - INFO - Epoch:[185/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.08
2025-03-02 15:22:13,612 - INFO - Epoch:[185/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 15:22:18,317 - INFO - Epoch:[185/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 15:22:23,624 - INFO - Epoch:[185/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 15:22:27,973 - INFO - Epoch:[185/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 15:22:31,478 - INFO - Epoch:[185/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.35 loss_cvh: 0.99
2025-03-02 15:22:32,477 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:23:09,222 - INFO - begin training stage: [186/805]
2025-03-02 15:23:09,223 - INFO - begin training stage: [186/805]
2025-03-02 15:23:16,880 - INFO - Epoch:[186/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 15:23:24,336 - INFO - Epoch:[186/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.20
2025-03-02 15:23:30,685 - INFO - Epoch:[186/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 15:23:34,716 - INFO - Epoch:[186/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.17
2025-03-02 15:23:38,937 - INFO - Epoch:[186/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 15:23:42,481 - INFO - Epoch:[186/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 15:23:45,919 - INFO - Epoch:[186/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 15:23:49,388 - INFO - Epoch:[186/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 15:23:53,089 - INFO - Epoch:[186/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.27 loss_cvh: 0.60
2025-03-02 15:23:54,821 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:24:41,335 - INFO - begin training stage: [187/805]
2025-03-02 15:24:41,335 - INFO - begin training stage: [187/805]
2025-03-02 15:24:45,767 - INFO - Epoch:[187/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 15:24:49,270 - INFO - Epoch:[187/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 15:24:52,710 - INFO - Epoch:[187/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 15:24:56,222 - INFO - Epoch:[187/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 15:24:59,740 - INFO - Epoch:[187/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 15:25:03,508 - INFO - Epoch:[187/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 15:25:08,247 - INFO - Epoch:[187/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.11
2025-03-02 15:25:12,751 - INFO - Epoch:[187/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.11
2025-03-02 15:25:16,845 - INFO - Epoch:[187/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.24 loss_cvh: 0.90
2025-03-02 15:25:18,233 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:26:00,373 - INFO - begin training stage: [188/805]
2025-03-02 15:26:00,374 - INFO - begin training stage: [188/805]
2025-03-02 15:26:05,051 - INFO - Epoch:[188/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.23
2025-03-02 15:26:08,555 - INFO - Epoch:[188/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 15:26:13,162 - INFO - Epoch:[188/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.19
2025-03-02 15:26:17,844 - INFO - Epoch:[188/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 15:26:24,895 - INFO - Epoch:[188/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 15:26:31,049 - INFO - Epoch:[188/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 15:26:36,602 - INFO - Epoch:[188/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 15:26:40,502 - INFO - Epoch:[188/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 15:26:43,896 - INFO - Epoch:[188/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.21 loss_cvh: 0.64
2025-03-02 15:26:44,880 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:27:24,621 - INFO - begin training stage: [189/805]
2025-03-02 15:27:24,621 - INFO - begin training stage: [189/805]
2025-03-02 15:27:28,994 - INFO - Epoch:[189/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.19
2025-03-02 15:27:33,111 - INFO - Epoch:[189/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 15:27:37,708 - INFO - Epoch:[189/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 15:27:42,816 - INFO - Epoch:[189/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 15:27:47,734 - INFO - Epoch:[189/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 15:27:53,021 - INFO - Epoch:[189/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 15:27:56,685 - INFO - Epoch:[189/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 15:28:00,290 - INFO - Epoch:[189/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 15:28:03,676 - INFO - Epoch:[189/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.21 loss_cvh: 0.72
2025-03-02 15:28:04,797 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:28:53,235 - INFO - begin training stage: [190/805]
2025-03-02 15:28:53,235 - INFO - begin training stage: [190/805]
2025-03-02 15:28:58,640 - INFO - Epoch:[190/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.19
2025-03-02 15:29:03,293 - INFO - Epoch:[190/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.14
2025-03-02 15:29:07,734 - INFO - Epoch:[190/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 15:29:11,280 - INFO - Epoch:[190/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.11
2025-03-02 15:29:14,634 - INFO - Epoch:[190/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 15:29:18,163 - INFO - Epoch:[190/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 15:29:22,554 - INFO - Epoch:[190/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 15:29:26,964 - INFO - Epoch:[190/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 15:29:31,320 - INFO - Epoch:[190/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.42 loss_cvh: 0.96
2025-03-02 15:29:32,899 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:30:13,156 - INFO - begin training stage: [191/805]
2025-03-02 15:30:13,157 - INFO - eval data number: 45600
2025-03-02 15:30:13,157 - INFO - loading eval data ......
2025-03-02 15:31:00,294 - INFO - retrieval costs: 33.32600665092468
2025-03-02 15:33:43,855 - INFO - hamming distance computation costs: 163.56117129325867
2025-03-02 15:33:58,798 - INFO - hamming ranking costs: 14.942239046096802
2025-03-02 15:33:58,799 - INFO - labels shape: (45600, 239)
2025-03-02 15:35:03,671 - INFO - similarity labels generation costs: 64.87310433387756
2025-03-02 15:35:03,807 - INFO - topK: 5:, map: 0.3067108333333333
2025-03-02 15:35:04,276 - INFO - topK: 20:, map: 0.22055524141294505
2025-03-02 15:35:05,191 - INFO - topK: 40:, map: 0.18990126472633778
2025-03-02 15:35:06,557 - INFO - topK: 60:, map: 0.17377363837174062
2025-03-02 15:35:08,323 - INFO - topK: 80:, map: 0.16151305981829683
2025-03-02 15:35:10,509 - INFO - topK: 100:, map: 0.15098745413039577
2025-03-02 15:35:12,541 - INFO - begin training stage: [191/805]
2025-03-02 15:35:20,193 - INFO - Epoch:[191/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 15:35:25,126 - INFO - Epoch:[191/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 15:35:28,888 - INFO - Epoch:[191/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 15:35:32,324 - INFO - Epoch:[191/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 15:35:36,196 - INFO - Epoch:[191/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 15:35:39,767 - INFO - Epoch:[191/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 15:35:43,630 - INFO - Epoch:[191/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 15:35:51,314 - INFO - Epoch:[191/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 15:35:58,981 - INFO - Epoch:[191/805] Step:[90/90] reconstruction_loss: 1.04 loss_vc: 1.27 loss_cvh: 0.90
2025-03-02 15:36:03,323 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:37:17,813 - INFO - begin training stage: [192/805]
2025-03-02 15:37:17,815 - INFO - begin training stage: [192/805]
2025-03-02 15:37:25,805 - INFO - Epoch:[192/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 15:37:30,810 - INFO - Epoch:[192/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 15:37:35,661 - INFO - Epoch:[192/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 15:37:40,537 - INFO - Epoch:[192/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.19
2025-03-02 15:37:45,447 - INFO - Epoch:[192/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 15:37:50,647 - INFO - Epoch:[192/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.19
2025-03-02 15:37:56,186 - INFO - Epoch:[192/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 15:38:01,028 - INFO - Epoch:[192/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 15:38:06,369 - INFO - Epoch:[192/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.34 loss_cvh: 0.94
2025-03-02 15:38:09,411 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:38:59,639 - INFO - begin training stage: [193/805]
2025-03-02 15:38:59,639 - INFO - begin training stage: [193/805]
2025-03-02 15:39:05,304 - INFO - Epoch:[193/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.05
2025-03-02 15:39:10,673 - INFO - Epoch:[193/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 15:39:17,024 - INFO - Epoch:[193/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 15:39:20,707 - INFO - Epoch:[193/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 15:39:24,977 - INFO - Epoch:[193/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 15:39:29,882 - INFO - Epoch:[193/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 15:39:33,812 - INFO - Epoch:[193/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.12
2025-03-02 15:39:38,191 - INFO - Epoch:[193/805] Step:[80/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.10
2025-03-02 15:39:41,880 - INFO - Epoch:[193/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.43 loss_cvh: 0.79
2025-03-02 15:39:42,928 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:40:32,499 - INFO - begin training stage: [194/805]
2025-03-02 15:40:32,499 - INFO - begin training stage: [194/805]
2025-03-02 15:40:37,714 - INFO - Epoch:[194/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 15:40:41,368 - INFO - Epoch:[194/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 15:40:44,970 - INFO - Epoch:[194/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 15:40:48,598 - INFO - Epoch:[194/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 15:40:52,220 - INFO - Epoch:[194/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 15:40:55,893 - INFO - Epoch:[194/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 15:40:59,546 - INFO - Epoch:[194/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.17
2025-03-02 15:41:03,082 - INFO - Epoch:[194/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 15:41:07,991 - INFO - Epoch:[194/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.43 loss_cvh: 0.70
2025-03-02 15:41:10,291 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:41:55,689 - INFO - begin training stage: [195/805]
2025-03-02 15:41:55,690 - INFO - begin training stage: [195/805]
2025-03-02 15:42:00,854 - INFO - Epoch:[195/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 15:42:04,347 - INFO - Epoch:[195/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.15
2025-03-02 15:42:07,808 - INFO - Epoch:[195/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 15:42:11,526 - INFO - Epoch:[195/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 15:42:17,034 - INFO - Epoch:[195/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 15:42:22,855 - INFO - Epoch:[195/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.18
2025-03-02 15:42:29,507 - INFO - Epoch:[195/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 15:42:34,088 - INFO - Epoch:[195/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 15:42:38,665 - INFO - Epoch:[195/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.28 loss_cvh: 0.60
2025-03-02 15:42:39,864 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:43:20,658 - INFO - begin training stage: [196/805]
2025-03-02 15:43:20,658 - INFO - begin training stage: [196/805]
2025-03-02 15:43:27,098 - INFO - Epoch:[196/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.14
2025-03-02 15:43:31,663 - INFO - Epoch:[196/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 15:43:35,949 - INFO - Epoch:[196/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 15:43:40,290 - INFO - Epoch:[196/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 15:43:44,429 - INFO - Epoch:[196/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.08
2025-03-02 15:43:48,352 - INFO - Epoch:[196/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 15:43:52,092 - INFO - Epoch:[196/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 15:43:55,688 - INFO - Epoch:[196/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 15:43:59,051 - INFO - Epoch:[196/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.29 loss_cvh: 0.85
2025-03-02 15:44:00,051 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:44:47,478 - INFO - begin training stage: [197/805]
2025-03-02 15:44:47,478 - INFO - begin training stage: [197/805]
2025-03-02 15:44:52,691 - INFO - Epoch:[197/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 15:44:56,454 - INFO - Epoch:[197/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.21
2025-03-02 15:44:59,929 - INFO - Epoch:[197/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 15:45:03,495 - INFO - Epoch:[197/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 15:45:07,035 - INFO - Epoch:[197/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 15:45:10,834 - INFO - Epoch:[197/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 15:45:15,135 - INFO - Epoch:[197/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 15:45:23,746 - INFO - Epoch:[197/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 15:45:30,533 - INFO - Epoch:[197/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.24 loss_cvh: 0.95
2025-03-02 15:45:33,508 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:46:15,852 - INFO - begin training stage: [198/805]
2025-03-02 15:46:15,852 - INFO - begin training stage: [198/805]
2025-03-02 15:46:20,819 - INFO - Epoch:[198/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.16
2025-03-02 15:46:25,124 - INFO - Epoch:[198/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 15:46:30,030 - INFO - Epoch:[198/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.47 loss_cvh: 3.15
2025-03-02 15:46:33,824 - INFO - Epoch:[198/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 15:46:37,686 - INFO - Epoch:[198/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 15:46:42,250 - INFO - Epoch:[198/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 15:46:46,454 - INFO - Epoch:[198/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 15:46:50,537 - INFO - Epoch:[198/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 15:46:54,844 - INFO - Epoch:[198/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.45 loss_cvh: 0.86
2025-03-02 15:46:56,597 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:47:41,130 - INFO - begin training stage: [199/805]
2025-03-02 15:47:41,130 - INFO - begin training stage: [199/805]
2025-03-02 15:47:45,608 - INFO - Epoch:[199/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 15:47:48,988 - INFO - Epoch:[199/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 15:47:52,432 - INFO - Epoch:[199/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 15:47:56,011 - INFO - Epoch:[199/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.43 loss_cvh: 3.18
2025-03-02 15:48:00,092 - INFO - Epoch:[199/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 15:48:05,045 - INFO - Epoch:[199/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 15:48:11,021 - INFO - Epoch:[199/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 15:48:15,085 - INFO - Epoch:[199/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 15:48:18,669 - INFO - Epoch:[199/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.44 loss_cvh: 0.95
2025-03-02 15:48:20,309 - INFO - now the learning rate is: 3.874204890000002e-05
2025-03-02 15:49:00,731 - INFO - begin training stage: [200/805]
2025-03-02 15:49:00,731 - INFO - begin training stage: [200/805]
2025-03-02 15:49:06,448 - INFO - Epoch:[200/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 15:49:10,782 - INFO - Epoch:[200/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 15:49:14,723 - INFO - Epoch:[200/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 15:49:18,404 - INFO - Epoch:[200/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 15:49:21,905 - INFO - Epoch:[200/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 15:49:25,595 - INFO - Epoch:[200/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 15:49:29,492 - INFO - Epoch:[200/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 15:49:33,371 - INFO - Epoch:[200/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 15:49:37,032 - INFO - Epoch:[200/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.35 loss_cvh: 0.71
2025-03-02 15:49:38,270 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 15:50:17,017 - INFO - begin training stage: [201/805]
2025-03-02 15:50:17,018 - INFO - eval data number: 45600
2025-03-02 15:50:17,018 - INFO - loading eval data ......
2025-03-02 15:51:07,371 - INFO - retrieval costs: 24.101367235183716
2025-03-02 15:53:58,606 - INFO - hamming distance computation costs: 171.23396182060242
2025-03-02 15:54:09,379 - INFO - hamming ranking costs: 10.77406930923462
2025-03-02 15:54:09,380 - INFO - labels shape: (45600, 239)
2025-03-02 15:55:16,692 - INFO - similarity labels generation costs: 67.31252384185791
2025-03-02 15:55:16,823 - INFO - topK: 5:, map: 0.310575
2025-03-02 15:55:17,289 - INFO - topK: 20:, map: 0.22285515588905633
2025-03-02 15:55:18,192 - INFO - topK: 40:, map: 0.19237982595299188
2025-03-02 15:55:19,523 - INFO - topK: 60:, map: 0.1753266216366892
2025-03-02 15:55:21,277 - INFO - topK: 80:, map: 0.1623173587153386
2025-03-02 15:55:23,483 - INFO - topK: 100:, map: 0.15125706137010683
2025-03-02 15:55:25,354 - INFO - begin training stage: [201/805]
2025-03-02 15:55:31,640 - INFO - Epoch:[201/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.45 loss_cvh: 3.13
2025-03-02 15:55:36,253 - INFO - Epoch:[201/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.08
2025-03-02 15:55:39,894 - INFO - Epoch:[201/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 15:55:43,758 - INFO - Epoch:[201/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.44 loss_cvh: 3.12
2025-03-02 15:55:47,751 - INFO - Epoch:[201/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 15:55:51,684 - INFO - Epoch:[201/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 15:55:56,739 - INFO - Epoch:[201/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 15:56:02,783 - INFO - Epoch:[201/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 15:56:07,956 - INFO - Epoch:[201/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.41 loss_cvh: 0.82
2025-03-02 15:56:09,069 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 15:57:29,162 - INFO - begin training stage: [202/805]
2025-03-02 15:57:29,163 - INFO - begin training stage: [202/805]
2025-03-02 15:57:35,212 - INFO - Epoch:[202/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 15:57:39,619 - INFO - Epoch:[202/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.05
2025-03-02 15:57:44,111 - INFO - Epoch:[202/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 15:57:48,636 - INFO - Epoch:[202/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 15:57:53,398 - INFO - Epoch:[202/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 15:57:57,998 - INFO - Epoch:[202/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.12
2025-03-02 15:58:02,533 - INFO - Epoch:[202/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.08
2025-03-02 15:58:07,328 - INFO - Epoch:[202/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.14
2025-03-02 15:58:11,896 - INFO - Epoch:[202/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.39 loss_cvh: 0.75
2025-03-02 15:58:13,906 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 15:58:58,971 - INFO - begin training stage: [203/805]
2025-03-02 15:58:58,971 - INFO - begin training stage: [203/805]
2025-03-02 15:59:07,156 - INFO - Epoch:[203/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 15:59:14,914 - INFO - Epoch:[203/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 15:59:22,431 - INFO - Epoch:[203/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 15:59:27,571 - INFO - Epoch:[203/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 15:59:31,881 - INFO - Epoch:[203/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 15:59:36,541 - INFO - Epoch:[203/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.06
2025-03-02 15:59:41,888 - INFO - Epoch:[203/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 15:59:45,940 - INFO - Epoch:[203/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 15:59:49,171 - INFO - Epoch:[203/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.28 loss_cvh: 0.77
2025-03-02 15:59:50,224 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:00:25,784 - INFO - begin training stage: [204/805]
2025-03-02 16:00:25,784 - INFO - begin training stage: [204/805]
2025-03-02 16:00:30,779 - INFO - Epoch:[204/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 16:00:34,493 - INFO - Epoch:[204/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 16:00:38,276 - INFO - Epoch:[204/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 16:00:42,045 - INFO - Epoch:[204/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 16:00:47,603 - INFO - Epoch:[204/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 16:00:53,359 - INFO - Epoch:[204/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 16:00:58,230 - INFO - Epoch:[204/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 16:01:03,094 - INFO - Epoch:[204/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.08
2025-03-02 16:01:07,347 - INFO - Epoch:[204/805] Step:[90/90] reconstruction_loss: 1.01 loss_vc: 1.30 loss_cvh: 0.76
2025-03-02 16:01:08,769 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:01:49,753 - INFO - begin training stage: [205/805]
2025-03-02 16:01:49,754 - INFO - begin training stage: [205/805]
2025-03-02 16:01:55,206 - INFO - Epoch:[205/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 16:01:59,283 - INFO - Epoch:[205/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 16:02:03,132 - INFO - Epoch:[205/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 16:02:06,744 - INFO - Epoch:[205/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 16:02:10,294 - INFO - Epoch:[205/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 16:02:13,750 - INFO - Epoch:[205/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 16:02:17,370 - INFO - Epoch:[205/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 16:02:21,418 - INFO - Epoch:[205/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 16:02:25,114 - INFO - Epoch:[205/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.22 loss_cvh: 0.83
2025-03-02 16:02:26,207 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:03:15,214 - INFO - begin training stage: [206/805]
2025-03-02 16:03:15,215 - INFO - begin training stage: [206/805]
2025-03-02 16:03:20,747 - INFO - Epoch:[206/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.18
2025-03-02 16:03:24,451 - INFO - Epoch:[206/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 16:03:28,046 - INFO - Epoch:[206/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 16:03:31,865 - INFO - Epoch:[206/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 16:03:35,966 - INFO - Epoch:[206/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.08
2025-03-02 16:03:39,569 - INFO - Epoch:[206/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.09
2025-03-02 16:03:43,856 - INFO - Epoch:[206/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 16:03:50,013 - INFO - Epoch:[206/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 16:03:55,481 - INFO - Epoch:[206/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.45 loss_cvh: 0.82
2025-03-02 16:03:57,398 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:04:39,783 - INFO - begin training stage: [207/805]
2025-03-02 16:04:39,783 - INFO - begin training stage: [207/805]
2025-03-02 16:04:44,056 - INFO - Epoch:[207/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.17
2025-03-02 16:04:47,664 - INFO - Epoch:[207/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.11
2025-03-02 16:04:51,104 - INFO - Epoch:[207/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 16:04:54,623 - INFO - Epoch:[207/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.04
2025-03-02 16:04:58,964 - INFO - Epoch:[207/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.16
2025-03-02 16:05:03,587 - INFO - Epoch:[207/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 16:05:09,901 - INFO - Epoch:[207/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 16:05:14,207 - INFO - Epoch:[207/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 16:05:18,654 - INFO - Epoch:[207/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.33 loss_cvh: 0.61
2025-03-02 16:05:20,680 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:06:18,451 - INFO - begin training stage: [208/805]
2025-03-02 16:06:18,452 - INFO - begin training stage: [208/805]
2025-03-02 16:06:25,896 - INFO - Epoch:[208/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.46 loss_cvh: 3.13
2025-03-02 16:06:29,669 - INFO - Epoch:[208/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.12
2025-03-02 16:06:33,311 - INFO - Epoch:[208/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 16:06:36,838 - INFO - Epoch:[208/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.10
2025-03-02 16:06:40,245 - INFO - Epoch:[208/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 16:06:43,937 - INFO - Epoch:[208/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.45 loss_cvh: 3.14
2025-03-02 16:06:47,413 - INFO - Epoch:[208/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 16:06:50,888 - INFO - Epoch:[208/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.44 loss_cvh: 3.09
2025-03-02 16:06:54,082 - INFO - Epoch:[208/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.40 loss_cvh: 0.76
2025-03-02 16:06:55,100 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:07:36,342 - INFO - begin training stage: [209/805]
2025-03-02 16:07:36,342 - INFO - begin training stage: [209/805]
2025-03-02 16:07:41,373 - INFO - Epoch:[209/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 16:07:45,506 - INFO - Epoch:[209/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 16:07:50,258 - INFO - Epoch:[209/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 16:07:55,874 - INFO - Epoch:[209/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.08
2025-03-02 16:08:00,765 - INFO - Epoch:[209/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 16:08:05,160 - INFO - Epoch:[209/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 16:08:09,283 - INFO - Epoch:[209/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.08
2025-03-02 16:08:13,699 - INFO - Epoch:[209/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 16:08:17,765 - INFO - Epoch:[209/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.22 loss_cvh: 0.74
2025-03-02 16:08:18,959 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:08:58,916 - INFO - begin training stage: [210/805]
2025-03-02 16:08:58,917 - INFO - begin training stage: [210/805]
2025-03-02 16:09:06,560 - INFO - Epoch:[210/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.17
2025-03-02 16:09:10,419 - INFO - Epoch:[210/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 16:09:13,987 - INFO - Epoch:[210/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.45 loss_cvh: 3.12
2025-03-02 16:09:18,577 - INFO - Epoch:[210/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 16:09:22,565 - INFO - Epoch:[210/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 16:09:26,428 - INFO - Epoch:[210/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 16:09:30,391 - INFO - Epoch:[210/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 16:09:35,047 - INFO - Epoch:[210/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 16:09:39,191 - INFO - Epoch:[210/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.47 loss_cvh: 0.93
2025-03-02 16:09:40,358 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:10:21,796 - INFO - begin training stage: [211/805]
2025-03-02 16:10:21,797 - INFO - eval data number: 45600
2025-03-02 16:10:21,797 - INFO - loading eval data ......
2025-03-02 16:11:01,957 - INFO - retrieval costs: 26.740644454956055
2025-03-02 16:13:35,587 - INFO - hamming distance computation costs: 153.62932658195496
2025-03-02 16:13:48,274 - INFO - hamming ranking costs: 12.687511444091797
2025-03-02 16:13:48,275 - INFO - labels shape: (45600, 239)
2025-03-02 16:14:43,209 - INFO - similarity labels generation costs: 54.934577226638794
2025-03-02 16:14:43,337 - INFO - topK: 5:, map: 0.30924
2025-03-02 16:14:43,783 - INFO - topK: 20:, map: 0.22498904412860102
2025-03-02 16:14:44,655 - INFO - topK: 40:, map: 0.19359968092793595
2025-03-02 16:14:45,951 - INFO - topK: 60:, map: 0.1769031679131658
2025-03-02 16:14:47,669 - INFO - topK: 80:, map: 0.16399289237171213
2025-03-02 16:14:49,811 - INFO - topK: 100:, map: 0.15320582039983174
2025-03-02 16:14:52,094 - INFO - begin training stage: [211/805]
2025-03-02 16:14:59,104 - INFO - Epoch:[211/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.13
2025-03-02 16:15:04,229 - INFO - Epoch:[211/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 16:15:09,011 - INFO - Epoch:[211/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.20
2025-03-02 16:15:14,290 - INFO - Epoch:[211/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 16:15:19,525 - INFO - Epoch:[211/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 16:15:25,086 - INFO - Epoch:[211/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 16:15:30,674 - INFO - Epoch:[211/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 16:15:35,757 - INFO - Epoch:[211/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 16:15:40,437 - INFO - Epoch:[211/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.11 loss_cvh: 0.77
2025-03-02 16:15:41,964 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:16:31,179 - INFO - begin training stage: [212/805]
2025-03-02 16:16:31,180 - INFO - begin training stage: [212/805]
2025-03-02 16:16:35,856 - INFO - Epoch:[212/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 16:16:39,382 - INFO - Epoch:[212/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.09
2025-03-02 16:16:44,120 - INFO - Epoch:[212/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 16:16:49,445 - INFO - Epoch:[212/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.10
2025-03-02 16:16:55,380 - INFO - Epoch:[212/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 16:17:00,921 - INFO - Epoch:[212/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.45 loss_cvh: 3.16
2025-03-02 16:17:06,988 - INFO - Epoch:[212/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 16:17:13,424 - INFO - Epoch:[212/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 16:17:18,694 - INFO - Epoch:[212/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.29 loss_cvh: 0.84
2025-03-02 16:17:20,708 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:18:44,740 - INFO - begin training stage: [213/805]
2025-03-02 16:18:44,740 - INFO - begin training stage: [213/805]
2025-03-02 16:18:53,950 - INFO - Epoch:[213/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 16:19:00,925 - INFO - Epoch:[213/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.07
2025-03-02 16:19:06,617 - INFO - Epoch:[213/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 16:19:10,198 - INFO - Epoch:[213/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 16:19:13,976 - INFO - Epoch:[213/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 16:19:18,551 - INFO - Epoch:[213/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 16:19:22,939 - INFO - Epoch:[213/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 16:19:28,375 - INFO - Epoch:[213/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 16:19:33,725 - INFO - Epoch:[213/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.32 loss_cvh: 0.91
2025-03-02 16:19:35,354 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:20:29,690 - INFO - begin training stage: [214/805]
2025-03-02 16:20:29,691 - INFO - begin training stage: [214/805]
2025-03-02 16:20:39,041 - INFO - Epoch:[214/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 16:20:43,860 - INFO - Epoch:[214/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 16:20:47,907 - INFO - Epoch:[214/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.19
2025-03-02 16:20:51,857 - INFO - Epoch:[214/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 16:20:55,502 - INFO - Epoch:[214/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 16:20:59,152 - INFO - Epoch:[214/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 16:21:02,686 - INFO - Epoch:[214/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 16:21:06,359 - INFO - Epoch:[214/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 16:21:10,072 - INFO - Epoch:[214/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.36 loss_cvh: 0.84
2025-03-02 16:21:12,308 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:22:00,536 - INFO - begin training stage: [215/805]
2025-03-02 16:22:00,536 - INFO - begin training stage: [215/805]
2025-03-02 16:22:09,483 - INFO - Epoch:[215/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 16:22:14,900 - INFO - Epoch:[215/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 16:22:19,967 - INFO - Epoch:[215/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 16:22:23,705 - INFO - Epoch:[215/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 16:22:27,361 - INFO - Epoch:[215/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 16:22:30,925 - INFO - Epoch:[215/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 16:22:34,554 - INFO - Epoch:[215/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 16:22:38,197 - INFO - Epoch:[215/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 16:22:42,500 - INFO - Epoch:[215/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.23 loss_cvh: 0.90
2025-03-02 16:22:44,654 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:23:29,138 - INFO - begin training stage: [216/805]
2025-03-02 16:23:29,138 - INFO - begin training stage: [216/805]
2025-03-02 16:23:34,578 - INFO - Epoch:[216/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 16:23:39,913 - INFO - Epoch:[216/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 16:23:45,790 - INFO - Epoch:[216/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 16:23:50,692 - INFO - Epoch:[216/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 16:23:54,713 - INFO - Epoch:[216/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 16:23:59,401 - INFO - Epoch:[216/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 16:24:04,250 - INFO - Epoch:[216/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 16:24:10,039 - INFO - Epoch:[216/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.11
2025-03-02 16:24:13,912 - INFO - Epoch:[216/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.17 loss_cvh: 0.71
2025-03-02 16:24:15,489 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:24:52,880 - INFO - begin training stage: [217/805]
2025-03-02 16:24:52,880 - INFO - begin training stage: [217/805]
2025-03-02 16:24:58,714 - INFO - Epoch:[217/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 16:25:02,351 - INFO - Epoch:[217/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.19
2025-03-02 16:25:06,731 - INFO - Epoch:[217/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 16:25:11,427 - INFO - Epoch:[217/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 16:25:16,493 - INFO - Epoch:[217/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 16:25:22,346 - INFO - Epoch:[217/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 16:25:28,642 - INFO - Epoch:[217/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 16:25:33,249 - INFO - Epoch:[217/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 16:25:36,683 - INFO - Epoch:[217/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.12 loss_cvh: 0.70
2025-03-02 16:25:37,845 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:26:25,110 - INFO - begin training stage: [218/805]
2025-03-02 16:26:25,110 - INFO - begin training stage: [218/805]
2025-03-02 16:26:30,110 - INFO - Epoch:[218/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 16:26:33,576 - INFO - Epoch:[218/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 16:26:37,122 - INFO - Epoch:[218/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 16:26:40,808 - INFO - Epoch:[218/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.17
2025-03-02 16:26:44,336 - INFO - Epoch:[218/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 16:26:47,731 - INFO - Epoch:[218/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 16:26:52,583 - INFO - Epoch:[218/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 16:26:58,706 - INFO - Epoch:[218/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.06
2025-03-02 16:27:06,380 - INFO - Epoch:[218/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.37 loss_cvh: 0.92
2025-03-02 16:27:10,425 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:27:51,597 - INFO - begin training stage: [219/805]
2025-03-02 16:27:51,597 - INFO - begin training stage: [219/805]
2025-03-02 16:27:57,779 - INFO - Epoch:[219/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.19
2025-03-02 16:28:01,541 - INFO - Epoch:[219/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 16:28:05,930 - INFO - Epoch:[219/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 16:28:10,414 - INFO - Epoch:[219/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 16:28:14,863 - INFO - Epoch:[219/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.09
2025-03-02 16:28:18,479 - INFO - Epoch:[219/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 16:28:22,870 - INFO - Epoch:[219/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 16:28:27,696 - INFO - Epoch:[219/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 16:28:31,520 - INFO - Epoch:[219/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.29 loss_cvh: 0.88
2025-03-02 16:28:32,735 - INFO - now the learning rate is: 3.4867844010000016e-05
2025-03-02 16:29:17,027 - INFO - begin training stage: [220/805]
2025-03-02 16:29:17,028 - INFO - begin training stage: [220/805]
2025-03-02 16:29:21,574 - INFO - Epoch:[220/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 16:29:24,927 - INFO - Epoch:[220/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 16:29:28,290 - INFO - Epoch:[220/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.17
2025-03-02 16:29:31,868 - INFO - Epoch:[220/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 16:29:35,572 - INFO - Epoch:[220/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 16:29:41,246 - INFO - Epoch:[220/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 16:29:48,625 - INFO - Epoch:[220/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.08
2025-03-02 16:29:54,350 - INFO - Epoch:[220/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 16:29:58,548 - INFO - Epoch:[220/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.15 loss_cvh: 0.85
2025-03-02 16:30:00,382 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:30:41,471 - INFO - begin training stage: [221/805]
2025-03-02 16:30:41,472 - INFO - eval data number: 45600
2025-03-02 16:30:41,473 - INFO - loading eval data ......
2025-03-02 16:31:29,541 - INFO - retrieval costs: 23.927746772766113
2025-03-02 16:33:57,136 - INFO - hamming distance computation costs: 147.59490513801575
2025-03-02 16:34:08,123 - INFO - hamming ranking costs: 10.98765254020691
2025-03-02 16:34:08,123 - INFO - labels shape: (45600, 239)
2025-03-02 16:35:16,810 - INFO - similarity labels generation costs: 68.68683457374573
2025-03-02 16:35:16,939 - INFO - topK: 5:, map: 0.31614833333333336
2025-03-02 16:35:17,390 - INFO - topK: 20:, map: 0.22496750364600354
2025-03-02 16:35:18,271 - INFO - topK: 40:, map: 0.19327861781470984
2025-03-02 16:35:19,578 - INFO - topK: 60:, map: 0.17705556997710586
2025-03-02 16:35:21,316 - INFO - topK: 80:, map: 0.16407974856008906
2025-03-02 16:35:23,488 - INFO - topK: 100:, map: 0.15383877546658822
2025-03-02 16:35:25,536 - INFO - begin training stage: [221/805]
2025-03-02 16:35:32,219 - INFO - Epoch:[221/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 16:35:37,603 - INFO - Epoch:[221/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 16:35:43,883 - INFO - Epoch:[221/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 16:35:49,190 - INFO - Epoch:[221/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 16:35:54,757 - INFO - Epoch:[221/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 16:36:00,556 - INFO - Epoch:[221/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 16:36:06,628 - INFO - Epoch:[221/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 16:36:12,360 - INFO - Epoch:[221/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 16:36:16,662 - INFO - Epoch:[221/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.24 loss_cvh: 0.90
2025-03-02 16:36:18,412 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:36:59,505 - INFO - begin training stage: [222/805]
2025-03-02 16:36:59,506 - INFO - begin training stage: [222/805]
2025-03-02 16:37:05,375 - INFO - Epoch:[222/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.22
2025-03-02 16:37:09,896 - INFO - Epoch:[222/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 16:37:14,429 - INFO - Epoch:[222/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 16:37:18,986 - INFO - Epoch:[222/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 16:37:23,969 - INFO - Epoch:[222/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 16:37:29,027 - INFO - Epoch:[222/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 16:37:35,172 - INFO - Epoch:[222/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 16:37:40,551 - INFO - Epoch:[222/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 16:37:45,656 - INFO - Epoch:[222/805] Step:[90/90] reconstruction_loss: 1.33 loss_vc: 1.37 loss_cvh: 0.90
2025-03-02 16:37:47,577 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:39:05,427 - INFO - begin training stage: [223/805]
2025-03-02 16:39:05,428 - INFO - begin training stage: [223/805]
2025-03-02 16:39:13,232 - INFO - Epoch:[223/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.18
2025-03-02 16:39:18,385 - INFO - Epoch:[223/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 16:39:23,557 - INFO - Epoch:[223/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 16:39:28,596 - INFO - Epoch:[223/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 16:39:32,357 - INFO - Epoch:[223/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 16:39:36,029 - INFO - Epoch:[223/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.07
2025-03-02 16:39:40,346 - INFO - Epoch:[223/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 16:39:45,003 - INFO - Epoch:[223/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 16:39:49,109 - INFO - Epoch:[223/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.22 loss_cvh: 0.68
2025-03-02 16:39:50,543 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:40:35,768 - INFO - begin training stage: [224/805]
2025-03-02 16:40:35,769 - INFO - begin training stage: [224/805]
2025-03-02 16:40:40,522 - INFO - Epoch:[224/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 16:40:44,151 - INFO - Epoch:[224/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 16:40:47,869 - INFO - Epoch:[224/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.46 loss_cvh: 3.18
2025-03-02 16:40:54,052 - INFO - Epoch:[224/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 16:41:01,357 - INFO - Epoch:[224/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 16:41:10,347 - INFO - Epoch:[224/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.46 loss_cvh: 3.14
2025-03-02 16:41:18,775 - INFO - Epoch:[224/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 16:41:26,002 - INFO - Epoch:[224/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 16:41:30,083 - INFO - Epoch:[224/805] Step:[90/90] reconstruction_loss: 1.35 loss_vc: 1.18 loss_cvh: 0.63
2025-03-02 16:41:31,274 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:42:17,751 - INFO - begin training stage: [225/805]
2025-03-02 16:42:17,751 - INFO - begin training stage: [225/805]
2025-03-02 16:42:23,492 - INFO - Epoch:[225/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 16:42:28,000 - INFO - Epoch:[225/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 16:42:32,470 - INFO - Epoch:[225/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 16:42:37,072 - INFO - Epoch:[225/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 16:42:41,797 - INFO - Epoch:[225/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 16:42:46,483 - INFO - Epoch:[225/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 16:42:51,356 - INFO - Epoch:[225/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 16:42:56,148 - INFO - Epoch:[225/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 16:43:00,455 - INFO - Epoch:[225/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.10 loss_cvh: 0.68
2025-03-02 16:43:01,861 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:43:44,074 - INFO - begin training stage: [226/805]
2025-03-02 16:43:44,075 - INFO - begin training stage: [226/805]
2025-03-02 16:43:49,471 - INFO - Epoch:[226/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 16:43:53,215 - INFO - Epoch:[226/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 16:43:58,373 - INFO - Epoch:[226/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 16:44:02,390 - INFO - Epoch:[226/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 16:44:06,170 - INFO - Epoch:[226/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 16:44:11,487 - INFO - Epoch:[226/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 16:44:18,765 - INFO - Epoch:[226/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 16:44:25,925 - INFO - Epoch:[226/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 16:44:30,442 - INFO - Epoch:[226/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.29 loss_cvh: 0.93
2025-03-02 16:44:33,361 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:45:15,602 - INFO - begin training stage: [227/805]
2025-03-02 16:45:15,602 - INFO - begin training stage: [227/805]
2025-03-02 16:45:24,122 - INFO - Epoch:[227/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 16:45:30,435 - INFO - Epoch:[227/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 16:45:34,475 - INFO - Epoch:[227/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 16:45:38,375 - INFO - Epoch:[227/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.05
2025-03-02 16:45:42,807 - INFO - Epoch:[227/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 16:45:49,319 - INFO - Epoch:[227/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 16:45:54,135 - INFO - Epoch:[227/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.06
2025-03-02 16:45:58,242 - INFO - Epoch:[227/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 16:46:03,342 - INFO - Epoch:[227/805] Step:[90/90] reconstruction_loss: 1.28 loss_vc: 1.30 loss_cvh: 0.75
2025-03-02 16:46:05,763 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:46:57,454 - INFO - begin training stage: [228/805]
2025-03-02 16:46:57,455 - INFO - begin training stage: [228/805]
2025-03-02 16:47:02,910 - INFO - Epoch:[228/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.08
2025-03-02 16:47:07,411 - INFO - Epoch:[228/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.14
2025-03-02 16:47:11,201 - INFO - Epoch:[228/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 16:47:14,921 - INFO - Epoch:[228/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 16:47:19,173 - INFO - Epoch:[228/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 16:47:23,780 - INFO - Epoch:[228/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 16:47:28,754 - INFO - Epoch:[228/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 16:47:33,878 - INFO - Epoch:[228/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.16
2025-03-02 16:47:39,527 - INFO - Epoch:[228/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.27 loss_cvh: 0.97
2025-03-02 16:47:41,489 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:48:24,069 - INFO - begin training stage: [229/805]
2025-03-02 16:48:24,069 - INFO - begin training stage: [229/805]
2025-03-02 16:48:29,024 - INFO - Epoch:[229/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 16:48:33,956 - INFO - Epoch:[229/805] Step:[20/90] reconstruction_loss: 1.20 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 16:48:42,707 - INFO - Epoch:[229/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 16:48:50,445 - INFO - Epoch:[229/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 16:48:54,923 - INFO - Epoch:[229/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 16:48:58,706 - INFO - Epoch:[229/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.11
2025-03-02 16:49:02,540 - INFO - Epoch:[229/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.17
2025-03-02 16:49:06,186 - INFO - Epoch:[229/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 16:49:09,454 - INFO - Epoch:[229/805] Step:[90/90] reconstruction_loss: 1.04 loss_vc: 1.11 loss_cvh: 0.88
2025-03-02 16:49:10,663 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:50:01,073 - INFO - begin training stage: [230/805]
2025-03-02 16:50:01,074 - INFO - begin training stage: [230/805]
2025-03-02 16:50:07,609 - INFO - Epoch:[230/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 16:50:13,468 - INFO - Epoch:[230/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 16:50:18,183 - INFO - Epoch:[230/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 16:50:22,025 - INFO - Epoch:[230/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 16:50:26,718 - INFO - Epoch:[230/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 16:50:30,945 - INFO - Epoch:[230/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 16:50:34,504 - INFO - Epoch:[230/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 16:50:38,069 - INFO - Epoch:[230/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.40 loss_cvh: 3.16
2025-03-02 16:50:41,569 - INFO - Epoch:[230/805] Step:[90/90] reconstruction_loss: 0.99 loss_vc: 1.36 loss_cvh: 1.02
2025-03-02 16:50:43,056 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:51:37,428 - INFO - begin training stage: [231/805]
2025-03-02 16:51:37,430 - INFO - eval data number: 45600
2025-03-02 16:51:37,430 - INFO - loading eval data ......
2025-03-02 16:52:18,304 - INFO - retrieval costs: 24.914042949676514
2025-03-02 16:54:47,902 - INFO - hamming distance computation costs: 149.59746193885803
2025-03-02 16:54:55,526 - INFO - hamming ranking costs: 7.623888969421387
2025-03-02 16:54:55,526 - INFO - labels shape: (45600, 239)
2025-03-02 16:56:01,074 - INFO - similarity labels generation costs: 65.54789328575134
2025-03-02 16:56:01,203 - INFO - topK: 5:, map: 0.3141775
2025-03-02 16:56:01,658 - INFO - topK: 20:, map: 0.22635215732216699
2025-03-02 16:56:02,545 - INFO - topK: 40:, map: 0.1947593929427709
2025-03-02 16:56:03,861 - INFO - topK: 60:, map: 0.1786349387112445
2025-03-02 16:56:05,633 - INFO - topK: 80:, map: 0.16600345880416376
2025-03-02 16:56:07,913 - INFO - topK: 100:, map: 0.15487450651279677
2025-03-02 16:56:09,959 - INFO - begin training stage: [231/805]
2025-03-02 16:56:17,632 - INFO - Epoch:[231/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 16:56:23,169 - INFO - Epoch:[231/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 16:56:28,828 - INFO - Epoch:[231/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.42 loss_cvh: 3.08
2025-03-02 16:56:33,582 - INFO - Epoch:[231/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.07
2025-03-02 16:56:38,651 - INFO - Epoch:[231/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 16:56:44,225 - INFO - Epoch:[231/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.16
2025-03-02 16:56:49,896 - INFO - Epoch:[231/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 16:56:55,634 - INFO - Epoch:[231/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 16:57:00,457 - INFO - Epoch:[231/805] Step:[90/90] reconstruction_loss: 1.32 loss_vc: 1.35 loss_cvh: 0.67
2025-03-02 16:57:02,493 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:58:19,353 - INFO - begin training stage: [232/805]
2025-03-02 16:58:19,354 - INFO - begin training stage: [232/805]
2025-03-02 16:58:26,505 - INFO - Epoch:[232/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 16:58:31,360 - INFO - Epoch:[232/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 16:58:36,424 - INFO - Epoch:[232/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 16:58:41,622 - INFO - Epoch:[232/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.17
2025-03-02 16:58:46,389 - INFO - Epoch:[232/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 16:58:52,808 - INFO - Epoch:[232/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 16:58:58,825 - INFO - Epoch:[232/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 16:59:05,774 - INFO - Epoch:[232/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 16:59:12,621 - INFO - Epoch:[232/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.50 loss_cvh: 0.99
2025-03-02 16:59:15,183 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 16:59:57,804 - INFO - begin training stage: [233/805]
2025-03-02 16:59:57,804 - INFO - begin training stage: [233/805]
2025-03-02 17:00:03,406 - INFO - Epoch:[233/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 17:00:07,147 - INFO - Epoch:[233/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 17:00:10,743 - INFO - Epoch:[233/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 17:00:14,280 - INFO - Epoch:[233/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 17:00:18,022 - INFO - Epoch:[233/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 17:00:23,458 - INFO - Epoch:[233/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 17:00:29,143 - INFO - Epoch:[233/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.21
2025-03-02 17:00:33,716 - INFO - Epoch:[233/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 17:00:37,260 - INFO - Epoch:[233/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.11 loss_cvh: 0.83
2025-03-02 17:00:39,523 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 17:01:46,409 - INFO - begin training stage: [234/805]
2025-03-02 17:01:46,409 - INFO - begin training stage: [234/805]
2025-03-02 17:01:51,877 - INFO - Epoch:[234/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 17:01:55,508 - INFO - Epoch:[234/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 17:01:59,399 - INFO - Epoch:[234/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 17:02:03,251 - INFO - Epoch:[234/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 17:02:06,890 - INFO - Epoch:[234/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 17:02:10,732 - INFO - Epoch:[234/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 17:02:15,845 - INFO - Epoch:[234/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.43 loss_cvh: 3.10
2025-03-02 17:02:20,280 - INFO - Epoch:[234/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 17:02:24,216 - INFO - Epoch:[234/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.24 loss_cvh: 0.77
2025-03-02 17:02:26,303 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 17:03:18,075 - INFO - begin training stage: [235/805]
2025-03-02 17:03:18,075 - INFO - begin training stage: [235/805]
2025-03-02 17:03:23,995 - INFO - Epoch:[235/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 17:03:29,207 - INFO - Epoch:[235/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 17:03:36,290 - INFO - Epoch:[235/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 17:03:42,422 - INFO - Epoch:[235/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 17:03:47,296 - INFO - Epoch:[235/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 17:03:51,191 - INFO - Epoch:[235/805] Step:[60/90] reconstruction_loss: 1.20 loss_vc: 4.43 loss_cvh: 3.08
2025-03-02 17:03:54,885 - INFO - Epoch:[235/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 17:03:58,586 - INFO - Epoch:[235/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.05
2025-03-02 17:04:02,390 - INFO - Epoch:[235/805] Step:[90/90] reconstruction_loss: 0.96 loss_vc: 1.29 loss_cvh: 0.68
2025-03-02 17:04:04,183 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 17:05:07,163 - INFO - begin training stage: [236/805]
2025-03-02 17:05:07,163 - INFO - begin training stage: [236/805]
2025-03-02 17:05:13,257 - INFO - Epoch:[236/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 17:05:17,890 - INFO - Epoch:[236/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 17:05:22,486 - INFO - Epoch:[236/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.05
2025-03-02 17:05:26,720 - INFO - Epoch:[236/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 17:05:31,018 - INFO - Epoch:[236/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 17:05:35,089 - INFO - Epoch:[236/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 17:05:40,047 - INFO - Epoch:[236/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.10
2025-03-02 17:05:47,779 - INFO - Epoch:[236/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 17:05:56,965 - INFO - Epoch:[236/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.22 loss_cvh: 0.96
2025-03-02 17:06:01,716 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 17:06:50,924 - INFO - begin training stage: [237/805]
2025-03-02 17:06:50,924 - INFO - begin training stage: [237/805]
2025-03-02 17:06:55,615 - INFO - Epoch:[237/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 17:06:59,048 - INFO - Epoch:[237/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 17:07:02,540 - INFO - Epoch:[237/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 17:07:06,403 - INFO - Epoch:[237/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 17:07:09,770 - INFO - Epoch:[237/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.02
2025-03-02 17:07:13,028 - INFO - Epoch:[237/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 17:07:16,322 - INFO - Epoch:[237/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 17:07:19,723 - INFO - Epoch:[237/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 17:07:22,772 - INFO - Epoch:[237/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.14 loss_cvh: 0.84
2025-03-02 17:07:24,090 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 17:08:07,997 - INFO - begin training stage: [238/805]
2025-03-02 17:08:07,997 - INFO - begin training stage: [238/805]
2025-03-02 17:08:13,089 - INFO - Epoch:[238/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 17:08:16,986 - INFO - Epoch:[238/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 17:08:20,311 - INFO - Epoch:[238/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 17:08:24,180 - INFO - Epoch:[238/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 17:08:29,197 - INFO - Epoch:[238/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.08
2025-03-02 17:08:34,062 - INFO - Epoch:[238/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.12
2025-03-02 17:08:38,697 - INFO - Epoch:[238/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 17:08:42,236 - INFO - Epoch:[238/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 17:08:45,291 - INFO - Epoch:[238/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.29 loss_cvh: 0.73
2025-03-02 17:08:46,457 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 17:09:19,660 - INFO - begin training stage: [239/805]
2025-03-02 17:09:19,660 - INFO - begin training stage: [239/805]
2025-03-02 17:09:24,644 - INFO - Epoch:[239/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 17:09:28,116 - INFO - Epoch:[239/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 17:09:31,514 - INFO - Epoch:[239/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 17:09:34,992 - INFO - Epoch:[239/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 17:09:39,918 - INFO - Epoch:[239/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 17:09:44,710 - INFO - Epoch:[239/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 17:09:48,540 - INFO - Epoch:[239/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 17:09:52,276 - INFO - Epoch:[239/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 17:09:56,092 - INFO - Epoch:[239/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.35 loss_cvh: 0.88
2025-03-02 17:09:57,326 - INFO - now the learning rate is: 3.138105960900002e-05
2025-03-02 17:10:43,627 - INFO - begin training stage: [240/805]
2025-03-02 17:10:43,628 - INFO - begin training stage: [240/805]
2025-03-02 17:10:47,833 - INFO - Epoch:[240/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.45 loss_cvh: 3.17
2025-03-02 17:10:51,031 - INFO - Epoch:[240/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 17:10:54,178 - INFO - Epoch:[240/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 17:10:57,378 - INFO - Epoch:[240/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 17:11:00,477 - INFO - Epoch:[240/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.44 loss_cvh: 3.11
2025-03-02 17:11:04,045 - INFO - Epoch:[240/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 17:11:08,385 - INFO - Epoch:[240/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 17:11:13,600 - INFO - Epoch:[240/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 17:11:16,818 - INFO - Epoch:[240/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.29 loss_cvh: 0.76
2025-03-02 17:11:17,963 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:12:09,068 - INFO - begin training stage: [241/805]
2025-03-02 17:12:09,069 - INFO - eval data number: 45600
2025-03-02 17:12:09,069 - INFO - loading eval data ......
2025-03-02 17:12:45,718 - INFO - retrieval costs: 21.275347471237183
2025-03-02 17:15:18,593 - INFO - hamming distance computation costs: 152.87492680549622
2025-03-02 17:15:27,500 - INFO - hamming ranking costs: 8.907063245773315
2025-03-02 17:15:27,500 - INFO - labels shape: (45600, 239)
2025-03-02 17:16:06,603 - INFO - similarity labels generation costs: 39.10284996032715
2025-03-02 17:16:06,681 - INFO - topK: 5:, map: 0.3190558333333333
2025-03-02 17:16:06,966 - INFO - topK: 20:, map: 0.227898312408964
2025-03-02 17:16:07,550 - INFO - topK: 40:, map: 0.19791079975459502
2025-03-02 17:16:08,618 - INFO - topK: 60:, map: 0.18041066581002346
2025-03-02 17:16:10,057 - INFO - topK: 80:, map: 0.16654667485521396
2025-03-02 17:16:12,020 - INFO - topK: 100:, map: 0.15542178146771782
2025-03-02 17:16:14,358 - INFO - begin training stage: [241/805]
2025-03-02 17:16:19,857 - INFO - Epoch:[241/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 17:16:23,798 - INFO - Epoch:[241/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 17:16:28,302 - INFO - Epoch:[241/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 17:16:33,713 - INFO - Epoch:[241/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 17:16:39,176 - INFO - Epoch:[241/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 17:16:44,073 - INFO - Epoch:[241/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 17:16:49,558 - INFO - Epoch:[241/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 17:16:54,425 - INFO - Epoch:[241/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 17:16:59,302 - INFO - Epoch:[241/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.33 loss_cvh: 0.82
2025-03-02 17:17:00,897 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:18:16,717 - INFO - begin training stage: [242/805]
2025-03-02 17:18:16,717 - INFO - begin training stage: [242/805]
2025-03-02 17:18:24,537 - INFO - Epoch:[242/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 17:18:30,349 - INFO - Epoch:[242/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 17:18:35,748 - INFO - Epoch:[242/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 17:18:40,822 - INFO - Epoch:[242/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 17:18:45,644 - INFO - Epoch:[242/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 17:18:50,793 - INFO - Epoch:[242/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 17:18:55,727 - INFO - Epoch:[242/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 17:19:00,377 - INFO - Epoch:[242/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.20
2025-03-02 17:19:04,763 - INFO - Epoch:[242/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.40 loss_cvh: 0.68
2025-03-02 17:19:07,038 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:20:09,027 - INFO - begin training stage: [243/805]
2025-03-02 17:20:09,028 - INFO - begin training stage: [243/805]
2025-03-02 17:20:16,414 - INFO - Epoch:[243/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 17:20:21,617 - INFO - Epoch:[243/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.18
2025-03-02 17:20:26,543 - INFO - Epoch:[243/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 17:20:31,489 - INFO - Epoch:[243/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 17:20:36,279 - INFO - Epoch:[243/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 17:20:40,365 - INFO - Epoch:[243/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 17:20:44,613 - INFO - Epoch:[243/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 17:20:48,558 - INFO - Epoch:[243/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 17:20:52,243 - INFO - Epoch:[243/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.25 loss_cvh: 0.79
2025-03-02 17:20:53,435 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:21:39,202 - INFO - begin training stage: [244/805]
2025-03-02 17:21:39,202 - INFO - begin training stage: [244/805]
2025-03-02 17:21:44,125 - INFO - Epoch:[244/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 17:21:47,848 - INFO - Epoch:[244/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 17:21:52,301 - INFO - Epoch:[244/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.16
2025-03-02 17:21:56,456 - INFO - Epoch:[244/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 17:22:00,368 - INFO - Epoch:[244/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 17:22:03,963 - INFO - Epoch:[244/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 17:22:07,563 - INFO - Epoch:[244/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 17:22:11,271 - INFO - Epoch:[244/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 17:22:14,840 - INFO - Epoch:[244/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.20 loss_cvh: 0.70
2025-03-02 17:22:16,114 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:22:56,303 - INFO - begin training stage: [245/805]
2025-03-02 17:22:56,303 - INFO - begin training stage: [245/805]
2025-03-02 17:23:01,201 - INFO - Epoch:[245/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 17:23:05,062 - INFO - Epoch:[245/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.08
2025-03-02 17:23:08,838 - INFO - Epoch:[245/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 17:23:12,587 - INFO - Epoch:[245/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 17:23:16,818 - INFO - Epoch:[245/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 17:23:22,873 - INFO - Epoch:[245/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 17:23:29,317 - INFO - Epoch:[245/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 17:23:36,212 - INFO - Epoch:[245/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 17:23:40,475 - INFO - Epoch:[245/805] Step:[90/90] reconstruction_loss: 1.05 loss_vc: 1.21 loss_cvh: 0.72
2025-03-02 17:23:41,841 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:24:19,485 - INFO - begin training stage: [246/805]
2025-03-02 17:24:19,485 - INFO - begin training stage: [246/805]
2025-03-02 17:24:25,393 - INFO - Epoch:[246/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 17:24:29,506 - INFO - Epoch:[246/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.43 loss_cvh: 3.07
2025-03-02 17:24:33,308 - INFO - Epoch:[246/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 17:24:37,149 - INFO - Epoch:[246/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 17:24:40,790 - INFO - Epoch:[246/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 17:24:44,568 - INFO - Epoch:[246/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 17:24:48,384 - INFO - Epoch:[246/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 17:24:52,235 - INFO - Epoch:[246/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 17:24:55,723 - INFO - Epoch:[246/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.16 loss_cvh: 0.72
2025-03-02 17:24:56,737 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:25:37,693 - INFO - begin training stage: [247/805]
2025-03-02 17:25:37,693 - INFO - begin training stage: [247/805]
2025-03-02 17:25:44,775 - INFO - Epoch:[247/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 17:25:49,922 - INFO - Epoch:[247/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 17:25:54,210 - INFO - Epoch:[247/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 17:25:58,355 - INFO - Epoch:[247/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 17:26:02,306 - INFO - Epoch:[247/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 17:26:06,086 - INFO - Epoch:[247/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 17:26:09,751 - INFO - Epoch:[247/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 17:26:13,557 - INFO - Epoch:[247/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 17:26:17,246 - INFO - Epoch:[247/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.37 loss_cvh: 0.93
2025-03-02 17:26:18,768 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:26:57,026 - INFO - begin training stage: [248/805]
2025-03-02 17:26:57,027 - INFO - begin training stage: [248/805]
2025-03-02 17:27:02,641 - INFO - Epoch:[248/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.16
2025-03-02 17:27:07,940 - INFO - Epoch:[248/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.14
2025-03-02 17:27:13,483 - INFO - Epoch:[248/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 17:27:17,478 - INFO - Epoch:[248/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 17:27:21,419 - INFO - Epoch:[248/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 17:27:25,741 - INFO - Epoch:[248/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 17:27:29,926 - INFO - Epoch:[248/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 17:27:33,677 - INFO - Epoch:[248/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 17:27:37,085 - INFO - Epoch:[248/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.35 loss_cvh: 0.70
2025-03-02 17:27:38,160 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:28:25,777 - INFO - begin training stage: [249/805]
2025-03-02 17:28:25,778 - INFO - begin training stage: [249/805]
2025-03-02 17:28:30,374 - INFO - Epoch:[249/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 17:28:33,893 - INFO - Epoch:[249/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 17:28:37,492 - INFO - Epoch:[249/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 17:28:41,119 - INFO - Epoch:[249/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.09
2025-03-02 17:28:44,773 - INFO - Epoch:[249/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 17:28:48,740 - INFO - Epoch:[249/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.17
2025-03-02 17:28:52,984 - INFO - Epoch:[249/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 17:28:57,074 - INFO - Epoch:[249/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 17:29:00,576 - INFO - Epoch:[249/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.30 loss_cvh: 0.87
2025-03-02 17:29:01,664 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:29:42,622 - INFO - begin training stage: [250/805]
2025-03-02 17:29:42,622 - INFO - begin training stage: [250/805]
2025-03-02 17:29:47,381 - INFO - Epoch:[250/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 17:29:53,013 - INFO - Epoch:[250/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.44 loss_cvh: 3.15
2025-03-02 17:29:58,600 - INFO - Epoch:[250/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.20
2025-03-02 17:30:03,905 - INFO - Epoch:[250/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.17
2025-03-02 17:30:11,085 - INFO - Epoch:[250/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 17:30:18,154 - INFO - Epoch:[250/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 17:30:24,346 - INFO - Epoch:[250/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 17:30:28,331 - INFO - Epoch:[250/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.18
2025-03-02 17:30:31,588 - INFO - Epoch:[250/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.22 loss_cvh: 0.71
2025-03-02 17:30:32,600 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:31:10,170 - INFO - begin training stage: [251/805]
2025-03-02 17:31:10,171 - INFO - eval data number: 45600
2025-03-02 17:31:10,171 - INFO - loading eval data ......
2025-03-02 17:31:50,165 - INFO - retrieval costs: 25.132611751556396
2025-03-02 17:34:12,453 - INFO - hamming distance computation costs: 142.2874505519867
2025-03-02 17:34:26,436 - INFO - hamming ranking costs: 13.983102560043335
2025-03-02 17:34:26,437 - INFO - labels shape: (45600, 239)
2025-03-02 17:35:06,359 - INFO - similarity labels generation costs: 39.92305397987366
2025-03-02 17:35:06,435 - INFO - topK: 5:, map: 0.3272758333333334
2025-03-02 17:35:06,700 - INFO - topK: 20:, map: 0.2317934061168557
2025-03-02 17:35:07,215 - INFO - topK: 40:, map: 0.19983923339338586
2025-03-02 17:35:07,991 - INFO - topK: 60:, map: 0.18211714205848292
2025-03-02 17:35:09,048 - INFO - topK: 80:, map: 0.1680514820105943
2025-03-02 17:35:10,419 - INFO - topK: 100:, map: 0.15640266606006645
2025-03-02 17:35:12,371 - INFO - begin training stage: [251/805]
2025-03-02 17:35:19,172 - INFO - Epoch:[251/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 17:35:23,483 - INFO - Epoch:[251/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 17:35:27,184 - INFO - Epoch:[251/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 17:35:30,660 - INFO - Epoch:[251/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 17:35:34,632 - INFO - Epoch:[251/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 17:35:39,038 - INFO - Epoch:[251/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 17:35:44,405 - INFO - Epoch:[251/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 17:35:49,489 - INFO - Epoch:[251/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 17:35:54,226 - INFO - Epoch:[251/805] Step:[90/90] reconstruction_loss: 1.39 loss_vc: 1.27 loss_cvh: 0.79
2025-03-02 17:35:55,896 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:37:13,226 - INFO - begin training stage: [252/805]
2025-03-02 17:37:13,227 - INFO - begin training stage: [252/805]
2025-03-02 17:37:19,745 - INFO - Epoch:[252/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 17:37:24,905 - INFO - Epoch:[252/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 17:37:30,197 - INFO - Epoch:[252/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 17:37:34,786 - INFO - Epoch:[252/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 17:37:39,481 - INFO - Epoch:[252/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 17:37:44,117 - INFO - Epoch:[252/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 17:37:48,653 - INFO - Epoch:[252/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 17:37:54,120 - INFO - Epoch:[252/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 17:37:58,872 - INFO - Epoch:[252/805] Step:[90/90] reconstruction_loss: 1.28 loss_vc: 1.11 loss_cvh: 0.70
2025-03-02 17:38:00,419 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:39:06,602 - INFO - begin training stage: [253/805]
2025-03-02 17:39:06,603 - INFO - begin training stage: [253/805]
2025-03-02 17:39:13,156 - INFO - Epoch:[253/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 17:39:18,169 - INFO - Epoch:[253/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.17
2025-03-02 17:39:23,538 - INFO - Epoch:[253/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 17:39:29,546 - INFO - Epoch:[253/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 17:39:34,905 - INFO - Epoch:[253/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 17:39:40,625 - INFO - Epoch:[253/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 17:39:45,945 - INFO - Epoch:[253/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 17:39:51,820 - INFO - Epoch:[253/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 17:39:57,020 - INFO - Epoch:[253/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.27 loss_cvh: 0.89
2025-03-02 17:39:58,653 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:40:42,901 - INFO - begin training stage: [254/805]
2025-03-02 17:40:42,901 - INFO - begin training stage: [254/805]
2025-03-02 17:40:47,297 - INFO - Epoch:[254/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 17:40:50,687 - INFO - Epoch:[254/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 17:40:53,986 - INFO - Epoch:[254/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 17:40:57,366 - INFO - Epoch:[254/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 17:41:00,901 - INFO - Epoch:[254/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.07
2025-03-02 17:41:06,278 - INFO - Epoch:[254/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.43 loss_cvh: 3.15
2025-03-02 17:41:13,353 - INFO - Epoch:[254/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 17:41:17,387 - INFO - Epoch:[254/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 17:41:20,831 - INFO - Epoch:[254/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.25 loss_cvh: 0.61
2025-03-02 17:41:21,835 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:42:18,504 - INFO - begin training stage: [255/805]
2025-03-02 17:42:18,504 - INFO - begin training stage: [255/805]
2025-03-02 17:42:23,412 - INFO - Epoch:[255/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 17:42:27,124 - INFO - Epoch:[255/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 17:42:30,808 - INFO - Epoch:[255/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 17:42:34,547 - INFO - Epoch:[255/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 17:42:38,223 - INFO - Epoch:[255/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 17:42:41,960 - INFO - Epoch:[255/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 17:42:45,617 - INFO - Epoch:[255/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 17:42:49,664 - INFO - Epoch:[255/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 17:42:53,449 - INFO - Epoch:[255/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.10 loss_cvh: 0.51
2025-03-02 17:42:54,637 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:43:35,642 - INFO - begin training stage: [256/805]
2025-03-02 17:43:35,643 - INFO - begin training stage: [256/805]
2025-03-02 17:43:40,684 - INFO - Epoch:[256/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 17:43:44,281 - INFO - Epoch:[256/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 17:43:48,061 - INFO - Epoch:[256/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 17:43:52,808 - INFO - Epoch:[256/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 17:43:58,413 - INFO - Epoch:[256/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 17:44:04,255 - INFO - Epoch:[256/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 17:44:08,289 - INFO - Epoch:[256/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 17:44:12,055 - INFO - Epoch:[256/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 17:44:15,530 - INFO - Epoch:[256/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.20 loss_cvh: 0.77
2025-03-02 17:44:16,547 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:44:54,493 - INFO - begin training stage: [257/805]
2025-03-02 17:44:54,493 - INFO - begin training stage: [257/805]
2025-03-02 17:45:00,059 - INFO - Epoch:[257/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 17:45:05,329 - INFO - Epoch:[257/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 17:45:12,197 - INFO - Epoch:[257/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 17:45:16,519 - INFO - Epoch:[257/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 17:45:20,363 - INFO - Epoch:[257/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.05
2025-03-02 17:45:24,406 - INFO - Epoch:[257/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 17:45:28,009 - INFO - Epoch:[257/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 17:45:31,918 - INFO - Epoch:[257/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 17:45:35,631 - INFO - Epoch:[257/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.36 loss_cvh: 0.80
2025-03-02 17:45:36,782 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:46:15,797 - INFO - begin training stage: [258/805]
2025-03-02 17:46:15,798 - INFO - begin training stage: [258/805]
2025-03-02 17:46:20,478 - INFO - Epoch:[258/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 17:46:24,078 - INFO - Epoch:[258/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 17:46:28,146 - INFO - Epoch:[258/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 17:46:34,025 - INFO - Epoch:[258/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 17:46:39,290 - INFO - Epoch:[258/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 17:46:44,036 - INFO - Epoch:[258/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 17:46:48,049 - INFO - Epoch:[258/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 17:46:52,640 - INFO - Epoch:[258/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 17:46:56,496 - INFO - Epoch:[258/805] Step:[90/90] reconstruction_loss: 1.00 loss_vc: 1.30 loss_cvh: 0.82
2025-03-02 17:46:58,792 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:48:05,922 - INFO - begin training stage: [259/805]
2025-03-02 17:48:05,923 - INFO - begin training stage: [259/805]
2025-03-02 17:48:11,512 - INFO - Epoch:[259/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 17:48:15,523 - INFO - Epoch:[259/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 17:48:20,058 - INFO - Epoch:[259/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 17:48:25,782 - INFO - Epoch:[259/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 17:48:32,085 - INFO - Epoch:[259/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 17:48:37,647 - INFO - Epoch:[259/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 17:48:42,308 - INFO - Epoch:[259/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 17:48:46,916 - INFO - Epoch:[259/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 17:48:50,764 - INFO - Epoch:[259/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.15 loss_cvh: 0.71
2025-03-02 17:48:52,403 - INFO - now the learning rate is: 2.8242953648100018e-05
2025-03-02 17:49:53,881 - INFO - begin training stage: [260/805]
2025-03-02 17:49:53,882 - INFO - begin training stage: [260/805]
2025-03-02 17:49:59,952 - INFO - Epoch:[260/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 17:50:07,008 - INFO - Epoch:[260/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 17:50:14,030 - INFO - Epoch:[260/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 17:50:19,831 - INFO - Epoch:[260/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.15
2025-03-02 17:50:24,564 - INFO - Epoch:[260/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 17:50:28,676 - INFO - Epoch:[260/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 17:50:32,353 - INFO - Epoch:[260/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 17:50:36,224 - INFO - Epoch:[260/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 17:50:40,321 - INFO - Epoch:[260/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.29 loss_cvh: 0.75
2025-03-02 17:50:42,454 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 17:51:45,338 - INFO - begin training stage: [261/805]
2025-03-02 17:51:45,341 - INFO - eval data number: 45600
2025-03-02 17:51:45,341 - INFO - loading eval data ......
2025-03-02 17:52:35,105 - INFO - retrieval costs: 31.75889229774475
2025-03-02 17:56:03,996 - INFO - hamming distance computation costs: 208.89120602607727
2025-03-02 17:56:16,250 - INFO - hamming ranking costs: 12.253312110900879
2025-03-02 17:56:16,250 - INFO - labels shape: (45600, 239)
2025-03-02 17:57:06,556 - INFO - similarity labels generation costs: 50.30672550201416
2025-03-02 17:57:06,686 - INFO - topK: 5:, map: 0.32069833333333336
2025-03-02 17:57:07,140 - INFO - topK: 20:, map: 0.22990081482780206
2025-03-02 17:57:08,024 - INFO - topK: 40:, map: 0.198339530644786
2025-03-02 17:57:09,334 - INFO - topK: 60:, map: 0.18132783363582877
2025-03-02 17:57:11,079 - INFO - topK: 80:, map: 0.16761840419695245
2025-03-02 17:57:13,245 - INFO - topK: 100:, map: 0.156350424236087
2025-03-02 17:57:15,176 - INFO - begin training stage: [261/805]
2025-03-02 17:57:23,229 - INFO - Epoch:[261/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 17:57:28,920 - INFO - Epoch:[261/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.16
2025-03-02 17:57:34,296 - INFO - Epoch:[261/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 17:57:40,336 - INFO - Epoch:[261/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 17:57:46,289 - INFO - Epoch:[261/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 17:57:51,785 - INFO - Epoch:[261/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.16
2025-03-02 17:57:56,940 - INFO - Epoch:[261/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 17:58:01,738 - INFO - Epoch:[261/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.17
2025-03-02 17:58:06,288 - INFO - Epoch:[261/805] Step:[90/90] reconstruction_loss: 1.31 loss_vc: 1.28 loss_cvh: 0.76
2025-03-02 17:58:07,699 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 17:59:28,722 - INFO - begin training stage: [262/805]
2025-03-02 17:59:28,723 - INFO - begin training stage: [262/805]
2025-03-02 17:59:35,549 - INFO - Epoch:[262/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.43 loss_cvh: 3.17
2025-03-02 17:59:40,454 - INFO - Epoch:[262/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 17:59:45,597 - INFO - Epoch:[262/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 17:59:50,449 - INFO - Epoch:[262/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 17:59:55,102 - INFO - Epoch:[262/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 17:59:59,517 - INFO - Epoch:[262/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 18:00:04,540 - INFO - Epoch:[262/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 18:00:10,013 - INFO - Epoch:[262/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 18:00:15,442 - INFO - Epoch:[262/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.28 loss_cvh: 0.82
2025-03-02 18:00:17,540 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:01:34,672 - INFO - begin training stage: [263/805]
2025-03-02 18:01:34,673 - INFO - begin training stage: [263/805]
2025-03-02 18:01:43,224 - INFO - Epoch:[263/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 18:01:49,574 - INFO - Epoch:[263/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 18:01:55,930 - INFO - Epoch:[263/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 18:02:02,110 - INFO - Epoch:[263/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 18:02:07,478 - INFO - Epoch:[263/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 18:02:12,604 - INFO - Epoch:[263/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 18:02:17,557 - INFO - Epoch:[263/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 18:02:22,459 - INFO - Epoch:[263/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 18:02:27,120 - INFO - Epoch:[263/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.19 loss_cvh: 0.73
2025-03-02 18:02:28,603 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:03:21,232 - INFO - begin training stage: [264/805]
2025-03-02 18:03:21,233 - INFO - begin training stage: [264/805]
2025-03-02 18:03:28,012 - INFO - Epoch:[264/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 18:03:33,654 - INFO - Epoch:[264/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 18:03:39,508 - INFO - Epoch:[264/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.44 loss_cvh: 3.10
2025-03-02 18:03:45,401 - INFO - Epoch:[264/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 18:03:50,729 - INFO - Epoch:[264/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 18:03:55,753 - INFO - Epoch:[264/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 18:04:00,909 - INFO - Epoch:[264/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 18:04:05,937 - INFO - Epoch:[264/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 18:04:09,865 - INFO - Epoch:[264/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.22 loss_cvh: 0.75
2025-03-02 18:04:11,093 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:05:07,401 - INFO - begin training stage: [265/805]
2025-03-02 18:05:07,401 - INFO - begin training stage: [265/805]
2025-03-02 18:05:13,196 - INFO - Epoch:[265/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 18:05:17,655 - INFO - Epoch:[265/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 18:05:21,747 - INFO - Epoch:[265/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 18:05:26,084 - INFO - Epoch:[265/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 18:05:30,294 - INFO - Epoch:[265/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.03
2025-03-02 18:05:34,168 - INFO - Epoch:[265/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 18:05:38,512 - INFO - Epoch:[265/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.17
2025-03-02 18:05:43,796 - INFO - Epoch:[265/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 18:05:49,874 - INFO - Epoch:[265/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.26 loss_cvh: 0.68
2025-03-02 18:05:52,361 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:06:43,687 - INFO - begin training stage: [266/805]
2025-03-02 18:06:43,687 - INFO - begin training stage: [266/805]
2025-03-02 18:06:50,353 - INFO - Epoch:[266/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.02
2025-03-02 18:06:55,093 - INFO - Epoch:[266/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 18:07:00,542 - INFO - Epoch:[266/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.40 loss_cvh: 3.17
2025-03-02 18:07:05,525 - INFO - Epoch:[266/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 18:07:09,958 - INFO - Epoch:[266/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 18:07:14,157 - INFO - Epoch:[266/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 18:07:18,777 - INFO - Epoch:[266/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.14
2025-03-02 18:07:23,494 - INFO - Epoch:[266/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 18:07:27,401 - INFO - Epoch:[266/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.19 loss_cvh: 0.85
2025-03-02 18:07:28,577 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:08:22,752 - INFO - begin training stage: [267/805]
2025-03-02 18:08:22,753 - INFO - begin training stage: [267/805]
2025-03-02 18:08:28,566 - INFO - Epoch:[267/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.43 loss_cvh: 3.11
2025-03-02 18:08:34,237 - INFO - Epoch:[267/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 18:08:38,417 - INFO - Epoch:[267/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 18:08:42,339 - INFO - Epoch:[267/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 18:08:46,345 - INFO - Epoch:[267/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 18:08:50,743 - INFO - Epoch:[267/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 18:08:55,598 - INFO - Epoch:[267/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 18:09:00,513 - INFO - Epoch:[267/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 18:09:04,166 - INFO - Epoch:[267/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.42 loss_cvh: 0.88
2025-03-02 18:09:05,335 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:10:01,366 - INFO - begin training stage: [268/805]
2025-03-02 18:10:01,366 - INFO - begin training stage: [268/805]
2025-03-02 18:10:07,025 - INFO - Epoch:[268/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 18:10:11,235 - INFO - Epoch:[268/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 18:10:15,719 - INFO - Epoch:[268/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 18:10:20,248 - INFO - Epoch:[268/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.16
2025-03-02 18:10:25,019 - INFO - Epoch:[268/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 18:10:30,201 - INFO - Epoch:[268/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 18:10:35,553 - INFO - Epoch:[268/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 18:10:40,109 - INFO - Epoch:[268/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 18:10:44,136 - INFO - Epoch:[268/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.27 loss_cvh: 0.88
2025-03-02 18:10:45,440 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:11:38,835 - INFO - begin training stage: [269/805]
2025-03-02 18:11:38,836 - INFO - begin training stage: [269/805]
2025-03-02 18:11:45,768 - INFO - Epoch:[269/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 18:11:50,316 - INFO - Epoch:[269/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 18:11:56,294 - INFO - Epoch:[269/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 18:12:01,544 - INFO - Epoch:[269/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 18:12:07,041 - INFO - Epoch:[269/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 18:12:11,933 - INFO - Epoch:[269/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 18:12:15,958 - INFO - Epoch:[269/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 18:12:20,107 - INFO - Epoch:[269/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 18:12:23,729 - INFO - Epoch:[269/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.21 loss_cvh: 0.63
2025-03-02 18:12:24,783 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:13:12,956 - INFO - begin training stage: [270/805]
2025-03-02 18:13:12,956 - INFO - begin training stage: [270/805]
2025-03-02 18:13:17,934 - INFO - Epoch:[270/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.15
2025-03-02 18:13:22,123 - INFO - Epoch:[270/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 18:13:28,204 - INFO - Epoch:[270/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 18:13:34,707 - INFO - Epoch:[270/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 18:13:40,949 - INFO - Epoch:[270/805] Step:[50/90] reconstruction_loss: 1.19 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 18:13:45,290 - INFO - Epoch:[270/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 18:13:49,684 - INFO - Epoch:[270/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 18:13:53,949 - INFO - Epoch:[270/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 18:13:57,579 - INFO - Epoch:[270/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.24 loss_cvh: 0.77
2025-03-02 18:13:58,839 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:14:51,353 - INFO - begin training stage: [271/805]
2025-03-02 18:14:51,355 - INFO - eval data number: 45600
2025-03-02 18:14:51,355 - INFO - loading eval data ......
2025-03-02 18:15:40,356 - INFO - retrieval costs: 31.102319717407227
2025-03-02 18:18:35,258 - INFO - hamming distance computation costs: 174.90211057662964
2025-03-02 18:18:45,785 - INFO - hamming ranking costs: 10.527273893356323
2025-03-02 18:18:45,786 - INFO - labels shape: (45600, 239)
2025-03-02 18:19:40,357 - INFO - similarity labels generation costs: 54.571812868118286
2025-03-02 18:19:40,499 - INFO - topK: 5:, map: 0.32170166666666666
2025-03-02 18:19:41,045 - INFO - topK: 20:, map: 0.23204363572454803
2025-03-02 18:19:42,082 - INFO - topK: 40:, map: 0.20126564862834606
2025-03-02 18:19:43,688 - INFO - topK: 60:, map: 0.182347249391736
2025-03-02 18:19:45,861 - INFO - topK: 80:, map: 0.16843723649322334
2025-03-02 18:19:48,508 - INFO - topK: 100:, map: 0.15740514199582584
2025-03-02 18:19:51,096 - INFO - begin training stage: [271/805]
2025-03-02 18:19:58,637 - INFO - Epoch:[271/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 18:20:04,000 - INFO - Epoch:[271/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 18:20:09,089 - INFO - Epoch:[271/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 18:20:14,166 - INFO - Epoch:[271/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 18:20:19,432 - INFO - Epoch:[271/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 18:20:24,562 - INFO - Epoch:[271/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 18:20:29,400 - INFO - Epoch:[271/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 18:20:34,458 - INFO - Epoch:[271/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 18:20:39,438 - INFO - Epoch:[271/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.21 loss_cvh: 0.80
2025-03-02 18:20:40,897 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:21:58,129 - INFO - begin training stage: [272/805]
2025-03-02 18:21:58,129 - INFO - begin training stage: [272/805]
2025-03-02 18:22:05,260 - INFO - Epoch:[272/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.07
2025-03-02 18:22:10,424 - INFO - Epoch:[272/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 18:22:15,687 - INFO - Epoch:[272/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 18:22:21,135 - INFO - Epoch:[272/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 18:22:26,665 - INFO - Epoch:[272/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 18:22:32,093 - INFO - Epoch:[272/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 18:22:37,582 - INFO - Epoch:[272/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 18:22:43,128 - INFO - Epoch:[272/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 18:22:47,941 - INFO - Epoch:[272/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.13 loss_cvh: 0.87
2025-03-02 18:22:49,507 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:24:04,821 - INFO - begin training stage: [273/805]
2025-03-02 18:24:04,821 - INFO - begin training stage: [273/805]
2025-03-02 18:24:11,703 - INFO - Epoch:[273/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 18:24:17,669 - INFO - Epoch:[273/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 18:24:23,772 - INFO - Epoch:[273/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 18:24:29,816 - INFO - Epoch:[273/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 18:24:35,648 - INFO - Epoch:[273/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 18:24:41,092 - INFO - Epoch:[273/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 18:24:46,076 - INFO - Epoch:[273/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 18:24:51,391 - INFO - Epoch:[273/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 18:24:56,420 - INFO - Epoch:[273/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.07 loss_cvh: 0.62
2025-03-02 18:24:57,906 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:25:46,765 - INFO - begin training stage: [274/805]
2025-03-02 18:25:46,766 - INFO - begin training stage: [274/805]
2025-03-02 18:25:51,738 - INFO - Epoch:[274/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 18:25:55,891 - INFO - Epoch:[274/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 18:25:59,515 - INFO - Epoch:[274/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 18:26:03,161 - INFO - Epoch:[274/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 18:26:06,913 - INFO - Epoch:[274/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 18:26:11,054 - INFO - Epoch:[274/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 18:26:16,744 - INFO - Epoch:[274/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 18:26:22,967 - INFO - Epoch:[274/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 18:26:29,718 - INFO - Epoch:[274/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.08 loss_cvh: 0.67
2025-03-02 18:26:31,569 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:27:22,842 - INFO - begin training stage: [275/805]
2025-03-02 18:27:22,843 - INFO - begin training stage: [275/805]
2025-03-02 18:27:31,320 - INFO - Epoch:[275/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 18:27:35,991 - INFO - Epoch:[275/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 18:27:40,064 - INFO - Epoch:[275/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 18:27:44,054 - INFO - Epoch:[275/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.15
2025-03-02 18:27:49,989 - INFO - Epoch:[275/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 18:27:56,515 - INFO - Epoch:[275/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 18:28:02,522 - INFO - Epoch:[275/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 18:28:07,063 - INFO - Epoch:[275/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.04
2025-03-02 18:28:11,843 - INFO - Epoch:[275/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.10 loss_cvh: 0.54
2025-03-02 18:28:14,027 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:29:01,011 - INFO - begin training stage: [276/805]
2025-03-02 18:29:01,012 - INFO - begin training stage: [276/805]
2025-03-02 18:29:06,172 - INFO - Epoch:[276/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 18:29:09,936 - INFO - Epoch:[276/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 18:29:14,005 - INFO - Epoch:[276/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 18:29:19,434 - INFO - Epoch:[276/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 18:29:24,403 - INFO - Epoch:[276/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 18:29:30,305 - INFO - Epoch:[276/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 18:29:37,123 - INFO - Epoch:[276/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 18:29:43,307 - INFO - Epoch:[276/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 18:29:48,256 - INFO - Epoch:[276/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.23 loss_cvh: 0.83
2025-03-02 18:29:49,520 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:30:35,703 - INFO - begin training stage: [277/805]
2025-03-02 18:30:35,703 - INFO - begin training stage: [277/805]
2025-03-02 18:30:40,708 - INFO - Epoch:[277/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.44 loss_cvh: 3.14
2025-03-02 18:30:44,503 - INFO - Epoch:[277/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 18:30:48,385 - INFO - Epoch:[277/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 18:30:52,172 - INFO - Epoch:[277/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 18:30:56,883 - INFO - Epoch:[277/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.07
2025-03-02 18:31:02,178 - INFO - Epoch:[277/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 18:31:06,318 - INFO - Epoch:[277/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 18:31:10,376 - INFO - Epoch:[277/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 18:31:14,190 - INFO - Epoch:[277/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.28 loss_cvh: 0.75
2025-03-02 18:31:15,558 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:32:04,003 - INFO - begin training stage: [278/805]
2025-03-02 18:32:04,004 - INFO - begin training stage: [278/805]
2025-03-02 18:32:09,419 - INFO - Epoch:[278/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 18:32:13,262 - INFO - Epoch:[278/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.18
2025-03-02 18:32:17,017 - INFO - Epoch:[278/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 18:32:20,887 - INFO - Epoch:[278/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 18:32:24,695 - INFO - Epoch:[278/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.13
2025-03-02 18:32:28,608 - INFO - Epoch:[278/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 18:32:33,658 - INFO - Epoch:[278/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 18:32:40,129 - INFO - Epoch:[278/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 18:32:45,924 - INFO - Epoch:[278/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.42 loss_cvh: 0.91
2025-03-02 18:32:48,371 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:33:32,911 - INFO - begin training stage: [279/805]
2025-03-02 18:33:32,911 - INFO - begin training stage: [279/805]
2025-03-02 18:33:37,865 - INFO - Epoch:[279/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.42 loss_cvh: 3.16
2025-03-02 18:33:41,726 - INFO - Epoch:[279/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.07
2025-03-02 18:33:45,637 - INFO - Epoch:[279/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 18:33:49,916 - INFO - Epoch:[279/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 18:33:54,181 - INFO - Epoch:[279/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 18:33:59,384 - INFO - Epoch:[279/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 18:34:04,776 - INFO - Epoch:[279/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 18:34:10,540 - INFO - Epoch:[279/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 18:34:15,532 - INFO - Epoch:[279/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.25 loss_cvh: 0.78
2025-03-02 18:34:18,281 - INFO - now the learning rate is: 2.5418658283290016e-05
2025-03-02 18:35:18,170 - INFO - begin training stage: [280/805]
2025-03-02 18:35:18,171 - INFO - begin training stage: [280/805]
2025-03-02 18:35:25,393 - INFO - Epoch:[280/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 18:35:29,761 - INFO - Epoch:[280/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.10
2025-03-02 18:35:34,219 - INFO - Epoch:[280/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 18:35:38,619 - INFO - Epoch:[280/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.17
2025-03-02 18:35:42,787 - INFO - Epoch:[280/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.05
2025-03-02 18:35:47,191 - INFO - Epoch:[280/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 18:35:51,397 - INFO - Epoch:[280/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 18:35:55,332 - INFO - Epoch:[280/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 18:35:59,378 - INFO - Epoch:[280/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.24 loss_cvh: 0.98
2025-03-02 18:36:00,852 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 18:36:57,433 - INFO - begin training stage: [281/805]
2025-03-02 18:36:57,434 - INFO - eval data number: 45600
2025-03-02 18:36:57,434 - INFO - loading eval data ......
2025-03-02 18:37:49,502 - INFO - retrieval costs: 36.55935192108154
2025-03-02 18:40:22,404 - INFO - hamming distance computation costs: 152.90117979049683
2025-03-02 18:40:35,368 - INFO - hamming ranking costs: 12.964967966079712
2025-03-02 18:40:35,369 - INFO - labels shape: (45600, 239)
2025-03-02 18:41:27,534 - INFO - similarity labels generation costs: 52.16509294509888
2025-03-02 18:41:27,666 - INFO - topK: 5:, map: 0.3268958333333334
2025-03-02 18:41:28,117 - INFO - topK: 20:, map: 0.2354593519816527
2025-03-02 18:41:29,001 - INFO - topK: 40:, map: 0.20407708140128636
2025-03-02 18:41:30,373 - INFO - topK: 60:, map: 0.18543061824872803
2025-03-02 18:41:32,096 - INFO - topK: 80:, map: 0.17104719601546836
2025-03-02 18:41:34,183 - INFO - topK: 100:, map: 0.15944509804262869
2025-03-02 18:41:36,383 - INFO - begin training stage: [281/805]
2025-03-02 18:41:43,262 - INFO - Epoch:[281/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 18:41:48,573 - INFO - Epoch:[281/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 18:41:54,145 - INFO - Epoch:[281/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 18:42:00,104 - INFO - Epoch:[281/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 18:42:05,425 - INFO - Epoch:[281/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 18:42:11,080 - INFO - Epoch:[281/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 18:42:15,952 - INFO - Epoch:[281/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 18:42:21,970 - INFO - Epoch:[281/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 18:42:26,995 - INFO - Epoch:[281/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.20 loss_cvh: 0.66
2025-03-02 18:42:28,567 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 18:43:44,701 - INFO - begin training stage: [282/805]
2025-03-02 18:43:44,702 - INFO - begin training stage: [282/805]
2025-03-02 18:43:49,557 - INFO - Epoch:[282/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 18:43:53,466 - INFO - Epoch:[282/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 18:43:57,537 - INFO - Epoch:[282/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 18:44:01,532 - INFO - Epoch:[282/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 18:44:05,813 - INFO - Epoch:[282/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 18:44:10,397 - INFO - Epoch:[282/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 18:44:15,277 - INFO - Epoch:[282/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 18:44:20,202 - INFO - Epoch:[282/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 18:44:24,696 - INFO - Epoch:[282/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.22 loss_cvh: 0.40
2025-03-02 18:44:26,094 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 18:45:43,153 - INFO - begin training stage: [283/805]
2025-03-02 18:45:43,153 - INFO - begin training stage: [283/805]
2025-03-02 18:45:50,461 - INFO - Epoch:[283/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 18:45:56,586 - INFO - Epoch:[283/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 18:46:03,024 - INFO - Epoch:[283/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 18:46:08,593 - INFO - Epoch:[283/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.43 loss_cvh: 3.09
2025-03-02 18:46:14,285 - INFO - Epoch:[283/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 18:46:19,391 - INFO - Epoch:[283/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.17
2025-03-02 18:46:24,360 - INFO - Epoch:[283/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 18:46:28,541 - INFO - Epoch:[283/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 18:46:32,275 - INFO - Epoch:[283/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.31 loss_cvh: 0.77
2025-03-02 18:46:33,715 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 18:47:15,128 - INFO - begin training stage: [284/805]
2025-03-02 18:47:15,129 - INFO - begin training stage: [284/805]
2025-03-02 18:47:20,739 - INFO - Epoch:[284/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.06
2025-03-02 18:47:26,737 - INFO - Epoch:[284/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.15
2025-03-02 18:47:31,786 - INFO - Epoch:[284/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 18:47:36,933 - INFO - Epoch:[284/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 18:47:41,250 - INFO - Epoch:[284/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.42 loss_cvh: 3.13
2025-03-02 18:47:45,603 - INFO - Epoch:[284/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 18:47:49,961 - INFO - Epoch:[284/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.06
2025-03-02 18:47:53,959 - INFO - Epoch:[284/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 18:47:57,501 - INFO - Epoch:[284/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.28 loss_cvh: 0.88
2025-03-02 18:47:58,835 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 18:48:53,093 - INFO - begin training stage: [285/805]
2025-03-02 18:48:53,093 - INFO - begin training stage: [285/805]
2025-03-02 18:48:58,268 - INFO - Epoch:[285/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 18:49:02,347 - INFO - Epoch:[285/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.43 loss_cvh: 3.10
2025-03-02 18:49:06,282 - INFO - Epoch:[285/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 18:49:10,000 - INFO - Epoch:[285/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 18:49:13,786 - INFO - Epoch:[285/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 18:49:17,394 - INFO - Epoch:[285/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 18:49:21,101 - INFO - Epoch:[285/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 18:49:24,968 - INFO - Epoch:[285/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 18:49:28,952 - INFO - Epoch:[285/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.16 loss_cvh: 0.77
2025-03-02 18:49:30,427 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 18:50:23,840 - INFO - begin training stage: [286/805]
2025-03-02 18:50:23,841 - INFO - begin training stage: [286/805]
2025-03-02 18:50:31,776 - INFO - Epoch:[286/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 18:50:36,452 - INFO - Epoch:[286/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 18:50:41,849 - INFO - Epoch:[286/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 18:50:47,430 - INFO - Epoch:[286/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 18:50:53,091 - INFO - Epoch:[286/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 18:50:56,985 - INFO - Epoch:[286/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 18:51:01,037 - INFO - Epoch:[286/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 18:51:04,961 - INFO - Epoch:[286/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 18:51:08,451 - INFO - Epoch:[286/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.25 loss_cvh: 0.64
2025-03-02 18:51:09,641 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 18:51:50,079 - INFO - begin training stage: [287/805]
2025-03-02 18:51:50,079 - INFO - begin training stage: [287/805]
2025-03-02 18:51:55,064 - INFO - Epoch:[287/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 18:51:59,107 - INFO - Epoch:[287/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 18:52:03,370 - INFO - Epoch:[287/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 18:52:07,298 - INFO - Epoch:[287/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 18:52:11,413 - INFO - Epoch:[287/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 18:52:17,217 - INFO - Epoch:[287/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 18:52:23,901 - INFO - Epoch:[287/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.09
2025-03-02 18:52:30,401 - INFO - Epoch:[287/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.02
2025-03-02 18:52:36,152 - INFO - Epoch:[287/805] Step:[90/90] reconstruction_loss: 1.34 loss_vc: 1.25 loss_cvh: 0.76
2025-03-02 18:52:38,783 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 18:53:25,048 - INFO - begin training stage: [288/805]
2025-03-02 18:53:25,049 - INFO - begin training stage: [288/805]
2025-03-02 18:53:29,860 - INFO - Epoch:[288/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 18:53:33,546 - INFO - Epoch:[288/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 18:53:37,537 - INFO - Epoch:[288/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 18:53:41,847 - INFO - Epoch:[288/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 18:53:45,452 - INFO - Epoch:[288/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 18:53:51,479 - INFO - Epoch:[288/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 18:53:56,238 - INFO - Epoch:[288/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 18:54:00,376 - INFO - Epoch:[288/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 18:54:04,127 - INFO - Epoch:[288/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.12 loss_cvh: 0.66
2025-03-02 18:54:05,356 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 18:54:53,008 - INFO - begin training stage: [289/805]
2025-03-02 18:54:53,008 - INFO - begin training stage: [289/805]
2025-03-02 18:54:57,936 - INFO - Epoch:[289/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 18:55:01,813 - INFO - Epoch:[289/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 18:55:05,432 - INFO - Epoch:[289/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 18:55:09,144 - INFO - Epoch:[289/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 18:55:13,449 - INFO - Epoch:[289/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 18:55:17,565 - INFO - Epoch:[289/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 18:55:23,312 - INFO - Epoch:[289/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 18:55:29,948 - INFO - Epoch:[289/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 18:55:35,318 - INFO - Epoch:[289/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.20 loss_cvh: 0.69
2025-03-02 18:55:37,002 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 18:56:20,603 - INFO - begin training stage: [290/805]
2025-03-02 18:56:20,603 - INFO - begin training stage: [290/805]
2025-03-02 18:56:25,202 - INFO - Epoch:[290/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 18:56:28,974 - INFO - Epoch:[290/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 18:56:33,446 - INFO - Epoch:[290/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 18:56:38,716 - INFO - Epoch:[290/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 18:56:44,377 - INFO - Epoch:[290/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 18:56:50,003 - INFO - Epoch:[290/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.04
2025-03-02 18:56:54,179 - INFO - Epoch:[290/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 18:56:59,478 - INFO - Epoch:[290/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 18:57:03,817 - INFO - Epoch:[290/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.18 loss_cvh: 0.82
2025-03-02 18:57:05,145 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 18:57:54,632 - INFO - begin training stage: [291/805]
2025-03-02 18:57:54,634 - INFO - eval data number: 45600
2025-03-02 18:57:54,634 - INFO - loading eval data ......
2025-03-02 18:58:32,982 - INFO - retrieval costs: 22.000415802001953
2025-03-02 19:01:06,662 - INFO - hamming distance computation costs: 153.67962074279785
2025-03-02 19:01:23,004 - INFO - hamming ranking costs: 16.34265112876892
2025-03-02 19:01:23,005 - INFO - labels shape: (45600, 239)
2025-03-02 19:02:26,729 - INFO - similarity labels generation costs: 63.72465777397156
2025-03-02 19:02:26,910 - INFO - topK: 5:, map: 0.32650083333333335
2025-03-02 19:02:27,564 - INFO - topK: 20:, map: 0.2331523254059322
2025-03-02 19:02:28,831 - INFO - topK: 40:, map: 0.2010499860468097
2025-03-02 19:02:30,699 - INFO - topK: 60:, map: 0.18321185525496306
2025-03-02 19:02:33,118 - INFO - topK: 80:, map: 0.16981324839517134
2025-03-02 19:02:35,947 - INFO - topK: 100:, map: 0.15857320614113257
2025-03-02 19:02:38,125 - INFO - begin training stage: [291/805]
2025-03-02 19:02:45,177 - INFO - Epoch:[291/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:02:50,362 - INFO - Epoch:[291/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.15
2025-03-02 19:02:55,081 - INFO - Epoch:[291/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 19:03:00,141 - INFO - Epoch:[291/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:03:06,045 - INFO - Epoch:[291/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 19:03:11,952 - INFO - Epoch:[291/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 19:03:17,671 - INFO - Epoch:[291/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.14
2025-03-02 19:03:23,623 - INFO - Epoch:[291/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 19:03:28,551 - INFO - Epoch:[291/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.31 loss_cvh: 0.72
2025-03-02 19:03:30,043 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 19:04:14,375 - INFO - begin training stage: [292/805]
2025-03-02 19:04:14,376 - INFO - begin training stage: [292/805]
2025-03-02 19:04:18,924 - INFO - Epoch:[292/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 19:04:22,794 - INFO - Epoch:[292/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 19:04:26,735 - INFO - Epoch:[292/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 19:04:30,535 - INFO - Epoch:[292/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 19:04:34,414 - INFO - Epoch:[292/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 19:04:38,794 - INFO - Epoch:[292/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 19:04:43,487 - INFO - Epoch:[292/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 19:04:49,104 - INFO - Epoch:[292/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 19:04:54,180 - INFO - Epoch:[292/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.11 loss_cvh: 0.80
2025-03-02 19:04:55,952 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 19:06:15,093 - INFO - begin training stage: [293/805]
2025-03-02 19:06:15,093 - INFO - begin training stage: [293/805]
2025-03-02 19:06:22,818 - INFO - Epoch:[293/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 19:06:28,616 - INFO - Epoch:[293/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.16
2025-03-02 19:06:33,856 - INFO - Epoch:[293/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 19:06:38,924 - INFO - Epoch:[293/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 19:06:43,682 - INFO - Epoch:[293/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 19:06:48,385 - INFO - Epoch:[293/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 19:06:52,876 - INFO - Epoch:[293/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 19:06:57,813 - INFO - Epoch:[293/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 19:07:02,240 - INFO - Epoch:[293/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.27 loss_cvh: 0.73
2025-03-02 19:07:03,622 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 19:07:48,484 - INFO - begin training stage: [294/805]
2025-03-02 19:07:48,484 - INFO - begin training stage: [294/805]
2025-03-02 19:07:53,499 - INFO - Epoch:[294/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 19:07:57,823 - INFO - Epoch:[294/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 19:08:02,643 - INFO - Epoch:[294/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 19:08:07,111 - INFO - Epoch:[294/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 19:08:11,268 - INFO - Epoch:[294/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 19:08:15,173 - INFO - Epoch:[294/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 19:08:20,717 - INFO - Epoch:[294/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 19:08:26,877 - INFO - Epoch:[294/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 19:08:31,986 - INFO - Epoch:[294/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.16 loss_cvh: 1.03
2025-03-02 19:08:33,648 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 19:09:16,378 - INFO - begin training stage: [295/805]
2025-03-02 19:09:16,378 - INFO - begin training stage: [295/805]
2025-03-02 19:09:21,923 - INFO - Epoch:[295/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 19:09:26,373 - INFO - Epoch:[295/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.15
2025-03-02 19:09:30,457 - INFO - Epoch:[295/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 19:09:34,733 - INFO - Epoch:[295/805] Step:[40/90] reconstruction_loss: 1.20 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:09:38,803 - INFO - Epoch:[295/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 19:09:43,115 - INFO - Epoch:[295/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 19:09:46,966 - INFO - Epoch:[295/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:09:51,372 - INFO - Epoch:[295/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 19:09:57,300 - INFO - Epoch:[295/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.29 loss_cvh: 0.78
2025-03-02 19:10:00,571 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 19:10:57,734 - INFO - begin training stage: [296/805]
2025-03-02 19:10:57,735 - INFO - begin training stage: [296/805]
2025-03-02 19:11:05,111 - INFO - Epoch:[296/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.42 loss_cvh: 3.15
2025-03-02 19:11:09,549 - INFO - Epoch:[296/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 19:11:13,728 - INFO - Epoch:[296/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 19:11:17,953 - INFO - Epoch:[296/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 19:11:22,435 - INFO - Epoch:[296/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 19:11:26,457 - INFO - Epoch:[296/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 19:11:30,744 - INFO - Epoch:[296/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 19:11:34,925 - INFO - Epoch:[296/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.05
2025-03-02 19:11:38,409 - INFO - Epoch:[296/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.14 loss_cvh: 0.78
2025-03-02 19:11:39,587 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 19:12:23,385 - INFO - begin training stage: [297/805]
2025-03-02 19:12:23,386 - INFO - begin training stage: [297/805]
2025-03-02 19:12:30,310 - INFO - Epoch:[297/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 19:12:35,041 - INFO - Epoch:[297/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 19:12:39,496 - INFO - Epoch:[297/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 19:12:43,545 - INFO - Epoch:[297/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 19:12:47,589 - INFO - Epoch:[297/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 19:12:51,809 - INFO - Epoch:[297/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 19:12:56,141 - INFO - Epoch:[297/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 19:13:00,292 - INFO - Epoch:[297/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 19:13:04,074 - INFO - Epoch:[297/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.24 loss_cvh: 0.98
2025-03-02 19:13:05,228 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 19:13:50,401 - INFO - begin training stage: [298/805]
2025-03-02 19:13:50,401 - INFO - begin training stage: [298/805]
2025-03-02 19:13:55,584 - INFO - Epoch:[298/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 19:13:59,284 - INFO - Epoch:[298/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 19:14:03,922 - INFO - Epoch:[298/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 19:14:08,189 - INFO - Epoch:[298/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 19:14:12,309 - INFO - Epoch:[298/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 19:14:16,547 - INFO - Epoch:[298/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.04
2025-03-02 19:14:20,401 - INFO - Epoch:[298/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:14:24,557 - INFO - Epoch:[298/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 19:14:28,461 - INFO - Epoch:[298/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.12 loss_cvh: 0.68
2025-03-02 19:14:29,481 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 19:15:12,828 - INFO - begin training stage: [299/805]
2025-03-02 19:15:12,828 - INFO - begin training stage: [299/805]
2025-03-02 19:15:18,067 - INFO - Epoch:[299/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 19:15:22,321 - INFO - Epoch:[299/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 19:15:26,525 - INFO - Epoch:[299/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 19:15:31,817 - INFO - Epoch:[299/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 19:15:37,512 - INFO - Epoch:[299/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 19:15:42,628 - INFO - Epoch:[299/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 19:15:47,260 - INFO - Epoch:[299/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:15:51,319 - INFO - Epoch:[299/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 19:15:55,482 - INFO - Epoch:[299/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.27 loss_cvh: 0.81
2025-03-02 19:15:56,837 - INFO - now the learning rate is: 2.2876792454961016e-05
2025-03-02 19:16:37,842 - INFO - begin training stage: [300/805]
2025-03-02 19:16:37,842 - INFO - begin training stage: [300/805]
2025-03-02 19:16:42,528 - INFO - Epoch:[300/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.06
2025-03-02 19:16:46,426 - INFO - Epoch:[300/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:16:50,731 - INFO - Epoch:[300/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 19:16:55,530 - INFO - Epoch:[300/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 19:16:59,814 - INFO - Epoch:[300/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 19:17:04,214 - INFO - Epoch:[300/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 19:17:08,411 - INFO - Epoch:[300/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 19:17:13,550 - INFO - Epoch:[300/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 19:17:17,900 - INFO - Epoch:[300/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.26 loss_cvh: 0.99
2025-03-02 19:17:19,355 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:18:09,630 - INFO - begin training stage: [301/805]
2025-03-02 19:18:09,632 - INFO - eval data number: 45600
2025-03-02 19:18:09,632 - INFO - loading eval data ......
2025-03-02 19:18:51,423 - INFO - retrieval costs: 26.28176712989807
2025-03-02 19:21:08,982 - INFO - hamming distance computation costs: 137.55826783180237
2025-03-02 19:21:16,306 - INFO - hamming ranking costs: 7.324743747711182
2025-03-02 19:21:16,307 - INFO - labels shape: (45600, 239)
2025-03-02 19:22:09,888 - INFO - similarity labels generation costs: 53.581470012664795
2025-03-02 19:22:10,022 - INFO - topK: 5:, map: 0.32785083333333337
2025-03-02 19:22:10,479 - INFO - topK: 20:, map: 0.23657648274310186
2025-03-02 19:22:11,375 - INFO - topK: 40:, map: 0.20445887526445294
2025-03-02 19:22:12,704 - INFO - topK: 60:, map: 0.1860816631505181
2025-03-02 19:22:14,496 - INFO - topK: 80:, map: 0.17231158743438676
2025-03-02 19:22:16,689 - INFO - topK: 100:, map: 0.16069696485692858
2025-03-02 19:22:19,089 - INFO - begin training stage: [301/805]
2025-03-02 19:22:25,394 - INFO - Epoch:[301/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 19:22:30,220 - INFO - Epoch:[301/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 19:22:35,088 - INFO - Epoch:[301/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 19:22:39,804 - INFO - Epoch:[301/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 19:22:44,476 - INFO - Epoch:[301/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:22:49,384 - INFO - Epoch:[301/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 19:22:53,976 - INFO - Epoch:[301/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 19:22:58,672 - INFO - Epoch:[301/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 19:23:03,148 - INFO - Epoch:[301/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.44 loss_cvh: 1.07
2025-03-02 19:23:04,637 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:23:49,312 - INFO - begin training stage: [302/805]
2025-03-02 19:23:49,313 - INFO - begin training stage: [302/805]
2025-03-02 19:23:54,544 - INFO - Epoch:[302/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 19:23:58,241 - INFO - Epoch:[302/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:24:01,859 - INFO - Epoch:[302/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:24:05,418 - INFO - Epoch:[302/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 19:24:09,117 - INFO - Epoch:[302/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 19:24:12,752 - INFO - Epoch:[302/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 19:24:16,728 - INFO - Epoch:[302/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 19:24:20,640 - INFO - Epoch:[302/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 19:24:23,912 - INFO - Epoch:[302/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.30 loss_cvh: 0.65
2025-03-02 19:24:24,878 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:25:34,974 - INFO - begin training stage: [303/805]
2025-03-02 19:25:34,974 - INFO - begin training stage: [303/805]
2025-03-02 19:25:41,533 - INFO - Epoch:[303/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 19:25:46,123 - INFO - Epoch:[303/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 19:25:50,952 - INFO - Epoch:[303/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 19:25:55,680 - INFO - Epoch:[303/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 19:26:00,511 - INFO - Epoch:[303/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 19:26:05,418 - INFO - Epoch:[303/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.42 loss_cvh: 3.12
2025-03-02 19:26:10,325 - INFO - Epoch:[303/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.16
2025-03-02 19:26:15,039 - INFO - Epoch:[303/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 19:26:19,368 - INFO - Epoch:[303/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.22 loss_cvh: 0.63
2025-03-02 19:26:20,722 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:27:04,296 - INFO - begin training stage: [304/805]
2025-03-02 19:27:04,296 - INFO - begin training stage: [304/805]
2025-03-02 19:27:08,821 - INFO - Epoch:[304/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 19:27:12,425 - INFO - Epoch:[304/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 19:27:15,921 - INFO - Epoch:[304/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:27:19,407 - INFO - Epoch:[304/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 19:27:22,946 - INFO - Epoch:[304/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 19:27:26,415 - INFO - Epoch:[304/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 19:27:29,993 - INFO - Epoch:[304/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 19:27:33,642 - INFO - Epoch:[304/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 19:27:37,062 - INFO - Epoch:[304/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.23 loss_cvh: 0.89
2025-03-02 19:27:38,017 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:28:16,829 - INFO - begin training stage: [305/805]
2025-03-02 19:28:16,829 - INFO - begin training stage: [305/805]
2025-03-02 19:28:21,564 - INFO - Epoch:[305/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:28:25,491 - INFO - Epoch:[305/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 19:28:29,589 - INFO - Epoch:[305/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 19:28:33,601 - INFO - Epoch:[305/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 19:28:37,752 - INFO - Epoch:[305/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 19:28:41,740 - INFO - Epoch:[305/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 19:28:45,950 - INFO - Epoch:[305/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 19:28:49,974 - INFO - Epoch:[305/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:28:53,759 - INFO - Epoch:[305/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.39 loss_cvh: 0.90
2025-03-02 19:28:54,881 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:29:34,024 - INFO - begin training stage: [306/805]
2025-03-02 19:29:34,024 - INFO - begin training stage: [306/805]
2025-03-02 19:29:39,598 - INFO - Epoch:[306/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.15
2025-03-02 19:29:43,841 - INFO - Epoch:[306/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 19:29:48,101 - INFO - Epoch:[306/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 19:29:52,248 - INFO - Epoch:[306/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 19:29:56,153 - INFO - Epoch:[306/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:30:00,182 - INFO - Epoch:[306/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:30:04,280 - INFO - Epoch:[306/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:30:08,468 - INFO - Epoch:[306/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 19:30:12,444 - INFO - Epoch:[306/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.18 loss_cvh: 0.98
2025-03-02 19:30:13,617 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:30:54,976 - INFO - begin training stage: [307/805]
2025-03-02 19:30:54,977 - INFO - begin training stage: [307/805]
2025-03-02 19:31:00,003 - INFO - Epoch:[307/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 19:31:04,149 - INFO - Epoch:[307/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 19:31:08,343 - INFO - Epoch:[307/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 19:31:12,382 - INFO - Epoch:[307/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 19:31:16,698 - INFO - Epoch:[307/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 19:31:20,737 - INFO - Epoch:[307/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 19:31:25,126 - INFO - Epoch:[307/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 19:31:29,227 - INFO - Epoch:[307/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 19:31:33,235 - INFO - Epoch:[307/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.08 loss_cvh: 0.67
2025-03-02 19:31:34,459 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:32:16,081 - INFO - begin training stage: [308/805]
2025-03-02 19:32:16,081 - INFO - begin training stage: [308/805]
2025-03-02 19:32:21,146 - INFO - Epoch:[308/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 19:32:25,258 - INFO - Epoch:[308/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.15
2025-03-02 19:32:29,297 - INFO - Epoch:[308/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 19:32:33,447 - INFO - Epoch:[308/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 19:32:37,720 - INFO - Epoch:[308/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:32:41,940 - INFO - Epoch:[308/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 19:32:46,005 - INFO - Epoch:[308/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 19:32:50,090 - INFO - Epoch:[308/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 19:32:53,871 - INFO - Epoch:[308/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.27 loss_cvh: 0.80
2025-03-02 19:32:55,034 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:33:38,931 - INFO - begin training stage: [309/805]
2025-03-02 19:33:38,931 - INFO - begin training stage: [309/805]
2025-03-02 19:33:44,369 - INFO - Epoch:[309/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 19:33:48,533 - INFO - Epoch:[309/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 19:33:52,689 - INFO - Epoch:[309/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 19:33:57,116 - INFO - Epoch:[309/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 19:34:01,812 - INFO - Epoch:[309/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 19:34:06,087 - INFO - Epoch:[309/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.15
2025-03-02 19:34:10,225 - INFO - Epoch:[309/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 19:34:14,234 - INFO - Epoch:[309/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.04
2025-03-02 19:34:18,164 - INFO - Epoch:[309/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.06 loss_cvh: 0.65
2025-03-02 19:34:19,325 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:35:02,171 - INFO - begin training stage: [310/805]
2025-03-02 19:35:02,172 - INFO - begin training stage: [310/805]
2025-03-02 19:35:07,029 - INFO - Epoch:[310/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.05
2025-03-02 19:35:11,071 - INFO - Epoch:[310/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 19:35:15,148 - INFO - Epoch:[310/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.03
2025-03-02 19:35:19,341 - INFO - Epoch:[310/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 19:35:23,513 - INFO - Epoch:[310/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:35:27,620 - INFO - Epoch:[310/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 19:35:31,449 - INFO - Epoch:[310/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:35:35,695 - INFO - Epoch:[310/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 19:35:39,704 - INFO - Epoch:[310/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.32 loss_cvh: 0.91
2025-03-02 19:35:41,234 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:36:22,171 - INFO - begin training stage: [311/805]
2025-03-02 19:36:22,171 - INFO - eval data number: 45600
2025-03-02 19:36:22,172 - INFO - loading eval data ......
2025-03-02 19:37:07,725 - INFO - retrieval costs: 31.28969717025757
2025-03-02 19:39:00,998 - INFO - hamming distance computation costs: 113.27328252792358
2025-03-02 19:39:08,310 - INFO - hamming ranking costs: 7.31174635887146
2025-03-02 19:39:08,310 - INFO - labels shape: (45600, 239)
2025-03-02 19:39:59,740 - INFO - similarity labels generation costs: 51.429603099823
2025-03-02 19:39:59,868 - INFO - topK: 5:, map: 0.32981
2025-03-02 19:40:00,315 - INFO - topK: 20:, map: 0.23633822343763908
2025-03-02 19:40:01,174 - INFO - topK: 40:, map: 0.20534572630140122
2025-03-02 19:40:02,357 - INFO - topK: 60:, map: 0.1871577070921061
2025-03-02 19:40:03,995 - INFO - topK: 80:, map: 0.17312555390021575
2025-03-02 19:40:06,154 - INFO - topK: 100:, map: 0.16132164555773876
2025-03-02 19:40:08,995 - INFO - begin training stage: [311/805]
2025-03-02 19:40:15,599 - INFO - Epoch:[311/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.14
2025-03-02 19:40:20,257 - INFO - Epoch:[311/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.16
2025-03-02 19:40:25,190 - INFO - Epoch:[311/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:40:30,588 - INFO - Epoch:[311/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 19:40:35,954 - INFO - Epoch:[311/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 19:40:41,623 - INFO - Epoch:[311/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 19:40:47,160 - INFO - Epoch:[311/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 19:40:51,997 - INFO - Epoch:[311/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:40:56,974 - INFO - Epoch:[311/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.31 loss_cvh: 0.83
2025-03-02 19:40:58,853 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:42:00,669 - INFO - begin training stage: [312/805]
2025-03-02 19:42:00,669 - INFO - begin training stage: [312/805]
2025-03-02 19:42:06,129 - INFO - Epoch:[312/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 19:42:10,365 - INFO - Epoch:[312/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 19:42:14,466 - INFO - Epoch:[312/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 19:42:19,062 - INFO - Epoch:[312/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 19:42:23,367 - INFO - Epoch:[312/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 19:42:27,275 - INFO - Epoch:[312/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 19:42:30,945 - INFO - Epoch:[312/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 19:42:34,645 - INFO - Epoch:[312/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 19:42:38,190 - INFO - Epoch:[312/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.14 loss_cvh: 0.83
2025-03-02 19:42:39,628 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:43:45,255 - INFO - begin training stage: [313/805]
2025-03-02 19:43:45,256 - INFO - begin training stage: [313/805]
2025-03-02 19:43:51,908 - INFO - Epoch:[313/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 19:43:56,888 - INFO - Epoch:[313/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 19:44:01,780 - INFO - Epoch:[313/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:44:06,742 - INFO - Epoch:[313/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 19:44:11,697 - INFO - Epoch:[313/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 19:44:16,608 - INFO - Epoch:[313/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 19:44:21,685 - INFO - Epoch:[313/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.03
2025-03-02 19:44:26,941 - INFO - Epoch:[313/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 19:44:32,585 - INFO - Epoch:[313/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.27 loss_cvh: 0.90
2025-03-02 19:44:34,013 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:45:09,145 - INFO - begin training stage: [314/805]
2025-03-02 19:45:09,146 - INFO - begin training stage: [314/805]
2025-03-02 19:45:13,923 - INFO - Epoch:[314/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 19:45:17,700 - INFO - Epoch:[314/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 19:45:21,400 - INFO - Epoch:[314/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 19:45:24,872 - INFO - Epoch:[314/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 19:45:28,490 - INFO - Epoch:[314/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 19:45:32,422 - INFO - Epoch:[314/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 19:45:36,617 - INFO - Epoch:[314/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 19:45:40,391 - INFO - Epoch:[314/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 19:45:44,096 - INFO - Epoch:[314/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.30 loss_cvh: 1.05
2025-03-02 19:45:45,577 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:46:22,737 - INFO - begin training stage: [315/805]
2025-03-02 19:46:22,737 - INFO - begin training stage: [315/805]
2025-03-02 19:46:28,119 - INFO - Epoch:[315/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 19:46:32,581 - INFO - Epoch:[315/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 19:46:37,083 - INFO - Epoch:[315/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.05
2025-03-02 19:46:41,904 - INFO - Epoch:[315/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:46:46,681 - INFO - Epoch:[315/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 19:46:51,030 - INFO - Epoch:[315/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 19:46:55,807 - INFO - Epoch:[315/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 19:47:00,562 - INFO - Epoch:[315/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 19:47:04,660 - INFO - Epoch:[315/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.15 loss_cvh: 0.61
2025-03-02 19:47:06,619 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:47:51,707 - INFO - begin training stage: [316/805]
2025-03-02 19:47:51,708 - INFO - begin training stage: [316/805]
2025-03-02 19:47:56,614 - INFO - Epoch:[316/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 19:48:00,533 - INFO - Epoch:[316/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 19:48:04,126 - INFO - Epoch:[316/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 19:48:08,750 - INFO - Epoch:[316/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 19:48:13,365 - INFO - Epoch:[316/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 19:48:17,957 - INFO - Epoch:[316/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 19:48:22,660 - INFO - Epoch:[316/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.04
2025-03-02 19:48:27,482 - INFO - Epoch:[316/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 19:48:31,905 - INFO - Epoch:[316/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.22 loss_cvh: 1.00
2025-03-02 19:48:33,123 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:49:15,047 - INFO - begin training stage: [317/805]
2025-03-02 19:49:15,047 - INFO - begin training stage: [317/805]
2025-03-02 19:49:19,970 - INFO - Epoch:[317/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 19:49:23,646 - INFO - Epoch:[317/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 19:49:28,670 - INFO - Epoch:[317/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 19:49:33,570 - INFO - Epoch:[317/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:49:38,427 - INFO - Epoch:[317/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 19:49:43,395 - INFO - Epoch:[317/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 19:49:48,577 - INFO - Epoch:[317/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 19:49:53,487 - INFO - Epoch:[317/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 19:49:57,977 - INFO - Epoch:[317/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.29 loss_cvh: 0.99
2025-03-02 19:49:59,289 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:50:42,192 - INFO - begin training stage: [318/805]
2025-03-02 19:50:42,192 - INFO - begin training stage: [318/805]
2025-03-02 19:50:47,036 - INFO - Epoch:[318/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 19:50:50,584 - INFO - Epoch:[318/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 19:50:54,205 - INFO - Epoch:[318/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 19:50:57,656 - INFO - Epoch:[318/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 19:51:01,743 - INFO - Epoch:[318/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.04
2025-03-02 19:51:05,769 - INFO - Epoch:[318/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 19:51:09,987 - INFO - Epoch:[318/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 19:51:14,060 - INFO - Epoch:[318/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 19:51:18,080 - INFO - Epoch:[318/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.18 loss_cvh: 0.77
2025-03-02 19:51:19,744 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:51:58,517 - INFO - begin training stage: [319/805]
2025-03-02 19:51:58,517 - INFO - begin training stage: [319/805]
2025-03-02 19:52:02,998 - INFO - Epoch:[319/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.16
2025-03-02 19:52:06,965 - INFO - Epoch:[319/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 19:52:10,578 - INFO - Epoch:[319/805] Step:[30/90] reconstruction_loss: 1.20 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 19:52:15,292 - INFO - Epoch:[319/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 19:52:20,131 - INFO - Epoch:[319/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 19:52:25,167 - INFO - Epoch:[319/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:52:30,183 - INFO - Epoch:[319/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.11
2025-03-02 19:52:34,839 - INFO - Epoch:[319/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 19:52:38,522 - INFO - Epoch:[319/805] Step:[90/90] reconstruction_loss: 1.05 loss_vc: 1.23 loss_cvh: 0.74
2025-03-02 19:52:40,023 - INFO - now the learning rate is: 2.0589113209464913e-05
2025-03-02 19:53:17,574 - INFO - begin training stage: [320/805]
2025-03-02 19:53:17,574 - INFO - begin training stage: [320/805]
2025-03-02 19:53:22,226 - INFO - Epoch:[320/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 19:53:26,871 - INFO - Epoch:[320/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 19:53:31,957 - INFO - Epoch:[320/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 19:53:37,069 - INFO - Epoch:[320/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 19:53:42,332 - INFO - Epoch:[320/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 19:53:46,822 - INFO - Epoch:[320/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 19:53:51,024 - INFO - Epoch:[320/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 19:53:55,004 - INFO - Epoch:[320/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 19:53:58,719 - INFO - Epoch:[320/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.27 loss_cvh: 0.76
2025-03-02 19:54:00,045 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 19:54:46,498 - INFO - begin training stage: [321/805]
2025-03-02 19:54:46,499 - INFO - eval data number: 45600
2025-03-02 19:54:46,499 - INFO - loading eval data ......
2025-03-02 19:55:21,253 - INFO - retrieval costs: 21.98882269859314
2025-03-02 19:57:42,745 - INFO - hamming distance computation costs: 141.49131679534912
2025-03-02 19:57:50,878 - INFO - hamming ranking costs: 8.133664846420288
2025-03-02 19:57:50,879 - INFO - labels shape: (45600, 239)
2025-03-02 19:58:38,382 - INFO - similarity labels generation costs: 47.503450870513916
2025-03-02 19:58:38,457 - INFO - topK: 5:, map: 0.32910416666666664
2025-03-02 19:58:38,721 - INFO - topK: 20:, map: 0.23612750954368988
2025-03-02 19:58:39,235 - INFO - topK: 40:, map: 0.20417482462203787
2025-03-02 19:58:39,994 - INFO - topK: 60:, map: 0.18514345713060998
2025-03-02 19:58:41,002 - INFO - topK: 80:, map: 0.1711571949042032
2025-03-02 19:58:42,245 - INFO - topK: 100:, map: 0.1595440025529304
2025-03-02 19:58:43,767 - INFO - begin training stage: [321/805]
2025-03-02 19:58:50,232 - INFO - Epoch:[321/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 19:58:55,716 - INFO - Epoch:[321/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 19:59:00,598 - INFO - Epoch:[321/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 19:59:05,257 - INFO - Epoch:[321/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 19:59:09,956 - INFO - Epoch:[321/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 19:59:14,892 - INFO - Epoch:[321/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 19:59:19,985 - INFO - Epoch:[321/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 19:59:24,548 - INFO - Epoch:[321/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 19:59:28,923 - INFO - Epoch:[321/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.20 loss_cvh: 0.73
2025-03-02 19:59:30,675 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:00:42,326 - INFO - begin training stage: [322/805]
2025-03-02 20:00:42,327 - INFO - begin training stage: [322/805]
2025-03-02 20:00:48,918 - INFO - Epoch:[322/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 20:00:54,013 - INFO - Epoch:[322/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.15
2025-03-02 20:00:59,195 - INFO - Epoch:[322/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:01:04,180 - INFO - Epoch:[322/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:01:09,257 - INFO - Epoch:[322/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:01:14,720 - INFO - Epoch:[322/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 20:01:20,032 - INFO - Epoch:[322/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 20:01:25,424 - INFO - Epoch:[322/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 20:01:29,870 - INFO - Epoch:[322/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.15 loss_cvh: 0.63
2025-03-02 20:01:31,268 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:02:18,517 - INFO - begin training stage: [323/805]
2025-03-02 20:02:18,517 - INFO - begin training stage: [323/805]
2025-03-02 20:02:24,829 - INFO - Epoch:[323/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 20:02:29,984 - INFO - Epoch:[323/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 20:02:35,042 - INFO - Epoch:[323/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 20:02:40,252 - INFO - Epoch:[323/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 20:02:44,681 - INFO - Epoch:[323/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:02:49,787 - INFO - Epoch:[323/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:02:54,769 - INFO - Epoch:[323/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 20:03:00,100 - INFO - Epoch:[323/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 20:03:04,412 - INFO - Epoch:[323/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.29 loss_cvh: 0.58
2025-03-02 20:03:05,794 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:03:56,919 - INFO - begin training stage: [324/805]
2025-03-02 20:03:56,919 - INFO - begin training stage: [324/805]
2025-03-02 20:04:03,283 - INFO - Epoch:[324/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 20:04:08,348 - INFO - Epoch:[324/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 20:04:13,064 - INFO - Epoch:[324/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 20:04:17,703 - INFO - Epoch:[324/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 20:04:22,587 - INFO - Epoch:[324/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 20:04:27,614 - INFO - Epoch:[324/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 20:04:32,731 - INFO - Epoch:[324/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 20:04:37,557 - INFO - Epoch:[324/805] Step:[80/90] reconstruction_loss: 1.19 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 20:04:41,911 - INFO - Epoch:[324/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.23 loss_cvh: 0.72
2025-03-02 20:04:43,289 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:05:33,498 - INFO - begin training stage: [325/805]
2025-03-02 20:05:33,498 - INFO - begin training stage: [325/805]
2025-03-02 20:05:39,808 - INFO - Epoch:[325/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 20:05:44,897 - INFO - Epoch:[325/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 20:05:50,151 - INFO - Epoch:[325/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 20:05:55,164 - INFO - Epoch:[325/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:06:00,211 - INFO - Epoch:[325/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 20:06:05,573 - INFO - Epoch:[325/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 20:06:10,853 - INFO - Epoch:[325/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 20:06:15,968 - INFO - Epoch:[325/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 20:06:20,346 - INFO - Epoch:[325/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.22 loss_cvh: 0.81
2025-03-02 20:06:21,616 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:07:12,640 - INFO - begin training stage: [326/805]
2025-03-02 20:07:12,640 - INFO - begin training stage: [326/805]
2025-03-02 20:07:19,041 - INFO - Epoch:[326/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 20:07:23,692 - INFO - Epoch:[326/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 20:07:28,789 - INFO - Epoch:[326/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.12
2025-03-02 20:07:34,119 - INFO - Epoch:[326/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 20:07:39,379 - INFO - Epoch:[326/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 20:07:44,376 - INFO - Epoch:[326/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:07:49,232 - INFO - Epoch:[326/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 20:07:53,613 - INFO - Epoch:[326/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 20:07:57,663 - INFO - Epoch:[326/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.27 loss_cvh: 0.76
2025-03-02 20:07:59,081 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:08:45,071 - INFO - begin training stage: [327/805]
2025-03-02 20:08:45,072 - INFO - begin training stage: [327/805]
2025-03-02 20:08:51,500 - INFO - Epoch:[327/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 20:08:56,725 - INFO - Epoch:[327/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 20:09:01,483 - INFO - Epoch:[327/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 20:09:05,900 - INFO - Epoch:[327/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 20:09:10,917 - INFO - Epoch:[327/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 20:09:15,301 - INFO - Epoch:[327/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:09:19,790 - INFO - Epoch:[327/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 20:09:24,515 - INFO - Epoch:[327/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 20:09:29,254 - INFO - Epoch:[327/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.22 loss_cvh: 0.69
2025-03-02 20:09:30,638 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:10:22,484 - INFO - begin training stage: [328/805]
2025-03-02 20:10:22,485 - INFO - begin training stage: [328/805]
2025-03-02 20:10:28,347 - INFO - Epoch:[328/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 20:10:33,200 - INFO - Epoch:[328/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 20:10:37,543 - INFO - Epoch:[328/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 20:10:42,242 - INFO - Epoch:[328/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.09
2025-03-02 20:10:46,596 - INFO - Epoch:[328/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 20:10:51,225 - INFO - Epoch:[328/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 20:10:56,052 - INFO - Epoch:[328/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.36 loss_cvh: 3.03
2025-03-02 20:11:00,647 - INFO - Epoch:[328/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.41 loss_cvh: 3.04
2025-03-02 20:11:04,975 - INFO - Epoch:[328/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.27 loss_cvh: 0.69
2025-03-02 20:11:06,325 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:11:49,899 - INFO - begin training stage: [329/805]
2025-03-02 20:11:49,900 - INFO - begin training stage: [329/805]
2025-03-02 20:11:55,707 - INFO - Epoch:[329/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 20:12:00,633 - INFO - Epoch:[329/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 20:12:04,940 - INFO - Epoch:[329/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 20:12:09,124 - INFO - Epoch:[329/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.42 loss_cvh: 3.14
2025-03-02 20:12:14,069 - INFO - Epoch:[329/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 20:12:18,275 - INFO - Epoch:[329/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.04
2025-03-02 20:12:22,785 - INFO - Epoch:[329/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 20:12:27,580 - INFO - Epoch:[329/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 20:12:32,363 - INFO - Epoch:[329/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.02 loss_cvh: 0.65
2025-03-02 20:12:34,169 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:13:41,260 - INFO - begin training stage: [330/805]
2025-03-02 20:13:41,260 - INFO - begin training stage: [330/805]
2025-03-02 20:13:47,857 - INFO - Epoch:[330/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 20:13:53,120 - INFO - Epoch:[330/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 20:13:58,518 - INFO - Epoch:[330/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:14:03,717 - INFO - Epoch:[330/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 20:14:09,017 - INFO - Epoch:[330/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 20:14:14,427 - INFO - Epoch:[330/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 20:14:19,357 - INFO - Epoch:[330/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 20:14:25,252 - INFO - Epoch:[330/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.19
2025-03-02 20:14:30,540 - INFO - Epoch:[330/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.14 loss_cvh: 0.59
2025-03-02 20:14:31,804 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:15:45,853 - INFO - begin training stage: [331/805]
2025-03-02 20:15:45,855 - INFO - eval data number: 45600
2025-03-02 20:15:45,855 - INFO - loading eval data ......
2025-03-02 20:16:26,527 - INFO - retrieval costs: 26.51681876182556
2025-03-02 20:18:17,686 - INFO - hamming distance computation costs: 111.15909576416016
2025-03-02 20:18:24,690 - INFO - hamming ranking costs: 7.0038087368011475
2025-03-02 20:18:24,690 - INFO - labels shape: (45600, 239)
2025-03-02 20:19:02,326 - INFO - similarity labels generation costs: 37.636025190353394
2025-03-02 20:19:02,401 - INFO - topK: 5:, map: 0.3291716666666667
2025-03-02 20:19:02,665 - INFO - topK: 20:, map: 0.23889407287307637
2025-03-02 20:19:03,183 - INFO - topK: 40:, map: 0.2058500648976407
2025-03-02 20:19:03,950 - INFO - topK: 60:, map: 0.18725569912236717
2025-03-02 20:19:04,967 - INFO - topK: 80:, map: 0.17258301345138224
2025-03-02 20:19:06,241 - INFO - topK: 100:, map: 0.16062300806820146
2025-03-02 20:19:07,583 - INFO - begin training stage: [331/805]
2025-03-02 20:19:13,280 - INFO - Epoch:[331/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 20:19:18,155 - INFO - Epoch:[331/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 20:19:22,612 - INFO - Epoch:[331/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:19:27,098 - INFO - Epoch:[331/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-02 20:19:31,755 - INFO - Epoch:[331/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 20:19:36,333 - INFO - Epoch:[331/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 20:19:40,809 - INFO - Epoch:[331/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 20:19:45,409 - INFO - Epoch:[331/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 20:19:49,564 - INFO - Epoch:[331/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.21 loss_cvh: 0.80
2025-03-02 20:19:50,603 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:20:25,184 - INFO - begin training stage: [332/805]
2025-03-02 20:20:25,185 - INFO - begin training stage: [332/805]
2025-03-02 20:20:30,170 - INFO - Epoch:[332/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 20:20:33,610 - INFO - Epoch:[332/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 20:20:37,087 - INFO - Epoch:[332/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 20:20:40,928 - INFO - Epoch:[332/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 20:20:44,334 - INFO - Epoch:[332/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 20:20:47,880 - INFO - Epoch:[332/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 20:20:51,302 - INFO - Epoch:[332/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.06
2025-03-02 20:20:54,768 - INFO - Epoch:[332/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 20:20:57,893 - INFO - Epoch:[332/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.33 loss_cvh: 0.91
2025-03-02 20:20:58,927 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:21:34,393 - INFO - begin training stage: [333/805]
2025-03-02 20:21:34,393 - INFO - begin training stage: [333/805]
2025-03-02 20:21:39,195 - INFO - Epoch:[333/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 20:21:42,701 - INFO - Epoch:[333/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 20:21:46,216 - INFO - Epoch:[333/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.06
2025-03-02 20:21:49,961 - INFO - Epoch:[333/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 20:21:54,084 - INFO - Epoch:[333/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:21:58,303 - INFO - Epoch:[333/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 20:22:02,387 - INFO - Epoch:[333/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 20:22:06,440 - INFO - Epoch:[333/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:22:10,015 - INFO - Epoch:[333/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.30 loss_cvh: 0.94
2025-03-02 20:22:11,251 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:22:50,518 - INFO - begin training stage: [334/805]
2025-03-02 20:22:50,519 - INFO - begin training stage: [334/805]
2025-03-02 20:22:55,655 - INFO - Epoch:[334/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.15
2025-03-02 20:22:59,799 - INFO - Epoch:[334/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 20:23:03,764 - INFO - Epoch:[334/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 20:23:07,847 - INFO - Epoch:[334/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 20:23:11,714 - INFO - Epoch:[334/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 20:23:15,414 - INFO - Epoch:[334/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 20:23:19,429 - INFO - Epoch:[334/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 20:23:23,392 - INFO - Epoch:[334/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 20:23:26,598 - INFO - Epoch:[334/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.29 loss_cvh: 0.72
2025-03-02 20:23:27,781 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:24:06,022 - INFO - begin training stage: [335/805]
2025-03-02 20:24:06,022 - INFO - begin training stage: [335/805]
2025-03-02 20:24:11,530 - INFO - Epoch:[335/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 20:24:15,423 - INFO - Epoch:[335/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 20:24:19,583 - INFO - Epoch:[335/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 20:24:23,600 - INFO - Epoch:[335/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 20:24:27,561 - INFO - Epoch:[335/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 20:24:31,434 - INFO - Epoch:[335/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 20:24:35,581 - INFO - Epoch:[335/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 20:24:39,623 - INFO - Epoch:[335/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 20:24:43,372 - INFO - Epoch:[335/805] Step:[90/90] reconstruction_loss: 1.05 loss_vc: 1.53 loss_cvh: 0.92
2025-03-02 20:24:44,555 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:25:24,602 - INFO - begin training stage: [336/805]
2025-03-02 20:25:24,602 - INFO - begin training stage: [336/805]
2025-03-02 20:25:29,884 - INFO - Epoch:[336/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 20:25:33,757 - INFO - Epoch:[336/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 20:25:37,530 - INFO - Epoch:[336/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 20:25:41,587 - INFO - Epoch:[336/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 20:25:45,384 - INFO - Epoch:[336/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 20:25:49,168 - INFO - Epoch:[336/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 20:25:52,880 - INFO - Epoch:[336/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 20:25:56,858 - INFO - Epoch:[336/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 20:26:00,480 - INFO - Epoch:[336/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.22 loss_cvh: 0.83
2025-03-02 20:26:01,518 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:26:40,707 - INFO - begin training stage: [337/805]
2025-03-02 20:26:40,707 - INFO - begin training stage: [337/805]
2025-03-02 20:26:45,764 - INFO - Epoch:[337/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 20:26:49,628 - INFO - Epoch:[337/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 20:26:53,138 - INFO - Epoch:[337/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 20:26:56,740 - INFO - Epoch:[337/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 20:27:00,180 - INFO - Epoch:[337/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 20:27:03,797 - INFO - Epoch:[337/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.10
2025-03-02 20:27:07,706 - INFO - Epoch:[337/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 20:27:11,356 - INFO - Epoch:[337/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 20:27:14,659 - INFO - Epoch:[337/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.31 loss_cvh: 0.89
2025-03-02 20:27:15,697 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:27:57,855 - INFO - begin training stage: [338/805]
2025-03-02 20:27:57,855 - INFO - begin training stage: [338/805]
2025-03-02 20:28:03,180 - INFO - Epoch:[338/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 20:28:07,193 - INFO - Epoch:[338/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 20:28:10,995 - INFO - Epoch:[338/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 20:28:14,648 - INFO - Epoch:[338/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 20:28:18,626 - INFO - Epoch:[338/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 20:28:22,643 - INFO - Epoch:[338/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 20:28:26,184 - INFO - Epoch:[338/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 20:28:30,041 - INFO - Epoch:[338/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 20:28:33,593 - INFO - Epoch:[338/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.14 loss_cvh: 0.73
2025-03-02 20:28:34,736 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:29:40,215 - INFO - begin training stage: [339/805]
2025-03-02 20:29:40,215 - INFO - begin training stage: [339/805]
2025-03-02 20:29:46,125 - INFO - Epoch:[339/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 20:29:51,151 - INFO - Epoch:[339/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 20:29:56,197 - INFO - Epoch:[339/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.10
2025-03-02 20:30:00,764 - INFO - Epoch:[339/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:30:05,612 - INFO - Epoch:[339/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.15
2025-03-02 20:30:10,238 - INFO - Epoch:[339/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 20:30:14,922 - INFO - Epoch:[339/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 20:30:19,677 - INFO - Epoch:[339/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 20:30:24,125 - INFO - Epoch:[339/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.24 loss_cvh: 0.86
2025-03-02 20:30:25,547 - INFO - now the learning rate is: 1.8530201888518422e-05
2025-03-02 20:31:13,857 - INFO - begin training stage: [340/805]
2025-03-02 20:31:13,857 - INFO - begin training stage: [340/805]
2025-03-02 20:31:18,005 - INFO - Epoch:[340/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 20:31:21,569 - INFO - Epoch:[340/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 20:31:25,307 - INFO - Epoch:[340/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 20:31:29,008 - INFO - Epoch:[340/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 20:31:32,898 - INFO - Epoch:[340/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:31:36,682 - INFO - Epoch:[340/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 20:31:40,459 - INFO - Epoch:[340/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 20:31:44,245 - INFO - Epoch:[340/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 20:31:47,880 - INFO - Epoch:[340/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.09 loss_cvh: 0.61
2025-03-02 20:31:48,968 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:33:01,010 - INFO - begin training stage: [341/805]
2025-03-02 20:33:01,012 - INFO - eval data number: 45600
2025-03-02 20:33:01,012 - INFO - loading eval data ......
2025-03-02 20:33:38,722 - INFO - retrieval costs: 23.68896722793579
2025-03-02 20:35:14,878 - INFO - hamming distance computation costs: 96.15562105178833
2025-03-02 20:35:21,842 - INFO - hamming ranking costs: 6.964274644851685
2025-03-02 20:35:21,842 - INFO - labels shape: (45600, 239)
2025-03-02 20:35:59,099 - INFO - similarity labels generation costs: 37.25674343109131
2025-03-02 20:35:59,246 - INFO - topK: 5:, map: 0.3311866666666667
2025-03-02 20:35:59,629 - INFO - topK: 20:, map: 0.23639557377623022
2025-03-02 20:36:00,382 - INFO - topK: 40:, map: 0.20412689276952123
2025-03-02 20:36:01,410 - INFO - topK: 60:, map: 0.1863486135840964
2025-03-02 20:36:02,996 - INFO - topK: 80:, map: 0.17203631117185042
2025-03-02 20:36:04,291 - INFO - topK: 100:, map: 0.16083056559011952
2025-03-02 20:36:05,791 - INFO - begin training stage: [341/805]
2025-03-02 20:36:10,473 - INFO - Epoch:[341/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 20:36:14,102 - INFO - Epoch:[341/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 20:36:17,711 - INFO - Epoch:[341/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 20:36:21,298 - INFO - Epoch:[341/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.41 loss_cvh: 3.14
2025-03-02 20:36:25,148 - INFO - Epoch:[341/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 20:36:28,913 - INFO - Epoch:[341/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.05
2025-03-02 20:36:32,513 - INFO - Epoch:[341/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 20:36:36,175 - INFO - Epoch:[341/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-02 20:36:39,563 - INFO - Epoch:[341/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.13 loss_cvh: 0.74
2025-03-02 20:36:40,580 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:37:19,011 - INFO - begin training stage: [342/805]
2025-03-02 20:37:19,012 - INFO - begin training stage: [342/805]
2025-03-02 20:37:25,069 - INFO - Epoch:[342/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 20:37:29,561 - INFO - Epoch:[342/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:37:33,521 - INFO - Epoch:[342/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 20:37:37,370 - INFO - Epoch:[342/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 20:37:40,963 - INFO - Epoch:[342/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:37:44,607 - INFO - Epoch:[342/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 20:37:48,260 - INFO - Epoch:[342/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 20:37:51,880 - INFO - Epoch:[342/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 20:37:55,583 - INFO - Epoch:[342/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.21 loss_cvh: 0.75
2025-03-02 20:37:56,740 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:38:32,789 - INFO - begin training stage: [343/805]
2025-03-02 20:38:32,789 - INFO - begin training stage: [343/805]
2025-03-02 20:38:37,329 - INFO - Epoch:[343/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:38:40,959 - INFO - Epoch:[343/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:38:44,533 - INFO - Epoch:[343/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 20:38:48,202 - INFO - Epoch:[343/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 20:38:51,973 - INFO - Epoch:[343/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.17
2025-03-02 20:38:55,597 - INFO - Epoch:[343/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 20:38:59,169 - INFO - Epoch:[343/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 20:39:02,820 - INFO - Epoch:[343/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 20:39:06,499 - INFO - Epoch:[343/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.28 loss_cvh: 0.71
2025-03-02 20:39:07,646 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:39:52,621 - INFO - begin training stage: [344/805]
2025-03-02 20:39:52,621 - INFO - begin training stage: [344/805]
2025-03-02 20:39:57,879 - INFO - Epoch:[344/805] Step:[10/90] reconstruction_loss: 1.20 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:40:02,000 - INFO - Epoch:[344/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:40:06,724 - INFO - Epoch:[344/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 20:40:11,135 - INFO - Epoch:[344/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 20:40:15,299 - INFO - Epoch:[344/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:40:19,449 - INFO - Epoch:[344/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 20:40:23,291 - INFO - Epoch:[344/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 20:40:26,928 - INFO - Epoch:[344/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:40:30,395 - INFO - Epoch:[344/805] Step:[90/90] reconstruction_loss: 1.36 loss_vc: 1.23 loss_cvh: 0.91
2025-03-02 20:40:31,519 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:41:17,435 - INFO - begin training stage: [345/805]
2025-03-02 20:41:17,435 - INFO - begin training stage: [345/805]
2025-03-02 20:41:22,210 - INFO - Epoch:[345/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 20:41:26,249 - INFO - Epoch:[345/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 20:41:30,408 - INFO - Epoch:[345/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 20:41:34,455 - INFO - Epoch:[345/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 20:41:38,434 - INFO - Epoch:[345/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:41:43,235 - INFO - Epoch:[345/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 20:41:47,213 - INFO - Epoch:[345/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:41:51,172 - INFO - Epoch:[345/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:41:54,576 - INFO - Epoch:[345/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.21 loss_cvh: 0.76
2025-03-02 20:41:55,668 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:42:41,608 - INFO - begin training stage: [346/805]
2025-03-02 20:42:41,609 - INFO - begin training stage: [346/805]
2025-03-02 20:42:47,029 - INFO - Epoch:[346/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:42:51,125 - INFO - Epoch:[346/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 20:42:55,434 - INFO - Epoch:[346/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 20:42:59,609 - INFO - Epoch:[346/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 20:43:03,759 - INFO - Epoch:[346/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 20:43:07,964 - INFO - Epoch:[346/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 20:43:12,211 - INFO - Epoch:[346/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 20:43:16,465 - INFO - Epoch:[346/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 20:43:20,342 - INFO - Epoch:[346/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.20 loss_cvh: 0.72
2025-03-02 20:43:21,471 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:44:08,484 - INFO - begin training stage: [347/805]
2025-03-02 20:44:08,484 - INFO - begin training stage: [347/805]
2025-03-02 20:44:13,037 - INFO - Epoch:[347/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 20:44:16,752 - INFO - Epoch:[347/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 20:44:21,001 - INFO - Epoch:[347/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 20:44:24,956 - INFO - Epoch:[347/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 20:44:29,172 - INFO - Epoch:[347/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 20:44:33,273 - INFO - Epoch:[347/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 20:44:37,286 - INFO - Epoch:[347/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-02 20:44:41,450 - INFO - Epoch:[347/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 20:44:45,437 - INFO - Epoch:[347/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.41 loss_cvh: 0.85
2025-03-02 20:44:46,495 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:45:27,075 - INFO - begin training stage: [348/805]
2025-03-02 20:45:27,075 - INFO - begin training stage: [348/805]
2025-03-02 20:45:31,840 - INFO - Epoch:[348/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.41 loss_cvh: 3.11
2025-03-02 20:45:35,831 - INFO - Epoch:[348/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 20:45:39,649 - INFO - Epoch:[348/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 20:45:43,530 - INFO - Epoch:[348/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 20:45:47,609 - INFO - Epoch:[348/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 20:45:51,666 - INFO - Epoch:[348/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 20:45:55,829 - INFO - Epoch:[348/805] Step:[70/90] reconstruction_loss: 1.20 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 20:46:00,021 - INFO - Epoch:[348/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 20:46:03,901 - INFO - Epoch:[348/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.48 loss_cvh: 0.86
2025-03-02 20:46:05,107 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:47:12,698 - INFO - begin training stage: [349/805]
2025-03-02 20:47:12,699 - INFO - begin training stage: [349/805]
2025-03-02 20:47:18,928 - INFO - Epoch:[349/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:47:23,723 - INFO - Epoch:[349/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 20:47:28,327 - INFO - Epoch:[349/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 20:47:33,018 - INFO - Epoch:[349/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:47:37,996 - INFO - Epoch:[349/805] Step:[50/90] reconstruction_loss: 1.20 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 20:47:43,101 - INFO - Epoch:[349/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 20:47:47,748 - INFO - Epoch:[349/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 20:47:52,600 - INFO - Epoch:[349/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 20:47:56,595 - INFO - Epoch:[349/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.32 loss_cvh: 0.77
2025-03-02 20:47:57,794 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:48:38,071 - INFO - begin training stage: [350/805]
2025-03-02 20:48:38,072 - INFO - begin training stage: [350/805]
2025-03-02 20:48:42,814 - INFO - Epoch:[350/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 20:48:47,407 - INFO - Epoch:[350/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 20:48:51,487 - INFO - Epoch:[350/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 20:48:55,390 - INFO - Epoch:[350/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.13
2025-03-02 20:48:59,373 - INFO - Epoch:[350/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-02 20:49:03,477 - INFO - Epoch:[350/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:49:07,411 - INFO - Epoch:[350/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.03
2025-03-02 20:49:11,032 - INFO - Epoch:[350/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 20:49:14,504 - INFO - Epoch:[350/805] Step:[90/90] reconstruction_loss: 1.03 loss_vc: 1.17 loss_cvh: 0.71
2025-03-02 20:49:15,638 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:50:23,979 - INFO - begin training stage: [351/805]
2025-03-02 20:50:23,981 - INFO - eval data number: 45600
2025-03-02 20:50:23,981 - INFO - loading eval data ......
2025-03-02 20:51:03,980 - INFO - retrieval costs: 26.595402717590332
2025-03-02 20:52:48,166 - INFO - hamming distance computation costs: 104.1858720779419
2025-03-02 20:52:54,827 - INFO - hamming ranking costs: 6.660843133926392
2025-03-02 20:52:54,827 - INFO - labels shape: (45600, 239)
2025-03-02 20:53:36,536 - INFO - similarity labels generation costs: 41.709428548812866
2025-03-02 20:53:36,619 - INFO - topK: 5:, map: 0.327305
2025-03-02 20:53:36,906 - INFO - topK: 20:, map: 0.2349399791503216
2025-03-02 20:53:37,469 - INFO - topK: 40:, map: 0.20397051173449557
2025-03-02 20:53:38,306 - INFO - topK: 60:, map: 0.18577734791639358
2025-03-02 20:53:39,443 - INFO - topK: 80:, map: 0.17195146288185378
2025-03-02 20:53:40,815 - INFO - topK: 100:, map: 0.160033574053473
2025-03-02 20:53:42,224 - INFO - begin training stage: [351/805]
2025-03-02 20:53:47,107 - INFO - Epoch:[351/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:53:50,768 - INFO - Epoch:[351/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.14
2025-03-02 20:53:54,287 - INFO - Epoch:[351/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.14
2025-03-02 20:53:58,199 - INFO - Epoch:[351/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:54:01,779 - INFO - Epoch:[351/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 20:54:05,326 - INFO - Epoch:[351/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 20:54:08,976 - INFO - Epoch:[351/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 20:54:12,537 - INFO - Epoch:[351/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 20:54:15,880 - INFO - Epoch:[351/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.14 loss_cvh: 0.80
2025-03-02 20:54:16,851 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:54:59,624 - INFO - begin training stage: [352/805]
2025-03-02 20:54:59,624 - INFO - begin training stage: [352/805]
2025-03-02 20:55:04,285 - INFO - Epoch:[352/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 20:55:07,846 - INFO - Epoch:[352/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 20:55:11,388 - INFO - Epoch:[352/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 20:55:14,913 - INFO - Epoch:[352/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 20:55:18,368 - INFO - Epoch:[352/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 20:55:21,980 - INFO - Epoch:[352/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 20:55:25,620 - INFO - Epoch:[352/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 20:55:29,079 - INFO - Epoch:[352/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.04
2025-03-02 20:55:32,318 - INFO - Epoch:[352/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.18 loss_cvh: 0.88
2025-03-02 20:55:33,275 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:56:10,713 - INFO - begin training stage: [353/805]
2025-03-02 20:56:10,713 - INFO - begin training stage: [353/805]
2025-03-02 20:56:16,078 - INFO - Epoch:[353/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.17
2025-03-02 20:56:20,289 - INFO - Epoch:[353/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 20:56:24,376 - INFO - Epoch:[353/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 20:56:28,188 - INFO - Epoch:[353/805] Step:[40/90] reconstruction_loss: 1.19 loss_vc: 4.40 loss_cvh: 3.15
2025-03-02 20:56:31,814 - INFO - Epoch:[353/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-02 20:56:35,475 - INFO - Epoch:[353/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 20:56:39,555 - INFO - Epoch:[353/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.15
2025-03-02 20:56:43,616 - INFO - Epoch:[353/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:56:47,240 - INFO - Epoch:[353/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.17 loss_cvh: 0.75
2025-03-02 20:56:48,189 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:57:37,967 - INFO - begin training stage: [354/805]
2025-03-02 20:57:37,967 - INFO - begin training stage: [354/805]
2025-03-02 20:57:43,346 - INFO - Epoch:[354/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 20:57:47,422 - INFO - Epoch:[354/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 20:57:51,419 - INFO - Epoch:[354/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:57:55,234 - INFO - Epoch:[354/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:57:59,170 - INFO - Epoch:[354/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-02 20:58:03,352 - INFO - Epoch:[354/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 20:58:07,125 - INFO - Epoch:[354/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 20:58:10,917 - INFO - Epoch:[354/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 20:58:14,600 - INFO - Epoch:[354/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.16 loss_cvh: 0.64
2025-03-02 20:58:15,718 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 20:58:59,527 - INFO - begin training stage: [355/805]
2025-03-02 20:58:59,528 - INFO - begin training stage: [355/805]
2025-03-02 20:59:04,709 - INFO - Epoch:[355/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 20:59:08,807 - INFO - Epoch:[355/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 20:59:12,796 - INFO - Epoch:[355/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 20:59:16,800 - INFO - Epoch:[355/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 20:59:21,069 - INFO - Epoch:[355/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 20:59:25,110 - INFO - Epoch:[355/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 20:59:29,172 - INFO - Epoch:[355/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 20:59:33,095 - INFO - Epoch:[355/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 20:59:36,859 - INFO - Epoch:[355/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.11 loss_cvh: 0.81
2025-03-02 20:59:37,813 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 21:00:21,602 - INFO - begin training stage: [356/805]
2025-03-02 21:00:21,602 - INFO - begin training stage: [356/805]
2025-03-02 21:00:27,223 - INFO - Epoch:[356/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 21:00:31,423 - INFO - Epoch:[356/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 21:00:35,490 - INFO - Epoch:[356/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 21:00:39,689 - INFO - Epoch:[356/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 21:00:43,524 - INFO - Epoch:[356/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 21:00:47,099 - INFO - Epoch:[356/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 21:00:50,661 - INFO - Epoch:[356/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 21:00:54,367 - INFO - Epoch:[356/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 21:00:58,049 - INFO - Epoch:[356/805] Step:[90/90] reconstruction_loss: 1.03 loss_vc: 1.14 loss_cvh: 0.74
2025-03-02 21:00:59,147 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 21:01:38,725 - INFO - begin training stage: [357/805]
2025-03-02 21:01:38,725 - INFO - begin training stage: [357/805]
2025-03-02 21:01:43,752 - INFO - Epoch:[357/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.13
2025-03-02 21:01:47,721 - INFO - Epoch:[357/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 21:01:51,889 - INFO - Epoch:[357/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 21:01:55,964 - INFO - Epoch:[357/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 21:01:59,978 - INFO - Epoch:[357/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-02 21:02:04,107 - INFO - Epoch:[357/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 21:02:07,976 - INFO - Epoch:[357/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 21:02:12,065 - INFO - Epoch:[357/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 21:02:16,065 - INFO - Epoch:[357/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.16 loss_cvh: 0.80
2025-03-02 21:02:17,196 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 21:02:56,419 - INFO - begin training stage: [358/805]
2025-03-02 21:02:56,420 - INFO - begin training stage: [358/805]
2025-03-02 21:03:00,809 - INFO - Epoch:[358/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 21:03:04,369 - INFO - Epoch:[358/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 21:03:08,277 - INFO - Epoch:[358/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 21:03:12,198 - INFO - Epoch:[358/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 21:03:15,738 - INFO - Epoch:[358/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 21:03:19,121 - INFO - Epoch:[358/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 21:03:22,545 - INFO - Epoch:[358/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 21:03:25,896 - INFO - Epoch:[358/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:03:29,071 - INFO - Epoch:[358/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.27 loss_cvh: 0.72
2025-03-02 21:03:30,106 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 21:04:35,799 - INFO - begin training stage: [359/805]
2025-03-02 21:04:35,799 - INFO - begin training stage: [359/805]
2025-03-02 21:04:41,739 - INFO - Epoch:[359/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 21:04:46,626 - INFO - Epoch:[359/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.03
2025-03-02 21:04:51,492 - INFO - Epoch:[359/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 21:04:56,093 - INFO - Epoch:[359/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 21:05:00,849 - INFO - Epoch:[359/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 21:05:05,457 - INFO - Epoch:[359/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.16
2025-03-02 21:05:09,852 - INFO - Epoch:[359/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 21:05:14,425 - INFO - Epoch:[359/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 21:05:18,669 - INFO - Epoch:[359/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.23 loss_cvh: 0.67
2025-03-02 21:05:20,035 - INFO - now the learning rate is: 1.667718169966658e-05
2025-03-02 21:05:56,037 - INFO - begin training stage: [360/805]
2025-03-02 21:05:56,038 - INFO - begin training stage: [360/805]
2025-03-02 21:06:00,278 - INFO - Epoch:[360/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 21:06:03,609 - INFO - Epoch:[360/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:06:07,494 - INFO - Epoch:[360/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 21:06:11,730 - INFO - Epoch:[360/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 21:06:15,377 - INFO - Epoch:[360/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 21:06:18,837 - INFO - Epoch:[360/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 21:06:22,378 - INFO - Epoch:[360/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 21:06:25,963 - INFO - Epoch:[360/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 21:06:29,280 - INFO - Epoch:[360/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.18 loss_cvh: 0.63
2025-03-02 21:06:30,273 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:07:05,961 - INFO - begin training stage: [361/805]
2025-03-02 21:07:05,962 - INFO - eval data number: 45600
2025-03-02 21:07:05,962 - INFO - loading eval data ......
2025-03-02 21:07:43,083 - INFO - retrieval costs: 22.286986351013184
2025-03-02 21:09:26,285 - INFO - hamming distance computation costs: 103.20139908790588
2025-03-02 21:09:33,746 - INFO - hamming ranking costs: 7.461255311965942
2025-03-02 21:09:33,746 - INFO - labels shape: (45600, 239)
2025-03-02 21:10:35,837 - INFO - similarity labels generation costs: 62.091184854507446
2025-03-02 21:10:35,963 - INFO - topK: 5:, map: 0.32901166666666665
2025-03-02 21:10:36,384 - INFO - topK: 20:, map: 0.2386228809346935
2025-03-02 21:10:37,247 - INFO - topK: 40:, map: 0.20637575995221077
2025-03-02 21:10:38,538 - INFO - topK: 60:, map: 0.18689051101930493
2025-03-02 21:10:40,169 - INFO - topK: 80:, map: 0.17260926009059363
2025-03-02 21:10:42,335 - INFO - topK: 100:, map: 0.16064078671864274
2025-03-02 21:10:44,873 - INFO - begin training stage: [361/805]
2025-03-02 21:10:51,569 - INFO - Epoch:[361/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 21:10:56,533 - INFO - Epoch:[361/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.03
2025-03-02 21:11:00,176 - INFO - Epoch:[361/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 21:11:03,658 - INFO - Epoch:[361/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 21:11:07,187 - INFO - Epoch:[361/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 21:11:10,777 - INFO - Epoch:[361/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 21:11:14,344 - INFO - Epoch:[361/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 21:11:17,860 - INFO - Epoch:[361/805] Step:[80/90] reconstruction_loss: 1.21 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 21:11:21,208 - INFO - Epoch:[361/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.15 loss_cvh: 0.76
2025-03-02 21:11:22,244 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:12:01,620 - INFO - begin training stage: [362/805]
2025-03-02 21:12:01,620 - INFO - begin training stage: [362/805]
2025-03-02 21:12:06,774 - INFO - Epoch:[362/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 21:12:10,764 - INFO - Epoch:[362/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 21:12:14,897 - INFO - Epoch:[362/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 21:12:18,940 - INFO - Epoch:[362/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 21:12:23,009 - INFO - Epoch:[362/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 21:12:27,089 - INFO - Epoch:[362/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 21:12:31,006 - INFO - Epoch:[362/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 21:12:34,961 - INFO - Epoch:[362/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 21:12:38,639 - INFO - Epoch:[362/805] Step:[90/90] reconstruction_loss: 1.05 loss_vc: 1.11 loss_cvh: 0.65
2025-03-02 21:12:39,784 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:13:21,382 - INFO - begin training stage: [363/805]
2025-03-02 21:13:21,383 - INFO - begin training stage: [363/805]
2025-03-02 21:13:26,734 - INFO - Epoch:[363/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 21:13:30,888 - INFO - Epoch:[363/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 21:13:35,040 - INFO - Epoch:[363/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.04
2025-03-02 21:13:39,966 - INFO - Epoch:[363/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 21:13:44,481 - INFO - Epoch:[363/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:13:49,078 - INFO - Epoch:[363/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 21:13:53,569 - INFO - Epoch:[363/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 21:13:57,970 - INFO - Epoch:[363/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.14
2025-03-02 21:14:02,094 - INFO - Epoch:[363/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.32 loss_cvh: 0.78
2025-03-02 21:14:03,579 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:15:09,753 - INFO - begin training stage: [364/805]
2025-03-02 21:15:09,757 - INFO - begin training stage: [364/805]
2025-03-02 21:15:16,308 - INFO - Epoch:[364/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:15:20,826 - INFO - Epoch:[364/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.15
2025-03-02 21:15:25,320 - INFO - Epoch:[364/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 21:15:29,484 - INFO - Epoch:[364/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 21:15:33,821 - INFO - Epoch:[364/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 21:15:38,049 - INFO - Epoch:[364/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 21:15:42,120 - INFO - Epoch:[364/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 21:15:46,465 - INFO - Epoch:[364/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 21:15:50,246 - INFO - Epoch:[364/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.16 loss_cvh: 0.73
2025-03-02 21:15:51,335 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:16:42,854 - INFO - begin training stage: [365/805]
2025-03-02 21:16:42,854 - INFO - begin training stage: [365/805]
2025-03-02 21:16:48,052 - INFO - Epoch:[365/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.04
2025-03-02 21:16:52,249 - INFO - Epoch:[365/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:16:56,203 - INFO - Epoch:[365/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 21:17:00,407 - INFO - Epoch:[365/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 21:17:05,123 - INFO - Epoch:[365/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:17:08,864 - INFO - Epoch:[365/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 21:17:12,671 - INFO - Epoch:[365/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.15
2025-03-02 21:17:16,372 - INFO - Epoch:[365/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 21:17:21,557 - INFO - Epoch:[365/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.18 loss_cvh: 0.76
2025-03-02 21:17:24,538 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:18:38,407 - INFO - begin training stage: [366/805]
2025-03-02 21:18:38,407 - INFO - begin training stage: [366/805]
2025-03-02 21:18:44,754 - INFO - Epoch:[366/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 21:18:49,404 - INFO - Epoch:[366/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 21:18:53,444 - INFO - Epoch:[366/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 21:18:57,218 - INFO - Epoch:[366/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 21:19:01,041 - INFO - Epoch:[366/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 21:19:04,755 - INFO - Epoch:[366/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 21:19:08,380 - INFO - Epoch:[366/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 21:19:12,165 - INFO - Epoch:[366/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 21:19:15,648 - INFO - Epoch:[366/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.11 loss_cvh: 0.63
2025-03-02 21:19:16,651 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:20:13,566 - INFO - begin training stage: [367/805]
2025-03-02 21:20:13,567 - INFO - begin training stage: [367/805]
2025-03-02 21:20:19,012 - INFO - Epoch:[367/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 21:20:23,469 - INFO - Epoch:[367/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 21:20:27,312 - INFO - Epoch:[367/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 21:20:31,842 - INFO - Epoch:[367/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 21:20:39,006 - INFO - Epoch:[367/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 21:20:44,878 - INFO - Epoch:[367/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:20:49,153 - INFO - Epoch:[367/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 21:20:53,656 - INFO - Epoch:[367/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 21:20:58,307 - INFO - Epoch:[367/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.23 loss_cvh: 0.92
2025-03-02 21:20:59,454 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:21:53,078 - INFO - begin training stage: [368/805]
2025-03-02 21:21:53,078 - INFO - begin training stage: [368/805]
2025-03-02 21:21:57,783 - INFO - Epoch:[368/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 21:22:01,400 - INFO - Epoch:[368/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 21:22:04,743 - INFO - Epoch:[368/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.15
2025-03-02 21:22:08,080 - INFO - Epoch:[368/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 21:22:11,617 - INFO - Epoch:[368/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:22:15,565 - INFO - Epoch:[368/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 21:22:23,265 - INFO - Epoch:[368/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.11
2025-03-02 21:22:28,904 - INFO - Epoch:[368/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 21:22:32,799 - INFO - Epoch:[368/805] Step:[90/90] reconstruction_loss: 1.05 loss_vc: 1.36 loss_cvh: 0.81
2025-03-02 21:22:33,939 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:23:51,794 - INFO - begin training stage: [369/805]
2025-03-02 21:23:51,794 - INFO - begin training stage: [369/805]
2025-03-02 21:23:58,936 - INFO - Epoch:[369/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:24:04,620 - INFO - Epoch:[369/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 21:24:09,742 - INFO - Epoch:[369/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 21:24:14,812 - INFO - Epoch:[369/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 21:24:19,568 - INFO - Epoch:[369/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 21:24:24,196 - INFO - Epoch:[369/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 21:24:28,900 - INFO - Epoch:[369/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 21:24:33,700 - INFO - Epoch:[369/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:24:38,306 - INFO - Epoch:[369/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.08 loss_cvh: 0.72
2025-03-02 21:24:39,711 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:25:57,018 - INFO - begin training stage: [370/805]
2025-03-02 21:25:57,023 - INFO - begin training stage: [370/805]
2025-03-02 21:26:04,571 - INFO - Epoch:[370/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 21:26:09,448 - INFO - Epoch:[370/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 21:26:13,059 - INFO - Epoch:[370/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 21:26:16,600 - INFO - Epoch:[370/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 21:26:20,180 - INFO - Epoch:[370/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 21:26:24,235 - INFO - Epoch:[370/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.04
2025-03-02 21:26:29,550 - INFO - Epoch:[370/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:26:34,895 - INFO - Epoch:[370/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 21:26:38,203 - INFO - Epoch:[370/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.20 loss_cvh: 0.66
2025-03-02 21:26:39,185 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:27:15,797 - INFO - begin training stage: [371/805]
2025-03-02 21:27:15,798 - INFO - eval data number: 45600
2025-03-02 21:27:15,799 - INFO - loading eval data ......
2025-03-02 21:28:00,255 - INFO - retrieval costs: 27.042541027069092
2025-03-02 21:31:14,946 - INFO - hamming distance computation costs: 194.69061636924744
2025-03-02 21:31:26,586 - INFO - hamming ranking costs: 11.640951871871948
2025-03-02 21:31:26,587 - INFO - labels shape: (45600, 239)
2025-03-02 21:32:30,315 - INFO - similarity labels generation costs: 63.72800016403198
2025-03-02 21:32:30,446 - INFO - topK: 5:, map: 0.33537833333333333
2025-03-02 21:32:30,910 - INFO - topK: 20:, map: 0.23882861943875053
2025-03-02 21:32:31,811 - INFO - topK: 40:, map: 0.20673675138592648
2025-03-02 21:32:33,149 - INFO - topK: 60:, map: 0.18783850748233868
2025-03-02 21:32:34,930 - INFO - topK: 80:, map: 0.1736008061865981
2025-03-02 21:32:37,147 - INFO - topK: 100:, map: 0.16159154182156862
2025-03-02 21:32:39,439 - INFO - begin training stage: [371/805]
2025-03-02 21:32:46,025 - INFO - Epoch:[371/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 21:32:51,136 - INFO - Epoch:[371/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 21:32:56,214 - INFO - Epoch:[371/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:33:01,550 - INFO - Epoch:[371/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:33:07,291 - INFO - Epoch:[371/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 21:33:12,452 - INFO - Epoch:[371/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:33:17,620 - INFO - Epoch:[371/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 21:33:22,598 - INFO - Epoch:[371/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 21:33:27,115 - INFO - Epoch:[371/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.08 loss_cvh: 0.82
2025-03-02 21:33:29,023 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:34:33,518 - INFO - begin training stage: [372/805]
2025-03-02 21:34:33,518 - INFO - begin training stage: [372/805]
2025-03-02 21:34:38,888 - INFO - Epoch:[372/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.12
2025-03-02 21:34:42,644 - INFO - Epoch:[372/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.10
2025-03-02 21:34:47,863 - INFO - Epoch:[372/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 21:34:54,431 - INFO - Epoch:[372/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:34:59,285 - INFO - Epoch:[372/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.08
2025-03-02 21:35:04,585 - INFO - Epoch:[372/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 21:35:12,307 - INFO - Epoch:[372/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 21:35:17,897 - INFO - Epoch:[372/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 21:35:21,450 - INFO - Epoch:[372/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.37 loss_cvh: 0.98
2025-03-02 21:35:22,582 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:36:05,566 - INFO - begin training stage: [373/805]
2025-03-02 21:36:05,566 - INFO - begin training stage: [373/805]
2025-03-02 21:36:10,773 - INFO - Epoch:[373/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:36:14,619 - INFO - Epoch:[373/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 21:36:18,569 - INFO - Epoch:[373/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 21:36:22,727 - INFO - Epoch:[373/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 21:36:31,357 - INFO - Epoch:[373/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 21:36:36,368 - INFO - Epoch:[373/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 21:36:40,483 - INFO - Epoch:[373/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 21:36:44,197 - INFO - Epoch:[373/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 21:36:47,573 - INFO - Epoch:[373/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.18 loss_cvh: 0.74
2025-03-02 21:36:50,497 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:37:41,624 - INFO - begin training stage: [374/805]
2025-03-02 21:37:41,625 - INFO - begin training stage: [374/805]
2025-03-02 21:37:47,188 - INFO - Epoch:[374/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 21:37:52,783 - INFO - Epoch:[374/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 21:37:56,618 - INFO - Epoch:[374/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 21:38:00,213 - INFO - Epoch:[374/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:38:04,542 - INFO - Epoch:[374/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:38:09,662 - INFO - Epoch:[374/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 21:38:14,315 - INFO - Epoch:[374/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.15
2025-03-02 21:38:18,039 - INFO - Epoch:[374/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:38:23,410 - INFO - Epoch:[374/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.27 loss_cvh: 0.69
2025-03-02 21:38:26,534 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:39:31,926 - INFO - begin training stage: [375/805]
2025-03-02 21:39:31,926 - INFO - begin training stage: [375/805]
2025-03-02 21:39:37,371 - INFO - Epoch:[375/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:39:41,245 - INFO - Epoch:[375/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 21:39:45,248 - INFO - Epoch:[375/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:39:49,578 - INFO - Epoch:[375/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 21:39:53,769 - INFO - Epoch:[375/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 21:39:57,750 - INFO - Epoch:[375/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:40:01,839 - INFO - Epoch:[375/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 21:40:06,266 - INFO - Epoch:[375/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.13
2025-03-02 21:40:10,214 - INFO - Epoch:[375/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.32 loss_cvh: 0.80
2025-03-02 21:40:11,450 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:41:25,279 - INFO - begin training stage: [376/805]
2025-03-02 21:41:25,279 - INFO - begin training stage: [376/805]
2025-03-02 21:41:32,251 - INFO - Epoch:[376/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 21:41:36,879 - INFO - Epoch:[376/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 21:41:42,015 - INFO - Epoch:[376/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 21:41:49,123 - INFO - Epoch:[376/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 21:41:56,605 - INFO - Epoch:[376/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.06
2025-03-02 21:42:02,883 - INFO - Epoch:[376/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 21:42:09,774 - INFO - Epoch:[376/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 21:42:17,614 - INFO - Epoch:[376/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 21:42:22,957 - INFO - Epoch:[376/805] Step:[90/90] reconstruction_loss: 0.94 loss_vc: 1.23 loss_cvh: 0.68
2025-03-02 21:42:25,235 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:43:16,619 - INFO - begin training stage: [377/805]
2025-03-02 21:43:16,619 - INFO - begin training stage: [377/805]
2025-03-02 21:43:21,682 - INFO - Epoch:[377/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 21:43:25,737 - INFO - Epoch:[377/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 21:43:29,590 - INFO - Epoch:[377/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 21:43:33,361 - INFO - Epoch:[377/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 21:43:37,579 - INFO - Epoch:[377/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.04
2025-03-02 21:43:41,540 - INFO - Epoch:[377/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:43:45,330 - INFO - Epoch:[377/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 21:43:49,923 - INFO - Epoch:[377/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.00
2025-03-02 21:43:54,886 - INFO - Epoch:[377/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.11 loss_cvh: 0.80
2025-03-02 21:43:56,685 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:44:55,928 - INFO - begin training stage: [378/805]
2025-03-02 21:44:55,928 - INFO - begin training stage: [378/805]
2025-03-02 21:45:02,430 - INFO - Epoch:[378/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 21:45:07,163 - INFO - Epoch:[378/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.05
2025-03-02 21:45:11,623 - INFO - Epoch:[378/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 21:45:16,604 - INFO - Epoch:[378/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:45:21,982 - INFO - Epoch:[378/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.04
2025-03-02 21:45:28,483 - INFO - Epoch:[378/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 21:45:35,466 - INFO - Epoch:[378/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 21:45:41,190 - INFO - Epoch:[378/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 21:45:45,857 - INFO - Epoch:[378/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.13 loss_cvh: 0.63
2025-03-02 21:45:47,779 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:47:08,788 - INFO - begin training stage: [379/805]
2025-03-02 21:47:08,789 - INFO - begin training stage: [379/805]
2025-03-02 21:47:19,474 - INFO - Epoch:[379/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 21:47:25,558 - INFO - Epoch:[379/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 21:47:32,050 - INFO - Epoch:[379/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 21:47:38,016 - INFO - Epoch:[379/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 21:47:44,411 - INFO - Epoch:[379/805] Step:[50/90] reconstruction_loss: 1.11 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 21:47:52,178 - INFO - Epoch:[379/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 21:48:00,193 - INFO - Epoch:[379/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 21:48:07,111 - INFO - Epoch:[379/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 21:48:12,947 - INFO - Epoch:[379/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.02 loss_cvh: 0.63
2025-03-02 21:48:14,971 - INFO - now the learning rate is: 1.5009463529699922e-05
2025-03-02 21:49:09,279 - INFO - begin training stage: [380/805]
2025-03-02 21:49:09,279 - INFO - begin training stage: [380/805]
2025-03-02 21:49:15,361 - INFO - Epoch:[380/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.41 loss_cvh: 3.13
2025-03-02 21:49:20,911 - INFO - Epoch:[380/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.02
2025-03-02 21:49:26,825 - INFO - Epoch:[380/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 21:49:32,485 - INFO - Epoch:[380/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 21:49:37,421 - INFO - Epoch:[380/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 21:49:42,609 - INFO - Epoch:[380/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 21:49:50,423 - INFO - Epoch:[380/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 21:49:56,742 - INFO - Epoch:[380/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.05
2025-03-02 21:50:01,403 - INFO - Epoch:[380/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.07 loss_cvh: 0.60
2025-03-02 21:50:02,751 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 21:51:02,451 - INFO - begin training stage: [381/805]
2025-03-02 21:51:02,453 - INFO - eval data number: 45600
2025-03-02 21:51:02,453 - INFO - loading eval data ......
2025-03-02 21:51:48,025 - INFO - retrieval costs: 25.418575763702393
2025-03-02 21:55:13,297 - INFO - hamming distance computation costs: 205.27211666107178
2025-03-02 21:55:27,525 - INFO - hamming ranking costs: 14.227515459060669
2025-03-02 21:55:27,525 - INFO - labels shape: (45600, 239)
2025-03-02 21:56:30,699 - INFO - similarity labels generation costs: 63.17386245727539
2025-03-02 21:56:30,827 - INFO - topK: 5:, map: 0.33151749999999996
2025-03-02 21:56:31,289 - INFO - topK: 20:, map: 0.23998801049671648
2025-03-02 21:56:32,225 - INFO - topK: 40:, map: 0.20807071357937967
2025-03-02 21:56:33,579 - INFO - topK: 60:, map: 0.1883277152186506
2025-03-02 21:56:35,370 - INFO - topK: 80:, map: 0.1744235384576178
2025-03-02 21:56:37,614 - INFO - topK: 100:, map: 0.16250757955725106
2025-03-02 21:56:40,041 - INFO - begin training stage: [381/805]
2025-03-02 21:56:48,129 - INFO - Epoch:[381/805] Step:[10/90] reconstruction_loss: 1.19 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 21:56:53,591 - INFO - Epoch:[381/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 21:56:59,418 - INFO - Epoch:[381/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 21:57:04,772 - INFO - Epoch:[381/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 21:57:10,620 - INFO - Epoch:[381/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.14
2025-03-02 21:57:16,470 - INFO - Epoch:[381/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.37 loss_cvh: 3.01
2025-03-02 21:57:21,460 - INFO - Epoch:[381/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 21:57:27,016 - INFO - Epoch:[381/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.12
2025-03-02 21:57:31,137 - INFO - Epoch:[381/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.15 loss_cvh: 0.73
2025-03-02 21:57:32,342 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 21:58:30,541 - INFO - begin training stage: [382/805]
2025-03-02 21:58:30,541 - INFO - begin training stage: [382/805]
2025-03-02 21:58:35,726 - INFO - Epoch:[382/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 21:58:39,647 - INFO - Epoch:[382/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.06
2025-03-02 21:58:43,616 - INFO - Epoch:[382/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 21:58:47,733 - INFO - Epoch:[382/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.41 loss_cvh: 3.10
2025-03-02 21:58:51,776 - INFO - Epoch:[382/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 21:58:56,080 - INFO - Epoch:[382/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 21:59:01,763 - INFO - Epoch:[382/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 21:59:05,473 - INFO - Epoch:[382/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 21:59:08,864 - INFO - Epoch:[382/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.05 loss_cvh: 0.75
2025-03-02 21:59:09,855 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:00:01,173 - INFO - begin training stage: [383/805]
2025-03-02 22:00:01,173 - INFO - begin training stage: [383/805]
2025-03-02 22:00:06,572 - INFO - Epoch:[383/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 22:00:11,457 - INFO - Epoch:[383/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 22:00:16,231 - INFO - Epoch:[383/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.17
2025-03-02 22:00:23,056 - INFO - Epoch:[383/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 22:00:31,728 - INFO - Epoch:[383/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 22:00:38,289 - INFO - Epoch:[383/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 22:00:45,937 - INFO - Epoch:[383/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 22:00:53,526 - INFO - Epoch:[383/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 22:00:58,232 - INFO - Epoch:[383/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.27 loss_cvh: 0.95
2025-03-02 22:00:59,673 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:01:41,500 - INFO - begin training stage: [384/805]
2025-03-02 22:01:41,500 - INFO - begin training stage: [384/805]
2025-03-02 22:01:48,898 - INFO - Epoch:[384/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 22:01:53,086 - INFO - Epoch:[384/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 22:01:57,277 - INFO - Epoch:[384/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-02 22:02:01,242 - INFO - Epoch:[384/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 22:02:05,462 - INFO - Epoch:[384/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 22:02:12,051 - INFO - Epoch:[384/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:02:17,865 - INFO - Epoch:[384/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 22:02:22,029 - INFO - Epoch:[384/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 22:02:25,722 - INFO - Epoch:[384/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.12 loss_cvh: 0.64
2025-03-02 22:02:26,731 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:03:27,958 - INFO - begin training stage: [385/805]
2025-03-02 22:03:27,959 - INFO - begin training stage: [385/805]
2025-03-02 22:03:33,883 - INFO - Epoch:[385/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.06
2025-03-02 22:03:38,558 - INFO - Epoch:[385/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 22:03:42,486 - INFO - Epoch:[385/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 22:03:47,834 - INFO - Epoch:[385/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-02 22:03:55,011 - INFO - Epoch:[385/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:04:01,643 - INFO - Epoch:[385/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 22:04:07,774 - INFO - Epoch:[385/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 22:04:13,053 - INFO - Epoch:[385/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 22:04:16,530 - INFO - Epoch:[385/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.41 loss_cvh: 0.85
2025-03-02 22:04:17,614 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:05:11,213 - INFO - begin training stage: [386/805]
2025-03-02 22:05:11,214 - INFO - begin training stage: [386/805]
2025-03-02 22:05:17,718 - INFO - Epoch:[386/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 22:05:21,735 - INFO - Epoch:[386/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:05:25,939 - INFO - Epoch:[386/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 22:05:30,395 - INFO - Epoch:[386/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 22:05:34,574 - INFO - Epoch:[386/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.02
2025-03-02 22:05:38,804 - INFO - Epoch:[386/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 22:05:46,485 - INFO - Epoch:[386/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 22:05:53,032 - INFO - Epoch:[386/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:05:57,005 - INFO - Epoch:[386/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.19 loss_cvh: 0.66
2025-03-02 22:05:58,363 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:06:44,713 - INFO - begin training stage: [387/805]
2025-03-02 22:06:44,714 - INFO - begin training stage: [387/805]
2025-03-02 22:06:51,540 - INFO - Epoch:[387/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 22:06:59,498 - INFO - Epoch:[387/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 22:07:05,072 - INFO - Epoch:[387/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-02 22:07:10,012 - INFO - Epoch:[387/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 22:07:14,751 - INFO - Epoch:[387/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 22:07:18,665 - INFO - Epoch:[387/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 22:07:22,793 - INFO - Epoch:[387/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 22:07:27,620 - INFO - Epoch:[387/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 22:07:32,074 - INFO - Epoch:[387/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.33 loss_cvh: 1.01
2025-03-02 22:07:33,150 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:08:48,549 - INFO - begin training stage: [388/805]
2025-03-02 22:08:48,550 - INFO - begin training stage: [388/805]
2025-03-02 22:08:55,586 - INFO - Epoch:[388/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 22:08:59,586 - INFO - Epoch:[388/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 22:09:03,733 - INFO - Epoch:[388/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 22:09:07,726 - INFO - Epoch:[388/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 22:09:11,977 - INFO - Epoch:[388/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 22:09:16,431 - INFO - Epoch:[388/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 22:09:20,409 - INFO - Epoch:[388/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 22:09:24,374 - INFO - Epoch:[388/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 22:09:27,788 - INFO - Epoch:[388/805] Step:[90/90] reconstruction_loss: 1.03 loss_vc: 1.37 loss_cvh: 0.68
2025-03-02 22:09:29,042 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:10:44,232 - INFO - begin training stage: [389/805]
2025-03-02 22:10:44,232 - INFO - begin training stage: [389/805]
2025-03-02 22:10:52,537 - INFO - Epoch:[389/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 22:10:59,340 - INFO - Epoch:[389/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 22:11:05,662 - INFO - Epoch:[389/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 22:11:11,873 - INFO - Epoch:[389/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:11:17,057 - INFO - Epoch:[389/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.01
2025-03-02 22:11:22,291 - INFO - Epoch:[389/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:11:28,122 - INFO - Epoch:[389/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:11:34,893 - INFO - Epoch:[389/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 22:11:41,459 - INFO - Epoch:[389/805] Step:[90/90] reconstruction_loss: 0.97 loss_vc: 1.25 loss_cvh: 0.66
2025-03-02 22:11:44,218 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:12:38,380 - INFO - begin training stage: [390/805]
2025-03-02 22:12:38,380 - INFO - begin training stage: [390/805]
2025-03-02 22:12:42,942 - INFO - Epoch:[390/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.04
2025-03-02 22:12:46,384 - INFO - Epoch:[390/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 22:12:50,298 - INFO - Epoch:[390/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:12:54,493 - INFO - Epoch:[390/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 22:12:58,997 - INFO - Epoch:[390/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 22:13:02,798 - INFO - Epoch:[390/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:13:06,521 - INFO - Epoch:[390/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 22:13:10,186 - INFO - Epoch:[390/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 22:13:14,033 - INFO - Epoch:[390/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.27 loss_cvh: 0.75
2025-03-02 22:13:17,725 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:14:22,381 - INFO - begin training stage: [391/805]
2025-03-02 22:14:22,383 - INFO - eval data number: 45600
2025-03-02 22:14:22,383 - INFO - loading eval data ......
2025-03-02 22:15:06,947 - INFO - retrieval costs: 27.44624352455139
2025-03-02 22:18:37,321 - INFO - hamming distance computation costs: 210.37399196624756
2025-03-02 22:18:44,894 - INFO - hamming ranking costs: 7.572972059249878
2025-03-02 22:18:44,894 - INFO - labels shape: (45600, 239)
2025-03-02 22:19:50,353 - INFO - similarity labels generation costs: 65.45954060554504
2025-03-02 22:19:50,489 - INFO - topK: 5:, map: 0.33022416666666665
2025-03-02 22:19:50,965 - INFO - topK: 20:, map: 0.23943199492130457
2025-03-02 22:19:51,890 - INFO - topK: 40:, map: 0.20754331581861735
2025-03-02 22:19:53,232 - INFO - topK: 60:, map: 0.18862326660684456
2025-03-02 22:19:55,010 - INFO - topK: 80:, map: 0.1746909710216447
2025-03-02 22:19:57,234 - INFO - topK: 100:, map: 0.16279466553184396
2025-03-02 22:19:59,296 - INFO - begin training stage: [391/805]
2025-03-02 22:20:06,372 - INFO - Epoch:[391/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 22:20:12,005 - INFO - Epoch:[391/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 22:20:17,463 - INFO - Epoch:[391/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:20:22,526 - INFO - Epoch:[391/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.04
2025-03-02 22:20:27,757 - INFO - Epoch:[391/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 22:20:33,016 - INFO - Epoch:[391/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 22:20:38,196 - INFO - Epoch:[391/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 22:20:43,496 - INFO - Epoch:[391/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 22:20:48,389 - INFO - Epoch:[391/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.23 loss_cvh: 0.78
2025-03-02 22:20:49,962 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:21:36,420 - INFO - begin training stage: [392/805]
2025-03-02 22:21:36,421 - INFO - begin training stage: [392/805]
2025-03-02 22:21:40,756 - INFO - Epoch:[392/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 22:21:44,265 - INFO - Epoch:[392/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 22:21:47,763 - INFO - Epoch:[392/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 22:21:51,357 - INFO - Epoch:[392/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 22:21:55,106 - INFO - Epoch:[392/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 22:21:59,382 - INFO - Epoch:[392/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 22:22:03,412 - INFO - Epoch:[392/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:22:07,428 - INFO - Epoch:[392/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 22:22:11,064 - INFO - Epoch:[392/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.19 loss_cvh: 0.92
2025-03-02 22:22:12,514 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:23:12,794 - INFO - begin training stage: [393/805]
2025-03-02 22:23:12,794 - INFO - begin training stage: [393/805]
2025-03-02 22:23:20,528 - INFO - Epoch:[393/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 22:23:25,215 - INFO - Epoch:[393/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.06
2025-03-02 22:23:29,590 - INFO - Epoch:[393/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.04
2025-03-02 22:23:33,970 - INFO - Epoch:[393/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 22:23:38,142 - INFO - Epoch:[393/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 22:23:42,535 - INFO - Epoch:[393/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 22:23:47,082 - INFO - Epoch:[393/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 22:23:51,476 - INFO - Epoch:[393/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 22:23:55,837 - INFO - Epoch:[393/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.23 loss_cvh: 0.76
2025-03-02 22:23:57,405 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:24:46,200 - INFO - begin training stage: [394/805]
2025-03-02 22:24:46,200 - INFO - begin training stage: [394/805]
2025-03-02 22:24:50,941 - INFO - Epoch:[394/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 22:24:54,658 - INFO - Epoch:[394/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:24:58,635 - INFO - Epoch:[394/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 22:25:02,422 - INFO - Epoch:[394/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 22:25:06,262 - INFO - Epoch:[394/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 22:25:10,492 - INFO - Epoch:[394/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.04
2025-03-02 22:25:14,512 - INFO - Epoch:[394/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-02 22:25:18,885 - INFO - Epoch:[394/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.06
2025-03-02 22:25:22,653 - INFO - Epoch:[394/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.17 loss_cvh: 0.71
2025-03-02 22:25:23,829 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:26:10,714 - INFO - begin training stage: [395/805]
2025-03-02 22:26:10,714 - INFO - begin training stage: [395/805]
2025-03-02 22:26:17,017 - INFO - Epoch:[395/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:26:22,839 - INFO - Epoch:[395/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 22:26:27,981 - INFO - Epoch:[395/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 22:26:32,525 - INFO - Epoch:[395/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:26:37,686 - INFO - Epoch:[395/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 22:26:43,036 - INFO - Epoch:[395/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 22:26:47,764 - INFO - Epoch:[395/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 22:26:52,338 - INFO - Epoch:[395/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:26:56,528 - INFO - Epoch:[395/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.18 loss_cvh: 0.97
2025-03-02 22:26:57,865 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:27:38,689 - INFO - begin training stage: [396/805]
2025-03-02 22:27:38,690 - INFO - begin training stage: [396/805]
2025-03-02 22:27:44,670 - INFO - Epoch:[396/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 22:27:48,865 - INFO - Epoch:[396/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 22:27:53,042 - INFO - Epoch:[396/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 22:27:57,430 - INFO - Epoch:[396/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 22:28:01,555 - INFO - Epoch:[396/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.12
2025-03-02 22:28:06,307 - INFO - Epoch:[396/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 22:28:11,536 - INFO - Epoch:[396/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.16
2025-03-02 22:28:16,247 - INFO - Epoch:[396/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 22:28:20,362 - INFO - Epoch:[396/805] Step:[90/90] reconstruction_loss: 1.03 loss_vc: 1.36 loss_cvh: 0.65
2025-03-02 22:28:21,793 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:29:10,624 - INFO - begin training stage: [397/805]
2025-03-02 22:29:10,625 - INFO - begin training stage: [397/805]
2025-03-02 22:29:16,252 - INFO - Epoch:[397/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 22:29:20,301 - INFO - Epoch:[397/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.16
2025-03-02 22:29:24,363 - INFO - Epoch:[397/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:29:28,779 - INFO - Epoch:[397/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 22:29:32,929 - INFO - Epoch:[397/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 22:29:37,097 - INFO - Epoch:[397/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.05
2025-03-02 22:29:41,560 - INFO - Epoch:[397/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.14
2025-03-02 22:29:46,487 - INFO - Epoch:[397/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 22:29:50,524 - INFO - Epoch:[397/805] Step:[90/90] reconstruction_loss: 1.37 loss_vc: 1.12 loss_cvh: 0.69
2025-03-02 22:29:51,771 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:30:45,865 - INFO - begin training stage: [398/805]
2025-03-02 22:30:45,865 - INFO - begin training stage: [398/805]
2025-03-02 22:30:51,225 - INFO - Epoch:[398/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 22:30:55,488 - INFO - Epoch:[398/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 22:30:59,860 - INFO - Epoch:[398/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.02
2025-03-02 22:31:04,214 - INFO - Epoch:[398/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.04
2025-03-02 22:31:08,150 - INFO - Epoch:[398/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 22:31:12,933 - INFO - Epoch:[398/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 22:31:17,670 - INFO - Epoch:[398/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.16
2025-03-02 22:31:22,086 - INFO - Epoch:[398/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.04
2025-03-02 22:31:26,051 - INFO - Epoch:[398/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.33 loss_cvh: 0.87
2025-03-02 22:31:27,381 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:32:12,211 - INFO - begin training stage: [399/805]
2025-03-02 22:32:12,211 - INFO - begin training stage: [399/805]
2025-03-02 22:32:17,055 - INFO - Epoch:[399/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.05
2025-03-02 22:32:21,832 - INFO - Epoch:[399/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 22:32:27,057 - INFO - Epoch:[399/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 22:32:31,865 - INFO - Epoch:[399/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 22:32:36,557 - INFO - Epoch:[399/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:32:40,671 - INFO - Epoch:[399/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 22:32:45,474 - INFO - Epoch:[399/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 22:32:50,593 - INFO - Epoch:[399/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.05
2025-03-02 22:32:55,665 - INFO - Epoch:[399/805] Step:[90/90] reconstruction_loss: 1.29 loss_vc: 1.44 loss_cvh: 0.70
2025-03-02 22:32:57,439 - INFO - now the learning rate is: 1.350851717672993e-05
2025-03-02 22:34:12,577 - INFO - begin training stage: [400/805]
2025-03-02 22:34:12,577 - INFO - begin training stage: [400/805]
2025-03-02 22:34:19,174 - INFO - Epoch:[400/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.14
2025-03-02 22:34:24,159 - INFO - Epoch:[400/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.05
2025-03-02 22:34:29,010 - INFO - Epoch:[400/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 22:34:34,046 - INFO - Epoch:[400/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 22:34:39,201 - INFO - Epoch:[400/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 22:34:44,657 - INFO - Epoch:[400/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 22:34:50,029 - INFO - Epoch:[400/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 22:34:55,528 - INFO - Epoch:[400/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 22:35:00,270 - INFO - Epoch:[400/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.31 loss_cvh: 0.73
2025-03-02 22:35:02,227 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 22:35:52,601 - INFO - begin training stage: [401/805]
2025-03-02 22:35:52,603 - INFO - eval data number: 45600
2025-03-02 22:35:52,603 - INFO - loading eval data ......
2025-03-02 22:36:28,016 - INFO - retrieval costs: 22.549610137939453
2025-03-02 22:39:20,661 - INFO - hamming distance computation costs: 172.64522910118103
2025-03-02 22:39:27,526 - INFO - hamming ranking costs: 6.865108251571655
2025-03-02 22:39:27,526 - INFO - labels shape: (45600, 239)
2025-03-02 22:40:14,504 - INFO - similarity labels generation costs: 46.978153705596924
2025-03-02 22:40:14,634 - INFO - topK: 5:, map: 0.3343075
2025-03-02 22:40:15,093 - INFO - topK: 20:, map: 0.2387795441575753
2025-03-02 22:40:15,976 - INFO - topK: 40:, map: 0.20656740382127675
2025-03-02 22:40:17,286 - INFO - topK: 60:, map: 0.18786412963583718
2025-03-02 22:40:19,023 - INFO - topK: 80:, map: 0.1742254062030405
2025-03-02 22:40:21,182 - INFO - topK: 100:, map: 0.16222796025017372
2025-03-02 22:40:22,701 - INFO - begin training stage: [401/805]
2025-03-02 22:40:29,137 - INFO - Epoch:[401/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 22:40:35,356 - INFO - Epoch:[401/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 22:40:41,091 - INFO - Epoch:[401/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 22:40:46,622 - INFO - Epoch:[401/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 22:40:51,933 - INFO - Epoch:[401/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 22:40:57,114 - INFO - Epoch:[401/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 22:41:02,416 - INFO - Epoch:[401/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 22:41:07,818 - INFO - Epoch:[401/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:41:12,774 - INFO - Epoch:[401/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.38 loss_cvh: 0.93
2025-03-02 22:41:14,355 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 22:42:28,027 - INFO - begin training stage: [402/805]
2025-03-02 22:42:28,027 - INFO - begin training stage: [402/805]
2025-03-02 22:42:33,031 - INFO - Epoch:[402/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 22:42:37,428 - INFO - Epoch:[402/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 22:42:42,154 - INFO - Epoch:[402/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 22:42:46,271 - INFO - Epoch:[402/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 22:42:50,079 - INFO - Epoch:[402/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 22:42:53,828 - INFO - Epoch:[402/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 22:42:57,801 - INFO - Epoch:[402/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 22:43:03,188 - INFO - Epoch:[402/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 22:43:09,330 - INFO - Epoch:[402/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.19 loss_cvh: 0.80
2025-03-02 22:43:11,716 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 22:44:04,374 - INFO - begin training stage: [403/805]
2025-03-02 22:44:04,375 - INFO - begin training stage: [403/805]
2025-03-02 22:44:10,311 - INFO - Epoch:[403/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 22:44:14,666 - INFO - Epoch:[403/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.05
2025-03-02 22:44:19,115 - INFO - Epoch:[403/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-02 22:44:23,386 - INFO - Epoch:[403/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-02 22:44:27,524 - INFO - Epoch:[403/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 22:44:31,703 - INFO - Epoch:[403/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-02 22:44:36,811 - INFO - Epoch:[403/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 22:44:44,553 - INFO - Epoch:[403/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 22:44:50,934 - INFO - Epoch:[403/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.64 loss_cvh: 1.05
2025-03-02 22:44:52,293 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 22:45:48,050 - INFO - begin training stage: [404/805]
2025-03-02 22:45:48,051 - INFO - begin training stage: [404/805]
2025-03-02 22:45:54,058 - INFO - Epoch:[404/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 22:45:58,665 - INFO - Epoch:[404/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 22:46:03,168 - INFO - Epoch:[404/805] Step:[30/90] reconstruction_loss: 1.11 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 22:46:07,147 - INFO - Epoch:[404/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 22:46:11,442 - INFO - Epoch:[404/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.11
2025-03-02 22:46:15,322 - INFO - Epoch:[404/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.11
2025-03-02 22:46:19,433 - INFO - Epoch:[404/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 22:46:23,545 - INFO - Epoch:[404/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 22:46:29,317 - INFO - Epoch:[404/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.27 loss_cvh: 1.08
2025-03-02 22:46:32,780 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 22:47:21,180 - INFO - begin training stage: [405/805]
2025-03-02 22:47:21,181 - INFO - begin training stage: [405/805]
2025-03-02 22:47:27,457 - INFO - Epoch:[405/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 22:47:32,037 - INFO - Epoch:[405/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 22:47:37,069 - INFO - Epoch:[405/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 22:47:41,596 - INFO - Epoch:[405/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 22:47:45,568 - INFO - Epoch:[405/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 22:47:51,206 - INFO - Epoch:[405/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 22:47:57,964 - INFO - Epoch:[405/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 22:48:03,138 - INFO - Epoch:[405/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.01
2025-03-02 22:48:09,144 - INFO - Epoch:[405/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.11 loss_cvh: 0.69
2025-03-02 22:48:12,779 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 22:49:05,774 - INFO - begin training stage: [406/805]
2025-03-02 22:49:05,774 - INFO - begin training stage: [406/805]
2025-03-02 22:49:12,665 - INFO - Epoch:[406/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:49:17,780 - INFO - Epoch:[406/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.02
2025-03-02 22:49:22,042 - INFO - Epoch:[406/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 22:49:26,056 - INFO - Epoch:[406/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.03
2025-03-02 22:49:30,118 - INFO - Epoch:[406/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 22:49:34,045 - INFO - Epoch:[406/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.04
2025-03-02 22:49:38,318 - INFO - Epoch:[406/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 22:49:42,769 - INFO - Epoch:[406/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 22:49:46,531 - INFO - Epoch:[406/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.13 loss_cvh: 0.83
2025-03-02 22:49:47,738 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 22:50:41,148 - INFO - begin training stage: [407/805]
2025-03-02 22:50:41,149 - INFO - begin training stage: [407/805]
2025-03-02 22:50:46,320 - INFO - Epoch:[407/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 22:50:50,143 - INFO - Epoch:[407/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 22:50:54,024 - INFO - Epoch:[407/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:50:57,985 - INFO - Epoch:[407/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 22:51:02,350 - INFO - Epoch:[407/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-02 22:51:06,995 - INFO - Epoch:[407/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-02 22:51:11,208 - INFO - Epoch:[407/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 22:51:16,025 - INFO - Epoch:[407/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.05
2025-03-02 22:51:19,779 - INFO - Epoch:[407/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.25 loss_cvh: 0.78
2025-03-02 22:51:20,986 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 22:52:25,453 - INFO - begin training stage: [408/805]
2025-03-02 22:52:25,453 - INFO - begin training stage: [408/805]
2025-03-02 22:52:30,711 - INFO - Epoch:[408/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 22:52:35,969 - INFO - Epoch:[408/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 22:52:41,736 - INFO - Epoch:[408/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:52:47,666 - INFO - Epoch:[408/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 22:52:52,416 - INFO - Epoch:[408/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 22:52:56,972 - INFO - Epoch:[408/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-02 22:53:01,423 - INFO - Epoch:[408/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 22:53:05,552 - INFO - Epoch:[408/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 22:53:09,125 - INFO - Epoch:[408/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.22 loss_cvh: 0.67
2025-03-02 22:53:10,256 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 22:53:51,078 - INFO - begin training stage: [409/805]
2025-03-02 22:53:51,079 - INFO - begin training stage: [409/805]
2025-03-02 22:53:56,675 - INFO - Epoch:[409/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:54:00,625 - INFO - Epoch:[409/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 22:54:04,499 - INFO - Epoch:[409/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 22:54:08,131 - INFO - Epoch:[409/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 22:54:12,044 - INFO - Epoch:[409/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.14
2025-03-02 22:54:17,941 - INFO - Epoch:[409/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 22:54:24,308 - INFO - Epoch:[409/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.05
2025-03-02 22:54:29,128 - INFO - Epoch:[409/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 22:54:34,119 - INFO - Epoch:[409/805] Step:[90/90] reconstruction_loss: 1.01 loss_vc: 1.15 loss_cvh: 0.74
2025-03-02 22:54:35,938 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 22:56:04,413 - INFO - begin training stage: [410/805]
2025-03-02 22:56:04,413 - INFO - begin training stage: [410/805]
2025-03-02 22:56:11,995 - INFO - Epoch:[410/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:56:17,349 - INFO - Epoch:[410/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 22:56:23,523 - INFO - Epoch:[410/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 22:56:28,991 - INFO - Epoch:[410/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 22:56:34,028 - INFO - Epoch:[410/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.02
2025-03-02 22:56:39,917 - INFO - Epoch:[410/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 22:56:45,769 - INFO - Epoch:[410/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.03
2025-03-02 22:56:51,082 - INFO - Epoch:[410/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 22:56:55,609 - INFO - Epoch:[410/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.32 loss_cvh: 1.06
2025-03-02 22:56:57,103 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 22:57:59,142 - INFO - begin training stage: [411/805]
2025-03-02 22:57:59,143 - INFO - eval data number: 45600
2025-03-02 22:57:59,143 - INFO - loading eval data ......
2025-03-02 22:58:37,850 - INFO - retrieval costs: 24.392137050628662
2025-03-02 23:01:30,347 - INFO - hamming distance computation costs: 172.4967930316925
2025-03-02 23:01:40,575 - INFO - hamming ranking costs: 10.228524446487427
2025-03-02 23:01:40,575 - INFO - labels shape: (45600, 239)
2025-03-02 23:02:28,480 - INFO - similarity labels generation costs: 47.90530848503113
2025-03-02 23:02:28,648 - INFO - topK: 5:, map: 0.3320416666666666
2025-03-02 23:02:29,072 - INFO - topK: 20:, map: 0.23831246079358165
2025-03-02 23:02:30,017 - INFO - topK: 40:, map: 0.20592271167225187
2025-03-02 23:02:31,538 - INFO - topK: 60:, map: 0.18659679995377218
2025-03-02 23:02:33,182 - INFO - topK: 80:, map: 0.17274987962025584
2025-03-02 23:02:35,333 - INFO - topK: 100:, map: 0.16066467587974143
2025-03-02 23:02:37,822 - INFO - begin training stage: [411/805]
2025-03-02 23:02:46,075 - INFO - Epoch:[411/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 23:02:52,298 - INFO - Epoch:[411/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 23:02:58,204 - INFO - Epoch:[411/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:03:04,472 - INFO - Epoch:[411/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 23:03:11,101 - INFO - Epoch:[411/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 23:03:18,072 - INFO - Epoch:[411/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 23:03:25,184 - INFO - Epoch:[411/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.03
2025-03-02 23:03:31,695 - INFO - Epoch:[411/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 23:03:37,565 - INFO - Epoch:[411/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.02 loss_cvh: 0.59
2025-03-02 23:03:39,509 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 23:05:02,510 - INFO - begin training stage: [412/805]
2025-03-02 23:05:02,511 - INFO - begin training stage: [412/805]
2025-03-02 23:05:08,724 - INFO - Epoch:[412/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.05
2025-03-02 23:05:13,029 - INFO - Epoch:[412/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 23:05:17,570 - INFO - Epoch:[412/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 23:05:22,171 - INFO - Epoch:[412/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 23:05:26,783 - INFO - Epoch:[412/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 23:05:31,382 - INFO - Epoch:[412/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 23:05:36,105 - INFO - Epoch:[412/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:05:40,422 - INFO - Epoch:[412/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 23:05:44,645 - INFO - Epoch:[412/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.21 loss_cvh: 0.76
2025-03-02 23:05:46,947 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 23:06:40,932 - INFO - begin training stage: [413/805]
2025-03-02 23:06:40,932 - INFO - begin training stage: [413/805]
2025-03-02 23:06:46,740 - INFO - Epoch:[413/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.04
2025-03-02 23:06:50,792 - INFO - Epoch:[413/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 23:06:54,962 - INFO - Epoch:[413/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 23:06:59,778 - INFO - Epoch:[413/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.15
2025-03-02 23:07:04,234 - INFO - Epoch:[413/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.08
2025-03-02 23:07:08,880 - INFO - Epoch:[413/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 23:07:13,230 - INFO - Epoch:[413/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-02 23:07:18,135 - INFO - Epoch:[413/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-02 23:07:22,436 - INFO - Epoch:[413/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.09 loss_cvh: 0.74
2025-03-02 23:07:23,757 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 23:08:05,911 - INFO - begin training stage: [414/805]
2025-03-02 23:08:05,911 - INFO - begin training stage: [414/805]
2025-03-02 23:08:11,435 - INFO - Epoch:[414/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:08:15,221 - INFO - Epoch:[414/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 23:08:18,927 - INFO - Epoch:[414/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 23:08:22,984 - INFO - Epoch:[414/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 23:08:27,806 - INFO - Epoch:[414/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 23:08:33,377 - INFO - Epoch:[414/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 23:08:40,926 - INFO - Epoch:[414/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.05
2025-03-02 23:08:45,260 - INFO - Epoch:[414/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 23:08:49,086 - INFO - Epoch:[414/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.40 loss_cvh: 0.82
2025-03-02 23:08:50,668 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 23:09:45,076 - INFO - begin training stage: [415/805]
2025-03-02 23:09:45,077 - INFO - begin training stage: [415/805]
2025-03-02 23:09:50,631 - INFO - Epoch:[415/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 23:09:54,320 - INFO - Epoch:[415/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.04
2025-03-02 23:09:58,190 - INFO - Epoch:[415/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.09
2025-03-02 23:10:01,940 - INFO - Epoch:[415/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:10:05,990 - INFO - Epoch:[415/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 23:10:09,801 - INFO - Epoch:[415/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.04
2025-03-02 23:10:13,446 - INFO - Epoch:[415/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 23:10:17,080 - INFO - Epoch:[415/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.13
2025-03-02 23:10:20,651 - INFO - Epoch:[415/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.11 loss_cvh: 0.79
2025-03-02 23:10:22,214 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 23:11:06,200 - INFO - begin training stage: [416/805]
2025-03-02 23:11:06,200 - INFO - begin training stage: [416/805]
2025-03-02 23:11:13,109 - INFO - Epoch:[416/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 23:11:17,185 - INFO - Epoch:[416/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 23:11:21,066 - INFO - Epoch:[416/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 23:11:24,996 - INFO - Epoch:[416/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.12
2025-03-02 23:11:29,828 - INFO - Epoch:[416/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 23:11:34,739 - INFO - Epoch:[416/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 23:11:39,171 - INFO - Epoch:[416/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 23:11:44,205 - INFO - Epoch:[416/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 23:11:48,543 - INFO - Epoch:[416/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.25 loss_cvh: 0.62
2025-03-02 23:11:50,850 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 23:12:41,334 - INFO - begin training stage: [417/805]
2025-03-02 23:12:41,335 - INFO - begin training stage: [417/805]
2025-03-02 23:12:47,117 - INFO - Epoch:[417/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 23:12:51,786 - INFO - Epoch:[417/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 23:12:56,390 - INFO - Epoch:[417/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 23:13:00,720 - INFO - Epoch:[417/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 23:13:05,317 - INFO - Epoch:[417/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 23:13:09,246 - INFO - Epoch:[417/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 23:13:13,712 - INFO - Epoch:[417/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 23:13:18,993 - INFO - Epoch:[417/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 23:13:23,855 - INFO - Epoch:[417/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.16 loss_cvh: 0.71
2025-03-02 23:13:26,131 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 23:14:11,809 - INFO - begin training stage: [418/805]
2025-03-02 23:14:11,809 - INFO - begin training stage: [418/805]
2025-03-02 23:14:18,118 - INFO - Epoch:[418/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 23:14:24,607 - INFO - Epoch:[418/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 23:14:29,994 - INFO - Epoch:[418/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 23:14:33,745 - INFO - Epoch:[418/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 23:14:37,919 - INFO - Epoch:[418/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 23:14:41,761 - INFO - Epoch:[418/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 23:14:45,498 - INFO - Epoch:[418/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 23:14:49,616 - INFO - Epoch:[418/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 23:14:53,559 - INFO - Epoch:[418/805] Step:[90/90] reconstruction_loss: 1.32 loss_vc: 1.38 loss_cvh: 1.04
2025-03-02 23:14:55,104 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 23:15:44,905 - INFO - begin training stage: [419/805]
2025-03-02 23:15:44,906 - INFO - begin training stage: [419/805]
2025-03-02 23:15:51,691 - INFO - Epoch:[419/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.41 loss_cvh: 3.08
2025-03-02 23:15:57,295 - INFO - Epoch:[419/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 23:16:02,005 - INFO - Epoch:[419/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-02 23:16:05,923 - INFO - Epoch:[419/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 23:16:10,081 - INFO - Epoch:[419/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 23:16:13,905 - INFO - Epoch:[419/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 23:16:17,277 - INFO - Epoch:[419/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 23:16:21,119 - INFO - Epoch:[419/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 23:16:25,805 - INFO - Epoch:[419/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.16 loss_cvh: 0.80
2025-03-02 23:16:28,337 - INFO - now the learning rate is: 1.2157665459056937e-05
2025-03-02 23:17:39,513 - INFO - begin training stage: [420/805]
2025-03-02 23:17:39,514 - INFO - begin training stage: [420/805]
2025-03-02 23:17:46,639 - INFO - Epoch:[420/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 23:17:51,645 - INFO - Epoch:[420/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 23:17:56,691 - INFO - Epoch:[420/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 23:18:01,508 - INFO - Epoch:[420/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 23:18:06,344 - INFO - Epoch:[420/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 23:18:11,320 - INFO - Epoch:[420/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 23:18:16,423 - INFO - Epoch:[420/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.40 loss_cvh: 3.07
2025-03-02 23:18:21,446 - INFO - Epoch:[420/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 23:18:26,151 - INFO - Epoch:[420/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.28 loss_cvh: 0.87
2025-03-02 23:18:28,088 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:19:42,058 - INFO - begin training stage: [421/805]
2025-03-02 23:19:42,061 - INFO - eval data number: 45600
2025-03-02 23:19:42,061 - INFO - loading eval data ......
2025-03-02 23:20:30,977 - INFO - retrieval costs: 31.465409755706787
2025-03-02 23:23:16,006 - INFO - hamming distance computation costs: 165.02911257743835
2025-03-02 23:23:27,123 - INFO - hamming ranking costs: 11.116724729537964
2025-03-02 23:23:27,123 - INFO - labels shape: (45600, 239)
2025-03-02 23:24:20,490 - INFO - similarity labels generation costs: 53.36734628677368
2025-03-02 23:24:20,575 - INFO - topK: 5:, map: 0.33056833333333335
2025-03-02 23:24:20,877 - INFO - topK: 20:, map: 0.23750560304628077
2025-03-02 23:24:21,456 - INFO - topK: 40:, map: 0.2066235559676516
2025-03-02 23:24:22,409 - INFO - topK: 60:, map: 0.18708590822693588
2025-03-02 23:24:23,569 - INFO - topK: 80:, map: 0.17265813852145426
2025-03-02 23:24:24,990 - INFO - topK: 100:, map: 0.16067419621266732
2025-03-02 23:24:26,631 - INFO - begin training stage: [421/805]
2025-03-02 23:24:32,680 - INFO - Epoch:[421/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.08
2025-03-02 23:24:37,718 - INFO - Epoch:[421/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 23:24:42,041 - INFO - Epoch:[421/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:24:46,908 - INFO - Epoch:[421/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.06
2025-03-02 23:24:51,672 - INFO - Epoch:[421/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 23:24:56,390 - INFO - Epoch:[421/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 23:25:01,216 - INFO - Epoch:[421/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 23:25:05,772 - INFO - Epoch:[421/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 23:25:09,949 - INFO - Epoch:[421/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.21 loss_cvh: 0.63
2025-03-02 23:25:11,539 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:26:28,627 - INFO - begin training stage: [422/805]
2025-03-02 23:26:28,628 - INFO - begin training stage: [422/805]
2025-03-02 23:26:35,545 - INFO - Epoch:[422/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 23:26:41,112 - INFO - Epoch:[422/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 23:26:47,091 - INFO - Epoch:[422/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 23:26:52,997 - INFO - Epoch:[422/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 23:26:58,041 - INFO - Epoch:[422/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 23:27:03,018 - INFO - Epoch:[422/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:27:07,642 - INFO - Epoch:[422/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 23:27:12,764 - INFO - Epoch:[422/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 23:27:17,825 - INFO - Epoch:[422/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.16 loss_cvh: 0.79
2025-03-02 23:27:19,695 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:28:17,179 - INFO - begin training stage: [423/805]
2025-03-02 23:28:17,180 - INFO - begin training stage: [423/805]
2025-03-02 23:28:23,954 - INFO - Epoch:[423/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 23:28:28,959 - INFO - Epoch:[423/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 23:28:33,352 - INFO - Epoch:[423/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 23:28:38,227 - INFO - Epoch:[423/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:28:43,258 - INFO - Epoch:[423/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 23:28:48,876 - INFO - Epoch:[423/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 23:28:54,538 - INFO - Epoch:[423/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-02 23:28:59,136 - INFO - Epoch:[423/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 23:29:03,775 - INFO - Epoch:[423/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.27 loss_cvh: 0.78
2025-03-02 23:29:05,410 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:29:58,080 - INFO - begin training stage: [424/805]
2025-03-02 23:29:58,080 - INFO - begin training stage: [424/805]
2025-03-02 23:30:03,777 - INFO - Epoch:[424/805] Step:[10/90] reconstruction_loss: 1.11 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:30:08,343 - INFO - Epoch:[424/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.11
2025-03-02 23:30:13,896 - INFO - Epoch:[424/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 23:30:19,880 - INFO - Epoch:[424/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-02 23:30:25,530 - INFO - Epoch:[424/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 23:30:30,125 - INFO - Epoch:[424/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:30:34,702 - INFO - Epoch:[424/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 23:30:39,968 - INFO - Epoch:[424/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 23:30:45,520 - INFO - Epoch:[424/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.26 loss_cvh: 0.84
2025-03-02 23:30:48,207 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:31:46,724 - INFO - begin training stage: [425/805]
2025-03-02 23:31:46,724 - INFO - begin training stage: [425/805]
2025-03-02 23:31:54,116 - INFO - Epoch:[425/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 23:31:59,485 - INFO - Epoch:[425/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:32:04,487 - INFO - Epoch:[425/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:32:09,548 - INFO - Epoch:[425/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 23:32:14,634 - INFO - Epoch:[425/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-02 23:32:19,325 - INFO - Epoch:[425/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 23:32:24,033 - INFO - Epoch:[425/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 23:32:28,675 - INFO - Epoch:[425/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 23:32:32,821 - INFO - Epoch:[425/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.29 loss_cvh: 0.88
2025-03-02 23:32:34,095 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:33:34,663 - INFO - begin training stage: [426/805]
2025-03-02 23:33:34,663 - INFO - begin training stage: [426/805]
2025-03-02 23:33:42,668 - INFO - Epoch:[426/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 23:33:47,871 - INFO - Epoch:[426/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 23:33:53,689 - INFO - Epoch:[426/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 23:33:58,818 - INFO - Epoch:[426/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-02 23:34:03,847 - INFO - Epoch:[426/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-02 23:34:09,544 - INFO - Epoch:[426/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 23:34:15,550 - INFO - Epoch:[426/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 23:34:21,789 - INFO - Epoch:[426/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.05
2025-03-02 23:34:27,419 - INFO - Epoch:[426/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.26 loss_cvh: 0.69
2025-03-02 23:34:29,328 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:35:19,783 - INFO - begin training stage: [427/805]
2025-03-02 23:35:19,783 - INFO - begin training stage: [427/805]
2025-03-02 23:35:26,053 - INFO - Epoch:[427/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 23:35:31,006 - INFO - Epoch:[427/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 23:35:36,629 - INFO - Epoch:[427/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 23:35:41,187 - INFO - Epoch:[427/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-02 23:35:46,603 - INFO - Epoch:[427/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-02 23:35:51,983 - INFO - Epoch:[427/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.15
2025-03-02 23:35:57,757 - INFO - Epoch:[427/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.12
2025-03-02 23:36:05,530 - INFO - Epoch:[427/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:36:11,407 - INFO - Epoch:[427/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.27 loss_cvh: 0.67
2025-03-02 23:36:13,213 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:37:06,051 - INFO - begin training stage: [428/805]
2025-03-02 23:37:06,051 - INFO - begin training stage: [428/805]
2025-03-02 23:37:12,624 - INFO - Epoch:[428/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 23:37:17,239 - INFO - Epoch:[428/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.14
2025-03-02 23:37:22,818 - INFO - Epoch:[428/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 23:37:28,173 - INFO - Epoch:[428/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.03
2025-03-02 23:37:33,089 - INFO - Epoch:[428/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-02 23:37:37,771 - INFO - Epoch:[428/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 23:37:42,553 - INFO - Epoch:[428/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.06
2025-03-02 23:37:47,846 - INFO - Epoch:[428/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 23:37:51,899 - INFO - Epoch:[428/805] Step:[90/90] reconstruction_loss: 1.03 loss_vc: 1.14 loss_cvh: 0.80
2025-03-02 23:37:53,308 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:39:13,388 - INFO - begin training stage: [429/805]
2025-03-02 23:39:13,389 - INFO - begin training stage: [429/805]
2025-03-02 23:39:20,525 - INFO - Epoch:[429/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-02 23:39:25,541 - INFO - Epoch:[429/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 23:39:30,397 - INFO - Epoch:[429/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 23:39:35,260 - INFO - Epoch:[429/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 23:39:40,012 - INFO - Epoch:[429/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.05
2025-03-02 23:39:44,776 - INFO - Epoch:[429/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.02
2025-03-02 23:39:49,645 - INFO - Epoch:[429/805] Step:[70/90] reconstruction_loss: 1.19 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 23:39:54,460 - INFO - Epoch:[429/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 23:39:59,171 - INFO - Epoch:[429/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.37 loss_cvh: 0.77
2025-03-02 23:40:01,131 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:41:17,208 - INFO - begin training stage: [430/805]
2025-03-02 23:41:17,209 - INFO - begin training stage: [430/805]
2025-03-02 23:41:24,340 - INFO - Epoch:[430/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.07
2025-03-02 23:41:29,776 - INFO - Epoch:[430/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 23:41:35,701 - INFO - Epoch:[430/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.07
2025-03-02 23:41:41,905 - INFO - Epoch:[430/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 23:41:47,895 - INFO - Epoch:[430/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-02 23:41:53,472 - INFO - Epoch:[430/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-02 23:41:58,814 - INFO - Epoch:[430/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 23:42:04,140 - INFO - Epoch:[430/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-02 23:42:08,384 - INFO - Epoch:[430/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.25 loss_cvh: 0.80
2025-03-02 23:42:09,951 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:43:00,987 - INFO - begin training stage: [431/805]
2025-03-02 23:43:00,988 - INFO - eval data number: 45600
2025-03-02 23:43:00,988 - INFO - loading eval data ......
2025-03-02 23:43:47,071 - INFO - retrieval costs: 29.742341995239258
2025-03-02 23:46:41,390 - INFO - hamming distance computation costs: 174.31851315498352
2025-03-02 23:46:51,484 - INFO - hamming ranking costs: 10.094353437423706
2025-03-02 23:46:51,484 - INFO - labels shape: (45600, 239)
2025-03-02 23:47:53,418 - INFO - similarity labels generation costs: 61.93346357345581
2025-03-02 23:47:53,547 - INFO - topK: 5:, map: 0.3291091666666667
2025-03-02 23:47:54,017 - INFO - topK: 20:, map: 0.23821537962854136
2025-03-02 23:47:54,953 - INFO - topK: 40:, map: 0.2068291233469193
2025-03-02 23:47:56,332 - INFO - topK: 60:, map: 0.1874760000919154
2025-03-02 23:47:58,200 - INFO - topK: 80:, map: 0.17332008115369404
2025-03-02 23:48:00,480 - INFO - topK: 100:, map: 0.1619459857853608
2025-03-02 23:48:02,721 - INFO - begin training stage: [431/805]
2025-03-02 23:48:11,250 - INFO - Epoch:[431/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.12
2025-03-02 23:48:17,396 - INFO - Epoch:[431/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 23:48:22,529 - INFO - Epoch:[431/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-02 23:48:27,881 - INFO - Epoch:[431/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.03
2025-03-02 23:48:32,697 - INFO - Epoch:[431/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 23:48:37,542 - INFO - Epoch:[431/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 23:48:42,318 - INFO - Epoch:[431/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-02 23:48:47,049 - INFO - Epoch:[431/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 23:48:51,460 - INFO - Epoch:[431/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.29 loss_cvh: 0.73
2025-03-02 23:48:53,089 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:49:43,521 - INFO - begin training stage: [432/805]
2025-03-02 23:49:43,521 - INFO - begin training stage: [432/805]
2025-03-02 23:49:49,657 - INFO - Epoch:[432/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 23:49:54,448 - INFO - Epoch:[432/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 23:49:59,461 - INFO - Epoch:[432/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 23:50:04,281 - INFO - Epoch:[432/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.04
2025-03-02 23:50:08,710 - INFO - Epoch:[432/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 23:50:13,442 - INFO - Epoch:[432/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 23:50:18,527 - INFO - Epoch:[432/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 23:50:23,435 - INFO - Epoch:[432/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 23:50:27,649 - INFO - Epoch:[432/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.35 loss_cvh: 0.86
2025-03-02 23:50:29,065 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:51:24,320 - INFO - begin training stage: [433/805]
2025-03-02 23:51:24,320 - INFO - begin training stage: [433/805]
2025-03-02 23:51:30,856 - INFO - Epoch:[433/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.09
2025-03-02 23:51:36,953 - INFO - Epoch:[433/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.10
2025-03-02 23:51:42,236 - INFO - Epoch:[433/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 23:51:47,364 - INFO - Epoch:[433/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-02 23:51:51,818 - INFO - Epoch:[433/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.13
2025-03-02 23:51:56,622 - INFO - Epoch:[433/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 23:52:01,787 - INFO - Epoch:[433/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.07
2025-03-02 23:52:06,526 - INFO - Epoch:[433/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-02 23:52:11,311 - INFO - Epoch:[433/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.36 loss_cvh: 0.78
2025-03-02 23:52:13,373 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:53:06,348 - INFO - begin training stage: [434/805]
2025-03-02 23:53:06,348 - INFO - begin training stage: [434/805]
2025-03-02 23:53:13,090 - INFO - Epoch:[434/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 23:53:18,038 - INFO - Epoch:[434/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.11
2025-03-02 23:53:22,737 - INFO - Epoch:[434/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-02 23:53:27,247 - INFO - Epoch:[434/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-02 23:53:31,500 - INFO - Epoch:[434/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 23:53:36,020 - INFO - Epoch:[434/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-02 23:53:40,966 - INFO - Epoch:[434/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.07
2025-03-02 23:53:46,212 - INFO - Epoch:[434/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-02 23:53:50,958 - INFO - Epoch:[434/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.10 loss_cvh: 0.79
2025-03-02 23:53:52,671 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:54:40,949 - INFO - begin training stage: [435/805]
2025-03-02 23:54:40,949 - INFO - begin training stage: [435/805]
2025-03-02 23:54:47,452 - INFO - Epoch:[435/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 23:54:52,662 - INFO - Epoch:[435/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 23:54:57,613 - INFO - Epoch:[435/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 23:55:02,674 - INFO - Epoch:[435/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 23:55:07,509 - INFO - Epoch:[435/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.39 loss_cvh: 3.08
2025-03-02 23:55:12,825 - INFO - Epoch:[435/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.13
2025-03-02 23:55:18,581 - INFO - Epoch:[435/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.06
2025-03-02 23:55:24,497 - INFO - Epoch:[435/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 23:55:29,559 - INFO - Epoch:[435/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.40 loss_cvh: 0.80
2025-03-02 23:55:31,331 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:56:26,646 - INFO - begin training stage: [436/805]
2025-03-02 23:56:26,647 - INFO - begin training stage: [436/805]
2025-03-02 23:56:32,968 - INFO - Epoch:[436/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 23:56:37,909 - INFO - Epoch:[436/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.07
2025-03-02 23:56:43,056 - INFO - Epoch:[436/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.04
2025-03-02 23:56:47,179 - INFO - Epoch:[436/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-02 23:56:51,970 - INFO - Epoch:[436/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-02 23:56:56,896 - INFO - Epoch:[436/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-02 23:57:00,908 - INFO - Epoch:[436/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-02 23:57:04,924 - INFO - Epoch:[436/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-02 23:57:08,670 - INFO - Epoch:[436/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.14 loss_cvh: 0.71
2025-03-02 23:57:10,054 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:58:05,506 - INFO - begin training stage: [437/805]
2025-03-02 23:58:05,507 - INFO - begin training stage: [437/805]
2025-03-02 23:58:13,626 - INFO - Epoch:[437/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.06
2025-03-02 23:58:18,261 - INFO - Epoch:[437/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.15
2025-03-02 23:58:23,376 - INFO - Epoch:[437/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-02 23:58:28,705 - INFO - Epoch:[437/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-02 23:58:33,781 - INFO - Epoch:[437/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-02 23:58:39,443 - INFO - Epoch:[437/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-02 23:58:44,942 - INFO - Epoch:[437/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.05
2025-03-02 23:58:49,912 - INFO - Epoch:[437/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-02 23:58:54,290 - INFO - Epoch:[437/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.23 loss_cvh: 0.66
2025-03-02 23:58:56,247 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-02 23:59:53,858 - INFO - begin training stage: [438/805]
2025-03-02 23:59:53,858 - INFO - begin training stage: [438/805]
2025-03-03 00:00:00,993 - INFO - Epoch:[438/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.06
2025-03-03 00:00:06,260 - INFO - Epoch:[438/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.14
2025-03-03 00:00:15,151 - INFO - Epoch:[438/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.14
2025-03-03 00:00:24,928 - INFO - Epoch:[438/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 00:00:32,515 - INFO - Epoch:[438/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:00:37,754 - INFO - Epoch:[438/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 00:00:43,289 - INFO - Epoch:[438/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 00:00:48,746 - INFO - Epoch:[438/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 00:00:53,453 - INFO - Epoch:[438/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.25 loss_cvh: 0.87
2025-03-03 00:00:55,376 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-03 00:02:09,719 - INFO - begin training stage: [439/805]
2025-03-03 00:02:09,720 - INFO - begin training stage: [439/805]
2025-03-03 00:02:18,774 - INFO - Epoch:[439/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.03
2025-03-03 00:02:24,934 - INFO - Epoch:[439/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.05
2025-03-03 00:02:31,060 - INFO - Epoch:[439/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 00:02:37,316 - INFO - Epoch:[439/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 00:02:44,033 - INFO - Epoch:[439/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 00:02:51,060 - INFO - Epoch:[439/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 00:02:57,874 - INFO - Epoch:[439/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 00:03:03,893 - INFO - Epoch:[439/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.40 loss_cvh: 3.09
2025-03-03 00:03:09,834 - INFO - Epoch:[439/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.16 loss_cvh: 0.76
2025-03-03 00:03:12,131 - INFO - now the learning rate is: 1.0941898913151244e-05
2025-03-03 00:04:09,759 - INFO - begin training stage: [440/805]
2025-03-03 00:04:09,760 - INFO - begin training stage: [440/805]
2025-03-03 00:04:14,211 - INFO - Epoch:[440/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 00:04:17,627 - INFO - Epoch:[440/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 00:04:21,056 - INFO - Epoch:[440/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.10
2025-03-03 00:04:24,455 - INFO - Epoch:[440/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.12
2025-03-03 00:04:27,868 - INFO - Epoch:[440/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 00:04:31,129 - INFO - Epoch:[440/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 00:04:34,343 - INFO - Epoch:[440/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 00:04:37,544 - INFO - Epoch:[440/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.03
2025-03-03 00:04:40,686 - INFO - Epoch:[440/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.20 loss_cvh: 0.59
2025-03-03 00:04:41,703 - INFO - now the learning rate is: 1e-05
2025-03-03 00:05:31,430 - INFO - begin training stage: [441/805]
2025-03-03 00:05:31,432 - INFO - eval data number: 45600
2025-03-03 00:05:31,432 - INFO - loading eval data ......
2025-03-03 00:06:21,720 - INFO - retrieval costs: 31.874255180358887
2025-03-03 00:09:15,959 - INFO - hamming distance computation costs: 174.23852610588074
2025-03-03 00:09:25,914 - INFO - hamming ranking costs: 9.955112218856812
2025-03-03 00:09:25,914 - INFO - labels shape: (45600, 239)
2025-03-03 00:10:29,311 - INFO - similarity labels generation costs: 63.397733211517334
2025-03-03 00:10:29,512 - INFO - topK: 5:, map: 0.33256166666666664
2025-03-03 00:10:30,203 - INFO - topK: 20:, map: 0.2413891696893685
2025-03-03 00:10:31,562 - INFO - topK: 40:, map: 0.20932451799574667
2025-03-03 00:10:33,591 - INFO - topK: 60:, map: 0.19015581935720183
2025-03-03 00:10:36,385 - INFO - topK: 80:, map: 0.17617550351873404
2025-03-03 00:10:40,092 - INFO - topK: 100:, map: 0.16376792053813602
2025-03-03 00:10:42,681 - INFO - begin training stage: [441/805]
2025-03-03 00:10:49,881 - INFO - Epoch:[441/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 00:10:53,836 - INFO - Epoch:[441/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 00:10:58,159 - INFO - Epoch:[441/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 00:11:02,739 - INFO - Epoch:[441/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 00:11:06,400 - INFO - Epoch:[441/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.02
2025-03-03 00:11:11,310 - INFO - Epoch:[441/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.09
2025-03-03 00:11:16,440 - INFO - Epoch:[441/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 00:11:20,354 - INFO - Epoch:[441/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 00:11:24,032 - INFO - Epoch:[441/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.12 loss_cvh: 0.76
2025-03-03 00:11:25,152 - INFO - now the learning rate is: 1e-05
2025-03-03 00:12:11,372 - INFO - begin training stage: [442/805]
2025-03-03 00:12:11,373 - INFO - begin training stage: [442/805]
2025-03-03 00:12:16,277 - INFO - Epoch:[442/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 00:12:20,321 - INFO - Epoch:[442/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 00:12:24,378 - INFO - Epoch:[442/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.15
2025-03-03 00:12:29,644 - INFO - Epoch:[442/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:12:33,988 - INFO - Epoch:[442/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 00:12:40,496 - INFO - Epoch:[442/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-03 00:12:47,149 - INFO - Epoch:[442/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:12:51,308 - INFO - Epoch:[442/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.05
2025-03-03 00:12:55,635 - INFO - Epoch:[442/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.21 loss_cvh: 0.76
2025-03-03 00:12:57,673 - INFO - now the learning rate is: 1e-05
2025-03-03 00:13:43,260 - INFO - begin training stage: [443/805]
2025-03-03 00:13:43,261 - INFO - begin training stage: [443/805]
2025-03-03 00:13:49,969 - INFO - Epoch:[443/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 00:13:54,269 - INFO - Epoch:[443/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 00:13:58,734 - INFO - Epoch:[443/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 00:14:02,565 - INFO - Epoch:[443/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.08
2025-03-03 00:14:07,953 - INFO - Epoch:[443/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 00:14:13,848 - INFO - Epoch:[443/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 00:14:18,989 - INFO - Epoch:[443/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:14:22,865 - INFO - Epoch:[443/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.03
2025-03-03 00:14:26,541 - INFO - Epoch:[443/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.12 loss_cvh: 0.58
2025-03-03 00:14:27,699 - INFO - now the learning rate is: 1e-05
2025-03-03 00:15:11,928 - INFO - begin training stage: [444/805]
2025-03-03 00:15:11,929 - INFO - begin training stage: [444/805]
2025-03-03 00:15:18,791 - INFO - Epoch:[444/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 00:15:24,714 - INFO - Epoch:[444/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 00:15:29,678 - INFO - Epoch:[444/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:15:34,870 - INFO - Epoch:[444/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-03 00:15:39,616 - INFO - Epoch:[444/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 00:15:44,103 - INFO - Epoch:[444/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 00:15:48,372 - INFO - Epoch:[444/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 00:15:52,349 - INFO - Epoch:[444/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 00:15:56,226 - INFO - Epoch:[444/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.38 loss_cvh: 1.05
2025-03-03 00:15:57,344 - INFO - now the learning rate is: 1e-05
2025-03-03 00:16:56,694 - INFO - begin training stage: [445/805]
2025-03-03 00:16:56,695 - INFO - begin training stage: [445/805]
2025-03-03 00:17:02,863 - INFO - Epoch:[445/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 00:17:07,787 - INFO - Epoch:[445/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 00:17:12,481 - INFO - Epoch:[445/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:17:17,420 - INFO - Epoch:[445/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 00:17:22,118 - INFO - Epoch:[445/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 00:17:26,577 - INFO - Epoch:[445/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 00:17:31,649 - INFO - Epoch:[445/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 00:17:36,149 - INFO - Epoch:[445/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 00:17:40,877 - INFO - Epoch:[445/805] Step:[90/90] reconstruction_loss: 1.03 loss_vc: 1.10 loss_cvh: 0.74
2025-03-03 00:17:43,057 - INFO - now the learning rate is: 1e-05
2025-03-03 00:18:28,464 - INFO - begin training stage: [446/805]
2025-03-03 00:18:28,465 - INFO - begin training stage: [446/805]
2025-03-03 00:18:34,008 - INFO - Epoch:[446/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 00:18:38,016 - INFO - Epoch:[446/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 00:18:42,289 - INFO - Epoch:[446/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 00:18:46,616 - INFO - Epoch:[446/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 00:18:50,603 - INFO - Epoch:[446/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 00:18:54,911 - INFO - Epoch:[446/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 00:19:00,161 - INFO - Epoch:[446/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 00:19:05,047 - INFO - Epoch:[446/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 00:19:09,443 - INFO - Epoch:[446/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.38 loss_cvh: 0.83
2025-03-03 00:19:10,539 - INFO - now the learning rate is: 1e-05
2025-03-03 00:20:01,055 - INFO - begin training stage: [447/805]
2025-03-03 00:20:01,055 - INFO - begin training stage: [447/805]
2025-03-03 00:20:07,406 - INFO - Epoch:[447/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 00:20:12,990 - INFO - Epoch:[447/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:20:17,973 - INFO - Epoch:[447/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 00:20:23,349 - INFO - Epoch:[447/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 00:20:28,135 - INFO - Epoch:[447/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 00:20:32,770 - INFO - Epoch:[447/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.16
2025-03-03 00:20:37,392 - INFO - Epoch:[447/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 00:20:42,023 - INFO - Epoch:[447/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:20:46,325 - INFO - Epoch:[447/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.29 loss_cvh: 0.88
2025-03-03 00:20:47,675 - INFO - now the learning rate is: 1e-05
2025-03-03 00:21:29,458 - INFO - begin training stage: [448/805]
2025-03-03 00:21:29,459 - INFO - begin training stage: [448/805]
2025-03-03 00:21:34,396 - INFO - Epoch:[448/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-03 00:21:38,741 - INFO - Epoch:[448/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.11
2025-03-03 00:21:43,416 - INFO - Epoch:[448/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 00:21:47,815 - INFO - Epoch:[448/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 00:21:52,342 - INFO - Epoch:[448/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 00:21:57,180 - INFO - Epoch:[448/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 00:22:02,107 - INFO - Epoch:[448/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 00:22:07,702 - INFO - Epoch:[448/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 00:22:13,111 - INFO - Epoch:[448/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.26 loss_cvh: 0.70
2025-03-03 00:22:14,912 - INFO - now the learning rate is: 1e-05
2025-03-03 00:23:14,160 - INFO - begin training stage: [449/805]
2025-03-03 00:23:14,161 - INFO - begin training stage: [449/805]
2025-03-03 00:23:20,105 - INFO - Epoch:[449/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.05
2025-03-03 00:23:24,648 - INFO - Epoch:[449/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 00:23:29,056 - INFO - Epoch:[449/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:23:33,388 - INFO - Epoch:[449/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 00:23:37,552 - INFO - Epoch:[449/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 00:23:41,267 - INFO - Epoch:[449/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:23:45,064 - INFO - Epoch:[449/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:23:48,668 - INFO - Epoch:[449/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 00:23:52,027 - INFO - Epoch:[449/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.12 loss_cvh: 0.68
2025-03-03 00:23:53,052 - INFO - now the learning rate is: 1e-05
2025-03-03 00:25:09,185 - INFO - begin training stage: [450/805]
2025-03-03 00:25:09,186 - INFO - begin training stage: [450/805]
2025-03-03 00:25:17,630 - INFO - Epoch:[450/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 00:25:23,686 - INFO - Epoch:[450/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 00:25:29,261 - INFO - Epoch:[450/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:25:34,794 - INFO - Epoch:[450/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.04
2025-03-03 00:25:39,896 - INFO - Epoch:[450/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 00:25:45,413 - INFO - Epoch:[450/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:25:52,036 - INFO - Epoch:[450/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.11
2025-03-03 00:25:57,561 - INFO - Epoch:[450/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 00:26:02,268 - INFO - Epoch:[450/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.25 loss_cvh: 0.80
2025-03-03 00:26:03,793 - INFO - now the learning rate is: 1e-05
2025-03-03 00:26:53,136 - INFO - begin training stage: [451/805]
2025-03-03 00:26:53,138 - INFO - eval data number: 45600
2025-03-03 00:26:53,138 - INFO - loading eval data ......
2025-03-03 00:27:39,482 - INFO - retrieval costs: 32.37053322792053
2025-03-03 00:30:47,550 - INFO - hamming distance computation costs: 188.06754684448242
2025-03-03 00:31:01,544 - INFO - hamming ranking costs: 13.99441933631897
2025-03-03 00:31:01,545 - INFO - labels shape: (45600, 239)
2025-03-03 00:32:02,890 - INFO - similarity labels generation costs: 61.34658646583557
2025-03-03 00:32:03,107 - INFO - topK: 5:, map: 0.3325708333333333
2025-03-03 00:32:03,768 - INFO - topK: 20:, map: 0.24188473595821747
2025-03-03 00:32:05,064 - INFO - topK: 40:, map: 0.20923783888778416
2025-03-03 00:32:06,981 - INFO - topK: 60:, map: 0.18933794845422058
2025-03-03 00:32:09,516 - INFO - topK: 80:, map: 0.17446678765358054
2025-03-03 00:32:12,680 - INFO - topK: 100:, map: 0.16259327444523197
2025-03-03 00:32:14,513 - INFO - begin training stage: [451/805]
2025-03-03 00:32:20,577 - INFO - Epoch:[451/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 00:32:26,092 - INFO - Epoch:[451/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 00:32:31,737 - INFO - Epoch:[451/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 00:32:37,016 - INFO - Epoch:[451/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 00:32:41,457 - INFO - Epoch:[451/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.13
2025-03-03 00:32:45,442 - INFO - Epoch:[451/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 00:32:49,605 - INFO - Epoch:[451/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 00:32:55,416 - INFO - Epoch:[451/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.03
2025-03-03 00:33:01,628 - INFO - Epoch:[451/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.05 loss_cvh: 0.65
2025-03-03 00:33:03,149 - INFO - now the learning rate is: 1e-05
2025-03-03 00:34:02,770 - INFO - begin training stage: [452/805]
2025-03-03 00:34:02,771 - INFO - begin training stage: [452/805]
2025-03-03 00:34:08,194 - INFO - Epoch:[452/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 00:34:12,218 - INFO - Epoch:[452/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 00:34:16,592 - INFO - Epoch:[452/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 00:34:21,434 - INFO - Epoch:[452/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:34:25,643 - INFO - Epoch:[452/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 00:34:30,332 - INFO - Epoch:[452/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 00:34:34,281 - INFO - Epoch:[452/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 00:34:38,281 - INFO - Epoch:[452/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 00:34:42,308 - INFO - Epoch:[452/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.16 loss_cvh: 0.81
2025-03-03 00:34:43,390 - INFO - now the learning rate is: 1e-05
2025-03-03 00:35:31,099 - INFO - begin training stage: [453/805]
2025-03-03 00:35:31,100 - INFO - begin training stage: [453/805]
2025-03-03 00:35:36,835 - INFO - Epoch:[453/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:35:41,429 - INFO - Epoch:[453/805] Step:[20/90] reconstruction_loss: 1.19 loss_vc: 4.39 loss_cvh: 3.12
2025-03-03 00:35:46,514 - INFO - Epoch:[453/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 00:35:50,998 - INFO - Epoch:[453/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 00:35:55,281 - INFO - Epoch:[453/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 00:35:59,544 - INFO - Epoch:[453/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 00:36:05,785 - INFO - Epoch:[453/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 00:36:13,427 - INFO - Epoch:[453/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 00:36:20,844 - INFO - Epoch:[453/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.19 loss_cvh: 0.68
2025-03-03 00:36:25,008 - INFO - now the learning rate is: 1e-05
2025-03-03 00:37:15,433 - INFO - begin training stage: [454/805]
2025-03-03 00:37:15,433 - INFO - begin training stage: [454/805]
2025-03-03 00:37:21,918 - INFO - Epoch:[454/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 00:37:26,929 - INFO - Epoch:[454/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 00:37:32,120 - INFO - Epoch:[454/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 00:37:37,240 - INFO - Epoch:[454/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 00:37:41,930 - INFO - Epoch:[454/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 00:37:47,836 - INFO - Epoch:[454/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 00:37:53,161 - INFO - Epoch:[454/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:37:58,149 - INFO - Epoch:[454/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 00:38:02,363 - INFO - Epoch:[454/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.26 loss_cvh: 0.80
2025-03-03 00:38:03,824 - INFO - now the learning rate is: 1e-05
2025-03-03 00:38:58,605 - INFO - begin training stage: [455/805]
2025-03-03 00:38:58,605 - INFO - begin training stage: [455/805]
2025-03-03 00:39:06,638 - INFO - Epoch:[455/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 00:39:14,040 - INFO - Epoch:[455/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 00:39:21,216 - INFO - Epoch:[455/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 00:39:26,548 - INFO - Epoch:[455/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.04
2025-03-03 00:39:31,338 - INFO - Epoch:[455/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.03
2025-03-03 00:39:35,796 - INFO - Epoch:[455/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 00:39:39,823 - INFO - Epoch:[455/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 00:39:45,702 - INFO - Epoch:[455/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 00:39:51,912 - INFO - Epoch:[455/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.07 loss_cvh: 0.57
2025-03-03 00:39:54,666 - INFO - now the learning rate is: 1e-05
2025-03-03 00:40:42,857 - INFO - begin training stage: [456/805]
2025-03-03 00:40:42,857 - INFO - begin training stage: [456/805]
2025-03-03 00:40:50,531 - INFO - Epoch:[456/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 00:40:56,812 - INFO - Epoch:[456/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 00:41:02,739 - INFO - Epoch:[456/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 00:41:07,520 - INFO - Epoch:[456/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 00:41:12,159 - INFO - Epoch:[456/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 00:41:16,145 - INFO - Epoch:[456/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 00:41:20,663 - INFO - Epoch:[456/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 00:41:25,481 - INFO - Epoch:[456/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.06
2025-03-03 00:41:30,325 - INFO - Epoch:[456/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.17 loss_cvh: 0.78
2025-03-03 00:41:32,050 - INFO - now the learning rate is: 1e-05
2025-03-03 00:42:29,873 - INFO - begin training stage: [457/805]
2025-03-03 00:42:29,873 - INFO - begin training stage: [457/805]
2025-03-03 00:42:35,584 - INFO - Epoch:[457/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 00:42:39,704 - INFO - Epoch:[457/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.02
2025-03-03 00:42:44,008 - INFO - Epoch:[457/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 00:42:50,974 - INFO - Epoch:[457/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 00:42:57,682 - INFO - Epoch:[457/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 00:43:02,978 - INFO - Epoch:[457/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 00:43:08,140 - INFO - Epoch:[457/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.06
2025-03-03 00:43:12,851 - INFO - Epoch:[457/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 00:43:16,713 - INFO - Epoch:[457/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.23 loss_cvh: 0.77
2025-03-03 00:43:17,977 - INFO - now the learning rate is: 1e-05
2025-03-03 00:44:16,763 - INFO - begin training stage: [458/805]
2025-03-03 00:44:16,763 - INFO - begin training stage: [458/805]
2025-03-03 00:44:21,936 - INFO - Epoch:[458/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.07
2025-03-03 00:44:26,695 - INFO - Epoch:[458/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 00:44:32,254 - INFO - Epoch:[458/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 00:44:36,819 - INFO - Epoch:[458/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 00:44:41,143 - INFO - Epoch:[458/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 00:44:45,210 - INFO - Epoch:[458/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 00:44:49,263 - INFO - Epoch:[458/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:44:53,694 - INFO - Epoch:[458/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:44:59,208 - INFO - Epoch:[458/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.20 loss_cvh: 0.70
2025-03-03 00:45:01,515 - INFO - now the learning rate is: 1e-05
2025-03-03 00:45:56,998 - INFO - begin training stage: [459/805]
2025-03-03 00:45:56,999 - INFO - begin training stage: [459/805]
2025-03-03 00:46:04,320 - INFO - Epoch:[459/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 00:46:11,368 - INFO - Epoch:[459/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 00:46:16,506 - INFO - Epoch:[459/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:46:22,082 - INFO - Epoch:[459/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 00:46:26,781 - INFO - Epoch:[459/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 00:46:31,543 - INFO - Epoch:[459/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 00:46:36,892 - INFO - Epoch:[459/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 00:46:42,096 - INFO - Epoch:[459/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 00:46:46,359 - INFO - Epoch:[459/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.27 loss_cvh: 0.97
2025-03-03 00:46:47,857 - INFO - now the learning rate is: 1e-05
2025-03-03 00:47:38,153 - INFO - begin training stage: [460/805]
2025-03-03 00:47:38,153 - INFO - begin training stage: [460/805]
2025-03-03 00:47:43,889 - INFO - Epoch:[460/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 00:47:47,828 - INFO - Epoch:[460/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 00:47:52,174 - INFO - Epoch:[460/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 00:47:57,575 - INFO - Epoch:[460/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.04
2025-03-03 00:48:02,782 - INFO - Epoch:[460/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 00:48:08,096 - INFO - Epoch:[460/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 00:48:13,217 - INFO - Epoch:[460/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 00:48:18,177 - INFO - Epoch:[460/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 00:48:22,699 - INFO - Epoch:[460/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.29 loss_cvh: 0.81
2025-03-03 00:48:24,267 - INFO - now the learning rate is: 1e-05
2025-03-03 00:49:59,544 - INFO - begin training stage: [461/805]
2025-03-03 00:49:59,546 - INFO - eval data number: 45600
2025-03-03 00:49:59,546 - INFO - loading eval data ......
2025-03-03 00:50:45,621 - INFO - retrieval costs: 30.045299530029297
2025-03-03 00:54:03,401 - INFO - hamming distance computation costs: 197.78015732765198
2025-03-03 00:54:16,862 - INFO - hamming ranking costs: 13.46038556098938
2025-03-03 00:54:16,862 - INFO - labels shape: (45600, 239)
2025-03-03 00:55:18,877 - INFO - similarity labels generation costs: 62.015533447265625
2025-03-03 00:55:19,002 - INFO - topK: 5:, map: 0.3383466666666667
2025-03-03 00:55:19,817 - INFO - topK: 20:, map: 0.2420534395274488
2025-03-03 00:55:21,328 - INFO - topK: 40:, map: 0.20945835858519804
2025-03-03 00:55:23,656 - INFO - topK: 60:, map: 0.18939572494301696
2025-03-03 00:55:26,320 - INFO - topK: 80:, map: 0.1747903972623526
2025-03-03 00:55:29,886 - INFO - topK: 100:, map: 0.16285112489316914
2025-03-03 00:55:32,669 - INFO - begin training stage: [461/805]
2025-03-03 00:55:40,252 - INFO - Epoch:[461/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 00:55:46,168 - INFO - Epoch:[461/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.06
2025-03-03 00:55:52,210 - INFO - Epoch:[461/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:55:57,988 - INFO - Epoch:[461/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 00:56:05,103 - INFO - Epoch:[461/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 00:56:11,258 - INFO - Epoch:[461/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 00:56:17,459 - INFO - Epoch:[461/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-03 00:56:23,543 - INFO - Epoch:[461/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 00:56:29,502 - INFO - Epoch:[461/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.22 loss_cvh: 0.78
2025-03-03 00:56:31,288 - INFO - now the learning rate is: 1e-05
2025-03-03 00:57:32,933 - INFO - begin training stage: [462/805]
2025-03-03 00:57:32,933 - INFO - begin training stage: [462/805]
2025-03-03 00:57:39,609 - INFO - Epoch:[462/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.06
2025-03-03 00:57:44,631 - INFO - Epoch:[462/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 00:57:49,964 - INFO - Epoch:[462/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 00:57:54,656 - INFO - Epoch:[462/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:57:58,994 - INFO - Epoch:[462/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 00:58:03,480 - INFO - Epoch:[462/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 00:58:08,057 - INFO - Epoch:[462/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:58:12,615 - INFO - Epoch:[462/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 00:58:16,792 - INFO - Epoch:[462/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.12 loss_cvh: 0.78
2025-03-03 00:58:18,160 - INFO - now the learning rate is: 1e-05
2025-03-03 00:59:02,062 - INFO - begin training stage: [463/805]
2025-03-03 00:59:02,063 - INFO - begin training stage: [463/805]
2025-03-03 00:59:08,132 - INFO - Epoch:[463/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 00:59:12,451 - INFO - Epoch:[463/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 00:59:16,507 - INFO - Epoch:[463/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 00:59:21,150 - INFO - Epoch:[463/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 00:59:26,078 - INFO - Epoch:[463/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 00:59:30,796 - INFO - Epoch:[463/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 00:59:35,287 - INFO - Epoch:[463/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 00:59:39,440 - INFO - Epoch:[463/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 00:59:43,260 - INFO - Epoch:[463/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.21 loss_cvh: 0.76
2025-03-03 00:59:44,693 - INFO - now the learning rate is: 1e-05
2025-03-03 01:00:34,318 - INFO - begin training stage: [464/805]
2025-03-03 01:00:34,318 - INFO - begin training stage: [464/805]
2025-03-03 01:00:40,028 - INFO - Epoch:[464/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 01:00:44,153 - INFO - Epoch:[464/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 01:00:48,664 - INFO - Epoch:[464/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 01:00:53,200 - INFO - Epoch:[464/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 01:00:57,840 - INFO - Epoch:[464/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 01:01:02,108 - INFO - Epoch:[464/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 01:01:06,313 - INFO - Epoch:[464/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 01:01:10,394 - INFO - Epoch:[464/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 01:01:14,260 - INFO - Epoch:[464/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.19 loss_cvh: 0.68
2025-03-03 01:01:15,953 - INFO - now the learning rate is: 1e-05
2025-03-03 01:02:13,423 - INFO - begin training stage: [465/805]
2025-03-03 01:02:13,423 - INFO - begin training stage: [465/805]
2025-03-03 01:02:19,079 - INFO - Epoch:[465/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 01:02:23,748 - INFO - Epoch:[465/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 01:02:28,401 - INFO - Epoch:[465/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:02:33,110 - INFO - Epoch:[465/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 01:02:37,626 - INFO - Epoch:[465/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 01:02:41,990 - INFO - Epoch:[465/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 01:02:46,737 - INFO - Epoch:[465/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 01:02:50,956 - INFO - Epoch:[465/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 01:02:54,829 - INFO - Epoch:[465/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.16 loss_cvh: 0.84
2025-03-03 01:02:56,542 - INFO - now the learning rate is: 1e-05
2025-03-03 01:03:45,457 - INFO - begin training stage: [466/805]
2025-03-03 01:03:45,457 - INFO - begin training stage: [466/805]
2025-03-03 01:03:51,735 - INFO - Epoch:[466/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 01:03:56,757 - INFO - Epoch:[466/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 01:04:01,545 - INFO - Epoch:[466/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 01:04:06,600 - INFO - Epoch:[466/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 01:04:12,020 - INFO - Epoch:[466/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 01:04:17,476 - INFO - Epoch:[466/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 01:04:21,846 - INFO - Epoch:[466/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 01:04:26,578 - INFO - Epoch:[466/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 01:04:31,061 - INFO - Epoch:[466/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.26 loss_cvh: 0.78
2025-03-03 01:04:32,758 - INFO - now the learning rate is: 1e-05
2025-03-03 01:05:32,511 - INFO - begin training stage: [467/805]
2025-03-03 01:05:32,512 - INFO - begin training stage: [467/805]
2025-03-03 01:05:39,401 - INFO - Epoch:[467/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 01:05:44,502 - INFO - Epoch:[467/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 01:05:49,384 - INFO - Epoch:[467/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 01:05:54,616 - INFO - Epoch:[467/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 01:05:59,774 - INFO - Epoch:[467/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:06:04,253 - INFO - Epoch:[467/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 01:06:08,481 - INFO - Epoch:[467/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 01:06:13,344 - INFO - Epoch:[467/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 01:06:17,757 - INFO - Epoch:[467/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.19 loss_cvh: 0.79
2025-03-03 01:06:19,181 - INFO - now the learning rate is: 1e-05
2025-03-03 01:07:11,966 - INFO - begin training stage: [468/805]
2025-03-03 01:07:11,966 - INFO - begin training stage: [468/805]
2025-03-03 01:07:18,488 - INFO - Epoch:[468/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 01:07:23,475 - INFO - Epoch:[468/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 01:07:28,999 - INFO - Epoch:[468/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 01:07:35,083 - INFO - Epoch:[468/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.10
2025-03-03 01:07:39,562 - INFO - Epoch:[468/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 01:07:44,423 - INFO - Epoch:[468/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 01:07:49,763 - INFO - Epoch:[468/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 01:07:55,226 - INFO - Epoch:[468/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 01:08:00,205 - INFO - Epoch:[468/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.20 loss_cvh: 0.80
2025-03-03 01:08:02,396 - INFO - now the learning rate is: 1e-05
2025-03-03 01:08:55,178 - INFO - begin training stage: [469/805]
2025-03-03 01:08:55,178 - INFO - begin training stage: [469/805]
2025-03-03 01:09:01,676 - INFO - Epoch:[469/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 01:09:06,324 - INFO - Epoch:[469/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 01:09:11,011 - INFO - Epoch:[469/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.13
2025-03-03 01:09:15,608 - INFO - Epoch:[469/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 01:09:20,324 - INFO - Epoch:[469/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 01:09:25,347 - INFO - Epoch:[469/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 01:09:30,304 - INFO - Epoch:[469/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.13
2025-03-03 01:09:35,257 - INFO - Epoch:[469/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 01:09:39,714 - INFO - Epoch:[469/805] Step:[90/90] reconstruction_loss: 1.04 loss_vc: 1.30 loss_cvh: 0.81
2025-03-03 01:09:42,171 - INFO - now the learning rate is: 1e-05
2025-03-03 01:10:38,981 - INFO - begin training stage: [470/805]
2025-03-03 01:10:38,981 - INFO - begin training stage: [470/805]
2025-03-03 01:10:46,546 - INFO - Epoch:[470/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 01:10:51,980 - INFO - Epoch:[470/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.12
2025-03-03 01:10:57,429 - INFO - Epoch:[470/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 01:11:02,253 - INFO - Epoch:[470/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 01:11:06,541 - INFO - Epoch:[470/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 01:11:11,378 - INFO - Epoch:[470/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 01:11:16,350 - INFO - Epoch:[470/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.09
2025-03-03 01:11:21,588 - INFO - Epoch:[470/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 01:11:26,102 - INFO - Epoch:[470/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.14 loss_cvh: 0.72
2025-03-03 01:11:27,799 - INFO - now the learning rate is: 1e-05
2025-03-03 01:12:51,495 - INFO - begin training stage: [471/805]
2025-03-03 01:12:51,496 - INFO - eval data number: 45600
2025-03-03 01:12:51,497 - INFO - loading eval data ......
2025-03-03 01:13:42,656 - INFO - retrieval costs: 32.5236496925354
2025-03-03 01:17:12,131 - INFO - hamming distance computation costs: 209.4739921092987
2025-03-03 01:17:21,332 - INFO - hamming ranking costs: 9.20142149925232
2025-03-03 01:17:21,332 - INFO - labels shape: (45600, 239)
2025-03-03 01:18:23,883 - INFO - similarity labels generation costs: 62.55098295211792
2025-03-03 01:18:24,020 - INFO - topK: 5:, map: 0.3363
2025-03-03 01:18:24,495 - INFO - topK: 20:, map: 0.24195508815235545
2025-03-03 01:18:25,426 - INFO - topK: 40:, map: 0.20931796833946148
2025-03-03 01:18:26,813 - INFO - topK: 60:, map: 0.18962753239056784
2025-03-03 01:18:28,660 - INFO - topK: 80:, map: 0.17516818065078715
2025-03-03 01:18:30,919 - INFO - topK: 100:, map: 0.16329672182442256
2025-03-03 01:18:33,045 - INFO - begin training stage: [471/805]
2025-03-03 01:18:41,231 - INFO - Epoch:[471/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 01:18:46,783 - INFO - Epoch:[471/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 01:18:51,896 - INFO - Epoch:[471/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 01:18:57,162 - INFO - Epoch:[471/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 01:19:02,509 - INFO - Epoch:[471/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 01:19:08,605 - INFO - Epoch:[471/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 01:19:16,742 - INFO - Epoch:[471/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 01:19:23,966 - INFO - Epoch:[471/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 01:19:30,601 - INFO - Epoch:[471/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.13 loss_cvh: 0.71
2025-03-03 01:19:33,019 - INFO - now the learning rate is: 1e-05
2025-03-03 01:20:36,603 - INFO - begin training stage: [472/805]
2025-03-03 01:20:36,603 - INFO - begin training stage: [472/805]
2025-03-03 01:20:43,683 - INFO - Epoch:[472/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 01:20:48,704 - INFO - Epoch:[472/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.05
2025-03-03 01:20:54,404 - INFO - Epoch:[472/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 01:20:59,880 - INFO - Epoch:[472/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 01:21:05,064 - INFO - Epoch:[472/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:21:09,652 - INFO - Epoch:[472/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 01:21:14,674 - INFO - Epoch:[472/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 01:21:20,394 - INFO - Epoch:[472/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 01:21:24,900 - INFO - Epoch:[472/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.38 loss_cvh: 0.93
2025-03-03 01:21:27,256 - INFO - now the learning rate is: 1e-05
2025-03-03 01:22:30,074 - INFO - begin training stage: [473/805]
2025-03-03 01:22:30,075 - INFO - begin training stage: [473/805]
2025-03-03 01:22:37,517 - INFO - Epoch:[473/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 01:22:42,436 - INFO - Epoch:[473/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 01:22:47,127 - INFO - Epoch:[473/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 01:22:51,895 - INFO - Epoch:[473/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 01:22:57,301 - INFO - Epoch:[473/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 01:23:04,664 - INFO - Epoch:[473/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.14
2025-03-03 01:23:12,839 - INFO - Epoch:[473/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.10
2025-03-03 01:23:19,148 - INFO - Epoch:[473/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 01:23:24,030 - INFO - Epoch:[473/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.31 loss_cvh: 0.88
2025-03-03 01:23:26,117 - INFO - now the learning rate is: 1e-05
2025-03-03 01:24:21,641 - INFO - begin training stage: [474/805]
2025-03-03 01:24:21,641 - INFO - begin training stage: [474/805]
2025-03-03 01:24:28,077 - INFO - Epoch:[474/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 01:24:32,980 - INFO - Epoch:[474/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.33 loss_cvh: 2.98
2025-03-03 01:24:37,612 - INFO - Epoch:[474/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 01:24:42,904 - INFO - Epoch:[474/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 01:24:48,653 - INFO - Epoch:[474/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 01:24:53,592 - INFO - Epoch:[474/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 01:24:58,452 - INFO - Epoch:[474/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 01:25:03,333 - INFO - Epoch:[474/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-03 01:25:07,583 - INFO - Epoch:[474/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.16 loss_cvh: 1.06
2025-03-03 01:25:10,837 - INFO - now the learning rate is: 1e-05
2025-03-03 01:25:58,983 - INFO - begin training stage: [475/805]
2025-03-03 01:25:58,984 - INFO - begin training stage: [475/805]
2025-03-03 01:26:06,024 - INFO - Epoch:[475/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 01:26:11,732 - INFO - Epoch:[475/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 01:26:16,823 - INFO - Epoch:[475/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 01:26:24,522 - INFO - Epoch:[475/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 01:26:30,971 - INFO - Epoch:[475/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 01:26:36,382 - INFO - Epoch:[475/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 01:26:42,814 - INFO - Epoch:[475/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 01:26:49,744 - INFO - Epoch:[475/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 01:26:54,414 - INFO - Epoch:[475/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.20 loss_cvh: 0.77
2025-03-03 01:26:56,402 - INFO - now the learning rate is: 1e-05
2025-03-03 01:28:00,189 - INFO - begin training stage: [476/805]
2025-03-03 01:28:00,190 - INFO - begin training stage: [476/805]
2025-03-03 01:28:07,743 - INFO - Epoch:[476/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 01:28:13,161 - INFO - Epoch:[476/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 01:28:18,099 - INFO - Epoch:[476/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:28:23,849 - INFO - Epoch:[476/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:28:29,397 - INFO - Epoch:[476/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:28:34,955 - INFO - Epoch:[476/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 01:28:40,315 - INFO - Epoch:[476/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 01:28:45,648 - INFO - Epoch:[476/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.02
2025-03-03 01:28:50,952 - INFO - Epoch:[476/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.33 loss_cvh: 0.84
2025-03-03 01:28:52,792 - INFO - now the learning rate is: 1e-05
2025-03-03 01:29:53,365 - INFO - begin training stage: [477/805]
2025-03-03 01:29:53,366 - INFO - begin training stage: [477/805]
2025-03-03 01:30:00,532 - INFO - Epoch:[477/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 01:30:05,787 - INFO - Epoch:[477/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 01:30:10,717 - INFO - Epoch:[477/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.04
2025-03-03 01:30:15,862 - INFO - Epoch:[477/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 01:30:20,572 - INFO - Epoch:[477/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 01:30:25,361 - INFO - Epoch:[477/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 01:30:32,360 - INFO - Epoch:[477/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 01:30:42,271 - INFO - Epoch:[477/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 01:30:48,503 - INFO - Epoch:[477/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.30 loss_cvh: 0.71
2025-03-03 01:30:50,021 - INFO - now the learning rate is: 1e-05
2025-03-03 01:31:48,242 - INFO - begin training stage: [478/805]
2025-03-03 01:31:48,243 - INFO - begin training stage: [478/805]
2025-03-03 01:31:56,652 - INFO - Epoch:[478/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 01:32:01,837 - INFO - Epoch:[478/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 01:32:07,070 - INFO - Epoch:[478/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 01:32:12,081 - INFO - Epoch:[478/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 01:32:17,233 - INFO - Epoch:[478/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 01:32:22,046 - INFO - Epoch:[478/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 01:32:27,120 - INFO - Epoch:[478/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 01:32:32,014 - INFO - Epoch:[478/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.33 loss_cvh: 3.06
2025-03-03 01:32:39,647 - INFO - Epoch:[478/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.10 loss_cvh: 0.63
2025-03-03 01:32:42,454 - INFO - now the learning rate is: 1e-05
2025-03-03 01:33:38,865 - INFO - begin training stage: [479/805]
2025-03-03 01:33:38,865 - INFO - begin training stage: [479/805]
2025-03-03 01:33:46,874 - INFO - Epoch:[479/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 01:33:52,094 - INFO - Epoch:[479/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.11
2025-03-03 01:33:57,350 - INFO - Epoch:[479/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 01:34:02,552 - INFO - Epoch:[479/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 01:34:07,348 - INFO - Epoch:[479/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.03
2025-03-03 01:34:12,287 - INFO - Epoch:[479/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 01:34:17,299 - INFO - Epoch:[479/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 01:34:22,580 - INFO - Epoch:[479/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 01:34:27,260 - INFO - Epoch:[479/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.25 loss_cvh: 0.82
2025-03-03 01:34:29,179 - INFO - now the learning rate is: 1e-05
2025-03-03 01:35:42,511 - INFO - begin training stage: [480/805]
2025-03-03 01:35:42,511 - INFO - begin training stage: [480/805]
2025-03-03 01:35:50,274 - INFO - Epoch:[480/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 01:35:55,215 - INFO - Epoch:[480/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:36:00,121 - INFO - Epoch:[480/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 01:36:04,921 - INFO - Epoch:[480/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 01:36:09,796 - INFO - Epoch:[480/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 01:36:14,642 - INFO - Epoch:[480/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.08
2025-03-03 01:36:19,687 - INFO - Epoch:[480/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 01:36:24,653 - INFO - Epoch:[480/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.15
2025-03-03 01:36:29,220 - INFO - Epoch:[480/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.30 loss_cvh: 0.70
2025-03-03 01:36:31,079 - INFO - now the learning rate is: 1e-05
2025-03-03 01:37:29,760 - INFO - begin training stage: [481/805]
2025-03-03 01:37:29,761 - INFO - eval data number: 45600
2025-03-03 01:37:29,761 - INFO - loading eval data ......
2025-03-03 01:38:08,015 - INFO - retrieval costs: 24.63088870048523
2025-03-03 01:41:33,341 - INFO - hamming distance computation costs: 205.32532238960266
2025-03-03 01:41:42,008 - INFO - hamming ranking costs: 8.667658567428589
2025-03-03 01:41:42,009 - INFO - labels shape: (45600, 239)
2025-03-03 01:42:45,605 - INFO - similarity labels generation costs: 63.596956968307495
2025-03-03 01:42:45,735 - INFO - topK: 5:, map: 0.33712583333333335
2025-03-03 01:42:46,199 - INFO - topK: 20:, map: 0.24074778721203546
2025-03-03 01:42:47,106 - INFO - topK: 40:, map: 0.20900947084960747
2025-03-03 01:42:48,298 - INFO - topK: 60:, map: 0.19009831216146728
2025-03-03 01:42:49,365 - INFO - topK: 80:, map: 0.17550828684155828
2025-03-03 01:42:50,650 - INFO - topK: 100:, map: 0.16353241574717967
2025-03-03 01:42:51,704 - INFO - begin training stage: [481/805]
2025-03-03 01:42:58,362 - INFO - Epoch:[481/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 01:43:03,651 - INFO - Epoch:[481/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 01:43:08,552 - INFO - Epoch:[481/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 01:43:13,495 - INFO - Epoch:[481/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 01:43:18,305 - INFO - Epoch:[481/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 01:43:23,158 - INFO - Epoch:[481/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 01:43:28,153 - INFO - Epoch:[481/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 01:43:33,001 - INFO - Epoch:[481/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 01:43:37,507 - INFO - Epoch:[481/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.34 loss_cvh: 0.72
2025-03-03 01:43:39,420 - INFO - now the learning rate is: 1e-05
2025-03-03 01:44:39,211 - INFO - begin training stage: [482/805]
2025-03-03 01:44:39,211 - INFO - begin training stage: [482/805]
2025-03-03 01:44:46,527 - INFO - Epoch:[482/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 01:44:51,854 - INFO - Epoch:[482/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 01:44:56,617 - INFO - Epoch:[482/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.04
2025-03-03 01:45:01,707 - INFO - Epoch:[482/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 01:45:05,880 - INFO - Epoch:[482/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 01:45:10,825 - INFO - Epoch:[482/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 01:45:15,752 - INFO - Epoch:[482/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 01:45:20,119 - INFO - Epoch:[482/805] Step:[80/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 01:45:24,629 - INFO - Epoch:[482/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.18 loss_cvh: 0.70
2025-03-03 01:45:25,963 - INFO - now the learning rate is: 1e-05
2025-03-03 01:46:14,563 - INFO - begin training stage: [483/805]
2025-03-03 01:46:14,564 - INFO - begin training stage: [483/805]
2025-03-03 01:46:20,230 - INFO - Epoch:[483/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 01:46:25,540 - INFO - Epoch:[483/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 01:46:31,023 - INFO - Epoch:[483/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 01:46:35,822 - INFO - Epoch:[483/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 01:46:41,358 - INFO - Epoch:[483/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 01:46:45,840 - INFO - Epoch:[483/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 01:46:50,356 - INFO - Epoch:[483/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 01:46:55,370 - INFO - Epoch:[483/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-03 01:46:59,602 - INFO - Epoch:[483/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.26 loss_cvh: 0.74
2025-03-03 01:47:01,381 - INFO - now the learning rate is: 1e-05
2025-03-03 01:47:54,127 - INFO - begin training stage: [484/805]
2025-03-03 01:47:54,127 - INFO - begin training stage: [484/805]
2025-03-03 01:48:00,572 - INFO - Epoch:[484/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 01:48:05,117 - INFO - Epoch:[484/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 01:48:09,732 - INFO - Epoch:[484/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 01:48:14,079 - INFO - Epoch:[484/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 01:48:18,555 - INFO - Epoch:[484/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 01:48:23,465 - INFO - Epoch:[484/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 01:48:28,548 - INFO - Epoch:[484/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.13
2025-03-03 01:48:33,558 - INFO - Epoch:[484/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 01:48:38,303 - INFO - Epoch:[484/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.26 loss_cvh: 0.84
2025-03-03 01:48:39,817 - INFO - now the learning rate is: 1e-05
2025-03-03 01:49:31,120 - INFO - begin training stage: [485/805]
2025-03-03 01:49:31,120 - INFO - begin training stage: [485/805]
2025-03-03 01:49:37,764 - INFO - Epoch:[485/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 01:49:42,456 - INFO - Epoch:[485/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 01:49:46,888 - INFO - Epoch:[485/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 01:49:51,929 - INFO - Epoch:[485/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:49:56,650 - INFO - Epoch:[485/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 01:50:01,440 - INFO - Epoch:[485/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 01:50:06,322 - INFO - Epoch:[485/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 01:50:11,010 - INFO - Epoch:[485/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 01:50:15,562 - INFO - Epoch:[485/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.43 loss_cvh: 0.94
2025-03-03 01:50:16,908 - INFO - now the learning rate is: 1e-05
2025-03-03 01:51:14,950 - INFO - begin training stage: [486/805]
2025-03-03 01:51:14,951 - INFO - begin training stage: [486/805]
2025-03-03 01:51:21,658 - INFO - Epoch:[486/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 01:51:26,876 - INFO - Epoch:[486/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 01:51:31,946 - INFO - Epoch:[486/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 01:51:37,229 - INFO - Epoch:[486/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 01:51:42,903 - INFO - Epoch:[486/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 01:51:47,990 - INFO - Epoch:[486/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.05
2025-03-03 01:51:52,947 - INFO - Epoch:[486/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 01:51:58,082 - INFO - Epoch:[486/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 01:52:02,636 - INFO - Epoch:[486/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.26 loss_cvh: 0.90
2025-03-03 01:52:04,799 - INFO - now the learning rate is: 1e-05
2025-03-03 01:52:55,025 - INFO - begin training stage: [487/805]
2025-03-03 01:52:55,025 - INFO - begin training stage: [487/805]
2025-03-03 01:53:01,589 - INFO - Epoch:[487/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 01:53:06,415 - INFO - Epoch:[487/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:53:10,941 - INFO - Epoch:[487/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 01:53:15,382 - INFO - Epoch:[487/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:53:19,884 - INFO - Epoch:[487/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 01:53:24,871 - INFO - Epoch:[487/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.12
2025-03-03 01:53:30,181 - INFO - Epoch:[487/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 01:53:35,261 - INFO - Epoch:[487/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:53:39,553 - INFO - Epoch:[487/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.37 loss_cvh: 0.99
2025-03-03 01:53:41,110 - INFO - now the learning rate is: 1e-05
2025-03-03 01:55:01,597 - INFO - begin training stage: [488/805]
2025-03-03 01:55:01,598 - INFO - begin training stage: [488/805]
2025-03-03 01:55:08,591 - INFO - Epoch:[488/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 01:55:13,409 - INFO - Epoch:[488/805] Step:[20/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 01:55:18,168 - INFO - Epoch:[488/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 01:55:23,623 - INFO - Epoch:[488/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:55:28,429 - INFO - Epoch:[488/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 01:55:33,183 - INFO - Epoch:[488/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 01:55:37,981 - INFO - Epoch:[488/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 01:55:42,751 - INFO - Epoch:[488/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 01:55:47,225 - INFO - Epoch:[488/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.35 loss_cvh: 0.75
2025-03-03 01:55:48,961 - INFO - now the learning rate is: 1e-05
2025-03-03 01:56:56,388 - INFO - begin training stage: [489/805]
2025-03-03 01:56:56,388 - INFO - begin training stage: [489/805]
2025-03-03 01:57:03,421 - INFO - Epoch:[489/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.12
2025-03-03 01:57:07,859 - INFO - Epoch:[489/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 01:57:12,520 - INFO - Epoch:[489/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 01:57:17,098 - INFO - Epoch:[489/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 01:57:22,364 - INFO - Epoch:[489/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.10
2025-03-03 01:57:28,263 - INFO - Epoch:[489/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 01:57:34,306 - INFO - Epoch:[489/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 01:57:39,808 - INFO - Epoch:[489/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 01:57:44,228 - INFO - Epoch:[489/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.17 loss_cvh: 0.64
2025-03-03 01:57:45,951 - INFO - now the learning rate is: 1e-05
2025-03-03 01:58:35,634 - INFO - begin training stage: [490/805]
2025-03-03 01:58:35,634 - INFO - begin training stage: [490/805]
2025-03-03 01:58:42,208 - INFO - Epoch:[490/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 01:58:46,881 - INFO - Epoch:[490/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 01:58:52,067 - INFO - Epoch:[490/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.01
2025-03-03 01:58:57,402 - INFO - Epoch:[490/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 01:59:02,061 - INFO - Epoch:[490/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 01:59:06,444 - INFO - Epoch:[490/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.11
2025-03-03 01:59:10,821 - INFO - Epoch:[490/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 01:59:15,192 - INFO - Epoch:[490/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 01:59:19,353 - INFO - Epoch:[490/805] Step:[90/90] reconstruction_loss: 0.99 loss_vc: 1.38 loss_cvh: 0.91
2025-03-03 01:59:20,784 - INFO - now the learning rate is: 1e-05
2025-03-03 02:00:32,797 - INFO - begin training stage: [491/805]
2025-03-03 02:00:32,798 - INFO - eval data number: 45600
2025-03-03 02:00:32,798 - INFO - loading eval data ......
2025-03-03 02:01:15,679 - INFO - retrieval costs: 29.01075577735901
2025-03-03 02:03:42,326 - INFO - hamming distance computation costs: 146.6469259262085
2025-03-03 02:03:49,564 - INFO - hamming ranking costs: 7.238036394119263
2025-03-03 02:03:49,565 - INFO - labels shape: (45600, 239)
2025-03-03 02:04:32,151 - INFO - similarity labels generation costs: 42.587034940719604
2025-03-03 02:04:32,277 - INFO - topK: 5:, map: 0.333695
2025-03-03 02:04:32,766 - INFO - topK: 20:, map: 0.24157319186902917
2025-03-03 02:04:33,628 - INFO - topK: 40:, map: 0.2088315189885386
2025-03-03 02:04:34,934 - INFO - topK: 60:, map: 0.18952827260221142
2025-03-03 02:04:36,864 - INFO - topK: 80:, map: 0.17522772651019686
2025-03-03 02:04:39,083 - INFO - topK: 100:, map: 0.1632116880653553
2025-03-03 02:04:40,662 - INFO - begin training stage: [491/805]
2025-03-03 02:04:48,600 - INFO - Epoch:[491/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 02:04:56,398 - INFO - Epoch:[491/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 02:05:01,620 - INFO - Epoch:[491/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 02:05:06,905 - INFO - Epoch:[491/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 02:05:11,956 - INFO - Epoch:[491/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 02:05:17,455 - INFO - Epoch:[491/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 02:05:22,656 - INFO - Epoch:[491/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.11
2025-03-03 02:05:27,826 - INFO - Epoch:[491/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 02:05:32,181 - INFO - Epoch:[491/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.25 loss_cvh: 1.01
2025-03-03 02:05:33,535 - INFO - now the learning rate is: 1e-05
2025-03-03 02:06:22,599 - INFO - begin training stage: [492/805]
2025-03-03 02:06:22,599 - INFO - begin training stage: [492/805]
2025-03-03 02:06:28,632 - INFO - Epoch:[492/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 02:06:33,248 - INFO - Epoch:[492/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 02:06:38,251 - INFO - Epoch:[492/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 02:06:43,239 - INFO - Epoch:[492/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 02:06:47,857 - INFO - Epoch:[492/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 02:06:52,879 - INFO - Epoch:[492/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 02:06:57,694 - INFO - Epoch:[492/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:07:02,668 - INFO - Epoch:[492/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 02:07:07,219 - INFO - Epoch:[492/805] Step:[90/90] reconstruction_loss: 1.36 loss_vc: 1.23 loss_cvh: 0.86
2025-03-03 02:07:08,428 - INFO - now the learning rate is: 1e-05
2025-03-03 02:07:52,285 - INFO - begin training stage: [493/805]
2025-03-03 02:07:52,285 - INFO - begin training stage: [493/805]
2025-03-03 02:08:00,626 - INFO - Epoch:[493/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:08:06,424 - INFO - Epoch:[493/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 02:08:10,111 - INFO - Epoch:[493/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:08:13,812 - INFO - Epoch:[493/805] Step:[40/90] reconstruction_loss: 1.11 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 02:08:18,053 - INFO - Epoch:[493/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 02:08:22,380 - INFO - Epoch:[493/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 02:08:25,816 - INFO - Epoch:[493/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 02:08:29,455 - INFO - Epoch:[493/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 02:08:32,639 - INFO - Epoch:[493/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.08 loss_cvh: 0.69
2025-03-03 02:08:33,780 - INFO - now the learning rate is: 1e-05
2025-03-03 02:09:11,165 - INFO - begin training stage: [494/805]
2025-03-03 02:09:11,166 - INFO - begin training stage: [494/805]
2025-03-03 02:09:15,910 - INFO - Epoch:[494/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:09:19,674 - INFO - Epoch:[494/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 02:09:23,104 - INFO - Epoch:[494/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 02:09:26,778 - INFO - Epoch:[494/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 02:09:30,374 - INFO - Epoch:[494/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 02:09:33,964 - INFO - Epoch:[494/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:09:37,453 - INFO - Epoch:[494/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 02:09:40,993 - INFO - Epoch:[494/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 02:09:44,332 - INFO - Epoch:[494/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.14 loss_cvh: 0.70
2025-03-03 02:09:45,487 - INFO - now the learning rate is: 1e-05
2025-03-03 02:10:22,225 - INFO - begin training stage: [495/805]
2025-03-03 02:10:22,225 - INFO - begin training stage: [495/805]
2025-03-03 02:10:26,932 - INFO - Epoch:[495/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 02:10:30,567 - INFO - Epoch:[495/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:10:34,389 - INFO - Epoch:[495/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 02:10:38,296 - INFO - Epoch:[495/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 02:10:42,881 - INFO - Epoch:[495/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.02
2025-03-03 02:10:47,063 - INFO - Epoch:[495/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 02:10:51,181 - INFO - Epoch:[495/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 02:10:54,965 - INFO - Epoch:[495/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 02:10:58,421 - INFO - Epoch:[495/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.13 loss_cvh: 0.74
2025-03-03 02:10:59,525 - INFO - now the learning rate is: 1e-05
2025-03-03 02:11:42,973 - INFO - begin training stage: [496/805]
2025-03-03 02:11:42,973 - INFO - begin training stage: [496/805]
2025-03-03 02:11:48,241 - INFO - Epoch:[496/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 02:11:52,356 - INFO - Epoch:[496/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 02:11:56,406 - INFO - Epoch:[496/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 02:12:00,108 - INFO - Epoch:[496/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 02:12:03,990 - INFO - Epoch:[496/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 02:12:08,107 - INFO - Epoch:[496/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 02:12:12,164 - INFO - Epoch:[496/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 02:12:16,203 - INFO - Epoch:[496/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 02:12:19,635 - INFO - Epoch:[496/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.31 loss_cvh: 0.89
2025-03-03 02:12:20,774 - INFO - now the learning rate is: 1e-05
2025-03-03 02:12:58,935 - INFO - begin training stage: [497/805]
2025-03-03 02:12:58,936 - INFO - begin training stage: [497/805]
2025-03-03 02:13:03,752 - INFO - Epoch:[497/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 02:13:07,347 - INFO - Epoch:[497/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 02:13:10,495 - INFO - Epoch:[497/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-03 02:13:14,115 - INFO - Epoch:[497/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 02:13:17,745 - INFO - Epoch:[497/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 02:13:21,914 - INFO - Epoch:[497/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 02:13:26,716 - INFO - Epoch:[497/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 02:13:31,120 - INFO - Epoch:[497/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 02:13:35,184 - INFO - Epoch:[497/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.25 loss_cvh: 0.78
2025-03-03 02:13:36,595 - INFO - now the learning rate is: 1e-05
2025-03-03 02:14:49,297 - INFO - begin training stage: [498/805]
2025-03-03 02:14:49,297 - INFO - begin training stage: [498/805]
2025-03-03 02:14:56,326 - INFO - Epoch:[498/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 02:15:01,754 - INFO - Epoch:[498/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:15:07,146 - INFO - Epoch:[498/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.02
2025-03-03 02:15:12,157 - INFO - Epoch:[498/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 02:15:17,035 - INFO - Epoch:[498/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 02:15:21,674 - INFO - Epoch:[498/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 02:15:25,286 - INFO - Epoch:[498/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:15:28,840 - INFO - Epoch:[498/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 02:15:32,606 - INFO - Epoch:[498/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.23 loss_cvh: 0.69
2025-03-03 02:15:33,831 - INFO - now the learning rate is: 1e-05
2025-03-03 02:16:12,161 - INFO - begin training stage: [499/805]
2025-03-03 02:16:12,162 - INFO - begin training stage: [499/805]
2025-03-03 02:16:16,635 - INFO - Epoch:[499/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 02:16:20,832 - INFO - Epoch:[499/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 02:16:24,820 - INFO - Epoch:[499/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 02:16:28,391 - INFO - Epoch:[499/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 02:16:32,464 - INFO - Epoch:[499/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 02:16:36,391 - INFO - Epoch:[499/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 02:16:39,967 - INFO - Epoch:[499/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 02:16:43,634 - INFO - Epoch:[499/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 02:16:47,214 - INFO - Epoch:[499/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.07 loss_cvh: 0.73
2025-03-03 02:16:48,331 - INFO - now the learning rate is: 1e-05
2025-03-03 02:17:30,010 - INFO - begin training stage: [500/805]
2025-03-03 02:17:30,010 - INFO - begin training stage: [500/805]
2025-03-03 02:17:35,062 - INFO - Epoch:[500/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 02:17:39,124 - INFO - Epoch:[500/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 02:17:42,638 - INFO - Epoch:[500/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 02:17:48,392 - INFO - Epoch:[500/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 02:17:54,926 - INFO - Epoch:[500/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 02:17:59,530 - INFO - Epoch:[500/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 02:18:03,611 - INFO - Epoch:[500/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 02:18:07,635 - INFO - Epoch:[500/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:18:11,060 - INFO - Epoch:[500/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.11 loss_cvh: 0.71
2025-03-03 02:18:12,420 - INFO - now the learning rate is: 1e-05
2025-03-03 02:19:24,090 - INFO - begin training stage: [501/805]
2025-03-03 02:19:24,091 - INFO - eval data number: 45600
2025-03-03 02:19:24,091 - INFO - loading eval data ......
2025-03-03 02:20:04,806 - INFO - retrieval costs: 27.03445315361023
2025-03-03 02:22:16,626 - INFO - hamming distance computation costs: 131.82033896446228
2025-03-03 02:22:25,399 - INFO - hamming ranking costs: 8.772778987884521
2025-03-03 02:22:25,399 - INFO - labels shape: (45600, 239)
2025-03-03 02:23:12,861 - INFO - similarity labels generation costs: 47.46168661117554
2025-03-03 02:23:13,040 - INFO - topK: 5:, map: 0.3370883333333334
2025-03-03 02:23:13,463 - INFO - topK: 20:, map: 0.24097284704878455
2025-03-03 02:23:14,350 - INFO - topK: 40:, map: 0.2079348442796201
2025-03-03 02:23:15,606 - INFO - topK: 60:, map: 0.18775713131895072
2025-03-03 02:23:17,323 - INFO - topK: 80:, map: 0.17334410002737136
2025-03-03 02:23:19,422 - INFO - topK: 100:, map: 0.1613282330063758
2025-03-03 02:23:21,612 - INFO - begin training stage: [501/805]
2025-03-03 02:23:27,361 - INFO - Epoch:[501/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 02:23:31,042 - INFO - Epoch:[501/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.15
2025-03-03 02:23:34,737 - INFO - Epoch:[501/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 02:23:38,340 - INFO - Epoch:[501/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 02:23:41,900 - INFO - Epoch:[501/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:23:45,537 - INFO - Epoch:[501/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 02:23:49,121 - INFO - Epoch:[501/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.13
2025-03-03 02:23:52,632 - INFO - Epoch:[501/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:23:56,010 - INFO - Epoch:[501/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.47 loss_cvh: 0.96
2025-03-03 02:23:57,128 - INFO - now the learning rate is: 1e-05
2025-03-03 02:24:41,901 - INFO - begin training stage: [502/805]
2025-03-03 02:24:41,901 - INFO - begin training stage: [502/805]
2025-03-03 02:24:48,235 - INFO - Epoch:[502/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 02:24:52,494 - INFO - Epoch:[502/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 02:24:56,276 - INFO - Epoch:[502/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 02:25:00,356 - INFO - Epoch:[502/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 02:25:04,324 - INFO - Epoch:[502/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 02:25:08,540 - INFO - Epoch:[502/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 02:25:12,552 - INFO - Epoch:[502/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 02:25:16,340 - INFO - Epoch:[502/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 02:25:19,865 - INFO - Epoch:[502/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.15 loss_cvh: 0.67
2025-03-03 02:25:20,943 - INFO - now the learning rate is: 1e-05
2025-03-03 02:26:01,049 - INFO - begin training stage: [503/805]
2025-03-03 02:26:01,050 - INFO - begin training stage: [503/805]
2025-03-03 02:26:06,100 - INFO - Epoch:[503/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 02:26:09,952 - INFO - Epoch:[503/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.14
2025-03-03 02:26:13,576 - INFO - Epoch:[503/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 02:26:17,418 - INFO - Epoch:[503/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 02:26:21,558 - INFO - Epoch:[503/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 02:26:25,689 - INFO - Epoch:[503/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 02:26:29,745 - INFO - Epoch:[503/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 02:26:33,814 - INFO - Epoch:[503/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 02:26:37,404 - INFO - Epoch:[503/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.11 loss_cvh: 0.70
2025-03-03 02:26:38,568 - INFO - now the learning rate is: 1e-05
2025-03-03 02:27:18,273 - INFO - begin training stage: [504/805]
2025-03-03 02:27:18,274 - INFO - begin training stage: [504/805]
2025-03-03 02:27:23,632 - INFO - Epoch:[504/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 02:27:27,612 - INFO - Epoch:[504/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 02:27:32,159 - INFO - Epoch:[504/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:27:39,404 - INFO - Epoch:[504/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 02:27:45,720 - INFO - Epoch:[504/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 02:27:50,232 - INFO - Epoch:[504/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 02:27:54,464 - INFO - Epoch:[504/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 02:27:58,781 - INFO - Epoch:[504/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 02:28:02,344 - INFO - Epoch:[504/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.14 loss_cvh: 0.76
2025-03-03 02:28:03,481 - INFO - now the learning rate is: 1e-05
2025-03-03 02:28:45,744 - INFO - begin training stage: [505/805]
2025-03-03 02:28:45,744 - INFO - begin training stage: [505/805]
2025-03-03 02:28:51,194 - INFO - Epoch:[505/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:28:55,069 - INFO - Epoch:[505/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 02:28:59,222 - INFO - Epoch:[505/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 02:29:03,599 - INFO - Epoch:[505/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:29:07,887 - INFO - Epoch:[505/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 02:29:11,953 - INFO - Epoch:[505/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 02:29:15,819 - INFO - Epoch:[505/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 02:29:19,791 - INFO - Epoch:[505/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 02:29:23,604 - INFO - Epoch:[505/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.17 loss_cvh: 0.75
2025-03-03 02:29:24,727 - INFO - now the learning rate is: 1e-05
2025-03-03 02:30:05,499 - INFO - begin training stage: [506/805]
2025-03-03 02:30:05,499 - INFO - begin training stage: [506/805]
2025-03-03 02:30:10,853 - INFO - Epoch:[506/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:30:15,493 - INFO - Epoch:[506/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 02:30:19,685 - INFO - Epoch:[506/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 02:30:24,513 - INFO - Epoch:[506/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 02:30:28,764 - INFO - Epoch:[506/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-03 02:30:33,158 - INFO - Epoch:[506/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.10
2025-03-03 02:30:37,282 - INFO - Epoch:[506/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 02:30:41,322 - INFO - Epoch:[506/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 02:30:45,663 - INFO - Epoch:[506/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.14 loss_cvh: 0.78
2025-03-03 02:30:48,548 - INFO - now the learning rate is: 1e-05
2025-03-03 02:31:32,023 - INFO - begin training stage: [507/805]
2025-03-03 02:31:32,024 - INFO - begin training stage: [507/805]
2025-03-03 02:31:38,208 - INFO - Epoch:[507/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.03
2025-03-03 02:31:42,271 - INFO - Epoch:[507/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 02:31:46,525 - INFO - Epoch:[507/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 02:31:51,409 - INFO - Epoch:[507/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 02:31:56,356 - INFO - Epoch:[507/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.09
2025-03-03 02:32:01,152 - INFO - Epoch:[507/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.33 loss_cvh: 3.02
2025-03-03 02:32:06,048 - INFO - Epoch:[507/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 02:32:11,036 - INFO - Epoch:[507/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 02:32:15,963 - INFO - Epoch:[507/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.17 loss_cvh: 0.72
2025-03-03 02:32:17,488 - INFO - now the learning rate is: 1e-05
2025-03-03 02:33:28,486 - INFO - begin training stage: [508/805]
2025-03-03 02:33:28,486 - INFO - begin training stage: [508/805]
2025-03-03 02:33:35,355 - INFO - Epoch:[508/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 02:33:40,473 - INFO - Epoch:[508/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.06
2025-03-03 02:33:45,001 - INFO - Epoch:[508/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 02:33:48,662 - INFO - Epoch:[508/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 02:33:52,228 - INFO - Epoch:[508/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 02:33:55,779 - INFO - Epoch:[508/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:33:59,282 - INFO - Epoch:[508/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 02:34:03,578 - INFO - Epoch:[508/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 02:34:08,931 - INFO - Epoch:[508/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.28 loss_cvh: 0.78
2025-03-03 02:34:11,632 - INFO - now the learning rate is: 1e-05
2025-03-03 02:34:54,490 - INFO - begin training stage: [509/805]
2025-03-03 02:34:54,490 - INFO - begin training stage: [509/805]
2025-03-03 02:34:59,464 - INFO - Epoch:[509/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 02:35:03,219 - INFO - Epoch:[509/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 02:35:07,171 - INFO - Epoch:[509/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 02:35:10,990 - INFO - Epoch:[509/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 02:35:15,015 - INFO - Epoch:[509/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 02:35:19,161 - INFO - Epoch:[509/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 02:35:22,846 - INFO - Epoch:[509/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 02:35:26,441 - INFO - Epoch:[509/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 02:35:29,781 - INFO - Epoch:[509/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.36 loss_cvh: 0.85
2025-03-03 02:35:30,793 - INFO - now the learning rate is: 1e-05
2025-03-03 02:36:07,598 - INFO - begin training stage: [510/805]
2025-03-03 02:36:07,598 - INFO - begin training stage: [510/805]
2025-03-03 02:36:11,910 - INFO - Epoch:[510/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 02:36:15,661 - INFO - Epoch:[510/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:36:19,794 - INFO - Epoch:[510/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 02:36:23,663 - INFO - Epoch:[510/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 02:36:27,547 - INFO - Epoch:[510/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 02:36:31,370 - INFO - Epoch:[510/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 02:36:34,770 - INFO - Epoch:[510/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 02:36:39,073 - INFO - Epoch:[510/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 02:36:43,895 - INFO - Epoch:[510/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.26 loss_cvh: 0.77
2025-03-03 02:36:45,422 - INFO - now the learning rate is: 1e-05
2025-03-03 02:38:00,412 - INFO - begin training stage: [511/805]
2025-03-03 02:38:00,414 - INFO - eval data number: 45600
2025-03-03 02:38:00,414 - INFO - loading eval data ......
2025-03-03 02:38:41,825 - INFO - retrieval costs: 27.335349082946777
2025-03-03 02:40:26,772 - INFO - hamming distance computation costs: 104.94636487960815
2025-03-03 02:40:39,374 - INFO - hamming ranking costs: 12.602177143096924
2025-03-03 02:40:39,374 - INFO - labels shape: (45600, 239)
2025-03-03 02:41:20,992 - INFO - similarity labels generation costs: 41.61810851097107
2025-03-03 02:41:21,068 - INFO - topK: 5:, map: 0.34009750000000005
2025-03-03 02:41:21,352 - INFO - topK: 20:, map: 0.2441230664249966
2025-03-03 02:41:21,880 - INFO - topK: 40:, map: 0.21102198851532578
2025-03-03 02:41:22,682 - INFO - topK: 60:, map: 0.19182446716463405
2025-03-03 02:41:23,747 - INFO - topK: 80:, map: 0.17680252047202955
2025-03-03 02:41:25,236 - INFO - topK: 100:, map: 0.16443475693512097
2025-03-03 02:41:26,989 - INFO - begin training stage: [511/805]
2025-03-03 02:41:34,254 - INFO - Epoch:[511/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 02:41:40,855 - INFO - Epoch:[511/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 02:41:47,158 - INFO - Epoch:[511/805] Step:[30/90] reconstruction_loss: 1.10 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 02:41:51,729 - INFO - Epoch:[511/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 02:41:56,176 - INFO - Epoch:[511/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 02:42:00,449 - INFO - Epoch:[511/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 02:42:04,690 - INFO - Epoch:[511/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 02:42:08,294 - INFO - Epoch:[511/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 02:42:12,137 - INFO - Epoch:[511/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.18 loss_cvh: 0.80
2025-03-03 02:42:13,291 - INFO - now the learning rate is: 1e-05
2025-03-03 02:42:54,383 - INFO - begin training stage: [512/805]
2025-03-03 02:42:54,383 - INFO - begin training stage: [512/805]
2025-03-03 02:42:59,486 - INFO - Epoch:[512/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 02:43:03,024 - INFO - Epoch:[512/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 02:43:06,864 - INFO - Epoch:[512/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 02:43:11,474 - INFO - Epoch:[512/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.11
2025-03-03 02:43:15,551 - INFO - Epoch:[512/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 02:43:19,555 - INFO - Epoch:[512/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 02:43:23,792 - INFO - Epoch:[512/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:43:27,730 - INFO - Epoch:[512/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 02:43:31,391 - INFO - Epoch:[512/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.11 loss_cvh: 0.71
2025-03-03 02:43:33,152 - INFO - now the learning rate is: 1e-05
2025-03-03 02:44:18,384 - INFO - begin training stage: [513/805]
2025-03-03 02:44:18,384 - INFO - begin training stage: [513/805]
2025-03-03 02:44:23,542 - INFO - Epoch:[513/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:44:27,664 - INFO - Epoch:[513/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 02:44:31,865 - INFO - Epoch:[513/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 02:44:36,404 - INFO - Epoch:[513/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 02:44:40,628 - INFO - Epoch:[513/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.39 loss_cvh: 3.10
2025-03-03 02:44:45,076 - INFO - Epoch:[513/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 02:44:49,544 - INFO - Epoch:[513/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 02:44:53,566 - INFO - Epoch:[513/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 02:44:57,053 - INFO - Epoch:[513/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.11 loss_cvh: 0.69
2025-03-03 02:44:58,290 - INFO - now the learning rate is: 1e-05
2025-03-03 02:45:38,309 - INFO - begin training stage: [514/805]
2025-03-03 02:45:38,310 - INFO - begin training stage: [514/805]
2025-03-03 02:45:43,499 - INFO - Epoch:[514/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 02:45:47,606 - INFO - Epoch:[514/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 02:45:51,547 - INFO - Epoch:[514/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 02:45:55,805 - INFO - Epoch:[514/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 02:45:59,776 - INFO - Epoch:[514/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 02:46:03,594 - INFO - Epoch:[514/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 02:46:07,560 - INFO - Epoch:[514/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 02:46:11,472 - INFO - Epoch:[514/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:46:15,149 - INFO - Epoch:[514/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.28 loss_cvh: 0.93
2025-03-03 02:46:16,340 - INFO - now the learning rate is: 1e-05
2025-03-03 02:47:06,717 - INFO - begin training stage: [515/805]
2025-03-03 02:47:06,717 - INFO - begin training stage: [515/805]
2025-03-03 02:47:12,105 - INFO - Epoch:[515/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 02:47:16,255 - INFO - Epoch:[515/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 02:47:20,921 - INFO - Epoch:[515/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 02:47:25,036 - INFO - Epoch:[515/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:47:29,144 - INFO - Epoch:[515/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 02:47:33,230 - INFO - Epoch:[515/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 02:47:37,743 - INFO - Epoch:[515/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.17
2025-03-03 02:47:42,232 - INFO - Epoch:[515/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 02:47:46,052 - INFO - Epoch:[515/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.17 loss_cvh: 0.72
2025-03-03 02:47:47,613 - INFO - now the learning rate is: 1e-05
2025-03-03 02:48:30,233 - INFO - begin training stage: [516/805]
2025-03-03 02:48:30,234 - INFO - begin training stage: [516/805]
2025-03-03 02:48:35,712 - INFO - Epoch:[516/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 02:48:39,607 - INFO - Epoch:[516/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 02:48:43,640 - INFO - Epoch:[516/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 02:48:47,658 - INFO - Epoch:[516/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.09
2025-03-03 02:48:51,813 - INFO - Epoch:[516/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.03
2025-03-03 02:48:55,777 - INFO - Epoch:[516/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 02:48:59,901 - INFO - Epoch:[516/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 02:49:04,007 - INFO - Epoch:[516/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:49:07,665 - INFO - Epoch:[516/805] Step:[90/90] reconstruction_loss: 1.30 loss_vc: 1.31 loss_cvh: 0.72
2025-03-03 02:49:08,918 - INFO - now the learning rate is: 1e-05
2025-03-03 02:49:49,699 - INFO - begin training stage: [517/805]
2025-03-03 02:49:49,700 - INFO - begin training stage: [517/805]
2025-03-03 02:49:54,816 - INFO - Epoch:[517/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 02:50:00,010 - INFO - Epoch:[517/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 02:50:05,732 - INFO - Epoch:[517/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 02:50:11,460 - INFO - Epoch:[517/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 02:50:16,849 - INFO - Epoch:[517/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 02:50:21,609 - INFO - Epoch:[517/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 02:50:26,677 - INFO - Epoch:[517/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:50:31,458 - INFO - Epoch:[517/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 02:50:35,779 - INFO - Epoch:[517/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.14 loss_cvh: 0.74
2025-03-03 02:50:37,330 - INFO - now the learning rate is: 1e-05
2025-03-03 02:51:51,857 - INFO - begin training stage: [518/805]
2025-03-03 02:51:51,858 - INFO - begin training stage: [518/805]
2025-03-03 02:51:58,276 - INFO - Epoch:[518/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 02:52:02,948 - INFO - Epoch:[518/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:52:06,833 - INFO - Epoch:[518/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 02:52:10,402 - INFO - Epoch:[518/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 02:52:13,889 - INFO - Epoch:[518/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 02:52:17,546 - INFO - Epoch:[518/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 02:52:21,388 - INFO - Epoch:[518/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 02:52:25,213 - INFO - Epoch:[518/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 02:52:28,834 - INFO - Epoch:[518/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.18 loss_cvh: 0.63
2025-03-03 02:52:29,965 - INFO - now the learning rate is: 1e-05
2025-03-03 02:53:14,808 - INFO - begin training stage: [519/805]
2025-03-03 02:53:14,808 - INFO - begin training stage: [519/805]
2025-03-03 02:53:21,560 - INFO - Epoch:[519/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 02:53:28,002 - INFO - Epoch:[519/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.14
2025-03-03 02:53:32,608 - INFO - Epoch:[519/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 02:53:36,242 - INFO - Epoch:[519/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.10
2025-03-03 02:53:39,932 - INFO - Epoch:[519/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 02:53:43,639 - INFO - Epoch:[519/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 02:53:47,344 - INFO - Epoch:[519/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 02:53:50,998 - INFO - Epoch:[519/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 02:53:54,429 - INFO - Epoch:[519/805] Step:[90/90] reconstruction_loss: 1.04 loss_vc: 1.25 loss_cvh: 0.75
2025-03-03 02:53:55,558 - INFO - now the learning rate is: 1e-05
2025-03-03 02:54:34,842 - INFO - begin training stage: [520/805]
2025-03-03 02:54:34,842 - INFO - begin training stage: [520/805]
2025-03-03 02:54:39,694 - INFO - Epoch:[520/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 02:54:43,307 - INFO - Epoch:[520/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 02:54:46,794 - INFO - Epoch:[520/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.11
2025-03-03 02:54:50,217 - INFO - Epoch:[520/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 02:54:53,593 - INFO - Epoch:[520/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.11
2025-03-03 02:54:57,490 - INFO - Epoch:[520/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 02:55:01,417 - INFO - Epoch:[520/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 02:55:05,209 - INFO - Epoch:[520/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 02:55:08,775 - INFO - Epoch:[520/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.37 loss_cvh: 0.86
2025-03-03 02:55:10,028 - INFO - now the learning rate is: 1e-05
2025-03-03 02:56:18,152 - INFO - begin training stage: [521/805]
2025-03-03 02:56:18,154 - INFO - eval data number: 45600
2025-03-03 02:56:18,154 - INFO - loading eval data ......
2025-03-03 02:57:03,211 - INFO - retrieval costs: 31.08086395263672
2025-03-03 02:59:00,959 - INFO - hamming distance computation costs: 117.74764227867126
2025-03-03 02:59:07,847 - INFO - hamming ranking costs: 6.887414932250977
2025-03-03 02:59:07,847 - INFO - labels shape: (45600, 239)
2025-03-03 02:59:48,095 - INFO - similarity labels generation costs: 40.247962474823
2025-03-03 02:59:48,184 - INFO - topK: 5:, map: 0.3319425
2025-03-03 02:59:48,543 - INFO - topK: 20:, map: 0.24105619742475876
2025-03-03 02:59:49,239 - INFO - topK: 40:, map: 0.20913887031588865
2025-03-03 02:59:50,226 - INFO - topK: 60:, map: 0.1898067245394293
2025-03-03 02:59:51,940 - INFO - topK: 80:, map: 0.17508982391030992
2025-03-03 02:59:54,365 - INFO - topK: 100:, map: 0.16313432919070464
2025-03-03 02:59:57,962 - INFO - begin training stage: [521/805]
2025-03-03 03:00:02,981 - INFO - Epoch:[521/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 03:00:06,611 - INFO - Epoch:[521/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 03:00:10,248 - INFO - Epoch:[521/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 03:00:14,009 - INFO - Epoch:[521/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 03:00:17,721 - INFO - Epoch:[521/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 03:00:21,390 - INFO - Epoch:[521/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:00:25,069 - INFO - Epoch:[521/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 03:00:28,724 - INFO - Epoch:[521/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 03:00:32,157 - INFO - Epoch:[521/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.16 loss_cvh: 0.72
2025-03-03 03:00:33,221 - INFO - now the learning rate is: 1e-05
2025-03-03 03:01:11,601 - INFO - begin training stage: [522/805]
2025-03-03 03:01:11,601 - INFO - begin training stage: [522/805]
2025-03-03 03:01:16,370 - INFO - Epoch:[522/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 03:01:19,933 - INFO - Epoch:[522/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 03:01:23,485 - INFO - Epoch:[522/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 03:01:27,094 - INFO - Epoch:[522/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 03:01:30,783 - INFO - Epoch:[522/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 03:01:34,436 - INFO - Epoch:[522/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 03:01:38,028 - INFO - Epoch:[522/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 03:01:41,574 - INFO - Epoch:[522/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 03:01:44,892 - INFO - Epoch:[522/805] Step:[90/90] reconstruction_loss: 1.29 loss_vc: 1.12 loss_cvh: 0.83
2025-03-03 03:01:45,868 - INFO - now the learning rate is: 1e-05
2025-03-03 03:02:31,821 - INFO - begin training stage: [523/805]
2025-03-03 03:02:31,821 - INFO - begin training stage: [523/805]
2025-03-03 03:02:36,478 - INFO - Epoch:[523/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 03:02:40,051 - INFO - Epoch:[523/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 03:02:43,614 - INFO - Epoch:[523/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 03:02:49,362 - INFO - Epoch:[523/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 03:02:56,785 - INFO - Epoch:[523/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 03:03:01,373 - INFO - Epoch:[523/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.00
2025-03-03 03:03:05,080 - INFO - Epoch:[523/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 03:03:08,908 - INFO - Epoch:[523/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 03:03:12,314 - INFO - Epoch:[523/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.23 loss_cvh: 0.81
2025-03-03 03:03:13,299 - INFO - now the learning rate is: 1e-05
2025-03-03 03:03:54,130 - INFO - begin training stage: [524/805]
2025-03-03 03:03:54,131 - INFO - begin training stage: [524/805]
2025-03-03 03:03:58,953 - INFO - Epoch:[524/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 03:04:02,623 - INFO - Epoch:[524/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:04:06,230 - INFO - Epoch:[524/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:04:09,854 - INFO - Epoch:[524/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:04:13,493 - INFO - Epoch:[524/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 03:04:17,534 - INFO - Epoch:[524/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 03:04:21,530 - INFO - Epoch:[524/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 03:04:25,448 - INFO - Epoch:[524/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:04:29,137 - INFO - Epoch:[524/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.33 loss_cvh: 0.94
2025-03-03 03:04:30,378 - INFO - now the learning rate is: 1e-05
2025-03-03 03:05:15,340 - INFO - begin training stage: [525/805]
2025-03-03 03:05:15,340 - INFO - begin training stage: [525/805]
2025-03-03 03:05:20,232 - INFO - Epoch:[525/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:05:23,908 - INFO - Epoch:[525/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:05:28,313 - INFO - Epoch:[525/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 03:05:32,774 - INFO - Epoch:[525/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 03:05:37,031 - INFO - Epoch:[525/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:05:41,241 - INFO - Epoch:[525/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.40 loss_cvh: 3.13
2025-03-03 03:05:45,020 - INFO - Epoch:[525/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:05:49,090 - INFO - Epoch:[525/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.05
2025-03-03 03:05:52,900 - INFO - Epoch:[525/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.07 loss_cvh: 0.72
2025-03-03 03:05:54,963 - INFO - now the learning rate is: 1e-05
2025-03-03 03:06:39,734 - INFO - begin training stage: [526/805]
2025-03-03 03:06:39,734 - INFO - begin training stage: [526/805]
2025-03-03 03:06:45,231 - INFO - Epoch:[526/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 03:06:49,349 - INFO - Epoch:[526/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 03:06:53,717 - INFO - Epoch:[526/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-03 03:06:57,856 - INFO - Epoch:[526/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 03:07:01,890 - INFO - Epoch:[526/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 03:07:06,022 - INFO - Epoch:[526/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 03:07:10,379 - INFO - Epoch:[526/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 03:07:14,289 - INFO - Epoch:[526/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 03:07:18,156 - INFO - Epoch:[526/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.27 loss_cvh: 0.78
2025-03-03 03:07:19,323 - INFO - now the learning rate is: 1e-05
2025-03-03 03:08:02,258 - INFO - begin training stage: [527/805]
2025-03-03 03:08:02,259 - INFO - begin training stage: [527/805]
2025-03-03 03:08:08,021 - INFO - Epoch:[527/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:08:12,237 - INFO - Epoch:[527/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.39 loss_cvh: 3.10
2025-03-03 03:08:16,513 - INFO - Epoch:[527/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 03:08:21,012 - INFO - Epoch:[527/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 03:08:25,983 - INFO - Epoch:[527/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 03:08:30,709 - INFO - Epoch:[527/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 03:08:35,382 - INFO - Epoch:[527/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 03:08:40,588 - INFO - Epoch:[527/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 03:08:45,257 - INFO - Epoch:[527/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.10 loss_cvh: 0.52
2025-03-03 03:08:47,019 - INFO - now the learning rate is: 1e-05
2025-03-03 03:09:55,216 - INFO - begin training stage: [528/805]
2025-03-03 03:09:55,216 - INFO - begin training stage: [528/805]
2025-03-03 03:10:01,376 - INFO - Epoch:[528/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 03:10:05,740 - INFO - Epoch:[528/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:10:09,359 - INFO - Epoch:[528/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:10:12,934 - INFO - Epoch:[528/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:10:16,472 - INFO - Epoch:[528/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 03:10:19,987 - INFO - Epoch:[528/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:10:23,559 - INFO - Epoch:[528/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:10:27,125 - INFO - Epoch:[528/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 03:10:30,468 - INFO - Epoch:[528/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.20 loss_cvh: 0.80
2025-03-03 03:10:31,391 - INFO - now the learning rate is: 1e-05
2025-03-03 03:11:10,949 - INFO - begin training stage: [529/805]
2025-03-03 03:11:10,950 - INFO - begin training stage: [529/805]
2025-03-03 03:11:15,817 - INFO - Epoch:[529/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 03:11:19,385 - INFO - Epoch:[529/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 03:11:22,907 - INFO - Epoch:[529/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 03:11:26,537 - INFO - Epoch:[529/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 03:11:30,156 - INFO - Epoch:[529/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:11:33,754 - INFO - Epoch:[529/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:11:37,275 - INFO - Epoch:[529/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 03:11:40,838 - INFO - Epoch:[529/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 03:11:44,096 - INFO - Epoch:[529/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.33 loss_cvh: 0.62
2025-03-03 03:11:45,052 - INFO - now the learning rate is: 1e-05
2025-03-03 03:12:21,459 - INFO - begin training stage: [530/805]
2025-03-03 03:12:21,459 - INFO - begin training stage: [530/805]
2025-03-03 03:12:26,490 - INFO - Epoch:[530/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 03:12:30,542 - INFO - Epoch:[530/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:12:34,735 - INFO - Epoch:[530/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 03:12:38,563 - INFO - Epoch:[530/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 03:12:42,104 - INFO - Epoch:[530/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:12:45,641 - INFO - Epoch:[530/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 03:12:49,204 - INFO - Epoch:[530/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.02
2025-03-03 03:12:52,753 - INFO - Epoch:[530/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.39 loss_cvh: 3.08
2025-03-03 03:12:56,655 - INFO - Epoch:[530/805] Step:[90/90] reconstruction_loss: 1.04 loss_vc: 1.26 loss_cvh: 0.95
2025-03-03 03:12:58,027 - INFO - now the learning rate is: 1e-05
2025-03-03 03:14:07,975 - INFO - begin training stage: [531/805]
2025-03-03 03:14:07,977 - INFO - eval data number: 45600
2025-03-03 03:14:07,977 - INFO - loading eval data ......
2025-03-03 03:14:43,979 - INFO - retrieval costs: 22.821956396102905
2025-03-03 03:16:18,317 - INFO - hamming distance computation costs: 94.33853268623352
2025-03-03 03:16:25,935 - INFO - hamming ranking costs: 7.6175336837768555
2025-03-03 03:16:25,935 - INFO - labels shape: (45600, 239)
2025-03-03 03:17:03,410 - INFO - similarity labels generation costs: 37.47528910636902
2025-03-03 03:17:03,520 - INFO - topK: 5:, map: 0.33339083333333336
2025-03-03 03:17:03,825 - INFO - topK: 20:, map: 0.2407474464767581
2025-03-03 03:17:04,532 - INFO - topK: 40:, map: 0.20866521704633975
2025-03-03 03:17:05,343 - INFO - topK: 60:, map: 0.18972276010305233
2025-03-03 03:17:06,463 - INFO - topK: 80:, map: 0.17532142640585013
2025-03-03 03:17:07,857 - INFO - topK: 100:, map: 0.16327850351115328
2025-03-03 03:17:09,409 - INFO - begin training stage: [531/805]
2025-03-03 03:17:13,866 - INFO - Epoch:[531/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 03:17:17,360 - INFO - Epoch:[531/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 03:17:20,888 - INFO - Epoch:[531/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 03:17:24,390 - INFO - Epoch:[531/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 03:17:28,029 - INFO - Epoch:[531/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.03
2025-03-03 03:17:31,540 - INFO - Epoch:[531/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 03:17:35,066 - INFO - Epoch:[531/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.03
2025-03-03 03:17:38,632 - INFO - Epoch:[531/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.02
2025-03-03 03:17:41,864 - INFO - Epoch:[531/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.18 loss_cvh: 0.87
2025-03-03 03:17:42,820 - INFO - now the learning rate is: 1e-05
2025-03-03 03:18:20,230 - INFO - begin training stage: [532/805]
2025-03-03 03:18:20,231 - INFO - begin training stage: [532/805]
2025-03-03 03:18:24,759 - INFO - Epoch:[532/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:18:28,298 - INFO - Epoch:[532/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-03 03:18:31,920 - INFO - Epoch:[532/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:18:35,456 - INFO - Epoch:[532/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 03:18:39,061 - INFO - Epoch:[532/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 03:18:42,541 - INFO - Epoch:[532/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 03:18:46,185 - INFO - Epoch:[532/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.06
2025-03-03 03:18:49,684 - INFO - Epoch:[532/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 03:18:52,850 - INFO - Epoch:[532/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.21 loss_cvh: 0.76
2025-03-03 03:18:53,819 - INFO - now the learning rate is: 1e-05
2025-03-03 03:19:28,990 - INFO - begin training stage: [533/805]
2025-03-03 03:19:28,990 - INFO - begin training stage: [533/805]
2025-03-03 03:19:33,620 - INFO - Epoch:[533/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:19:37,547 - INFO - Epoch:[533/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 03:19:41,325 - INFO - Epoch:[533/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 03:19:44,996 - INFO - Epoch:[533/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 03:19:49,037 - INFO - Epoch:[533/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 03:19:52,862 - INFO - Epoch:[533/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 03:19:56,365 - INFO - Epoch:[533/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:19:59,955 - INFO - Epoch:[533/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 03:20:03,338 - INFO - Epoch:[533/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.38 loss_cvh: 0.92
2025-03-03 03:20:04,332 - INFO - now the learning rate is: 1e-05
2025-03-03 03:20:39,604 - INFO - begin training stage: [534/805]
2025-03-03 03:20:39,604 - INFO - begin training stage: [534/805]
2025-03-03 03:20:44,132 - INFO - Epoch:[534/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 03:20:47,675 - INFO - Epoch:[534/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 03:20:51,307 - INFO - Epoch:[534/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 03:20:55,462 - INFO - Epoch:[534/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:20:59,437 - INFO - Epoch:[534/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 03:21:03,426 - INFO - Epoch:[534/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 03:21:07,518 - INFO - Epoch:[534/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 03:21:11,176 - INFO - Epoch:[534/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:21:14,397 - INFO - Epoch:[534/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.11 loss_cvh: 0.59
2025-03-03 03:21:15,371 - INFO - now the learning rate is: 1e-05
2025-03-03 03:21:52,221 - INFO - begin training stage: [535/805]
2025-03-03 03:21:52,222 - INFO - begin training stage: [535/805]
2025-03-03 03:21:56,733 - INFO - Epoch:[535/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:22:00,215 - INFO - Epoch:[535/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:22:03,788 - INFO - Epoch:[535/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 03:22:07,253 - INFO - Epoch:[535/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:22:10,849 - INFO - Epoch:[535/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-03 03:22:14,481 - INFO - Epoch:[535/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 03:22:17,981 - INFO - Epoch:[535/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 03:22:21,496 - INFO - Epoch:[535/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:22:24,831 - INFO - Epoch:[535/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.05 loss_cvh: 0.68
2025-03-03 03:22:25,764 - INFO - now the learning rate is: 1e-05
2025-03-03 03:23:05,071 - INFO - begin training stage: [536/805]
2025-03-03 03:23:05,071 - INFO - begin training stage: [536/805]
2025-03-03 03:23:09,811 - INFO - Epoch:[536/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 03:23:13,347 - INFO - Epoch:[536/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 03:23:16,912 - INFO - Epoch:[536/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 03:23:20,504 - INFO - Epoch:[536/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:23:24,075 - INFO - Epoch:[536/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:23:27,656 - INFO - Epoch:[536/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 03:23:31,250 - INFO - Epoch:[536/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:23:34,835 - INFO - Epoch:[536/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 03:23:38,184 - INFO - Epoch:[536/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.26 loss_cvh: 0.73
2025-03-03 03:23:39,138 - INFO - now the learning rate is: 1e-05
2025-03-03 03:24:15,158 - INFO - begin training stage: [537/805]
2025-03-03 03:24:15,158 - INFO - begin training stage: [537/805]
2025-03-03 03:24:20,172 - INFO - Epoch:[537/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 03:24:23,792 - INFO - Epoch:[537/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 03:24:27,639 - INFO - Epoch:[537/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 03:24:31,167 - INFO - Epoch:[537/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:24:34,972 - INFO - Epoch:[537/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 03:24:39,388 - INFO - Epoch:[537/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:24:43,555 - INFO - Epoch:[537/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.05
2025-03-03 03:24:47,411 - INFO - Epoch:[537/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 03:24:50,969 - INFO - Epoch:[537/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.29 loss_cvh: 0.85
2025-03-03 03:24:51,952 - INFO - now the learning rate is: 1e-05
2025-03-03 03:25:26,488 - INFO - begin training stage: [538/805]
2025-03-03 03:25:26,489 - INFO - begin training stage: [538/805]
2025-03-03 03:25:31,342 - INFO - Epoch:[538/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 03:25:34,972 - INFO - Epoch:[538/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 03:25:38,809 - INFO - Epoch:[538/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 03:25:42,901 - INFO - Epoch:[538/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 03:25:46,903 - INFO - Epoch:[538/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 03:25:50,483 - INFO - Epoch:[538/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 03:25:53,983 - INFO - Epoch:[538/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 03:25:57,491 - INFO - Epoch:[538/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:26:00,876 - INFO - Epoch:[538/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.32 loss_cvh: 0.76
2025-03-03 03:26:01,992 - INFO - now the learning rate is: 1e-05
2025-03-03 03:26:41,294 - INFO - begin training stage: [539/805]
2025-03-03 03:26:41,294 - INFO - begin training stage: [539/805]
2025-03-03 03:26:45,802 - INFO - Epoch:[539/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 03:26:49,403 - INFO - Epoch:[539/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 03:26:52,892 - INFO - Epoch:[539/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:26:56,371 - INFO - Epoch:[539/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 03:26:59,826 - INFO - Epoch:[539/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:27:03,588 - INFO - Epoch:[539/805] Step:[60/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 03:27:07,684 - INFO - Epoch:[539/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:27:11,538 - INFO - Epoch:[539/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:27:14,968 - INFO - Epoch:[539/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.18 loss_cvh: 0.79
2025-03-03 03:27:15,901 - INFO - now the learning rate is: 1e-05
2025-03-03 03:27:57,250 - INFO - begin training stage: [540/805]
2025-03-03 03:27:57,251 - INFO - begin training stage: [540/805]
2025-03-03 03:28:02,058 - INFO - Epoch:[540/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 03:28:05,938 - INFO - Epoch:[540/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 03:28:09,700 - INFO - Epoch:[540/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 03:28:13,200 - INFO - Epoch:[540/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 03:28:16,572 - INFO - Epoch:[540/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 03:28:20,053 - INFO - Epoch:[540/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 03:28:23,569 - INFO - Epoch:[540/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:28:27,888 - INFO - Epoch:[540/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 03:28:32,263 - INFO - Epoch:[540/805] Step:[90/90] reconstruction_loss: 1.00 loss_vc: 1.10 loss_cvh: 0.67
2025-03-03 03:28:33,694 - INFO - now the learning rate is: 1e-05
2025-03-03 03:29:46,857 - INFO - begin training stage: [541/805]
2025-03-03 03:29:46,859 - INFO - eval data number: 45600
2025-03-03 03:29:46,859 - INFO - loading eval data ......
2025-03-03 03:30:26,778 - INFO - retrieval costs: 26.461063146591187
2025-03-03 03:32:16,614 - INFO - hamming distance computation costs: 109.834965467453
2025-03-03 03:32:27,589 - INFO - hamming ranking costs: 10.974991798400879
2025-03-03 03:32:27,591 - INFO - labels shape: (45600, 239)
2025-03-03 03:33:18,820 - INFO - similarity labels generation costs: 51.23157095909119
2025-03-03 03:33:18,905 - INFO - topK: 5:, map: 0.33479333333333333
2025-03-03 03:33:19,203 - INFO - topK: 20:, map: 0.24049111958136676
2025-03-03 03:33:19,780 - INFO - topK: 40:, map: 0.20837520719703195
2025-03-03 03:33:20,643 - INFO - topK: 60:, map: 0.18944434252172307
2025-03-03 03:33:21,775 - INFO - topK: 80:, map: 0.1751370158669445
2025-03-03 03:33:23,183 - INFO - topK: 100:, map: 0.16319438035944375
2025-03-03 03:33:24,335 - INFO - begin training stage: [541/805]
2025-03-03 03:33:29,497 - INFO - Epoch:[541/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 03:33:33,660 - INFO - Epoch:[541/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.33 loss_cvh: 3.01
2025-03-03 03:33:37,244 - INFO - Epoch:[541/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 03:33:40,857 - INFO - Epoch:[541/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 03:33:44,565 - INFO - Epoch:[541/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 03:33:48,352 - INFO - Epoch:[541/805] Step:[60/90] reconstruction_loss: 1.19 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 03:33:52,178 - INFO - Epoch:[541/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 03:33:55,886 - INFO - Epoch:[541/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 03:33:59,297 - INFO - Epoch:[541/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.17 loss_cvh: 0.77
2025-03-03 03:34:00,306 - INFO - now the learning rate is: 1e-05
2025-03-03 03:34:35,954 - INFO - begin training stage: [542/805]
2025-03-03 03:34:35,954 - INFO - begin training stage: [542/805]
2025-03-03 03:34:40,348 - INFO - Epoch:[542/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 03:34:44,010 - INFO - Epoch:[542/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:34:47,530 - INFO - Epoch:[542/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 03:34:51,005 - INFO - Epoch:[542/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 03:34:54,517 - INFO - Epoch:[542/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 03:34:58,400 - INFO - Epoch:[542/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 03:35:01,976 - INFO - Epoch:[542/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 03:35:05,466 - INFO - Epoch:[542/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 03:35:08,709 - INFO - Epoch:[542/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.24 loss_cvh: 0.75
2025-03-03 03:35:09,701 - INFO - now the learning rate is: 1e-05
2025-03-03 03:35:44,813 - INFO - begin training stage: [543/805]
2025-03-03 03:35:44,813 - INFO - begin training stage: [543/805]
2025-03-03 03:35:49,286 - INFO - Epoch:[543/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:35:52,731 - INFO - Epoch:[543/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 03:35:56,236 - INFO - Epoch:[543/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:35:59,744 - INFO - Epoch:[543/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 03:36:03,278 - INFO - Epoch:[543/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 03:36:06,977 - INFO - Epoch:[543/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 03:36:10,802 - INFO - Epoch:[543/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.05
2025-03-03 03:36:14,491 - INFO - Epoch:[543/805] Step:[80/90] reconstruction_loss: 1.10 loss_vc: 4.33 loss_cvh: 3.09
2025-03-03 03:36:17,838 - INFO - Epoch:[543/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.10 loss_cvh: 0.60
2025-03-03 03:36:18,843 - INFO - now the learning rate is: 1e-05
2025-03-03 03:36:55,284 - INFO - begin training stage: [544/805]
2025-03-03 03:36:55,285 - INFO - begin training stage: [544/805]
2025-03-03 03:36:59,647 - INFO - Epoch:[544/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:37:03,319 - INFO - Epoch:[544/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 03:37:06,897 - INFO - Epoch:[544/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 03:37:10,614 - INFO - Epoch:[544/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:37:14,081 - INFO - Epoch:[544/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 03:37:17,657 - INFO - Epoch:[544/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 03:37:21,520 - INFO - Epoch:[544/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.16
2025-03-03 03:37:25,302 - INFO - Epoch:[544/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:37:28,856 - INFO - Epoch:[544/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.23 loss_cvh: 0.67
2025-03-03 03:37:29,864 - INFO - now the learning rate is: 1e-05
2025-03-03 03:38:05,021 - INFO - begin training stage: [545/805]
2025-03-03 03:38:05,022 - INFO - begin training stage: [545/805]
2025-03-03 03:38:10,077 - INFO - Epoch:[545/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 03:38:13,533 - INFO - Epoch:[545/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 03:38:17,054 - INFO - Epoch:[545/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:38:20,536 - INFO - Epoch:[545/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:38:24,038 - INFO - Epoch:[545/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 03:38:27,481 - INFO - Epoch:[545/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 03:38:30,964 - INFO - Epoch:[545/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 03:38:34,785 - INFO - Epoch:[545/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 03:38:38,368 - INFO - Epoch:[545/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.33 loss_cvh: 0.65
2025-03-03 03:38:39,562 - INFO - now the learning rate is: 1e-05
2025-03-03 03:39:17,844 - INFO - begin training stage: [546/805]
2025-03-03 03:39:17,844 - INFO - begin training stage: [546/805]
2025-03-03 03:39:22,492 - INFO - Epoch:[546/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:39:26,126 - INFO - Epoch:[546/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 03:39:29,617 - INFO - Epoch:[546/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 03:39:33,175 - INFO - Epoch:[546/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 03:39:36,593 - INFO - Epoch:[546/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 03:39:40,016 - INFO - Epoch:[546/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 03:39:43,543 - INFO - Epoch:[546/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 03:39:47,109 - INFO - Epoch:[546/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 03:39:50,777 - INFO - Epoch:[546/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.29 loss_cvh: 0.77
2025-03-03 03:39:51,763 - INFO - now the learning rate is: 1e-05
2025-03-03 03:40:28,419 - INFO - begin training stage: [547/805]
2025-03-03 03:40:28,419 - INFO - begin training stage: [547/805]
2025-03-03 03:40:32,992 - INFO - Epoch:[547/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 03:40:36,488 - INFO - Epoch:[547/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.10
2025-03-03 03:40:39,999 - INFO - Epoch:[547/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 03:40:43,520 - INFO - Epoch:[547/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:40:47,159 - INFO - Epoch:[547/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 03:40:50,655 - INFO - Epoch:[547/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 03:40:54,169 - INFO - Epoch:[547/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 03:40:57,623 - INFO - Epoch:[547/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:41:00,933 - INFO - Epoch:[547/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.23 loss_cvh: 0.93
2025-03-03 03:41:02,181 - INFO - now the learning rate is: 1e-05
2025-03-03 03:41:38,518 - INFO - begin training stage: [548/805]
2025-03-03 03:41:38,518 - INFO - begin training stage: [548/805]
2025-03-03 03:41:42,860 - INFO - Epoch:[548/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:41:46,524 - INFO - Epoch:[548/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 03:41:50,186 - INFO - Epoch:[548/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 03:41:53,677 - INFO - Epoch:[548/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 03:41:57,177 - INFO - Epoch:[548/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 03:42:00,755 - INFO - Epoch:[548/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.03
2025-03-03 03:42:04,434 - INFO - Epoch:[548/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 03:42:08,008 - INFO - Epoch:[548/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 03:42:11,218 - INFO - Epoch:[548/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.19 loss_cvh: 0.74
2025-03-03 03:42:12,183 - INFO - now the learning rate is: 1e-05
2025-03-03 03:42:48,483 - INFO - begin training stage: [549/805]
2025-03-03 03:42:48,483 - INFO - begin training stage: [549/805]
2025-03-03 03:42:52,941 - INFO - Epoch:[549/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 03:42:56,404 - INFO - Epoch:[549/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:42:59,948 - INFO - Epoch:[549/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:43:04,054 - INFO - Epoch:[549/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 03:43:08,293 - INFO - Epoch:[549/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 03:43:12,140 - INFO - Epoch:[549/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 03:43:15,718 - INFO - Epoch:[549/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 03:43:19,231 - INFO - Epoch:[549/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:43:22,431 - INFO - Epoch:[549/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.14 loss_cvh: 0.76
2025-03-03 03:43:23,379 - INFO - now the learning rate is: 1e-05
2025-03-03 03:44:00,221 - INFO - begin training stage: [550/805]
2025-03-03 03:44:00,221 - INFO - begin training stage: [550/805]
2025-03-03 03:44:04,983 - INFO - Epoch:[550/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.12
2025-03-03 03:44:08,564 - INFO - Epoch:[550/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 03:44:12,044 - INFO - Epoch:[550/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 03:44:15,598 - INFO - Epoch:[550/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 03:44:19,109 - INFO - Epoch:[550/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:44:22,756 - INFO - Epoch:[550/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 03:44:26,286 - INFO - Epoch:[550/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 03:44:29,828 - INFO - Epoch:[550/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 03:44:33,131 - INFO - Epoch:[550/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.14 loss_cvh: 0.75
2025-03-03 03:44:34,073 - INFO - now the learning rate is: 1e-05
2025-03-03 03:45:13,021 - INFO - begin training stage: [551/805]
2025-03-03 03:45:13,022 - INFO - eval data number: 45600
2025-03-03 03:45:13,022 - INFO - loading eval data ......
2025-03-03 03:45:52,380 - INFO - retrieval costs: 25.9104220867157
2025-03-03 03:48:15,206 - INFO - hamming distance computation costs: 142.82529139518738
2025-03-03 03:48:22,678 - INFO - hamming ranking costs: 7.472520112991333
2025-03-03 03:48:22,678 - INFO - labels shape: (45600, 239)
2025-03-03 03:49:04,389 - INFO - similarity labels generation costs: 41.71083450317383
2025-03-03 03:49:04,471 - INFO - topK: 5:, map: 0.33705083333333336
2025-03-03 03:49:04,746 - INFO - topK: 20:, map: 0.2418020601317757
2025-03-03 03:49:05,265 - INFO - topK: 40:, map: 0.20903902165914104
2025-03-03 03:49:06,036 - INFO - topK: 60:, map: 0.190548262431066
2025-03-03 03:49:07,048 - INFO - topK: 80:, map: 0.1755961008104278
2025-03-03 03:49:08,310 - INFO - topK: 100:, map: 0.16355095306031797
2025-03-03 03:49:09,434 - INFO - begin training stage: [551/805]
2025-03-03 03:49:13,892 - INFO - Epoch:[551/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:49:17,400 - INFO - Epoch:[551/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 03:49:20,939 - INFO - Epoch:[551/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 03:49:25,322 - INFO - Epoch:[551/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 03:49:29,797 - INFO - Epoch:[551/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.03
2025-03-03 03:49:34,567 - INFO - Epoch:[551/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 03:49:39,450 - INFO - Epoch:[551/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 03:49:44,505 - INFO - Epoch:[551/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 03:49:49,070 - INFO - Epoch:[551/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.16 loss_cvh: 0.68
2025-03-03 03:49:50,571 - INFO - now the learning rate is: 1e-05
2025-03-03 03:51:01,307 - INFO - begin training stage: [552/805]
2025-03-03 03:51:01,307 - INFO - begin training stage: [552/805]
2025-03-03 03:51:07,479 - INFO - Epoch:[552/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:51:11,611 - INFO - Epoch:[552/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 03:51:15,609 - INFO - Epoch:[552/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 03:51:19,480 - INFO - Epoch:[552/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 03:51:23,395 - INFO - Epoch:[552/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 03:51:26,892 - INFO - Epoch:[552/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 03:51:30,528 - INFO - Epoch:[552/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 03:51:33,990 - INFO - Epoch:[552/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.07
2025-03-03 03:51:37,452 - INFO - Epoch:[552/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.31 loss_cvh: 0.93
2025-03-03 03:51:38,605 - INFO - now the learning rate is: 1e-05
2025-03-03 03:52:14,818 - INFO - begin training stage: [553/805]
2025-03-03 03:52:14,819 - INFO - begin training stage: [553/805]
2025-03-03 03:52:19,456 - INFO - Epoch:[553/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 03:52:23,065 - INFO - Epoch:[553/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 03:52:26,633 - INFO - Epoch:[553/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.16
2025-03-03 03:52:30,207 - INFO - Epoch:[553/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 03:52:34,059 - INFO - Epoch:[553/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.06
2025-03-03 03:52:38,198 - INFO - Epoch:[553/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 03:52:42,250 - INFO - Epoch:[553/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 03:52:46,344 - INFO - Epoch:[553/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:52:50,145 - INFO - Epoch:[553/805] Step:[90/90] reconstruction_loss: 0.98 loss_vc: 1.20 loss_cvh: 0.80
2025-03-03 03:52:51,385 - INFO - now the learning rate is: 1e-05
2025-03-03 03:53:50,806 - INFO - begin training stage: [554/805]
2025-03-03 03:53:50,806 - INFO - begin training stage: [554/805]
2025-03-03 03:53:56,251 - INFO - Epoch:[554/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:54:00,382 - INFO - Epoch:[554/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:54:04,406 - INFO - Epoch:[554/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 03:54:08,597 - INFO - Epoch:[554/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 03:54:12,791 - INFO - Epoch:[554/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 03:54:16,754 - INFO - Epoch:[554/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 03:54:20,909 - INFO - Epoch:[554/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 03:54:25,030 - INFO - Epoch:[554/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 03:54:28,939 - INFO - Epoch:[554/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.30 loss_cvh: 0.85
2025-03-03 03:54:30,164 - INFO - now the learning rate is: 1e-05
2025-03-03 03:55:12,001 - INFO - begin training stage: [555/805]
2025-03-03 03:55:12,001 - INFO - begin training stage: [555/805]
2025-03-03 03:55:17,314 - INFO - Epoch:[555/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 03:55:21,199 - INFO - Epoch:[555/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.03
2025-03-03 03:55:25,135 - INFO - Epoch:[555/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 03:55:29,067 - INFO - Epoch:[555/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 03:55:32,710 - INFO - Epoch:[555/805] Step:[50/90] reconstruction_loss: 1.11 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 03:55:36,500 - INFO - Epoch:[555/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.40 loss_cvh: 3.04
2025-03-03 03:55:40,705 - INFO - Epoch:[555/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 03:55:44,883 - INFO - Epoch:[555/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 03:55:48,559 - INFO - Epoch:[555/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.23 loss_cvh: 0.56
2025-03-03 03:55:49,803 - INFO - now the learning rate is: 1e-05
2025-03-03 03:56:29,559 - INFO - begin training stage: [556/805]
2025-03-03 03:56:29,560 - INFO - begin training stage: [556/805]
2025-03-03 03:56:34,705 - INFO - Epoch:[556/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 03:56:38,788 - INFO - Epoch:[556/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 03:56:42,765 - INFO - Epoch:[556/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 03:56:46,832 - INFO - Epoch:[556/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:56:50,666 - INFO - Epoch:[556/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 03:56:54,068 - INFO - Epoch:[556/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 03:56:58,060 - INFO - Epoch:[556/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 03:57:01,908 - INFO - Epoch:[556/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 03:57:05,839 - INFO - Epoch:[556/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.19 loss_cvh: 0.73
2025-03-03 03:57:07,077 - INFO - now the learning rate is: 1e-05
2025-03-03 03:57:46,965 - INFO - begin training stage: [557/805]
2025-03-03 03:57:46,965 - INFO - begin training stage: [557/805]
2025-03-03 03:57:52,309 - INFO - Epoch:[557/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 03:57:56,190 - INFO - Epoch:[557/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 03:58:00,393 - INFO - Epoch:[557/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 03:58:04,802 - INFO - Epoch:[557/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 03:58:09,196 - INFO - Epoch:[557/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 03:58:13,060 - INFO - Epoch:[557/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 03:58:16,853 - INFO - Epoch:[557/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 03:58:20,446 - INFO - Epoch:[557/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 03:58:24,127 - INFO - Epoch:[557/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.41 loss_cvh: 0.83
2025-03-03 03:58:25,495 - INFO - now the learning rate is: 1e-05
2025-03-03 03:59:05,701 - INFO - begin training stage: [558/805]
2025-03-03 03:59:05,702 - INFO - begin training stage: [558/805]
2025-03-03 03:59:11,195 - INFO - Epoch:[558/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 03:59:15,164 - INFO - Epoch:[558/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 03:59:19,320 - INFO - Epoch:[558/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 03:59:23,690 - INFO - Epoch:[558/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 03:59:27,967 - INFO - Epoch:[558/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 03:59:31,705 - INFO - Epoch:[558/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.40 loss_cvh: 3.09
2025-03-03 03:59:35,479 - INFO - Epoch:[558/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 03:59:39,588 - INFO - Epoch:[558/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 03:59:43,707 - INFO - Epoch:[558/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.11 loss_cvh: 0.79
2025-03-03 03:59:45,240 - INFO - now the learning rate is: 1e-05
2025-03-03 04:00:26,081 - INFO - begin training stage: [559/805]
2025-03-03 04:00:26,081 - INFO - begin training stage: [559/805]
2025-03-03 04:00:32,402 - INFO - Epoch:[559/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 04:00:36,516 - INFO - Epoch:[559/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 04:00:40,123 - INFO - Epoch:[559/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 04:00:43,949 - INFO - Epoch:[559/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 04:00:48,197 - INFO - Epoch:[559/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 04:00:54,147 - INFO - Epoch:[559/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 04:00:59,857 - INFO - Epoch:[559/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 04:01:05,690 - INFO - Epoch:[559/805] Step:[80/90] reconstruction_loss: 1.11 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 04:01:10,323 - INFO - Epoch:[559/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.21 loss_cvh: 0.62
2025-03-03 04:01:11,710 - INFO - now the learning rate is: 1e-05
2025-03-03 04:01:52,100 - INFO - begin training stage: [560/805]
2025-03-03 04:01:52,101 - INFO - begin training stage: [560/805]
2025-03-03 04:01:57,660 - INFO - Epoch:[560/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 04:02:01,583 - INFO - Epoch:[560/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 04:02:05,493 - INFO - Epoch:[560/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 04:02:09,593 - INFO - Epoch:[560/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:02:13,573 - INFO - Epoch:[560/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:02:17,641 - INFO - Epoch:[560/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 04:02:21,607 - INFO - Epoch:[560/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 04:02:25,547 - INFO - Epoch:[560/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 04:02:28,940 - INFO - Epoch:[560/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.31 loss_cvh: 0.86
2025-03-03 04:02:30,046 - INFO - now the learning rate is: 1e-05
2025-03-03 04:03:34,259 - INFO - begin training stage: [561/805]
2025-03-03 04:03:34,261 - INFO - eval data number: 45600
2025-03-03 04:03:34,261 - INFO - loading eval data ......
2025-03-03 04:04:14,559 - INFO - retrieval costs: 26.461816549301147
2025-03-03 04:06:05,448 - INFO - hamming distance computation costs: 110.88895559310913
2025-03-03 04:06:12,118 - INFO - hamming ranking costs: 6.669356822967529
2025-03-03 04:06:12,118 - INFO - labels shape: (45600, 239)
2025-03-03 04:06:58,559 - INFO - similarity labels generation costs: 46.44090032577515
2025-03-03 04:06:58,689 - INFO - topK: 5:, map: 0.33323416666666666
2025-03-03 04:06:59,146 - INFO - topK: 20:, map: 0.24007172495004778
2025-03-03 04:07:00,036 - INFO - topK: 40:, map: 0.2089983244144875
2025-03-03 04:07:01,356 - INFO - topK: 60:, map: 0.18976444177214752
2025-03-03 04:07:03,112 - INFO - topK: 80:, map: 0.17521210105816357
2025-03-03 04:07:05,304 - INFO - topK: 100:, map: 0.16294771958015436
2025-03-03 04:07:07,091 - INFO - begin training stage: [561/805]
2025-03-03 04:07:13,496 - INFO - Epoch:[561/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.07
2025-03-03 04:07:18,404 - INFO - Epoch:[561/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:07:23,165 - INFO - Epoch:[561/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:07:27,962 - INFO - Epoch:[561/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 04:07:32,750 - INFO - Epoch:[561/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 04:07:37,676 - INFO - Epoch:[561/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 04:07:42,420 - INFO - Epoch:[561/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:07:47,120 - INFO - Epoch:[561/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:07:51,525 - INFO - Epoch:[561/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.12 loss_cvh: 0.54
2025-03-03 04:07:53,083 - INFO - now the learning rate is: 1e-05
2025-03-03 04:08:39,997 - INFO - begin training stage: [562/805]
2025-03-03 04:08:39,998 - INFO - begin training stage: [562/805]
2025-03-03 04:08:44,747 - INFO - Epoch:[562/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:08:48,684 - INFO - Epoch:[562/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.02
2025-03-03 04:08:52,494 - INFO - Epoch:[562/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 04:08:56,485 - INFO - Epoch:[562/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 04:09:00,378 - INFO - Epoch:[562/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 04:09:04,119 - INFO - Epoch:[562/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 04:09:08,122 - INFO - Epoch:[562/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 04:09:12,208 - INFO - Epoch:[562/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 04:09:15,519 - INFO - Epoch:[562/805] Step:[90/90] reconstruction_loss: 1.28 loss_vc: 1.23 loss_cvh: 0.89
2025-03-03 04:09:16,579 - INFO - now the learning rate is: 1e-05
2025-03-03 04:09:53,569 - INFO - begin training stage: [563/805]
2025-03-03 04:09:53,569 - INFO - begin training stage: [563/805]
2025-03-03 04:09:58,481 - INFO - Epoch:[563/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 04:10:02,466 - INFO - Epoch:[563/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 04:10:06,325 - INFO - Epoch:[563/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 04:10:10,229 - INFO - Epoch:[563/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:10:14,106 - INFO - Epoch:[563/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 04:10:18,019 - INFO - Epoch:[563/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 04:10:21,964 - INFO - Epoch:[563/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 04:10:26,209 - INFO - Epoch:[563/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.13
2025-03-03 04:10:29,856 - INFO - Epoch:[563/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.12 loss_cvh: 0.68
2025-03-03 04:10:31,244 - INFO - now the learning rate is: 1e-05
2025-03-03 04:11:10,897 - INFO - begin training stage: [564/805]
2025-03-03 04:11:10,898 - INFO - begin training stage: [564/805]
2025-03-03 04:11:15,920 - INFO - Epoch:[564/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 04:11:19,780 - INFO - Epoch:[564/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:11:23,532 - INFO - Epoch:[564/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 04:11:27,688 - INFO - Epoch:[564/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 04:11:31,507 - INFO - Epoch:[564/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 04:11:35,441 - INFO - Epoch:[564/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 04:11:39,332 - INFO - Epoch:[564/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 04:11:43,581 - INFO - Epoch:[564/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 04:11:47,260 - INFO - Epoch:[564/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.20 loss_cvh: 0.75
2025-03-03 04:11:48,411 - INFO - now the learning rate is: 1e-05
2025-03-03 04:12:28,725 - INFO - begin training stage: [565/805]
2025-03-03 04:12:28,726 - INFO - begin training stage: [565/805]
2025-03-03 04:12:33,588 - INFO - Epoch:[565/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:12:37,605 - INFO - Epoch:[565/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 04:12:41,703 - INFO - Epoch:[565/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 04:12:45,612 - INFO - Epoch:[565/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.04
2025-03-03 04:12:49,505 - INFO - Epoch:[565/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 04:12:53,337 - INFO - Epoch:[565/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 04:12:57,543 - INFO - Epoch:[565/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 04:13:01,521 - INFO - Epoch:[565/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 04:13:05,117 - INFO - Epoch:[565/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.37 loss_cvh: 0.80
2025-03-03 04:13:06,312 - INFO - now the learning rate is: 1e-05
2025-03-03 04:13:44,523 - INFO - begin training stage: [566/805]
2025-03-03 04:13:44,524 - INFO - begin training stage: [566/805]
2025-03-03 04:13:50,579 - INFO - Epoch:[566/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:13:54,441 - INFO - Epoch:[566/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:13:58,414 - INFO - Epoch:[566/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 04:14:02,268 - INFO - Epoch:[566/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:14:06,256 - INFO - Epoch:[566/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 04:14:10,314 - INFO - Epoch:[566/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 04:14:14,485 - INFO - Epoch:[566/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 04:14:18,531 - INFO - Epoch:[566/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 04:14:22,127 - INFO - Epoch:[566/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.28 loss_cvh: 0.73
2025-03-03 04:14:23,424 - INFO - now the learning rate is: 1e-05
2025-03-03 04:15:17,826 - INFO - begin training stage: [567/805]
2025-03-03 04:15:17,826 - INFO - begin training stage: [567/805]
2025-03-03 04:15:23,518 - INFO - Epoch:[567/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.16
2025-03-03 04:15:27,867 - INFO - Epoch:[567/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:15:32,501 - INFO - Epoch:[567/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:15:37,050 - INFO - Epoch:[567/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 04:15:41,031 - INFO - Epoch:[567/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:15:44,880 - INFO - Epoch:[567/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 04:15:48,836 - INFO - Epoch:[567/805] Step:[70/90] reconstruction_loss: 1.11 loss_vc: 4.38 loss_cvh: 3.15
2025-03-03 04:15:52,781 - INFO - Epoch:[567/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.16
2025-03-03 04:15:56,463 - INFO - Epoch:[567/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.36 loss_cvh: 0.78
2025-03-03 04:15:57,750 - INFO - now the learning rate is: 1e-05
2025-03-03 04:16:37,605 - INFO - begin training stage: [568/805]
2025-03-03 04:16:37,605 - INFO - begin training stage: [568/805]
2025-03-03 04:16:42,917 - INFO - Epoch:[568/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.16
2025-03-03 04:16:46,669 - INFO - Epoch:[568/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 04:16:50,529 - INFO - Epoch:[568/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 04:16:54,423 - INFO - Epoch:[568/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 04:16:58,196 - INFO - Epoch:[568/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:17:02,218 - INFO - Epoch:[568/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:17:06,238 - INFO - Epoch:[568/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 04:17:10,061 - INFO - Epoch:[568/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 04:17:13,233 - INFO - Epoch:[568/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.14 loss_cvh: 0.82
2025-03-03 04:17:14,424 - INFO - now the learning rate is: 1e-05
2025-03-03 04:18:08,635 - INFO - begin training stage: [569/805]
2025-03-03 04:18:08,635 - INFO - begin training stage: [569/805]
2025-03-03 04:18:14,426 - INFO - Epoch:[569/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 04:18:18,079 - INFO - Epoch:[569/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 04:18:21,641 - INFO - Epoch:[569/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:18:25,589 - INFO - Epoch:[569/805] Step:[40/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 04:18:29,879 - INFO - Epoch:[569/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:18:33,848 - INFO - Epoch:[569/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:18:37,695 - INFO - Epoch:[569/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.06
2025-03-03 04:18:41,292 - INFO - Epoch:[569/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 04:18:45,031 - INFO - Epoch:[569/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.20 loss_cvh: 0.85
2025-03-03 04:18:46,414 - INFO - now the learning rate is: 1e-05
2025-03-03 04:19:25,768 - INFO - begin training stage: [570/805]
2025-03-03 04:19:25,768 - INFO - begin training stage: [570/805]
2025-03-03 04:19:31,065 - INFO - Epoch:[570/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:19:34,942 - INFO - Epoch:[570/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:19:38,507 - INFO - Epoch:[570/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 04:19:42,146 - INFO - Epoch:[570/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 04:19:45,712 - INFO - Epoch:[570/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 04:19:49,454 - INFO - Epoch:[570/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:19:53,240 - INFO - Epoch:[570/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 04:19:57,078 - INFO - Epoch:[570/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 04:20:00,596 - INFO - Epoch:[570/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.19 loss_cvh: 0.90
2025-03-03 04:20:01,784 - INFO - now the learning rate is: 1e-05
2025-03-03 04:20:40,111 - INFO - begin training stage: [571/805]
2025-03-03 04:20:40,112 - INFO - eval data number: 45600
2025-03-03 04:20:40,112 - INFO - loading eval data ......
2025-03-03 04:21:19,282 - INFO - retrieval costs: 25.1528902053833
2025-03-03 04:24:18,331 - INFO - hamming distance computation costs: 179.0487380027771
2025-03-03 04:24:25,368 - INFO - hamming ranking costs: 7.0371057987213135
2025-03-03 04:24:25,368 - INFO - labels shape: (45600, 239)
2025-03-03 04:25:21,271 - INFO - similarity labels generation costs: 55.902788400650024
2025-03-03 04:25:21,346 - INFO - topK: 5:, map: 0.3373741666666667
2025-03-03 04:25:21,624 - INFO - topK: 20:, map: 0.24227124326820193
2025-03-03 04:25:22,148 - INFO - topK: 40:, map: 0.20968788983787048
2025-03-03 04:25:22,926 - INFO - topK: 60:, map: 0.1910280126592134
2025-03-03 04:25:23,998 - INFO - topK: 80:, map: 0.17599796487555114
2025-03-03 04:25:25,311 - INFO - topK: 100:, map: 0.16375924074783024
2025-03-03 04:25:26,554 - INFO - begin training stage: [571/805]
2025-03-03 04:25:33,252 - INFO - Epoch:[571/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 04:25:38,980 - INFO - Epoch:[571/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 04:25:44,451 - INFO - Epoch:[571/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 04:25:49,965 - INFO - Epoch:[571/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 04:25:55,967 - INFO - Epoch:[571/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 04:26:00,785 - INFO - Epoch:[571/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 04:26:05,513 - INFO - Epoch:[571/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:26:10,279 - INFO - Epoch:[571/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 04:26:14,879 - INFO - Epoch:[571/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.17 loss_cvh: 0.92
2025-03-03 04:26:16,247 - INFO - now the learning rate is: 1e-05
2025-03-03 04:27:08,996 - INFO - begin training stage: [572/805]
2025-03-03 04:27:08,996 - INFO - begin training stage: [572/805]
2025-03-03 04:27:14,462 - INFO - Epoch:[572/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 04:27:18,632 - INFO - Epoch:[572/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.33 loss_cvh: 3.11
2025-03-03 04:27:23,379 - INFO - Epoch:[572/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 04:27:27,693 - INFO - Epoch:[572/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 04:27:32,496 - INFO - Epoch:[572/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 04:27:37,563 - INFO - Epoch:[572/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 04:27:41,747 - INFO - Epoch:[572/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:27:46,307 - INFO - Epoch:[572/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:27:50,669 - INFO - Epoch:[572/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.26 loss_cvh: 0.79
2025-03-03 04:27:51,984 - INFO - now the learning rate is: 1e-05
2025-03-03 04:28:41,505 - INFO - begin training stage: [573/805]
2025-03-03 04:28:41,506 - INFO - begin training stage: [573/805]
2025-03-03 04:28:47,892 - INFO - Epoch:[573/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 04:28:52,753 - INFO - Epoch:[573/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.05
2025-03-03 04:28:57,515 - INFO - Epoch:[573/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 04:29:02,633 - INFO - Epoch:[573/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 04:29:07,645 - INFO - Epoch:[573/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:29:12,628 - INFO - Epoch:[573/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 04:29:17,557 - INFO - Epoch:[573/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:29:22,392 - INFO - Epoch:[573/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 04:29:27,030 - INFO - Epoch:[573/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.23 loss_cvh: 0.56
2025-03-03 04:29:28,964 - INFO - now the learning rate is: 1e-05
2025-03-03 04:30:18,303 - INFO - begin training stage: [574/805]
2025-03-03 04:30:18,303 - INFO - begin training stage: [574/805]
2025-03-03 04:30:24,676 - INFO - Epoch:[574/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 04:30:30,233 - INFO - Epoch:[574/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 04:30:35,536 - INFO - Epoch:[574/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 04:30:40,700 - INFO - Epoch:[574/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:30:45,573 - INFO - Epoch:[574/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:30:50,762 - INFO - Epoch:[574/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:30:56,185 - INFO - Epoch:[574/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 04:31:01,411 - INFO - Epoch:[574/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:31:06,220 - INFO - Epoch:[574/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.18 loss_cvh: 0.94
2025-03-03 04:31:07,496 - INFO - now the learning rate is: 1e-05
2025-03-03 04:31:57,872 - INFO - begin training stage: [575/805]
2025-03-03 04:31:57,873 - INFO - begin training stage: [575/805]
2025-03-03 04:32:04,059 - INFO - Epoch:[575/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:32:09,113 - INFO - Epoch:[575/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 04:32:14,216 - INFO - Epoch:[575/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.16
2025-03-03 04:32:19,305 - INFO - Epoch:[575/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.08
2025-03-03 04:32:24,370 - INFO - Epoch:[575/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.03
2025-03-03 04:32:29,569 - INFO - Epoch:[575/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 04:32:34,656 - INFO - Epoch:[575/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 04:32:39,116 - INFO - Epoch:[575/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 04:32:43,145 - INFO - Epoch:[575/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.32 loss_cvh: 0.76
2025-03-03 04:32:44,498 - INFO - now the learning rate is: 1e-05
2025-03-03 04:33:30,115 - INFO - begin training stage: [576/805]
2025-03-03 04:33:30,115 - INFO - begin training stage: [576/805]
2025-03-03 04:33:35,789 - INFO - Epoch:[576/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 04:33:40,367 - INFO - Epoch:[576/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:33:45,429 - INFO - Epoch:[576/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 04:33:49,886 - INFO - Epoch:[576/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 04:33:54,243 - INFO - Epoch:[576/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 04:33:58,569 - INFO - Epoch:[576/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 04:34:02,837 - INFO - Epoch:[576/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 04:34:07,048 - INFO - Epoch:[576/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.04
2025-03-03 04:34:10,985 - INFO - Epoch:[576/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.23 loss_cvh: 0.78
2025-03-03 04:34:12,479 - INFO - now the learning rate is: 1e-05
2025-03-03 04:34:56,743 - INFO - begin training stage: [577/805]
2025-03-03 04:34:56,744 - INFO - begin training stage: [577/805]
2025-03-03 04:35:02,400 - INFO - Epoch:[577/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 04:35:07,114 - INFO - Epoch:[577/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:35:12,574 - INFO - Epoch:[577/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.15
2025-03-03 04:35:16,830 - INFO - Epoch:[577/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 04:35:21,656 - INFO - Epoch:[577/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 04:35:25,988 - INFO - Epoch:[577/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:35:30,225 - INFO - Epoch:[577/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.32 loss_cvh: 3.08
2025-03-03 04:35:34,700 - INFO - Epoch:[577/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 04:35:39,142 - INFO - Epoch:[577/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.09 loss_cvh: 0.65
2025-03-03 04:35:40,753 - INFO - now the learning rate is: 1e-05
2025-03-03 04:36:29,205 - INFO - begin training stage: [578/805]
2025-03-03 04:36:29,205 - INFO - begin training stage: [578/805]
2025-03-03 04:36:35,071 - INFO - Epoch:[578/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 04:36:39,876 - INFO - Epoch:[578/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 04:36:44,897 - INFO - Epoch:[578/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 04:36:49,518 - INFO - Epoch:[578/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 04:36:54,429 - INFO - Epoch:[578/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 04:36:59,289 - INFO - Epoch:[578/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 04:37:03,988 - INFO - Epoch:[578/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 04:37:08,354 - INFO - Epoch:[578/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 04:37:13,018 - INFO - Epoch:[578/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.27 loss_cvh: 0.92
2025-03-03 04:37:14,274 - INFO - now the learning rate is: 1e-05
2025-03-03 04:38:04,019 - INFO - begin training stage: [579/805]
2025-03-03 04:38:04,019 - INFO - begin training stage: [579/805]
2025-03-03 04:38:10,536 - INFO - Epoch:[579/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 04:38:15,794 - INFO - Epoch:[579/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:38:20,892 - INFO - Epoch:[579/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 04:38:26,056 - INFO - Epoch:[579/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 04:38:31,377 - INFO - Epoch:[579/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 04:38:36,445 - INFO - Epoch:[579/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 04:38:41,380 - INFO - Epoch:[579/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 04:38:46,410 - INFO - Epoch:[579/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 04:38:51,103 - INFO - Epoch:[579/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.27 loss_cvh: 0.74
2025-03-03 04:38:52,739 - INFO - now the learning rate is: 1e-05
2025-03-03 04:40:01,045 - INFO - begin training stage: [580/805]
2025-03-03 04:40:01,046 - INFO - begin training stage: [580/805]
2025-03-03 04:40:07,655 - INFO - Epoch:[580/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.14
2025-03-03 04:40:13,047 - INFO - Epoch:[580/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 04:40:18,173 - INFO - Epoch:[580/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:40:23,637 - INFO - Epoch:[580/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 04:40:28,553 - INFO - Epoch:[580/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 04:40:33,469 - INFO - Epoch:[580/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 04:40:38,956 - INFO - Epoch:[580/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:40:44,271 - INFO - Epoch:[580/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 04:40:48,691 - INFO - Epoch:[580/805] Step:[90/90] reconstruction_loss: 1.05 loss_vc: 1.24 loss_cvh: 0.61
2025-03-03 04:40:50,385 - INFO - now the learning rate is: 1e-05
2025-03-03 04:41:40,165 - INFO - begin training stage: [581/805]
2025-03-03 04:41:40,166 - INFO - eval data number: 45600
2025-03-03 04:41:40,166 - INFO - loading eval data ......
2025-03-03 04:42:19,699 - INFO - retrieval costs: 24.08768105506897
2025-03-03 04:44:06,154 - INFO - hamming distance computation costs: 106.45414590835571
2025-03-03 04:44:13,190 - INFO - hamming ranking costs: 7.036395788192749
2025-03-03 04:44:13,190 - INFO - labels shape: (45600, 239)
2025-03-03 04:44:51,176 - INFO - similarity labels generation costs: 37.98626112937927
2025-03-03 04:44:51,282 - INFO - topK: 5:, map: 0.33914999999999995
2025-03-03 04:44:51,611 - INFO - topK: 20:, map: 0.24339691215947795
2025-03-03 04:44:52,137 - INFO - topK: 40:, map: 0.20979051376661384
2025-03-03 04:44:52,921 - INFO - topK: 60:, map: 0.19050452642328417
2025-03-03 04:44:54,014 - INFO - topK: 80:, map: 0.17588640195889388
2025-03-03 04:44:55,307 - INFO - topK: 100:, map: 0.16379266597807005
2025-03-03 04:44:56,784 - INFO - begin training stage: [581/805]
2025-03-03 04:45:02,577 - INFO - Epoch:[581/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:45:06,940 - INFO - Epoch:[581/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 04:45:11,248 - INFO - Epoch:[581/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.04
2025-03-03 04:45:15,661 - INFO - Epoch:[581/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 04:45:20,108 - INFO - Epoch:[581/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 04:45:24,418 - INFO - Epoch:[581/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.13
2025-03-03 04:45:28,794 - INFO - Epoch:[581/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:45:33,100 - INFO - Epoch:[581/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 04:45:37,376 - INFO - Epoch:[581/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.35 loss_cvh: 0.75
2025-03-03 04:45:38,403 - INFO - now the learning rate is: 1e-05
2025-03-03 04:46:12,488 - INFO - begin training stage: [582/805]
2025-03-03 04:46:12,488 - INFO - begin training stage: [582/805]
2025-03-03 04:46:16,918 - INFO - Epoch:[582/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:46:20,437 - INFO - Epoch:[582/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:46:24,220 - INFO - Epoch:[582/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:46:27,541 - INFO - Epoch:[582/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 04:46:30,857 - INFO - Epoch:[582/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 04:46:34,204 - INFO - Epoch:[582/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 04:46:37,594 - INFO - Epoch:[582/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 04:46:40,889 - INFO - Epoch:[582/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 04:46:44,009 - INFO - Epoch:[582/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.16 loss_cvh: 0.85
2025-03-03 04:46:45,005 - INFO - now the learning rate is: 1e-05
2025-03-03 04:47:20,483 - INFO - begin training stage: [583/805]
2025-03-03 04:47:20,484 - INFO - begin training stage: [583/805]
2025-03-03 04:47:24,994 - INFO - Epoch:[583/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:47:28,340 - INFO - Epoch:[583/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 04:47:31,702 - INFO - Epoch:[583/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 04:47:35,400 - INFO - Epoch:[583/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 04:47:38,911 - INFO - Epoch:[583/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:47:42,446 - INFO - Epoch:[583/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 04:47:45,938 - INFO - Epoch:[583/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 04:47:49,307 - INFO - Epoch:[583/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 04:47:52,434 - INFO - Epoch:[583/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.39 loss_cvh: 0.83
2025-03-03 04:47:53,457 - INFO - now the learning rate is: 1e-05
2025-03-03 04:48:27,424 - INFO - begin training stage: [584/805]
2025-03-03 04:48:27,425 - INFO - begin training stage: [584/805]
2025-03-03 04:48:31,865 - INFO - Epoch:[584/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:48:35,237 - INFO - Epoch:[584/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:48:38,677 - INFO - Epoch:[584/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:48:42,414 - INFO - Epoch:[584/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:48:46,006 - INFO - Epoch:[584/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 04:48:49,685 - INFO - Epoch:[584/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 04:48:53,065 - INFO - Epoch:[584/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 04:48:56,587 - INFO - Epoch:[584/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 04:48:59,712 - INFO - Epoch:[584/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.17 loss_cvh: 0.71
2025-03-03 04:49:00,809 - INFO - now the learning rate is: 1e-05
2025-03-03 04:49:36,149 - INFO - begin training stage: [585/805]
2025-03-03 04:49:36,149 - INFO - begin training stage: [585/805]
2025-03-03 04:49:40,485 - INFO - Epoch:[585/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 04:49:43,879 - INFO - Epoch:[585/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.12
2025-03-03 04:49:47,296 - INFO - Epoch:[585/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 04:49:50,718 - INFO - Epoch:[585/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:49:54,239 - INFO - Epoch:[585/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 04:49:58,045 - INFO - Epoch:[585/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:50:01,680 - INFO - Epoch:[585/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:50:05,011 - INFO - Epoch:[585/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 04:50:08,121 - INFO - Epoch:[585/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.25 loss_cvh: 0.72
2025-03-03 04:50:09,110 - INFO - now the learning rate is: 1e-05
2025-03-03 04:50:42,468 - INFO - begin training stage: [586/805]
2025-03-03 04:50:42,468 - INFO - begin training stage: [586/805]
2025-03-03 04:50:46,714 - INFO - Epoch:[586/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 04:50:50,129 - INFO - Epoch:[586/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 04:50:53,580 - INFO - Epoch:[586/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 04:50:57,083 - INFO - Epoch:[586/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 04:51:00,459 - INFO - Epoch:[586/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 04:51:03,846 - INFO - Epoch:[586/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 04:51:07,329 - INFO - Epoch:[586/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 04:51:11,020 - INFO - Epoch:[586/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:51:14,202 - INFO - Epoch:[586/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.23 loss_cvh: 0.79
2025-03-03 04:51:15,178 - INFO - now the learning rate is: 1e-05
2025-03-03 04:51:49,432 - INFO - begin training stage: [587/805]
2025-03-03 04:51:49,433 - INFO - begin training stage: [587/805]
2025-03-03 04:51:53,718 - INFO - Epoch:[587/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 04:51:57,126 - INFO - Epoch:[587/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 04:52:00,524 - INFO - Epoch:[587/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:52:03,882 - INFO - Epoch:[587/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 04:52:07,250 - INFO - Epoch:[587/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:52:10,660 - INFO - Epoch:[587/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.39 loss_cvh: 3.12
2025-03-03 04:52:14,099 - INFO - Epoch:[587/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 04:52:17,641 - INFO - Epoch:[587/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.03
2025-03-03 04:52:21,192 - INFO - Epoch:[587/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.33 loss_cvh: 0.85
2025-03-03 04:52:22,311 - INFO - now the learning rate is: 1e-05
2025-03-03 04:52:55,997 - INFO - begin training stage: [588/805]
2025-03-03 04:52:55,997 - INFO - begin training stage: [588/805]
2025-03-03 04:53:00,326 - INFO - Epoch:[588/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 04:53:03,745 - INFO - Epoch:[588/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 04:53:07,561 - INFO - Epoch:[588/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 04:53:11,319 - INFO - Epoch:[588/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 04:53:14,855 - INFO - Epoch:[588/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.16
2025-03-03 04:53:18,256 - INFO - Epoch:[588/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 04:53:21,663 - INFO - Epoch:[588/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 04:53:24,962 - INFO - Epoch:[588/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 04:53:28,057 - INFO - Epoch:[588/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.23 loss_cvh: 0.78
2025-03-03 04:53:28,990 - INFO - now the learning rate is: 1e-05
2025-03-03 04:54:06,454 - INFO - begin training stage: [589/805]
2025-03-03 04:54:06,455 - INFO - begin training stage: [589/805]
2025-03-03 04:54:10,590 - INFO - Epoch:[589/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.05
2025-03-03 04:54:13,831 - INFO - Epoch:[589/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 04:54:17,145 - INFO - Epoch:[589/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:54:20,490 - INFO - Epoch:[589/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 04:54:23,846 - INFO - Epoch:[589/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 04:54:27,197 - INFO - Epoch:[589/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 04:54:30,658 - INFO - Epoch:[589/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 04:54:34,066 - INFO - Epoch:[589/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 04:54:37,668 - INFO - Epoch:[589/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 0.98 loss_cvh: 0.62
2025-03-03 04:54:39,067 - INFO - now the learning rate is: 1e-05
2025-03-03 04:55:44,078 - INFO - begin training stage: [590/805]
2025-03-03 04:55:44,078 - INFO - begin training stage: [590/805]
2025-03-03 04:55:50,160 - INFO - Epoch:[590/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 04:55:54,711 - INFO - Epoch:[590/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 04:55:59,111 - INFO - Epoch:[590/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 04:56:03,491 - INFO - Epoch:[590/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 04:56:08,134 - INFO - Epoch:[590/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 04:56:12,676 - INFO - Epoch:[590/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 04:56:17,368 - INFO - Epoch:[590/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.10
2025-03-03 04:56:21,756 - INFO - Epoch:[590/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 04:56:25,924 - INFO - Epoch:[590/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.11 loss_cvh: 0.63
2025-03-03 04:56:27,366 - INFO - now the learning rate is: 1e-05
2025-03-03 04:57:31,548 - INFO - begin training stage: [591/805]
2025-03-03 04:57:31,550 - INFO - eval data number: 45600
2025-03-03 04:57:31,550 - INFO - loading eval data ......
2025-03-03 04:58:08,304 - INFO - retrieval costs: 23.48215079307556
2025-03-03 04:59:48,607 - INFO - hamming distance computation costs: 100.30268216133118
2025-03-03 04:59:55,449 - INFO - hamming ranking costs: 6.842700242996216
2025-03-03 04:59:55,450 - INFO - labels shape: (45600, 239)
2025-03-03 05:00:33,207 - INFO - similarity labels generation costs: 37.75729036331177
2025-03-03 05:00:33,283 - INFO - topK: 5:, map: 0.33523000000000003
2025-03-03 05:00:33,560 - INFO - topK: 20:, map: 0.24162154551502849
2025-03-03 05:00:34,082 - INFO - topK: 40:, map: 0.20824236770575044
2025-03-03 05:00:34,865 - INFO - topK: 60:, map: 0.1897003741168511
2025-03-03 05:00:35,906 - INFO - topK: 80:, map: 0.1747376674792011
2025-03-03 05:00:37,216 - INFO - topK: 100:, map: 0.1626127333008816
2025-03-03 05:00:38,143 - INFO - begin training stage: [591/805]
2025-03-03 05:00:42,552 - INFO - Epoch:[591/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 05:00:46,050 - INFO - Epoch:[591/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 05:00:49,802 - INFO - Epoch:[591/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 05:00:53,431 - INFO - Epoch:[591/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 05:00:57,080 - INFO - Epoch:[591/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.06
2025-03-03 05:01:00,666 - INFO - Epoch:[591/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.39 loss_cvh: 3.15
2025-03-03 05:01:04,161 - INFO - Epoch:[591/805] Step:[70/90] reconstruction_loss: 1.11 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 05:01:07,688 - INFO - Epoch:[591/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.04
2025-03-03 05:01:10,979 - INFO - Epoch:[591/805] Step:[90/90] reconstruction_loss: 1.01 loss_vc: 1.11 loss_cvh: 0.69
2025-03-03 05:01:11,953 - INFO - now the learning rate is: 1e-05
2025-03-03 05:01:50,767 - INFO - begin training stage: [592/805]
2025-03-03 05:01:50,767 - INFO - begin training stage: [592/805]
2025-03-03 05:01:55,328 - INFO - Epoch:[592/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 05:01:59,289 - INFO - Epoch:[592/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:02:03,268 - INFO - Epoch:[592/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 05:02:06,837 - INFO - Epoch:[592/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 05:02:10,299 - INFO - Epoch:[592/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:02:13,793 - INFO - Epoch:[592/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 05:02:17,301 - INFO - Epoch:[592/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 05:02:20,744 - INFO - Epoch:[592/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 05:02:24,124 - INFO - Epoch:[592/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.26 loss_cvh: 0.93
2025-03-03 05:02:25,249 - INFO - now the learning rate is: 1e-05
2025-03-03 05:03:05,071 - INFO - begin training stage: [593/805]
2025-03-03 05:03:05,071 - INFO - begin training stage: [593/805]
2025-03-03 05:03:09,937 - INFO - Epoch:[593/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.05
2025-03-03 05:03:13,813 - INFO - Epoch:[593/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 05:03:17,665 - INFO - Epoch:[593/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:03:21,283 - INFO - Epoch:[593/805] Step:[40/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 05:03:25,246 - INFO - Epoch:[593/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 05:03:29,233 - INFO - Epoch:[593/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 05:03:32,958 - INFO - Epoch:[593/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 05:03:36,614 - INFO - Epoch:[593/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:03:40,465 - INFO - Epoch:[593/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.35 loss_cvh: 0.79
2025-03-03 05:03:41,529 - INFO - now the learning rate is: 1e-05
2025-03-03 05:04:20,409 - INFO - begin training stage: [594/805]
2025-03-03 05:04:20,409 - INFO - begin training stage: [594/805]
2025-03-03 05:04:25,605 - INFO - Epoch:[594/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 05:04:29,614 - INFO - Epoch:[594/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:04:33,525 - INFO - Epoch:[594/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 05:04:37,346 - INFO - Epoch:[594/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:04:41,429 - INFO - Epoch:[594/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 05:04:45,476 - INFO - Epoch:[594/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:04:49,520 - INFO - Epoch:[594/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 05:04:53,404 - INFO - Epoch:[594/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:04:57,109 - INFO - Epoch:[594/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.11 loss_cvh: 0.75
2025-03-03 05:04:58,239 - INFO - now the learning rate is: 1e-05
2025-03-03 05:05:37,689 - INFO - begin training stage: [595/805]
2025-03-03 05:05:37,690 - INFO - begin training stage: [595/805]
2025-03-03 05:05:44,076 - INFO - Epoch:[595/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.03
2025-03-03 05:05:47,747 - INFO - Epoch:[595/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 05:05:51,812 - INFO - Epoch:[595/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.01
2025-03-03 05:05:55,467 - INFO - Epoch:[595/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:05:59,144 - INFO - Epoch:[595/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 05:06:02,790 - INFO - Epoch:[595/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:06:06,749 - INFO - Epoch:[595/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:06:10,595 - INFO - Epoch:[595/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 05:06:14,384 - INFO - Epoch:[595/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.19 loss_cvh: 0.63
2025-03-03 05:06:15,533 - INFO - now the learning rate is: 1e-05
2025-03-03 05:06:54,499 - INFO - begin training stage: [596/805]
2025-03-03 05:06:54,500 - INFO - begin training stage: [596/805]
2025-03-03 05:07:00,697 - INFO - Epoch:[596/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:07:04,839 - INFO - Epoch:[596/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 05:07:08,923 - INFO - Epoch:[596/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 05:07:12,928 - INFO - Epoch:[596/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 05:07:17,081 - INFO - Epoch:[596/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 05:07:20,905 - INFO - Epoch:[596/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 05:07:24,933 - INFO - Epoch:[596/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:07:29,093 - INFO - Epoch:[596/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 05:07:32,801 - INFO - Epoch:[596/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.22 loss_cvh: 0.97
2025-03-03 05:07:33,916 - INFO - now the learning rate is: 1e-05
2025-03-03 05:08:13,677 - INFO - begin training stage: [597/805]
2025-03-03 05:08:13,678 - INFO - begin training stage: [597/805]
2025-03-03 05:08:18,792 - INFO - Epoch:[597/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 05:08:22,900 - INFO - Epoch:[597/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:08:26,934 - INFO - Epoch:[597/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:08:30,876 - INFO - Epoch:[597/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.16
2025-03-03 05:08:34,851 - INFO - Epoch:[597/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:08:39,406 - INFO - Epoch:[597/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 05:08:43,561 - INFO - Epoch:[597/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 05:08:47,375 - INFO - Epoch:[597/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:08:51,117 - INFO - Epoch:[597/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.15 loss_cvh: 0.96
2025-03-03 05:08:52,286 - INFO - now the learning rate is: 1e-05
2025-03-03 05:09:32,907 - INFO - begin training stage: [598/805]
2025-03-03 05:09:32,907 - INFO - begin training stage: [598/805]
2025-03-03 05:09:37,505 - INFO - Epoch:[598/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 05:09:41,125 - INFO - Epoch:[598/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 05:09:44,718 - INFO - Epoch:[598/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 05:09:48,466 - INFO - Epoch:[598/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 05:09:52,139 - INFO - Epoch:[598/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:09:55,731 - INFO - Epoch:[598/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:09:59,409 - INFO - Epoch:[598/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 05:10:03,511 - INFO - Epoch:[598/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:10:07,363 - INFO - Epoch:[598/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.10 loss_cvh: 0.62
2025-03-03 05:10:08,486 - INFO - now the learning rate is: 1e-05
2025-03-03 05:10:48,745 - INFO - begin training stage: [599/805]
2025-03-03 05:10:48,746 - INFO - begin training stage: [599/805]
2025-03-03 05:10:54,092 - INFO - Epoch:[599/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 05:10:57,930 - INFO - Epoch:[599/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.16
2025-03-03 05:11:02,105 - INFO - Epoch:[599/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:11:05,752 - INFO - Epoch:[599/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 05:11:09,315 - INFO - Epoch:[599/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 05:11:13,733 - INFO - Epoch:[599/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:11:17,624 - INFO - Epoch:[599/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:11:21,547 - INFO - Epoch:[599/805] Step:[80/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:11:24,801 - INFO - Epoch:[599/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.23 loss_cvh: 0.72
2025-03-03 05:11:25,820 - INFO - now the learning rate is: 1e-05
2025-03-03 05:12:33,202 - INFO - begin training stage: [600/805]
2025-03-03 05:12:33,202 - INFO - begin training stage: [600/805]
2025-03-03 05:12:38,960 - INFO - Epoch:[600/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 05:12:43,552 - INFO - Epoch:[600/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 05:12:48,516 - INFO - Epoch:[600/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:12:53,500 - INFO - Epoch:[600/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 05:12:58,432 - INFO - Epoch:[600/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 05:13:03,321 - INFO - Epoch:[600/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 05:13:08,048 - INFO - Epoch:[600/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 05:13:12,740 - INFO - Epoch:[600/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 05:13:16,929 - INFO - Epoch:[600/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.15 loss_cvh: 0.68
2025-03-03 05:13:18,395 - INFO - now the learning rate is: 1e-05
2025-03-03 05:14:26,278 - INFO - begin training stage: [601/805]
2025-03-03 05:14:26,280 - INFO - eval data number: 45600
2025-03-03 05:14:26,280 - INFO - loading eval data ......
2025-03-03 05:15:02,464 - INFO - retrieval costs: 22.848219633102417
2025-03-03 05:16:38,882 - INFO - hamming distance computation costs: 96.41789054870605
2025-03-03 05:16:45,920 - INFO - hamming ranking costs: 7.038379430770874
2025-03-03 05:16:45,920 - INFO - labels shape: (45600, 239)
2025-03-03 05:17:27,121 - INFO - similarity labels generation costs: 41.20075297355652
2025-03-03 05:17:27,207 - INFO - topK: 5:, map: 0.33828083333333336
2025-03-03 05:17:27,473 - INFO - topK: 20:, map: 0.24410951523874946
2025-03-03 05:17:28,003 - INFO - topK: 40:, map: 0.20980954117038084
2025-03-03 05:17:28,780 - INFO - topK: 60:, map: 0.19005046351127844
2025-03-03 05:17:29,815 - INFO - topK: 80:, map: 0.17576845710740063
2025-03-03 05:17:31,103 - INFO - topK: 100:, map: 0.1635683568941971
2025-03-03 05:17:31,968 - INFO - begin training stage: [601/805]
2025-03-03 05:17:36,412 - INFO - Epoch:[601/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:17:39,922 - INFO - Epoch:[601/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 05:17:43,408 - INFO - Epoch:[601/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 05:17:46,987 - INFO - Epoch:[601/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 05:17:50,678 - INFO - Epoch:[601/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 05:17:54,373 - INFO - Epoch:[601/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 05:17:57,893 - INFO - Epoch:[601/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 05:18:01,401 - INFO - Epoch:[601/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:18:04,726 - INFO - Epoch:[601/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.13 loss_cvh: 0.75
2025-03-03 05:18:05,711 - INFO - now the learning rate is: 1e-05
2025-03-03 05:18:41,007 - INFO - begin training stage: [602/805]
2025-03-03 05:18:41,008 - INFO - begin training stage: [602/805]
2025-03-03 05:18:46,061 - INFO - Epoch:[602/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 05:18:50,184 - INFO - Epoch:[602/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 05:18:53,738 - INFO - Epoch:[602/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 05:18:57,371 - INFO - Epoch:[602/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:19:01,092 - INFO - Epoch:[602/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 05:19:04,660 - INFO - Epoch:[602/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 05:19:08,195 - INFO - Epoch:[602/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:19:11,789 - INFO - Epoch:[602/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 05:19:15,435 - INFO - Epoch:[602/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.19 loss_cvh: 0.88
2025-03-03 05:19:16,407 - INFO - now the learning rate is: 1e-05
2025-03-03 05:19:53,304 - INFO - begin training stage: [603/805]
2025-03-03 05:19:53,305 - INFO - begin training stage: [603/805]
2025-03-03 05:19:57,947 - INFO - Epoch:[603/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 05:20:01,492 - INFO - Epoch:[603/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 05:20:05,040 - INFO - Epoch:[603/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:20:08,797 - INFO - Epoch:[603/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.03
2025-03-03 05:20:12,347 - INFO - Epoch:[603/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:20:15,901 - INFO - Epoch:[603/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:20:19,415 - INFO - Epoch:[603/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:20:22,895 - INFO - Epoch:[603/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 05:20:26,184 - INFO - Epoch:[603/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.19 loss_cvh: 0.70
2025-03-03 05:20:27,162 - INFO - now the learning rate is: 1e-05
2025-03-03 05:21:02,374 - INFO - begin training stage: [604/805]
2025-03-03 05:21:02,374 - INFO - begin training stage: [604/805]
2025-03-03 05:21:07,120 - INFO - Epoch:[604/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 05:21:11,233 - INFO - Epoch:[604/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 05:21:15,192 - INFO - Epoch:[604/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:21:19,292 - INFO - Epoch:[604/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 05:21:22,923 - INFO - Epoch:[604/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.14
2025-03-03 05:21:26,503 - INFO - Epoch:[604/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 05:21:30,058 - INFO - Epoch:[604/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 05:21:33,601 - INFO - Epoch:[604/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:21:36,929 - INFO - Epoch:[604/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.18 loss_cvh: 0.84
2025-03-03 05:21:37,913 - INFO - now the learning rate is: 1e-05
2025-03-03 05:22:13,658 - INFO - begin training stage: [605/805]
2025-03-03 05:22:13,658 - INFO - begin training stage: [605/805]
2025-03-03 05:22:18,201 - INFO - Epoch:[605/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 05:22:21,741 - INFO - Epoch:[605/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:22:25,308 - INFO - Epoch:[605/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 05:22:29,024 - INFO - Epoch:[605/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:22:32,793 - INFO - Epoch:[605/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 05:22:36,644 - INFO - Epoch:[605/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 05:22:40,358 - INFO - Epoch:[605/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 05:22:44,376 - INFO - Epoch:[605/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:22:47,796 - INFO - Epoch:[605/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.12 loss_cvh: 0.89
2025-03-03 05:22:48,821 - INFO - now the learning rate is: 1e-05
2025-03-03 05:23:25,765 - INFO - begin training stage: [606/805]
2025-03-03 05:23:25,765 - INFO - begin training stage: [606/805]
2025-03-03 05:23:30,289 - INFO - Epoch:[606/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:23:34,292 - INFO - Epoch:[606/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 05:23:38,121 - INFO - Epoch:[606/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:23:42,097 - INFO - Epoch:[606/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 05:23:45,984 - INFO - Epoch:[606/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 05:23:49,964 - INFO - Epoch:[606/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 05:23:54,286 - INFO - Epoch:[606/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 05:23:58,344 - INFO - Epoch:[606/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 05:24:02,052 - INFO - Epoch:[606/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.20 loss_cvh: 0.78
2025-03-03 05:24:03,204 - INFO - now the learning rate is: 1e-05
2025-03-03 05:24:43,833 - INFO - begin training stage: [607/805]
2025-03-03 05:24:43,833 - INFO - begin training stage: [607/805]
2025-03-03 05:24:48,684 - INFO - Epoch:[607/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 05:24:52,652 - INFO - Epoch:[607/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 05:24:56,231 - INFO - Epoch:[607/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 05:25:00,098 - INFO - Epoch:[607/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:25:04,028 - INFO - Epoch:[607/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 05:25:07,988 - INFO - Epoch:[607/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 05:25:12,012 - INFO - Epoch:[607/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 05:25:15,622 - INFO - Epoch:[607/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:25:18,898 - INFO - Epoch:[607/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.26 loss_cvh: 0.64
2025-03-03 05:25:19,899 - INFO - now the learning rate is: 1e-05
2025-03-03 05:25:59,055 - INFO - begin training stage: [608/805]
2025-03-03 05:25:59,055 - INFO - begin training stage: [608/805]
2025-03-03 05:26:04,231 - INFO - Epoch:[608/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 05:26:08,212 - INFO - Epoch:[608/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 05:26:12,109 - INFO - Epoch:[608/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:26:16,048 - INFO - Epoch:[608/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 05:26:20,120 - INFO - Epoch:[608/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 05:26:23,836 - INFO - Epoch:[608/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:26:27,690 - INFO - Epoch:[608/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 05:26:31,586 - INFO - Epoch:[608/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 05:26:35,345 - INFO - Epoch:[608/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.11 loss_cvh: 0.67
2025-03-03 05:26:36,480 - INFO - now the learning rate is: 1e-05
2025-03-03 05:27:18,469 - INFO - begin training stage: [609/805]
2025-03-03 05:27:18,470 - INFO - begin training stage: [609/805]
2025-03-03 05:27:23,611 - INFO - Epoch:[609/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 05:27:27,339 - INFO - Epoch:[609/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:27:31,704 - INFO - Epoch:[609/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 05:27:35,669 - INFO - Epoch:[609/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:27:39,590 - INFO - Epoch:[609/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:27:43,426 - INFO - Epoch:[609/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 05:27:47,348 - INFO - Epoch:[609/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 05:27:51,186 - INFO - Epoch:[609/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.15
2025-03-03 05:27:54,762 - INFO - Epoch:[609/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.24 loss_cvh: 0.83
2025-03-03 05:27:55,913 - INFO - now the learning rate is: 1e-05
2025-03-03 05:29:01,591 - INFO - begin training stage: [610/805]
2025-03-03 05:29:01,592 - INFO - begin training stage: [610/805]
2025-03-03 05:29:07,412 - INFO - Epoch:[610/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 05:29:12,136 - INFO - Epoch:[610/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 05:29:16,726 - INFO - Epoch:[610/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:29:21,288 - INFO - Epoch:[610/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 05:29:25,709 - INFO - Epoch:[610/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 05:29:30,290 - INFO - Epoch:[610/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 05:29:34,860 - INFO - Epoch:[610/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:29:39,688 - INFO - Epoch:[610/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.06
2025-03-03 05:29:43,875 - INFO - Epoch:[610/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.20 loss_cvh: 0.69
2025-03-03 05:29:45,223 - INFO - now the learning rate is: 1e-05
2025-03-03 05:30:53,467 - INFO - begin training stage: [611/805]
2025-03-03 05:30:53,469 - INFO - eval data number: 45600
2025-03-03 05:30:53,469 - INFO - loading eval data ......
2025-03-03 05:31:30,045 - INFO - retrieval costs: 23.16328763961792
2025-03-03 05:33:07,690 - INFO - hamming distance computation costs: 97.64524745941162
2025-03-03 05:33:14,764 - INFO - hamming ranking costs: 7.073697805404663
2025-03-03 05:33:14,764 - INFO - labels shape: (45600, 239)
2025-03-03 05:33:53,983 - INFO - similarity labels generation costs: 39.21882629394531
2025-03-03 05:33:54,092 - INFO - topK: 5:, map: 0.34072916666666664
2025-03-03 05:33:54,429 - INFO - topK: 20:, map: 0.24519898266765913
2025-03-03 05:33:54,939 - INFO - topK: 40:, map: 0.21172944698693447
2025-03-03 05:33:55,713 - INFO - topK: 60:, map: 0.19208485949854548
2025-03-03 05:33:56,751 - INFO - topK: 80:, map: 0.17685546243491676
2025-03-03 05:33:58,044 - INFO - topK: 100:, map: 0.16463069471925326
2025-03-03 05:33:59,172 - INFO - begin training stage: [611/805]
2025-03-03 05:34:03,608 - INFO - Epoch:[611/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:34:07,272 - INFO - Epoch:[611/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 05:34:10,761 - INFO - Epoch:[611/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 05:34:14,232 - INFO - Epoch:[611/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:34:18,096 - INFO - Epoch:[611/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 05:34:21,754 - INFO - Epoch:[611/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:34:25,328 - INFO - Epoch:[611/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.14
2025-03-03 05:34:28,899 - INFO - Epoch:[611/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:34:32,216 - INFO - Epoch:[611/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.10 loss_cvh: 0.85
2025-03-03 05:34:33,196 - INFO - now the learning rate is: 1e-05
2025-03-03 05:35:10,097 - INFO - begin training stage: [612/805]
2025-03-03 05:35:10,098 - INFO - begin training stage: [612/805]
2025-03-03 05:35:14,581 - INFO - Epoch:[612/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:35:18,058 - INFO - Epoch:[612/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.14
2025-03-03 05:35:21,633 - INFO - Epoch:[612/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 05:35:25,142 - INFO - Epoch:[612/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:35:28,839 - INFO - Epoch:[612/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.16
2025-03-03 05:35:32,361 - INFO - Epoch:[612/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 05:35:36,013 - INFO - Epoch:[612/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 05:35:39,712 - INFO - Epoch:[612/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 05:35:42,881 - INFO - Epoch:[612/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.14 loss_cvh: 0.74
2025-03-03 05:35:43,852 - INFO - now the learning rate is: 1e-05
2025-03-03 05:36:20,705 - INFO - begin training stage: [613/805]
2025-03-03 05:36:20,705 - INFO - begin training stage: [613/805]
2025-03-03 05:36:25,099 - INFO - Epoch:[613/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 05:36:28,616 - INFO - Epoch:[613/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 05:36:32,152 - INFO - Epoch:[613/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 05:36:35,784 - INFO - Epoch:[613/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 05:36:39,648 - INFO - Epoch:[613/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 05:36:43,234 - INFO - Epoch:[613/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 05:36:46,759 - INFO - Epoch:[613/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 05:36:50,322 - INFO - Epoch:[613/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 05:36:53,604 - INFO - Epoch:[613/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.18 loss_cvh: 0.93
2025-03-03 05:36:54,606 - INFO - now the learning rate is: 1e-05
2025-03-03 05:37:36,290 - INFO - begin training stage: [614/805]
2025-03-03 05:37:36,290 - INFO - begin training stage: [614/805]
2025-03-03 05:37:40,933 - INFO - Epoch:[614/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 05:37:44,515 - INFO - Epoch:[614/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:37:48,085 - INFO - Epoch:[614/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 05:37:51,869 - INFO - Epoch:[614/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:37:55,545 - INFO - Epoch:[614/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 05:37:59,145 - INFO - Epoch:[614/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 05:38:02,820 - INFO - Epoch:[614/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 05:38:06,350 - INFO - Epoch:[614/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 05:38:09,888 - INFO - Epoch:[614/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.38 loss_cvh: 0.86
2025-03-03 05:38:10,992 - INFO - now the learning rate is: 1e-05
2025-03-03 05:38:52,668 - INFO - begin training stage: [615/805]
2025-03-03 05:38:52,669 - INFO - begin training stage: [615/805]
2025-03-03 05:38:57,362 - INFO - Epoch:[615/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 05:39:00,959 - INFO - Epoch:[615/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 05:39:04,706 - INFO - Epoch:[615/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:39:08,317 - INFO - Epoch:[615/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:39:11,886 - INFO - Epoch:[615/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 05:39:15,523 - INFO - Epoch:[615/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 05:39:19,293 - INFO - Epoch:[615/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 05:39:22,751 - INFO - Epoch:[615/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 05:39:26,176 - INFO - Epoch:[615/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.15 loss_cvh: 0.55
2025-03-03 05:39:27,172 - INFO - now the learning rate is: 1e-05
2025-03-03 05:40:06,809 - INFO - begin training stage: [616/805]
2025-03-03 05:40:06,809 - INFO - begin training stage: [616/805]
2025-03-03 05:40:11,761 - INFO - Epoch:[616/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 05:40:15,444 - INFO - Epoch:[616/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 05:40:19,770 - INFO - Epoch:[616/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 05:40:24,297 - INFO - Epoch:[616/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:40:27,905 - INFO - Epoch:[616/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 05:40:31,662 - INFO - Epoch:[616/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 05:40:35,759 - INFO - Epoch:[616/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.05
2025-03-03 05:40:39,362 - INFO - Epoch:[616/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 05:40:43,019 - INFO - Epoch:[616/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.28 loss_cvh: 0.63
2025-03-03 05:40:44,062 - INFO - now the learning rate is: 1e-05
2025-03-03 05:41:23,091 - INFO - begin training stage: [617/805]
2025-03-03 05:41:23,091 - INFO - begin training stage: [617/805]
2025-03-03 05:41:28,175 - INFO - Epoch:[617/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 05:41:31,770 - INFO - Epoch:[617/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:41:35,486 - INFO - Epoch:[617/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 05:41:39,215 - INFO - Epoch:[617/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:41:43,427 - INFO - Epoch:[617/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:41:47,263 - INFO - Epoch:[617/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:41:51,331 - INFO - Epoch:[617/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 05:41:55,365 - INFO - Epoch:[617/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 05:41:59,125 - INFO - Epoch:[617/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.16 loss_cvh: 0.79
2025-03-03 05:42:00,284 - INFO - now the learning rate is: 1e-05
2025-03-03 05:42:41,116 - INFO - begin training stage: [618/805]
2025-03-03 05:42:41,117 - INFO - begin training stage: [618/805]
2025-03-03 05:42:46,436 - INFO - Epoch:[618/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 05:42:50,460 - INFO - Epoch:[618/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:42:54,561 - INFO - Epoch:[618/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:42:58,093 - INFO - Epoch:[618/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:43:02,152 - INFO - Epoch:[618/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 05:43:06,188 - INFO - Epoch:[618/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 05:43:10,425 - INFO - Epoch:[618/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 05:43:14,098 - INFO - Epoch:[618/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 05:43:17,784 - INFO - Epoch:[618/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.30 loss_cvh: 0.92
2025-03-03 05:43:18,891 - INFO - now the learning rate is: 1e-05
2025-03-03 05:43:59,233 - INFO - begin training stage: [619/805]
2025-03-03 05:43:59,234 - INFO - begin training stage: [619/805]
2025-03-03 05:44:03,951 - INFO - Epoch:[619/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.22
2025-03-03 05:44:07,763 - INFO - Epoch:[619/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 05:44:11,620 - INFO - Epoch:[619/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:44:15,390 - INFO - Epoch:[619/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 05:44:18,914 - INFO - Epoch:[619/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:44:22,635 - INFO - Epoch:[619/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:44:26,476 - INFO - Epoch:[619/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 05:44:30,339 - INFO - Epoch:[619/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 05:44:33,927 - INFO - Epoch:[619/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.17 loss_cvh: 0.84
2025-03-03 05:44:35,078 - INFO - now the learning rate is: 1e-05
2025-03-03 05:45:40,871 - INFO - begin training stage: [620/805]
2025-03-03 05:45:40,871 - INFO - begin training stage: [620/805]
2025-03-03 05:45:47,084 - INFO - Epoch:[620/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 05:45:51,723 - INFO - Epoch:[620/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 05:45:56,099 - INFO - Epoch:[620/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 05:46:00,431 - INFO - Epoch:[620/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 05:46:04,975 - INFO - Epoch:[620/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 05:46:09,369 - INFO - Epoch:[620/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 05:46:13,747 - INFO - Epoch:[620/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 05:46:18,132 - INFO - Epoch:[620/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 05:46:22,237 - INFO - Epoch:[620/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.11 loss_cvh: 0.76
2025-03-03 05:46:23,655 - INFO - now the learning rate is: 1e-05
2025-03-03 05:47:32,494 - INFO - begin training stage: [621/805]
2025-03-03 05:47:32,496 - INFO - eval data number: 45600
2025-03-03 05:47:32,496 - INFO - loading eval data ......
2025-03-03 05:48:11,301 - INFO - retrieval costs: 25.567931413650513
2025-03-03 05:49:55,482 - INFO - hamming distance computation costs: 104.18113303184509
2025-03-03 05:50:03,459 - INFO - hamming ranking costs: 7.97705864906311
2025-03-03 05:50:03,459 - INFO - labels shape: (45600, 239)
2025-03-03 05:50:46,006 - INFO - similarity labels generation costs: 42.54709529876709
2025-03-03 05:50:46,088 - INFO - topK: 5:, map: 0.33911083333333336
2025-03-03 05:50:46,378 - INFO - topK: 20:, map: 0.2413341183347419
2025-03-03 05:50:46,955 - INFO - topK: 40:, map: 0.20877501127202208
2025-03-03 05:50:48,191 - INFO - topK: 60:, map: 0.18908866876720573
2025-03-03 05:50:50,318 - INFO - topK: 80:, map: 0.17475703540428142
2025-03-03 05:50:52,955 - INFO - topK: 100:, map: 0.16268412662062323
2025-03-03 05:50:54,499 - INFO - begin training stage: [621/805]
2025-03-03 05:51:00,378 - INFO - Epoch:[621/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 05:51:04,658 - INFO - Epoch:[621/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.14
2025-03-03 05:51:08,800 - INFO - Epoch:[621/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 05:51:12,595 - INFO - Epoch:[621/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 05:51:16,310 - INFO - Epoch:[621/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:51:20,099 - INFO - Epoch:[621/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.16
2025-03-03 05:51:23,709 - INFO - Epoch:[621/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 05:51:27,248 - INFO - Epoch:[621/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 05:51:30,607 - INFO - Epoch:[621/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.16 loss_cvh: 0.62
2025-03-03 05:51:31,616 - INFO - now the learning rate is: 1e-05
2025-03-03 05:52:07,113 - INFO - begin training stage: [622/805]
2025-03-03 05:52:07,113 - INFO - begin training stage: [622/805]
2025-03-03 05:52:11,618 - INFO - Epoch:[622/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 05:52:15,244 - INFO - Epoch:[622/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 05:52:19,012 - INFO - Epoch:[622/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:52:22,720 - INFO - Epoch:[622/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 05:52:26,418 - INFO - Epoch:[622/805] Step:[50/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 05:52:30,133 - INFO - Epoch:[622/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 05:52:33,714 - INFO - Epoch:[622/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 05:52:37,324 - INFO - Epoch:[622/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 05:52:40,681 - INFO - Epoch:[622/805] Step:[90/90] reconstruction_loss: 1.05 loss_vc: 1.33 loss_cvh: 0.72
2025-03-03 05:52:41,674 - INFO - now the learning rate is: 1e-05
2025-03-03 05:53:17,228 - INFO - begin training stage: [623/805]
2025-03-03 05:53:17,229 - INFO - begin training stage: [623/805]
2025-03-03 05:53:21,845 - INFO - Epoch:[623/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 05:53:25,520 - INFO - Epoch:[623/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 05:53:29,375 - INFO - Epoch:[623/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 05:53:32,945 - INFO - Epoch:[623/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 05:53:36,630 - INFO - Epoch:[623/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 05:53:40,231 - INFO - Epoch:[623/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:53:43,992 - INFO - Epoch:[623/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 05:53:47,643 - INFO - Epoch:[623/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 05:53:50,879 - INFO - Epoch:[623/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.20 loss_cvh: 0.75
2025-03-03 05:53:51,845 - INFO - now the learning rate is: 1e-05
2025-03-03 05:54:27,500 - INFO - begin training stage: [624/805]
2025-03-03 05:54:27,500 - INFO - begin training stage: [624/805]
2025-03-03 05:54:33,030 - INFO - Epoch:[624/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 05:54:36,932 - INFO - Epoch:[624/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 05:54:40,619 - INFO - Epoch:[624/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:54:44,264 - INFO - Epoch:[624/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 05:54:47,807 - INFO - Epoch:[624/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:54:51,404 - INFO - Epoch:[624/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:54:55,031 - INFO - Epoch:[624/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 05:54:58,531 - INFO - Epoch:[624/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 05:55:01,821 - INFO - Epoch:[624/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.16 loss_cvh: 0.72
2025-03-03 05:55:02,810 - INFO - now the learning rate is: 1e-05
2025-03-03 05:55:43,008 - INFO - begin training stage: [625/805]
2025-03-03 05:55:43,008 - INFO - begin training stage: [625/805]
2025-03-03 05:55:47,435 - INFO - Epoch:[625/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 05:55:51,171 - INFO - Epoch:[625/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:55:54,765 - INFO - Epoch:[625/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 05:55:58,380 - INFO - Epoch:[625/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 05:56:02,003 - INFO - Epoch:[625/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:56:05,686 - INFO - Epoch:[625/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 05:56:09,279 - INFO - Epoch:[625/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:56:12,804 - INFO - Epoch:[625/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 05:56:16,117 - INFO - Epoch:[625/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.17 loss_cvh: 0.60
2025-03-03 05:56:17,071 - INFO - now the learning rate is: 1e-05
2025-03-03 05:56:59,630 - INFO - begin training stage: [626/805]
2025-03-03 05:56:59,631 - INFO - begin training stage: [626/805]
2025-03-03 05:57:04,584 - INFO - Epoch:[626/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 05:57:08,490 - INFO - Epoch:[626/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 05:57:12,192 - INFO - Epoch:[626/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 05:57:15,838 - INFO - Epoch:[626/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.03
2025-03-03 05:57:19,516 - INFO - Epoch:[626/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.05
2025-03-03 05:57:23,188 - INFO - Epoch:[626/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 05:57:26,838 - INFO - Epoch:[626/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.13
2025-03-03 05:57:30,458 - INFO - Epoch:[626/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 05:57:33,829 - INFO - Epoch:[626/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.12 loss_cvh: 0.70
2025-03-03 05:57:34,829 - INFO - now the learning rate is: 1e-05
2025-03-03 05:58:18,269 - INFO - begin training stage: [627/805]
2025-03-03 05:58:18,269 - INFO - begin training stage: [627/805]
2025-03-03 05:58:22,945 - INFO - Epoch:[627/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 05:58:26,586 - INFO - Epoch:[627/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:58:30,267 - INFO - Epoch:[627/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 05:58:33,799 - INFO - Epoch:[627/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:58:37,624 - INFO - Epoch:[627/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.03
2025-03-03 05:58:41,172 - INFO - Epoch:[627/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 05:58:44,712 - INFO - Epoch:[627/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 05:58:48,279 - INFO - Epoch:[627/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 05:58:51,562 - INFO - Epoch:[627/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.12 loss_cvh: 0.86
2025-03-03 05:58:52,506 - INFO - now the learning rate is: 1e-05
2025-03-03 05:59:40,091 - INFO - begin training stage: [628/805]
2025-03-03 05:59:40,091 - INFO - begin training stage: [628/805]
2025-03-03 05:59:44,689 - INFO - Epoch:[628/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 05:59:48,304 - INFO - Epoch:[628/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 05:59:52,322 - INFO - Epoch:[628/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 05:59:56,248 - INFO - Epoch:[628/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 05:59:59,767 - INFO - Epoch:[628/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:00:03,424 - INFO - Epoch:[628/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:00:06,964 - INFO - Epoch:[628/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:00:10,580 - INFO - Epoch:[628/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:00:13,840 - INFO - Epoch:[628/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.22 loss_cvh: 0.76
2025-03-03 06:00:14,757 - INFO - now the learning rate is: 1e-05
2025-03-03 06:01:06,261 - INFO - begin training stage: [629/805]
2025-03-03 06:01:06,261 - INFO - begin training stage: [629/805]
2025-03-03 06:01:10,686 - INFO - Epoch:[629/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:01:14,818 - INFO - Epoch:[629/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.15
2025-03-03 06:01:18,308 - INFO - Epoch:[629/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:01:22,062 - INFO - Epoch:[629/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 06:01:25,663 - INFO - Epoch:[629/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 06:01:29,525 - INFO - Epoch:[629/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 06:01:33,241 - INFO - Epoch:[629/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:01:37,147 - INFO - Epoch:[629/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:01:40,729 - INFO - Epoch:[629/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.24 loss_cvh: 0.75
2025-03-03 06:01:41,925 - INFO - now the learning rate is: 1e-05
2025-03-03 06:02:50,293 - INFO - begin training stage: [630/805]
2025-03-03 06:02:50,294 - INFO - begin training stage: [630/805]
2025-03-03 06:02:56,796 - INFO - Epoch:[630/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 06:03:01,472 - INFO - Epoch:[630/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:03:06,089 - INFO - Epoch:[630/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 06:03:10,621 - INFO - Epoch:[630/805] Step:[40/90] reconstruction_loss: 1.11 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 06:03:15,341 - INFO - Epoch:[630/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 06:03:19,942 - INFO - Epoch:[630/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 06:03:24,960 - INFO - Epoch:[630/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:03:29,554 - INFO - Epoch:[630/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:03:33,257 - INFO - Epoch:[630/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.22 loss_cvh: 0.90
2025-03-03 06:03:34,599 - INFO - now the learning rate is: 1e-05
2025-03-03 06:04:43,329 - INFO - begin training stage: [631/805]
2025-03-03 06:04:43,331 - INFO - eval data number: 45600
2025-03-03 06:04:43,331 - INFO - loading eval data ......
2025-03-03 06:05:21,417 - INFO - retrieval costs: 24.3740451335907
2025-03-03 06:06:56,886 - INFO - hamming distance computation costs: 95.4689872264862
2025-03-03 06:07:03,492 - INFO - hamming ranking costs: 6.6060545444488525
2025-03-03 06:07:03,492 - INFO - labels shape: (45600, 239)
2025-03-03 06:07:41,191 - INFO - similarity labels generation costs: 37.699058055877686
2025-03-03 06:07:41,278 - INFO - topK: 5:, map: 0.3400008333333333
2025-03-03 06:07:41,552 - INFO - topK: 20:, map: 0.24349665332340306
2025-03-03 06:07:42,079 - INFO - topK: 40:, map: 0.2103119846795048
2025-03-03 06:07:42,968 - INFO - topK: 60:, map: 0.19090389048996773
2025-03-03 06:07:44,160 - INFO - topK: 80:, map: 0.17644626518505327
2025-03-03 06:07:45,536 - INFO - topK: 100:, map: 0.164385578970827
2025-03-03 06:07:46,773 - INFO - begin training stage: [631/805]
2025-03-03 06:07:51,401 - INFO - Epoch:[631/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 06:07:55,020 - INFO - Epoch:[631/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:07:58,679 - INFO - Epoch:[631/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:08:02,396 - INFO - Epoch:[631/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.06
2025-03-03 06:08:06,154 - INFO - Epoch:[631/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:08:09,836 - INFO - Epoch:[631/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.16
2025-03-03 06:08:13,432 - INFO - Epoch:[631/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:08:16,972 - INFO - Epoch:[631/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 06:08:20,208 - INFO - Epoch:[631/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.10 loss_cvh: 0.53
2025-03-03 06:08:21,146 - INFO - now the learning rate is: 1e-05
2025-03-03 06:08:55,602 - INFO - begin training stage: [632/805]
2025-03-03 06:08:55,602 - INFO - begin training stage: [632/805]
2025-03-03 06:09:00,371 - INFO - Epoch:[632/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 06:09:04,040 - INFO - Epoch:[632/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 06:09:07,652 - INFO - Epoch:[632/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 06:09:11,260 - INFO - Epoch:[632/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 06:09:14,872 - INFO - Epoch:[632/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 06:09:18,456 - INFO - Epoch:[632/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 06:09:22,071 - INFO - Epoch:[632/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:09:25,740 - INFO - Epoch:[632/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 06:09:29,098 - INFO - Epoch:[632/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.25 loss_cvh: 0.72
2025-03-03 06:09:30,405 - INFO - now the learning rate is: 1e-05
2025-03-03 06:10:06,620 - INFO - begin training stage: [633/805]
2025-03-03 06:10:06,620 - INFO - begin training stage: [633/805]
2025-03-03 06:10:11,313 - INFO - Epoch:[633/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 06:10:14,980 - INFO - Epoch:[633/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:10:18,622 - INFO - Epoch:[633/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:10:22,243 - INFO - Epoch:[633/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 06:10:25,904 - INFO - Epoch:[633/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:10:29,379 - INFO - Epoch:[633/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.08
2025-03-03 06:10:33,043 - INFO - Epoch:[633/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 06:10:36,612 - INFO - Epoch:[633/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:10:39,941 - INFO - Epoch:[633/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.22 loss_cvh: 0.93
2025-03-03 06:10:41,247 - INFO - now the learning rate is: 1e-05
2025-03-03 06:11:15,447 - INFO - begin training stage: [634/805]
2025-03-03 06:11:15,448 - INFO - begin training stage: [634/805]
2025-03-03 06:11:19,808 - INFO - Epoch:[634/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:11:23,406 - INFO - Epoch:[634/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 06:11:26,959 - INFO - Epoch:[634/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:11:30,539 - INFO - Epoch:[634/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 06:11:34,099 - INFO - Epoch:[634/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 06:11:37,612 - INFO - Epoch:[634/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 06:11:41,130 - INFO - Epoch:[634/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 06:11:44,628 - INFO - Epoch:[634/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 06:11:47,924 - INFO - Epoch:[634/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.24 loss_cvh: 0.83
2025-03-03 06:11:49,265 - INFO - now the learning rate is: 1e-05
2025-03-03 06:12:23,529 - INFO - begin training stage: [635/805]
2025-03-03 06:12:23,529 - INFO - begin training stage: [635/805]
2025-03-03 06:12:28,010 - INFO - Epoch:[635/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 06:12:31,562 - INFO - Epoch:[635/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 06:12:35,026 - INFO - Epoch:[635/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 06:12:38,495 - INFO - Epoch:[635/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 06:12:41,853 - INFO - Epoch:[635/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.09
2025-03-03 06:12:45,245 - INFO - Epoch:[635/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 06:12:48,640 - INFO - Epoch:[635/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:12:52,019 - INFO - Epoch:[635/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:12:55,183 - INFO - Epoch:[635/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.26 loss_cvh: 0.91
2025-03-03 06:12:56,133 - INFO - now the learning rate is: 1e-05
2025-03-03 06:13:29,462 - INFO - begin training stage: [636/805]
2025-03-03 06:13:29,463 - INFO - begin training stage: [636/805]
2025-03-03 06:13:33,694 - INFO - Epoch:[636/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:13:37,085 - INFO - Epoch:[636/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 06:13:40,501 - INFO - Epoch:[636/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:13:43,911 - INFO - Epoch:[636/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 06:13:47,282 - INFO - Epoch:[636/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.18
2025-03-03 06:13:50,778 - INFO - Epoch:[636/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:13:54,320 - INFO - Epoch:[636/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:13:57,904 - INFO - Epoch:[636/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 06:14:01,071 - INFO - Epoch:[636/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.10 loss_cvh: 0.76
2025-03-03 06:14:01,997 - INFO - now the learning rate is: 1e-05
2025-03-03 06:14:35,580 - INFO - begin training stage: [637/805]
2025-03-03 06:14:35,580 - INFO - begin training stage: [637/805]
2025-03-03 06:14:39,917 - INFO - Epoch:[637/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 06:14:43,372 - INFO - Epoch:[637/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:14:46,813 - INFO - Epoch:[637/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 06:14:50,356 - INFO - Epoch:[637/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.33 loss_cvh: 3.12
2025-03-03 06:14:53,729 - INFO - Epoch:[637/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:14:57,210 - INFO - Epoch:[637/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 06:15:00,633 - INFO - Epoch:[637/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:15:04,114 - INFO - Epoch:[637/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 06:15:07,377 - INFO - Epoch:[637/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.22 loss_cvh: 0.71
2025-03-03 06:15:08,310 - INFO - now the learning rate is: 1e-05
2025-03-03 06:15:41,792 - INFO - begin training stage: [638/805]
2025-03-03 06:15:41,792 - INFO - begin training stage: [638/805]
2025-03-03 06:15:46,132 - INFO - Epoch:[638/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 06:15:49,633 - INFO - Epoch:[638/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.04
2025-03-03 06:15:53,060 - INFO - Epoch:[638/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:15:56,529 - INFO - Epoch:[638/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 06:15:59,948 - INFO - Epoch:[638/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 06:16:03,327 - INFO - Epoch:[638/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:16:06,757 - INFO - Epoch:[638/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:16:10,125 - INFO - Epoch:[638/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:16:13,291 - INFO - Epoch:[638/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.27 loss_cvh: 0.76
2025-03-03 06:16:14,203 - INFO - now the learning rate is: 1e-05
2025-03-03 06:16:47,924 - INFO - begin training stage: [639/805]
2025-03-03 06:16:47,925 - INFO - begin training stage: [639/805]
2025-03-03 06:16:52,327 - INFO - Epoch:[639/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:16:55,905 - INFO - Epoch:[639/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 06:17:00,437 - INFO - Epoch:[639/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 06:17:05,254 - INFO - Epoch:[639/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:17:10,368 - INFO - Epoch:[639/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:17:14,935 - INFO - Epoch:[639/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 06:17:19,433 - INFO - Epoch:[639/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:17:24,563 - INFO - Epoch:[639/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:17:29,029 - INFO - Epoch:[639/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.28 loss_cvh: 0.69
2025-03-03 06:17:30,412 - INFO - now the learning rate is: 1e-05
2025-03-03 06:18:11,202 - INFO - begin training stage: [640/805]
2025-03-03 06:18:11,202 - INFO - begin training stage: [640/805]
2025-03-03 06:18:15,140 - INFO - Epoch:[640/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.09
2025-03-03 06:18:18,388 - INFO - Epoch:[640/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:18:21,651 - INFO - Epoch:[640/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:18:24,898 - INFO - Epoch:[640/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:18:28,168 - INFO - Epoch:[640/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 06:18:31,426 - INFO - Epoch:[640/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:18:34,742 - INFO - Epoch:[640/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 06:18:38,659 - INFO - Epoch:[640/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 06:18:43,053 - INFO - Epoch:[640/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.10 loss_cvh: 0.69
2025-03-03 06:18:44,391 - INFO - now the learning rate is: 1e-05
2025-03-03 06:19:43,808 - INFO - begin training stage: [641/805]
2025-03-03 06:19:43,810 - INFO - eval data number: 45600
2025-03-03 06:19:43,810 - INFO - loading eval data ......
2025-03-03 06:20:13,430 - INFO - retrieval costs: 18.45163655281067
2025-03-03 06:21:22,046 - INFO - hamming distance computation costs: 68.6153392791748
2025-03-03 06:21:27,486 - INFO - hamming ranking costs: 5.440149784088135
2025-03-03 06:21:27,486 - INFO - labels shape: (45600, 239)
2025-03-03 06:22:02,638 - INFO - similarity labels generation costs: 35.1518816947937
2025-03-03 06:22:02,710 - INFO - topK: 5:, map: 0.3433233333333333
2025-03-03 06:22:02,961 - INFO - topK: 20:, map: 0.2451924820975271
2025-03-03 06:22:03,453 - INFO - topK: 40:, map: 0.21025702107283067
2025-03-03 06:22:04,178 - INFO - topK: 60:, map: 0.1905023217758723
2025-03-03 06:22:05,138 - INFO - topK: 80:, map: 0.1755309927649372
2025-03-03 06:22:06,330 - INFO - topK: 100:, map: 0.1629390925728902
2025-03-03 06:22:07,656 - INFO - begin training stage: [641/805]
2025-03-03 06:22:12,056 - INFO - Epoch:[641/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:22:15,472 - INFO - Epoch:[641/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 06:22:18,955 - INFO - Epoch:[641/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 06:22:22,382 - INFO - Epoch:[641/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 06:22:25,826 - INFO - Epoch:[641/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.14
2025-03-03 06:22:29,267 - INFO - Epoch:[641/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:22:32,618 - INFO - Epoch:[641/805] Step:[70/90] reconstruction_loss: 1.11 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 06:22:36,068 - INFO - Epoch:[641/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.03
2025-03-03 06:22:39,269 - INFO - Epoch:[641/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.26 loss_cvh: 0.83
2025-03-03 06:22:40,286 - INFO - now the learning rate is: 1e-05
2025-03-03 06:23:14,646 - INFO - begin training stage: [642/805]
2025-03-03 06:23:14,647 - INFO - begin training stage: [642/805]
2025-03-03 06:23:18,925 - INFO - Epoch:[642/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 06:23:22,359 - INFO - Epoch:[642/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:23:25,746 - INFO - Epoch:[642/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 06:23:29,240 - INFO - Epoch:[642/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:23:32,633 - INFO - Epoch:[642/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.07
2025-03-03 06:23:36,029 - INFO - Epoch:[642/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.33 loss_cvh: 3.06
2025-03-03 06:23:39,456 - INFO - Epoch:[642/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 06:23:42,824 - INFO - Epoch:[642/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.10
2025-03-03 06:23:45,962 - INFO - Epoch:[642/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.19 loss_cvh: 0.62
2025-03-03 06:23:46,901 - INFO - now the learning rate is: 1e-05
2025-03-03 06:24:20,577 - INFO - begin training stage: [643/805]
2025-03-03 06:24:20,578 - INFO - begin training stage: [643/805]
2025-03-03 06:24:24,847 - INFO - Epoch:[643/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 06:24:28,209 - INFO - Epoch:[643/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 06:24:31,622 - INFO - Epoch:[643/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 06:24:35,252 - INFO - Epoch:[643/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:24:38,611 - INFO - Epoch:[643/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 06:24:42,007 - INFO - Epoch:[643/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:24:45,525 - INFO - Epoch:[643/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 06:24:48,994 - INFO - Epoch:[643/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 06:24:52,169 - INFO - Epoch:[643/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.26 loss_cvh: 0.78
2025-03-03 06:24:53,119 - INFO - now the learning rate is: 1e-05
2025-03-03 06:25:27,111 - INFO - begin training stage: [644/805]
2025-03-03 06:25:27,112 - INFO - begin training stage: [644/805]
2025-03-03 06:25:31,358 - INFO - Epoch:[644/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 06:25:34,748 - INFO - Epoch:[644/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 06:25:38,150 - INFO - Epoch:[644/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 06:25:41,587 - INFO - Epoch:[644/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:25:44,986 - INFO - Epoch:[644/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 06:25:48,433 - INFO - Epoch:[644/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 06:25:51,906 - INFO - Epoch:[644/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:25:55,376 - INFO - Epoch:[644/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 06:25:58,581 - INFO - Epoch:[644/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.30 loss_cvh: 0.88
2025-03-03 06:25:59,529 - INFO - now the learning rate is: 1e-05
2025-03-03 06:26:32,741 - INFO - begin training stage: [645/805]
2025-03-03 06:26:32,742 - INFO - begin training stage: [645/805]
2025-03-03 06:26:37,217 - INFO - Epoch:[645/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.04
2025-03-03 06:26:40,772 - INFO - Epoch:[645/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 06:26:44,285 - INFO - Epoch:[645/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.06
2025-03-03 06:26:47,792 - INFO - Epoch:[645/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:26:51,420 - INFO - Epoch:[645/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 06:26:54,922 - INFO - Epoch:[645/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 06:26:58,426 - INFO - Epoch:[645/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 06:27:01,931 - INFO - Epoch:[645/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 06:27:05,153 - INFO - Epoch:[645/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.06 loss_cvh: 0.75
2025-03-03 06:27:06,084 - INFO - now the learning rate is: 1e-05
2025-03-03 06:27:39,741 - INFO - begin training stage: [646/805]
2025-03-03 06:27:39,741 - INFO - begin training stage: [646/805]
2025-03-03 06:27:43,978 - INFO - Epoch:[646/805] Step:[10/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:27:47,389 - INFO - Epoch:[646/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.03
2025-03-03 06:27:50,800 - INFO - Epoch:[646/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:27:54,319 - INFO - Epoch:[646/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 06:27:57,712 - INFO - Epoch:[646/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:28:01,080 - INFO - Epoch:[646/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 06:28:04,419 - INFO - Epoch:[646/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:28:07,746 - INFO - Epoch:[646/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:28:10,970 - INFO - Epoch:[646/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.28 loss_cvh: 0.73
2025-03-03 06:28:11,884 - INFO - now the learning rate is: 1e-05
2025-03-03 06:28:45,020 - INFO - begin training stage: [647/805]
2025-03-03 06:28:45,020 - INFO - begin training stage: [647/805]
2025-03-03 06:28:49,216 - INFO - Epoch:[647/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:28:52,595 - INFO - Epoch:[647/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 06:28:55,997 - INFO - Epoch:[647/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:28:59,444 - INFO - Epoch:[647/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 06:29:02,842 - INFO - Epoch:[647/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.15
2025-03-03 06:29:06,265 - INFO - Epoch:[647/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:29:09,683 - INFO - Epoch:[647/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:29:13,151 - INFO - Epoch:[647/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 06:29:16,332 - INFO - Epoch:[647/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.16 loss_cvh: 0.65
2025-03-03 06:29:17,269 - INFO - now the learning rate is: 1e-05
2025-03-03 06:29:51,490 - INFO - begin training stage: [648/805]
2025-03-03 06:29:51,490 - INFO - begin training stage: [648/805]
2025-03-03 06:29:55,791 - INFO - Epoch:[648/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 06:29:59,250 - INFO - Epoch:[648/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:30:02,811 - INFO - Epoch:[648/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 06:30:06,251 - INFO - Epoch:[648/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 06:30:09,685 - INFO - Epoch:[648/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 06:30:13,144 - INFO - Epoch:[648/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:30:16,534 - INFO - Epoch:[648/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 06:30:19,943 - INFO - Epoch:[648/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:30:23,055 - INFO - Epoch:[648/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.08 loss_cvh: 0.76
2025-03-03 06:30:24,078 - INFO - now the learning rate is: 1e-05
2025-03-03 06:31:28,237 - INFO - begin training stage: [649/805]
2025-03-03 06:31:28,238 - INFO - begin training stage: [649/805]
2025-03-03 06:31:34,773 - INFO - Epoch:[649/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:31:39,334 - INFO - Epoch:[649/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 06:31:44,305 - INFO - Epoch:[649/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 06:31:48,114 - INFO - Epoch:[649/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 06:31:51,429 - INFO - Epoch:[649/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 06:31:54,838 - INFO - Epoch:[649/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:31:58,225 - INFO - Epoch:[649/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:32:01,615 - INFO - Epoch:[649/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:32:04,814 - INFO - Epoch:[649/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.19 loss_cvh: 0.68
2025-03-03 06:32:05,762 - INFO - now the learning rate is: 1e-05
2025-03-03 06:32:38,802 - INFO - begin training stage: [650/805]
2025-03-03 06:32:38,802 - INFO - begin training stage: [650/805]
2025-03-03 06:32:43,058 - INFO - Epoch:[650/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 06:32:46,426 - INFO - Epoch:[650/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 06:32:49,636 - INFO - Epoch:[650/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:32:52,909 - INFO - Epoch:[650/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:32:56,174 - INFO - Epoch:[650/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 06:32:59,444 - INFO - Epoch:[650/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:33:02,734 - INFO - Epoch:[650/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:33:06,009 - INFO - Epoch:[650/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:33:09,018 - INFO - Epoch:[650/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.39 loss_cvh: 0.82
2025-03-03 06:33:09,931 - INFO - now the learning rate is: 1e-05
2025-03-03 06:34:16,218 - INFO - begin training stage: [651/805]
2025-03-03 06:34:16,220 - INFO - eval data number: 45600
2025-03-03 06:34:16,220 - INFO - loading eval data ......
2025-03-03 06:34:47,509 - INFO - retrieval costs: 18.689688444137573
2025-03-03 06:35:57,089 - INFO - hamming distance computation costs: 69.58027935028076
2025-03-03 06:36:03,119 - INFO - hamming ranking costs: 6.029811859130859
2025-03-03 06:36:03,119 - INFO - labels shape: (45600, 239)
2025-03-03 06:36:37,685 - INFO - similarity labels generation costs: 34.565900564193726
2025-03-03 06:36:37,755 - INFO - topK: 5:, map: 0.340025
2025-03-03 06:36:38,008 - INFO - topK: 20:, map: 0.24322201658264977
2025-03-03 06:36:38,513 - INFO - topK: 40:, map: 0.2098084590381527
2025-03-03 06:36:39,232 - INFO - topK: 60:, map: 0.19004983361202202
2025-03-03 06:36:40,385 - INFO - topK: 80:, map: 0.17547482366506478
2025-03-03 06:36:41,935 - INFO - topK: 100:, map: 0.16326807635482254
2025-03-03 06:36:43,062 - INFO - begin training stage: [651/805]
2025-03-03 06:36:47,514 - INFO - Epoch:[651/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 06:36:50,991 - INFO - Epoch:[651/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.09
2025-03-03 06:36:54,426 - INFO - Epoch:[651/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:36:57,833 - INFO - Epoch:[651/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:37:01,264 - INFO - Epoch:[651/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 06:37:04,696 - INFO - Epoch:[651/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:37:08,204 - INFO - Epoch:[651/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:37:11,692 - INFO - Epoch:[651/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 06:37:14,837 - INFO - Epoch:[651/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.13 loss_cvh: 0.58
2025-03-03 06:37:15,760 - INFO - now the learning rate is: 1e-05
2025-03-03 06:37:48,908 - INFO - begin training stage: [652/805]
2025-03-03 06:37:48,908 - INFO - begin training stage: [652/805]
2025-03-03 06:37:53,255 - INFO - Epoch:[652/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:37:56,873 - INFO - Epoch:[652/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 06:38:00,361 - INFO - Epoch:[652/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:38:03,892 - INFO - Epoch:[652/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 06:38:07,480 - INFO - Epoch:[652/805] Step:[50/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:38:11,020 - INFO - Epoch:[652/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:38:14,545 - INFO - Epoch:[652/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:38:18,078 - INFO - Epoch:[652/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 06:38:21,247 - INFO - Epoch:[652/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.14 loss_cvh: 0.75
2025-03-03 06:38:22,307 - INFO - now the learning rate is: 1e-05
2025-03-03 06:38:55,557 - INFO - begin training stage: [653/805]
2025-03-03 06:38:55,557 - INFO - begin training stage: [653/805]
2025-03-03 06:38:59,859 - INFO - Epoch:[653/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 06:39:03,279 - INFO - Epoch:[653/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 06:39:06,667 - INFO - Epoch:[653/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 06:39:10,052 - INFO - Epoch:[653/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.13
2025-03-03 06:39:13,467 - INFO - Epoch:[653/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 06:39:16,859 - INFO - Epoch:[653/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 06:39:20,318 - INFO - Epoch:[653/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 06:39:23,751 - INFO - Epoch:[653/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:39:26,861 - INFO - Epoch:[653/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.24 loss_cvh: 0.86
2025-03-03 06:39:27,791 - INFO - now the learning rate is: 1e-05
2025-03-03 06:40:00,875 - INFO - begin training stage: [654/805]
2025-03-03 06:40:00,875 - INFO - begin training stage: [654/805]
2025-03-03 06:40:05,260 - INFO - Epoch:[654/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.04
2025-03-03 06:40:08,668 - INFO - Epoch:[654/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:40:12,055 - INFO - Epoch:[654/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:40:15,434 - INFO - Epoch:[654/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:40:18,827 - INFO - Epoch:[654/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:40:22,239 - INFO - Epoch:[654/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 06:40:25,545 - INFO - Epoch:[654/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:40:28,926 - INFO - Epoch:[654/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 06:40:32,152 - INFO - Epoch:[654/805] Step:[90/90] reconstruction_loss: 1.04 loss_vc: 1.21 loss_cvh: 0.68
2025-03-03 06:40:33,111 - INFO - now the learning rate is: 1e-05
2025-03-03 06:41:07,531 - INFO - begin training stage: [655/805]
2025-03-03 06:41:07,531 - INFO - begin training stage: [655/805]
2025-03-03 06:41:11,823 - INFO - Epoch:[655/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:41:15,226 - INFO - Epoch:[655/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 06:41:18,585 - INFO - Epoch:[655/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:41:22,014 - INFO - Epoch:[655/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:41:25,498 - INFO - Epoch:[655/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:41:28,891 - INFO - Epoch:[655/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 06:41:32,187 - INFO - Epoch:[655/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:41:35,638 - INFO - Epoch:[655/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:41:38,707 - INFO - Epoch:[655/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.20 loss_cvh: 0.76
2025-03-03 06:41:39,653 - INFO - now the learning rate is: 1e-05
2025-03-03 06:42:12,912 - INFO - begin training stage: [656/805]
2025-03-03 06:42:12,912 - INFO - begin training stage: [656/805]
2025-03-03 06:42:17,296 - INFO - Epoch:[656/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:42:20,882 - INFO - Epoch:[656/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 06:42:24,395 - INFO - Epoch:[656/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 06:42:28,031 - INFO - Epoch:[656/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:42:31,464 - INFO - Epoch:[656/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 06:42:34,832 - INFO - Epoch:[656/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:42:38,178 - INFO - Epoch:[656/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:42:41,488 - INFO - Epoch:[656/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 06:42:44,603 - INFO - Epoch:[656/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.15 loss_cvh: 0.76
2025-03-03 06:42:45,565 - INFO - now the learning rate is: 1e-05
2025-03-03 06:43:18,797 - INFO - begin training stage: [657/805]
2025-03-03 06:43:18,798 - INFO - begin training stage: [657/805]
2025-03-03 06:43:23,279 - INFO - Epoch:[657/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 06:43:26,744 - INFO - Epoch:[657/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 06:43:30,157 - INFO - Epoch:[657/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:43:33,507 - INFO - Epoch:[657/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 06:43:36,870 - INFO - Epoch:[657/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 06:43:40,278 - INFO - Epoch:[657/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 06:43:43,689 - INFO - Epoch:[657/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 06:43:47,044 - INFO - Epoch:[657/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:43:50,158 - INFO - Epoch:[657/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.26 loss_cvh: 0.72
2025-03-03 06:43:51,118 - INFO - now the learning rate is: 1e-05
2025-03-03 06:44:24,415 - INFO - begin training stage: [658/805]
2025-03-03 06:44:24,415 - INFO - begin training stage: [658/805]
2025-03-03 06:44:28,675 - INFO - Epoch:[658/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 06:44:32,085 - INFO - Epoch:[658/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:44:35,482 - INFO - Epoch:[658/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 06:44:38,781 - INFO - Epoch:[658/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 06:44:42,085 - INFO - Epoch:[658/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 06:44:45,397 - INFO - Epoch:[658/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:44:48,838 - INFO - Epoch:[658/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 06:44:52,200 - INFO - Epoch:[658/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 06:44:56,323 - INFO - Epoch:[658/805] Step:[90/90] reconstruction_loss: 1.05 loss_vc: 1.13 loss_cvh: 0.81
2025-03-03 06:44:57,801 - INFO - now the learning rate is: 1e-05
2025-03-03 06:46:05,587 - INFO - begin training stage: [659/805]
2025-03-03 06:46:05,588 - INFO - begin training stage: [659/805]
2025-03-03 06:46:10,360 - INFO - Epoch:[659/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 06:46:13,847 - INFO - Epoch:[659/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 06:46:17,277 - INFO - Epoch:[659/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:46:20,728 - INFO - Epoch:[659/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 06:46:24,162 - INFO - Epoch:[659/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 06:46:27,624 - INFO - Epoch:[659/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 06:46:31,050 - INFO - Epoch:[659/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:46:34,614 - INFO - Epoch:[659/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 06:46:37,909 - INFO - Epoch:[659/805] Step:[90/90] reconstruction_loss: 1.01 loss_vc: 1.22 loss_cvh: 0.87
2025-03-03 06:46:38,828 - INFO - now the learning rate is: 1e-05
2025-03-03 06:47:11,430 - INFO - begin training stage: [660/805]
2025-03-03 06:47:11,430 - INFO - begin training stage: [660/805]
2025-03-03 06:47:15,562 - INFO - Epoch:[660/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 06:47:19,532 - INFO - Epoch:[660/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 06:47:24,156 - INFO - Epoch:[660/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:47:28,763 - INFO - Epoch:[660/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 06:47:33,860 - INFO - Epoch:[660/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 06:47:38,716 - INFO - Epoch:[660/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 06:47:43,904 - INFO - Epoch:[660/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:47:48,670 - INFO - Epoch:[660/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 06:47:53,177 - INFO - Epoch:[660/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.29 loss_cvh: 0.77
2025-03-03 06:47:54,627 - INFO - now the learning rate is: 1e-05
2025-03-03 06:48:35,833 - INFO - begin training stage: [661/805]
2025-03-03 06:48:35,834 - INFO - eval data number: 45600
2025-03-03 06:48:35,834 - INFO - loading eval data ......
2025-03-03 06:49:05,899 - INFO - retrieval costs: 18.71709680557251
2025-03-03 06:50:22,035 - INFO - hamming distance computation costs: 76.13635158538818
2025-03-03 06:50:28,026 - INFO - hamming ranking costs: 5.990830659866333
2025-03-03 06:50:28,026 - INFO - labels shape: (45600, 239)
2025-03-03 06:51:03,570 - INFO - similarity labels generation costs: 35.543866872787476
2025-03-03 06:51:03,659 - INFO - topK: 5:, map: 0.33808750000000004
2025-03-03 06:51:03,909 - INFO - topK: 20:, map: 0.24321572464831995
2025-03-03 06:51:04,402 - INFO - topK: 40:, map: 0.20929875472594928
2025-03-03 06:51:05,128 - INFO - topK: 60:, map: 0.18943556901564274
2025-03-03 06:51:06,093 - INFO - topK: 80:, map: 0.17503211759504186
2025-03-03 06:51:07,301 - INFO - topK: 100:, map: 0.16275069957848878
2025-03-03 06:51:08,529 - INFO - begin training stage: [661/805]
2025-03-03 06:51:13,115 - INFO - Epoch:[661/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:51:16,644 - INFO - Epoch:[661/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 06:51:20,022 - INFO - Epoch:[661/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:51:23,404 - INFO - Epoch:[661/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.01
2025-03-03 06:51:26,760 - INFO - Epoch:[661/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 06:51:30,258 - INFO - Epoch:[661/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 06:51:33,851 - INFO - Epoch:[661/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 06:51:37,304 - INFO - Epoch:[661/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.03
2025-03-03 06:51:40,444 - INFO - Epoch:[661/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.32 loss_cvh: 0.81
2025-03-03 06:51:41,387 - INFO - now the learning rate is: 1e-05
2025-03-03 06:52:16,712 - INFO - begin training stage: [662/805]
2025-03-03 06:52:16,713 - INFO - begin training stage: [662/805]
2025-03-03 06:52:21,018 - INFO - Epoch:[662/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 06:52:24,458 - INFO - Epoch:[662/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 06:52:27,893 - INFO - Epoch:[662/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:52:31,310 - INFO - Epoch:[662/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:52:34,746 - INFO - Epoch:[662/805] Step:[50/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 06:52:38,238 - INFO - Epoch:[662/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 06:52:41,675 - INFO - Epoch:[662/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 06:52:45,077 - INFO - Epoch:[662/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 06:52:48,222 - INFO - Epoch:[662/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.26 loss_cvh: 0.70
2025-03-03 06:52:49,183 - INFO - now the learning rate is: 1e-05
2025-03-03 06:53:22,305 - INFO - begin training stage: [663/805]
2025-03-03 06:53:22,305 - INFO - begin training stage: [663/805]
2025-03-03 06:53:26,560 - INFO - Epoch:[663/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.03
2025-03-03 06:53:29,971 - INFO - Epoch:[663/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:53:33,371 - INFO - Epoch:[663/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 06:53:36,741 - INFO - Epoch:[663/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:53:40,320 - INFO - Epoch:[663/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 06:53:43,736 - INFO - Epoch:[663/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 06:53:47,327 - INFO - Epoch:[663/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.02
2025-03-03 06:53:50,742 - INFO - Epoch:[663/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 06:53:53,916 - INFO - Epoch:[663/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.10 loss_cvh: 0.70
2025-03-03 06:53:54,903 - INFO - now the learning rate is: 1e-05
2025-03-03 06:54:27,938 - INFO - begin training stage: [664/805]
2025-03-03 06:54:27,938 - INFO - begin training stage: [664/805]
2025-03-03 06:54:32,101 - INFO - Epoch:[664/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 06:54:35,607 - INFO - Epoch:[664/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 06:54:38,932 - INFO - Epoch:[664/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:54:42,266 - INFO - Epoch:[664/805] Step:[40/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 06:54:45,729 - INFO - Epoch:[664/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:54:49,163 - INFO - Epoch:[664/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:54:52,574 - INFO - Epoch:[664/805] Step:[70/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 06:54:55,996 - INFO - Epoch:[664/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 06:54:59,139 - INFO - Epoch:[664/805] Step:[90/90] reconstruction_loss: 1.04 loss_vc: 1.15 loss_cvh: 0.68
2025-03-03 06:55:00,153 - INFO - now the learning rate is: 1e-05
2025-03-03 06:55:33,340 - INFO - begin training stage: [665/805]
2025-03-03 06:55:33,341 - INFO - begin training stage: [665/805]
2025-03-03 06:55:37,649 - INFO - Epoch:[665/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 06:55:41,073 - INFO - Epoch:[665/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 06:55:44,597 - INFO - Epoch:[665/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 06:55:47,992 - INFO - Epoch:[665/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:55:51,372 - INFO - Epoch:[665/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 06:55:55,074 - INFO - Epoch:[665/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 06:55:58,536 - INFO - Epoch:[665/805] Step:[70/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:56:01,903 - INFO - Epoch:[665/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:56:04,993 - INFO - Epoch:[665/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.27 loss_cvh: 0.66
2025-03-03 06:56:05,957 - INFO - now the learning rate is: 1e-05
2025-03-03 06:56:39,775 - INFO - begin training stage: [666/805]
2025-03-03 06:56:39,775 - INFO - begin training stage: [666/805]
2025-03-03 06:56:43,983 - INFO - Epoch:[666/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 06:56:47,410 - INFO - Epoch:[666/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 06:56:50,798 - INFO - Epoch:[666/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 06:56:54,207 - INFO - Epoch:[666/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 06:56:57,604 - INFO - Epoch:[666/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 06:57:00,996 - INFO - Epoch:[666/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:57:04,396 - INFO - Epoch:[666/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 06:57:07,748 - INFO - Epoch:[666/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 06:57:10,894 - INFO - Epoch:[666/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.27 loss_cvh: 0.75
2025-03-03 06:57:11,876 - INFO - now the learning rate is: 1e-05
2025-03-03 06:57:45,540 - INFO - begin training stage: [667/805]
2025-03-03 06:57:45,540 - INFO - begin training stage: [667/805]
2025-03-03 06:57:49,871 - INFO - Epoch:[667/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.12
2025-03-03 06:57:53,435 - INFO - Epoch:[667/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 06:57:56,867 - INFO - Epoch:[667/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:58:00,361 - INFO - Epoch:[667/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 06:58:03,823 - INFO - Epoch:[667/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 06:58:07,237 - INFO - Epoch:[667/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:58:10,687 - INFO - Epoch:[667/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 06:58:14,063 - INFO - Epoch:[667/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:58:17,258 - INFO - Epoch:[667/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.28 loss_cvh: 0.88
2025-03-03 06:58:18,232 - INFO - now the learning rate is: 1e-05
2025-03-03 06:58:51,375 - INFO - begin training stage: [668/805]
2025-03-03 06:58:51,375 - INFO - begin training stage: [668/805]
2025-03-03 06:58:55,823 - INFO - Epoch:[668/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 06:58:59,204 - INFO - Epoch:[668/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 06:59:02,629 - INFO - Epoch:[668/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 06:59:06,026 - INFO - Epoch:[668/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 06:59:09,609 - INFO - Epoch:[668/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.06
2025-03-03 06:59:13,859 - INFO - Epoch:[668/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 06:59:18,677 - INFO - Epoch:[668/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 06:59:23,426 - INFO - Epoch:[668/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 06:59:27,747 - INFO - Epoch:[668/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.17 loss_cvh: 0.88
2025-03-03 06:59:29,123 - INFO - now the learning rate is: 1e-05
2025-03-03 07:00:24,612 - INFO - begin training stage: [669/805]
2025-03-03 07:00:24,613 - INFO - begin training stage: [669/805]
2025-03-03 07:00:28,954 - INFO - Epoch:[669/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.16
2025-03-03 07:00:32,242 - INFO - Epoch:[669/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:00:35,421 - INFO - Epoch:[669/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 07:00:38,626 - INFO - Epoch:[669/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:00:41,837 - INFO - Epoch:[669/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:00:45,108 - INFO - Epoch:[669/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 07:00:48,403 - INFO - Epoch:[669/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 07:00:51,669 - INFO - Epoch:[669/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:00:54,813 - INFO - Epoch:[669/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.11 loss_cvh: 0.78
2025-03-03 07:00:55,712 - INFO - now the learning rate is: 1e-05
2025-03-03 07:02:03,179 - INFO - begin training stage: [670/805]
2025-03-03 07:02:03,180 - INFO - begin training stage: [670/805]
2025-03-03 07:02:08,900 - INFO - Epoch:[670/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:02:12,145 - INFO - Epoch:[670/805] Step:[20/90] reconstruction_loss: 1.11 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 07:02:15,366 - INFO - Epoch:[670/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 07:02:18,584 - INFO - Epoch:[670/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 07:02:21,888 - INFO - Epoch:[670/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:02:25,045 - INFO - Epoch:[670/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 07:02:28,225 - INFO - Epoch:[670/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 07:02:31,448 - INFO - Epoch:[670/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 07:02:34,608 - INFO - Epoch:[670/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.27 loss_cvh: 0.72
2025-03-03 07:02:35,525 - INFO - now the learning rate is: 1e-05
2025-03-03 07:03:08,124 - INFO - begin training stage: [671/805]
2025-03-03 07:03:08,125 - INFO - eval data number: 45600
2025-03-03 07:03:08,125 - INFO - loading eval data ......
2025-03-03 07:03:39,306 - INFO - retrieval costs: 19.626455545425415
2025-03-03 07:04:52,913 - INFO - hamming distance computation costs: 73.60640454292297
2025-03-03 07:04:58,886 - INFO - hamming ranking costs: 5.973430871963501
2025-03-03 07:04:58,886 - INFO - labels shape: (45600, 239)
2025-03-03 07:05:33,778 - INFO - similarity labels generation costs: 34.89137816429138
2025-03-03 07:05:33,848 - INFO - topK: 5:, map: 0.33653583333333337
2025-03-03 07:05:34,096 - INFO - topK: 20:, map: 0.2423412335759893
2025-03-03 07:05:34,580 - INFO - topK: 40:, map: 0.20896959536227921
2025-03-03 07:05:35,311 - INFO - topK: 60:, map: 0.18982704086506275
2025-03-03 07:05:36,273 - INFO - topK: 80:, map: 0.17509720422317898
2025-03-03 07:05:37,472 - INFO - topK: 100:, map: 0.16307759913806325
2025-03-03 07:05:38,866 - INFO - begin training stage: [671/805]
2025-03-03 07:05:43,445 - INFO - Epoch:[671/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:05:46,934 - INFO - Epoch:[671/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:05:50,369 - INFO - Epoch:[671/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:05:53,868 - INFO - Epoch:[671/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 07:05:57,298 - INFO - Epoch:[671/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:06:00,730 - INFO - Epoch:[671/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:06:04,056 - INFO - Epoch:[671/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 07:06:07,543 - INFO - Epoch:[671/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:06:10,878 - INFO - Epoch:[671/805] Step:[90/90] reconstruction_loss: 1.04 loss_vc: 1.28 loss_cvh: 0.87
2025-03-03 07:06:11,848 - INFO - now the learning rate is: 1e-05
2025-03-03 07:06:44,867 - INFO - begin training stage: [672/805]
2025-03-03 07:06:44,867 - INFO - begin training stage: [672/805]
2025-03-03 07:06:49,520 - INFO - Epoch:[672/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:06:52,969 - INFO - Epoch:[672/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:06:56,422 - INFO - Epoch:[672/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 07:06:59,793 - INFO - Epoch:[672/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 07:07:03,358 - INFO - Epoch:[672/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 07:07:06,741 - INFO - Epoch:[672/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:07:10,247 - INFO - Epoch:[672/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 07:07:13,624 - INFO - Epoch:[672/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 07:07:16,772 - INFO - Epoch:[672/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.05 loss_cvh: 0.66
2025-03-03 07:07:17,737 - INFO - now the learning rate is: 1e-05
2025-03-03 07:07:51,112 - INFO - begin training stage: [673/805]
2025-03-03 07:07:51,112 - INFO - begin training stage: [673/805]
2025-03-03 07:07:55,715 - INFO - Epoch:[673/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 07:07:59,244 - INFO - Epoch:[673/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 07:08:02,676 - INFO - Epoch:[673/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 07:08:06,137 - INFO - Epoch:[673/805] Step:[40/90] reconstruction_loss: 1.11 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 07:08:09,507 - INFO - Epoch:[673/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 07:08:12,935 - INFO - Epoch:[673/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:08:16,442 - INFO - Epoch:[673/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.15
2025-03-03 07:08:20,050 - INFO - Epoch:[673/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 07:08:23,301 - INFO - Epoch:[673/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.18 loss_cvh: 0.53
2025-03-03 07:08:24,262 - INFO - now the learning rate is: 1e-05
2025-03-03 07:08:57,150 - INFO - begin training stage: [674/805]
2025-03-03 07:08:57,151 - INFO - begin training stage: [674/805]
2025-03-03 07:09:01,730 - INFO - Epoch:[674/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 07:09:05,202 - INFO - Epoch:[674/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:09:08,571 - INFO - Epoch:[674/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 07:09:12,098 - INFO - Epoch:[674/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:09:15,457 - INFO - Epoch:[674/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 07:09:18,938 - INFO - Epoch:[674/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:09:22,348 - INFO - Epoch:[674/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:09:25,818 - INFO - Epoch:[674/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 07:09:29,012 - INFO - Epoch:[674/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.26 loss_cvh: 0.75
2025-03-03 07:09:29,980 - INFO - now the learning rate is: 1e-05
2025-03-03 07:10:03,126 - INFO - begin training stage: [675/805]
2025-03-03 07:10:03,126 - INFO - begin training stage: [675/805]
2025-03-03 07:10:07,527 - INFO - Epoch:[675/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.15
2025-03-03 07:10:10,882 - INFO - Epoch:[675/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:10:14,309 - INFO - Epoch:[675/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 07:10:17,667 - INFO - Epoch:[675/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 07:10:21,157 - INFO - Epoch:[675/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:10:24,702 - INFO - Epoch:[675/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:10:28,313 - INFO - Epoch:[675/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 07:10:31,886 - INFO - Epoch:[675/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 07:10:35,079 - INFO - Epoch:[675/805] Step:[90/90] reconstruction_loss: 1.40 loss_vc: 1.21 loss_cvh: 0.83
2025-03-03 07:10:36,029 - INFO - now the learning rate is: 1e-05
2025-03-03 07:11:08,800 - INFO - begin training stage: [676/805]
2025-03-03 07:11:08,800 - INFO - begin training stage: [676/805]
2025-03-03 07:11:13,171 - INFO - Epoch:[676/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 07:11:16,624 - INFO - Epoch:[676/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:11:20,095 - INFO - Epoch:[676/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 07:11:23,579 - INFO - Epoch:[676/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:11:27,071 - INFO - Epoch:[676/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 07:11:30,619 - INFO - Epoch:[676/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:11:34,151 - INFO - Epoch:[676/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:11:37,605 - INFO - Epoch:[676/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 07:11:40,843 - INFO - Epoch:[676/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.13 loss_cvh: 0.81
2025-03-03 07:11:41,795 - INFO - now the learning rate is: 1e-05
2025-03-03 07:12:14,606 - INFO - begin training stage: [677/805]
2025-03-03 07:12:14,606 - INFO - begin training stage: [677/805]
2025-03-03 07:12:18,959 - INFO - Epoch:[677/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.09
2025-03-03 07:12:22,339 - INFO - Epoch:[677/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 07:12:25,736 - INFO - Epoch:[677/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 07:12:29,258 - INFO - Epoch:[677/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 07:12:32,678 - INFO - Epoch:[677/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:12:36,042 - INFO - Epoch:[677/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 07:12:39,431 - INFO - Epoch:[677/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 07:12:42,761 - INFO - Epoch:[677/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 07:12:45,893 - INFO - Epoch:[677/805] Step:[90/90] reconstruction_loss: 0.96 loss_vc: 1.05 loss_cvh: 0.80
2025-03-03 07:12:46,870 - INFO - now the learning rate is: 1e-05
2025-03-03 07:13:48,404 - INFO - begin training stage: [678/805]
2025-03-03 07:13:48,405 - INFO - begin training stage: [678/805]
2025-03-03 07:13:54,481 - INFO - Epoch:[678/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:13:59,074 - INFO - Epoch:[678/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 07:14:03,909 - INFO - Epoch:[678/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 07:14:08,906 - INFO - Epoch:[678/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 07:14:13,781 - INFO - Epoch:[678/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 07:14:17,903 - INFO - Epoch:[678/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 07:14:21,276 - INFO - Epoch:[678/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 07:14:24,597 - INFO - Epoch:[678/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 07:14:27,688 - INFO - Epoch:[678/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.29 loss_cvh: 0.69
2025-03-03 07:14:28,591 - INFO - now the learning rate is: 1e-05
2025-03-03 07:15:01,315 - INFO - begin training stage: [679/805]
2025-03-03 07:15:01,315 - INFO - begin training stage: [679/805]
2025-03-03 07:15:05,546 - INFO - Epoch:[679/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:15:08,821 - INFO - Epoch:[679/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 07:15:12,022 - INFO - Epoch:[679/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:15:15,297 - INFO - Epoch:[679/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:15:18,530 - INFO - Epoch:[679/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:15:21,961 - INFO - Epoch:[679/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 07:15:25,242 - INFO - Epoch:[679/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:15:28,493 - INFO - Epoch:[679/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 07:15:31,571 - INFO - Epoch:[679/805] Step:[90/90] reconstruction_loss: 1.28 loss_vc: 1.23 loss_cvh: 0.65
2025-03-03 07:15:32,537 - INFO - now the learning rate is: 1e-05
2025-03-03 07:16:43,031 - INFO - begin training stage: [680/805]
2025-03-03 07:16:43,031 - INFO - begin training stage: [680/805]
2025-03-03 07:16:47,340 - INFO - Epoch:[680/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:16:50,630 - INFO - Epoch:[680/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 07:16:53,934 - INFO - Epoch:[680/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 07:16:57,148 - INFO - Epoch:[680/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 07:17:00,342 - INFO - Epoch:[680/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:17:03,599 - INFO - Epoch:[680/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 07:17:06,807 - INFO - Epoch:[680/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:17:09,985 - INFO - Epoch:[680/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 07:17:12,983 - INFO - Epoch:[680/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.12 loss_cvh: 0.85
2025-03-03 07:17:13,916 - INFO - now the learning rate is: 1e-05
2025-03-03 07:17:46,922 - INFO - begin training stage: [681/805]
2025-03-03 07:17:46,923 - INFO - eval data number: 45600
2025-03-03 07:17:46,923 - INFO - loading eval data ......
2025-03-03 07:18:18,304 - INFO - retrieval costs: 19.627628326416016
2025-03-03 07:19:33,494 - INFO - hamming distance computation costs: 75.18923997879028
2025-03-03 07:19:39,446 - INFO - hamming ranking costs: 5.9524266719818115
2025-03-03 07:19:39,446 - INFO - labels shape: (45600, 239)
2025-03-03 07:20:15,038 - INFO - similarity labels generation costs: 35.591585636138916
2025-03-03 07:20:15,110 - INFO - topK: 5:, map: 0.3369591666666667
2025-03-03 07:20:15,369 - INFO - topK: 20:, map: 0.24252499462402274
2025-03-03 07:20:15,873 - INFO - topK: 40:, map: 0.20986634207170354
2025-03-03 07:20:16,624 - INFO - topK: 60:, map: 0.19059798021648983
2025-03-03 07:20:17,618 - INFO - topK: 80:, map: 0.17538493106332528
2025-03-03 07:20:18,853 - INFO - topK: 100:, map: 0.1633272105020639
2025-03-03 07:20:20,351 - INFO - begin training stage: [681/805]
2025-03-03 07:20:25,079 - INFO - Epoch:[681/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 07:20:28,826 - INFO - Epoch:[681/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 07:20:32,333 - INFO - Epoch:[681/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 07:20:35,875 - INFO - Epoch:[681/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.10
2025-03-03 07:20:39,638 - INFO - Epoch:[681/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:20:43,222 - INFO - Epoch:[681/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:20:46,626 - INFO - Epoch:[681/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.09
2025-03-03 07:20:50,087 - INFO - Epoch:[681/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 07:20:53,304 - INFO - Epoch:[681/805] Step:[90/90] reconstruction_loss: 1.27 loss_vc: 1.15 loss_cvh: 0.89
2025-03-03 07:20:54,256 - INFO - now the learning rate is: 1e-05
2025-03-03 07:21:28,146 - INFO - begin training stage: [682/805]
2025-03-03 07:21:28,146 - INFO - begin training stage: [682/805]
2025-03-03 07:21:32,487 - INFO - Epoch:[682/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:21:35,893 - INFO - Epoch:[682/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 07:21:39,463 - INFO - Epoch:[682/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 07:21:42,906 - INFO - Epoch:[682/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:21:46,339 - INFO - Epoch:[682/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:21:49,762 - INFO - Epoch:[682/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 07:21:53,204 - INFO - Epoch:[682/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.15
2025-03-03 07:21:56,490 - INFO - Epoch:[682/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:21:59,624 - INFO - Epoch:[682/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.27 loss_cvh: 0.72
2025-03-03 07:22:00,577 - INFO - now the learning rate is: 1e-05
2025-03-03 07:22:33,810 - INFO - begin training stage: [683/805]
2025-03-03 07:22:33,811 - INFO - begin training stage: [683/805]
2025-03-03 07:22:38,339 - INFO - Epoch:[683/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 07:22:41,697 - INFO - Epoch:[683/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 07:22:45,077 - INFO - Epoch:[683/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 07:22:48,456 - INFO - Epoch:[683/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 07:22:51,957 - INFO - Epoch:[683/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:22:55,336 - INFO - Epoch:[683/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 07:22:58,728 - INFO - Epoch:[683/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:23:02,111 - INFO - Epoch:[683/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:23:05,201 - INFO - Epoch:[683/805] Step:[90/90] reconstruction_loss: 1.03 loss_vc: 1.21 loss_cvh: 0.79
2025-03-03 07:23:06,150 - INFO - now the learning rate is: 1e-05
2025-03-03 07:23:39,979 - INFO - begin training stage: [684/805]
2025-03-03 07:23:39,979 - INFO - begin training stage: [684/805]
2025-03-03 07:23:44,247 - INFO - Epoch:[684/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:23:47,641 - INFO - Epoch:[684/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:23:51,207 - INFO - Epoch:[684/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 07:23:54,579 - INFO - Epoch:[684/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.12
2025-03-03 07:23:57,980 - INFO - Epoch:[684/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:24:01,381 - INFO - Epoch:[684/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 07:24:04,807 - INFO - Epoch:[684/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 07:24:08,137 - INFO - Epoch:[684/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 07:24:11,293 - INFO - Epoch:[684/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.02 loss_cvh: 0.75
2025-03-03 07:24:12,273 - INFO - now the learning rate is: 1e-05
2025-03-03 07:24:45,892 - INFO - begin training stage: [685/805]
2025-03-03 07:24:45,892 - INFO - begin training stage: [685/805]
2025-03-03 07:24:50,170 - INFO - Epoch:[685/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:24:53,634 - INFO - Epoch:[685/805] Step:[20/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 07:24:57,055 - INFO - Epoch:[685/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 07:25:00,595 - INFO - Epoch:[685/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 07:25:04,009 - INFO - Epoch:[685/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:25:07,443 - INFO - Epoch:[685/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:25:10,844 - INFO - Epoch:[685/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 07:25:14,161 - INFO - Epoch:[685/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:25:17,322 - INFO - Epoch:[685/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.27 loss_cvh: 0.75
2025-03-03 07:25:18,261 - INFO - now the learning rate is: 1e-05
2025-03-03 07:25:52,281 - INFO - begin training stage: [686/805]
2025-03-03 07:25:52,281 - INFO - begin training stage: [686/805]
2025-03-03 07:25:56,686 - INFO - Epoch:[686/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 07:26:00,234 - INFO - Epoch:[686/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 07:26:03,644 - INFO - Epoch:[686/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 07:26:07,006 - INFO - Epoch:[686/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 07:26:10,393 - INFO - Epoch:[686/805] Step:[50/90] reconstruction_loss: 1.10 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:26:13,780 - INFO - Epoch:[686/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:26:17,154 - INFO - Epoch:[686/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 07:26:20,599 - INFO - Epoch:[686/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:26:23,699 - INFO - Epoch:[686/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.15 loss_cvh: 0.85
2025-03-03 07:26:24,631 - INFO - now the learning rate is: 1e-05
2025-03-03 07:26:58,106 - INFO - begin training stage: [687/805]
2025-03-03 07:26:58,106 - INFO - begin training stage: [687/805]
2025-03-03 07:27:02,349 - INFO - Epoch:[687/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 07:27:05,897 - INFO - Epoch:[687/805] Step:[20/90] reconstruction_loss: 1.11 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 07:27:09,291 - INFO - Epoch:[687/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 07:27:12,704 - INFO - Epoch:[687/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 07:27:16,108 - INFO - Epoch:[687/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 07:27:19,530 - INFO - Epoch:[687/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 07:27:23,841 - INFO - Epoch:[687/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 07:27:28,992 - INFO - Epoch:[687/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 07:27:33,644 - INFO - Epoch:[687/805] Step:[90/90] reconstruction_loss: 0.97 loss_vc: 1.19 loss_cvh: 0.77
2025-03-03 07:27:35,043 - INFO - now the learning rate is: 1e-05
2025-03-03 07:28:41,126 - INFO - begin training stage: [688/805]
2025-03-03 07:28:41,126 - INFO - begin training stage: [688/805]
2025-03-03 07:28:45,405 - INFO - Epoch:[688/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:28:48,857 - INFO - Epoch:[688/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:28:52,262 - INFO - Epoch:[688/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 07:28:55,813 - INFO - Epoch:[688/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 07:28:59,200 - INFO - Epoch:[688/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 07:29:02,589 - INFO - Epoch:[688/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 07:29:05,884 - INFO - Epoch:[688/805] Step:[70/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 07:29:09,180 - INFO - Epoch:[688/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:29:12,330 - INFO - Epoch:[688/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.36 loss_cvh: 0.94
2025-03-03 07:29:13,277 - INFO - now the learning rate is: 1e-05
2025-03-03 07:29:46,660 - INFO - begin training stage: [689/805]
2025-03-03 07:29:46,661 - INFO - begin training stage: [689/805]
2025-03-03 07:29:50,870 - INFO - Epoch:[689/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:29:54,267 - INFO - Epoch:[689/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 07:29:57,609 - INFO - Epoch:[689/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 07:30:00,928 - INFO - Epoch:[689/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 07:30:04,267 - INFO - Epoch:[689/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 07:30:07,590 - INFO - Epoch:[689/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:30:10,939 - INFO - Epoch:[689/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 07:30:14,382 - INFO - Epoch:[689/805] Step:[80/90] reconstruction_loss: 1.11 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 07:30:18,459 - INFO - Epoch:[689/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.27 loss_cvh: 0.70
2025-03-03 07:30:19,833 - INFO - now the learning rate is: 1e-05
2025-03-03 07:31:27,826 - INFO - begin training stage: [690/805]
2025-03-03 07:31:27,826 - INFO - begin training stage: [690/805]
2025-03-03 07:31:32,238 - INFO - Epoch:[690/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:31:35,522 - INFO - Epoch:[690/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 07:31:38,854 - INFO - Epoch:[690/805] Step:[30/90] reconstruction_loss: 1.19 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 07:31:42,066 - INFO - Epoch:[690/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:31:45,274 - INFO - Epoch:[690/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 07:31:48,449 - INFO - Epoch:[690/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 07:31:51,648 - INFO - Epoch:[690/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.13
2025-03-03 07:31:54,858 - INFO - Epoch:[690/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 07:31:57,780 - INFO - Epoch:[690/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.22 loss_cvh: 0.86
2025-03-03 07:31:58,656 - INFO - now the learning rate is: 1e-05
2025-03-03 07:32:31,228 - INFO - begin training stage: [691/805]
2025-03-03 07:32:31,229 - INFO - eval data number: 45600
2025-03-03 07:32:31,229 - INFO - loading eval data ......
2025-03-03 07:33:02,465 - INFO - retrieval costs: 19.670595169067383
2025-03-03 07:34:24,539 - INFO - hamming distance computation costs: 82.07413721084595
2025-03-03 07:34:30,361 - INFO - hamming ranking costs: 5.821873903274536
2025-03-03 07:34:30,361 - INFO - labels shape: (45600, 239)
2025-03-03 07:35:05,714 - INFO - similarity labels generation costs: 35.35296821594238
2025-03-03 07:35:05,786 - INFO - topK: 5:, map: 0.3420341666666667
2025-03-03 07:35:06,050 - INFO - topK: 20:, map: 0.24430032602615176
2025-03-03 07:35:06,560 - INFO - topK: 40:, map: 0.21063879667026067
2025-03-03 07:35:07,312 - INFO - topK: 60:, map: 0.19025296778274936
2025-03-03 07:35:08,325 - INFO - topK: 80:, map: 0.1755270222785369
2025-03-03 07:35:09,587 - INFO - topK: 100:, map: 0.16343739753197703
2025-03-03 07:35:11,001 - INFO - begin training stage: [691/805]
2025-03-03 07:35:15,331 - INFO - Epoch:[691/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.05
2025-03-03 07:35:18,810 - INFO - Epoch:[691/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:35:22,197 - INFO - Epoch:[691/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 07:35:25,624 - INFO - Epoch:[691/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 07:35:28,992 - INFO - Epoch:[691/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 07:35:32,297 - INFO - Epoch:[691/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:35:35,627 - INFO - Epoch:[691/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 07:35:38,994 - INFO - Epoch:[691/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:35:42,069 - INFO - Epoch:[691/805] Step:[90/90] reconstruction_loss: 1.20 loss_vc: 1.15 loss_cvh: 0.83
2025-03-03 07:35:43,032 - INFO - now the learning rate is: 1e-05
2025-03-03 07:36:16,352 - INFO - begin training stage: [692/805]
2025-03-03 07:36:16,352 - INFO - begin training stage: [692/805]
2025-03-03 07:36:20,851 - INFO - Epoch:[692/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 07:36:24,267 - INFO - Epoch:[692/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 07:36:27,653 - INFO - Epoch:[692/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.15
2025-03-03 07:36:31,074 - INFO - Epoch:[692/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 07:36:34,586 - INFO - Epoch:[692/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 07:36:38,046 - INFO - Epoch:[692/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 07:36:41,483 - INFO - Epoch:[692/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 07:36:45,001 - INFO - Epoch:[692/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 07:36:48,230 - INFO - Epoch:[692/805] Step:[90/90] reconstruction_loss: 1.30 loss_vc: 1.08 loss_cvh: 0.66
2025-03-03 07:36:49,180 - INFO - now the learning rate is: 1e-05
2025-03-03 07:37:22,671 - INFO - begin training stage: [693/805]
2025-03-03 07:37:22,671 - INFO - begin training stage: [693/805]
2025-03-03 07:37:26,954 - INFO - Epoch:[693/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:37:30,511 - INFO - Epoch:[693/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 07:37:33,935 - INFO - Epoch:[693/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:37:37,336 - INFO - Epoch:[693/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:37:40,728 - INFO - Epoch:[693/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:37:44,090 - INFO - Epoch:[693/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 07:37:47,461 - INFO - Epoch:[693/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 07:37:50,886 - INFO - Epoch:[693/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 07:37:54,011 - INFO - Epoch:[693/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.18 loss_cvh: 0.79
2025-03-03 07:37:54,991 - INFO - now the learning rate is: 1e-05
2025-03-03 07:38:28,583 - INFO - begin training stage: [694/805]
2025-03-03 07:38:28,584 - INFO - begin training stage: [694/805]
2025-03-03 07:38:32,965 - INFO - Epoch:[694/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 07:38:36,348 - INFO - Epoch:[694/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 07:38:39,739 - INFO - Epoch:[694/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:38:43,132 - INFO - Epoch:[694/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 07:38:46,510 - INFO - Epoch:[694/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 07:38:49,900 - INFO - Epoch:[694/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.32 loss_cvh: 3.07
2025-03-03 07:38:53,238 - INFO - Epoch:[694/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:38:56,573 - INFO - Epoch:[694/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 07:38:59,662 - INFO - Epoch:[694/805] Step:[90/90] reconstruction_loss: 1.28 loss_vc: 1.23 loss_cvh: 0.65
2025-03-03 07:39:00,574 - INFO - now the learning rate is: 1e-05
2025-03-03 07:39:33,946 - INFO - begin training stage: [695/805]
2025-03-03 07:39:33,946 - INFO - begin training stage: [695/805]
2025-03-03 07:39:38,385 - INFO - Epoch:[695/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 07:39:41,798 - INFO - Epoch:[695/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:39:45,216 - INFO - Epoch:[695/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 07:39:48,658 - INFO - Epoch:[695/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 07:39:52,051 - INFO - Epoch:[695/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 07:39:55,475 - INFO - Epoch:[695/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 07:39:58,916 - INFO - Epoch:[695/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 07:40:02,269 - INFO - Epoch:[695/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.32 loss_cvh: 3.09
2025-03-03 07:40:05,360 - INFO - Epoch:[695/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.31 loss_cvh: 0.74
2025-03-03 07:40:06,269 - INFO - now the learning rate is: 1e-05
2025-03-03 07:40:39,798 - INFO - begin training stage: [696/805]
2025-03-03 07:40:39,798 - INFO - begin training stage: [696/805]
2025-03-03 07:40:44,168 - INFO - Epoch:[696/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:40:47,559 - INFO - Epoch:[696/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 07:40:50,899 - INFO - Epoch:[696/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 07:40:54,288 - INFO - Epoch:[696/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:40:57,645 - INFO - Epoch:[696/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 07:41:01,009 - INFO - Epoch:[696/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.14
2025-03-03 07:41:04,340 - INFO - Epoch:[696/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:41:07,649 - INFO - Epoch:[696/805] Step:[80/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 07:41:10,721 - INFO - Epoch:[696/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.15 loss_cvh: 0.71
2025-03-03 07:41:11,632 - INFO - now the learning rate is: 1e-05
2025-03-03 07:41:44,879 - INFO - begin training stage: [697/805]
2025-03-03 07:41:44,879 - INFO - begin training stage: [697/805]
2025-03-03 07:41:49,263 - INFO - Epoch:[697/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:41:53,476 - INFO - Epoch:[697/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 07:41:58,095 - INFO - Epoch:[697/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 07:42:02,980 - INFO - Epoch:[697/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 07:42:07,688 - INFO - Epoch:[697/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:42:12,669 - INFO - Epoch:[697/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:42:17,287 - INFO - Epoch:[697/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:42:22,096 - INFO - Epoch:[697/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:42:26,753 - INFO - Epoch:[697/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.30 loss_cvh: 0.95
2025-03-03 07:42:28,148 - INFO - now the learning rate is: 1e-05
2025-03-03 07:43:10,058 - INFO - begin training stage: [698/805]
2025-03-03 07:43:10,058 - INFO - begin training stage: [698/805]
2025-03-03 07:43:14,249 - INFO - Epoch:[698/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:43:17,582 - INFO - Epoch:[698/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:43:20,936 - INFO - Epoch:[698/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:43:24,249 - INFO - Epoch:[698/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 07:43:27,586 - INFO - Epoch:[698/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 07:43:30,887 - INFO - Epoch:[698/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 07:43:34,181 - INFO - Epoch:[698/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 07:43:37,530 - INFO - Epoch:[698/805] Step:[80/90] reconstruction_loss: 1.18 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 07:43:40,565 - INFO - Epoch:[698/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.46 loss_cvh: 0.95
2025-03-03 07:43:41,455 - INFO - now the learning rate is: 1e-05
2025-03-03 07:44:14,756 - INFO - begin training stage: [699/805]
2025-03-03 07:44:14,756 - INFO - begin training stage: [699/805]
2025-03-03 07:44:18,734 - INFO - Epoch:[699/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.12
2025-03-03 07:44:22,018 - INFO - Epoch:[699/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 07:44:25,321 - INFO - Epoch:[699/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 07:44:28,597 - INFO - Epoch:[699/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:44:31,869 - INFO - Epoch:[699/805] Step:[50/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 07:44:35,139 - INFO - Epoch:[699/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 07:44:38,483 - INFO - Epoch:[699/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:44:42,581 - INFO - Epoch:[699/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 07:44:46,878 - INFO - Epoch:[699/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.43 loss_cvh: 0.80
2025-03-03 07:44:48,258 - INFO - now the learning rate is: 1e-05
2025-03-03 07:45:55,333 - INFO - begin training stage: [700/805]
2025-03-03 07:45:55,334 - INFO - begin training stage: [700/805]
2025-03-03 07:45:59,536 - INFO - Epoch:[700/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 07:46:02,692 - INFO - Epoch:[700/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:46:05,830 - INFO - Epoch:[700/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 07:46:08,975 - INFO - Epoch:[700/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.14
2025-03-03 07:46:12,105 - INFO - Epoch:[700/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:46:15,212 - INFO - Epoch:[700/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:46:18,383 - INFO - Epoch:[700/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:46:21,546 - INFO - Epoch:[700/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:46:24,456 - INFO - Epoch:[700/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.20 loss_cvh: 0.73
2025-03-03 07:46:25,413 - INFO - now the learning rate is: 1e-05
2025-03-03 07:46:58,170 - INFO - begin training stage: [701/805]
2025-03-03 07:46:58,171 - INFO - eval data number: 45600
2025-03-03 07:46:58,171 - INFO - loading eval data ......
2025-03-03 07:47:29,741 - INFO - retrieval costs: 20.01080083847046
2025-03-03 07:48:45,297 - INFO - hamming distance computation costs: 75.5561830997467
2025-03-03 07:48:51,010 - INFO - hamming ranking costs: 5.7130653858184814
2025-03-03 07:48:51,010 - INFO - labels shape: (45600, 239)
2025-03-03 07:49:25,485 - INFO - similarity labels generation costs: 34.47441816329956
2025-03-03 07:49:25,564 - INFO - topK: 5:, map: 0.33710249999999997
2025-03-03 07:49:25,828 - INFO - topK: 20:, map: 0.2443414700348456
2025-03-03 07:49:26,308 - INFO - topK: 40:, map: 0.20935329965483707
2025-03-03 07:49:27,028 - INFO - topK: 60:, map: 0.18964310200787246
2025-03-03 07:49:28,002 - INFO - topK: 80:, map: 0.17497256219609966
2025-03-03 07:49:29,200 - INFO - topK: 100:, map: 0.16268895941168393
2025-03-03 07:49:30,709 - INFO - begin training stage: [701/805]
2025-03-03 07:49:35,095 - INFO - Epoch:[701/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 07:49:38,521 - INFO - Epoch:[701/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.17
2025-03-03 07:49:41,979 - INFO - Epoch:[701/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 07:49:45,431 - INFO - Epoch:[701/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:49:48,871 - INFO - Epoch:[701/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:49:52,326 - INFO - Epoch:[701/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 07:49:55,795 - INFO - Epoch:[701/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 07:49:59,176 - INFO - Epoch:[701/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 07:50:02,336 - INFO - Epoch:[701/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.18 loss_cvh: 0.69
2025-03-03 07:50:03,348 - INFO - now the learning rate is: 1e-05
2025-03-03 07:50:36,789 - INFO - begin training stage: [702/805]
2025-03-03 07:50:36,789 - INFO - begin training stage: [702/805]
2025-03-03 07:50:41,217 - INFO - Epoch:[702/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:50:44,858 - INFO - Epoch:[702/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 07:50:48,494 - INFO - Epoch:[702/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 07:50:52,074 - INFO - Epoch:[702/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 07:50:55,544 - INFO - Epoch:[702/805] Step:[50/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 07:50:58,966 - INFO - Epoch:[702/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:51:02,473 - INFO - Epoch:[702/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:51:05,823 - INFO - Epoch:[702/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:51:09,007 - INFO - Epoch:[702/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.16 loss_cvh: 0.75
2025-03-03 07:51:10,024 - INFO - now the learning rate is: 1e-05
2025-03-03 07:51:43,737 - INFO - begin training stage: [703/805]
2025-03-03 07:51:43,738 - INFO - begin training stage: [703/805]
2025-03-03 07:51:48,057 - INFO - Epoch:[703/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:51:51,532 - INFO - Epoch:[703/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 07:51:54,986 - INFO - Epoch:[703/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.36 loss_cvh: 3.16
2025-03-03 07:51:58,430 - INFO - Epoch:[703/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:52:01,868 - INFO - Epoch:[703/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 07:52:05,338 - INFO - Epoch:[703/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 07:52:08,858 - INFO - Epoch:[703/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 07:52:12,279 - INFO - Epoch:[703/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 07:52:15,421 - INFO - Epoch:[703/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.21 loss_cvh: 0.75
2025-03-03 07:52:16,361 - INFO - now the learning rate is: 1e-05
2025-03-03 07:52:50,016 - INFO - begin training stage: [704/805]
2025-03-03 07:52:50,017 - INFO - begin training stage: [704/805]
2025-03-03 07:52:54,366 - INFO - Epoch:[704/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 07:52:57,750 - INFO - Epoch:[704/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.15
2025-03-03 07:53:01,183 - INFO - Epoch:[704/805] Step:[30/90] reconstruction_loss: 1.11 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 07:53:04,612 - INFO - Epoch:[704/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 07:53:08,031 - INFO - Epoch:[704/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 07:53:11,491 - INFO - Epoch:[704/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:53:14,920 - INFO - Epoch:[704/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:53:18,341 - INFO - Epoch:[704/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 07:53:21,430 - INFO - Epoch:[704/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.15 loss_cvh: 0.67
2025-03-03 07:53:22,337 - INFO - now the learning rate is: 1e-05
2025-03-03 07:53:55,254 - INFO - begin training stage: [705/805]
2025-03-03 07:53:55,255 - INFO - begin training stage: [705/805]
2025-03-03 07:53:59,469 - INFO - Epoch:[705/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:54:02,892 - INFO - Epoch:[705/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:54:06,264 - INFO - Epoch:[705/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:54:09,842 - INFO - Epoch:[705/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 07:54:13,264 - INFO - Epoch:[705/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 07:54:16,706 - INFO - Epoch:[705/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:54:20,127 - INFO - Epoch:[705/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 07:54:23,484 - INFO - Epoch:[705/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 07:54:26,595 - INFO - Epoch:[705/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.12 loss_cvh: 0.69
2025-03-03 07:54:27,511 - INFO - now the learning rate is: 1e-05
2025-03-03 07:55:00,808 - INFO - begin training stage: [706/805]
2025-03-03 07:55:00,808 - INFO - begin training stage: [706/805]
2025-03-03 07:55:05,044 - INFO - Epoch:[706/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:55:08,462 - INFO - Epoch:[706/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 07:55:11,888 - INFO - Epoch:[706/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 07:55:15,325 - INFO - Epoch:[706/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 07:55:18,816 - INFO - Epoch:[706/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.15
2025-03-03 07:55:22,218 - INFO - Epoch:[706/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 07:55:25,609 - INFO - Epoch:[706/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:55:29,041 - INFO - Epoch:[706/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:55:32,167 - INFO - Epoch:[706/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.13 loss_cvh: 0.75
2025-03-03 07:55:33,143 - INFO - now the learning rate is: 1e-05
2025-03-03 07:56:35,756 - INFO - begin training stage: [707/805]
2025-03-03 07:56:35,756 - INFO - begin training stage: [707/805]
2025-03-03 07:56:41,881 - INFO - Epoch:[707/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 07:56:46,295 - INFO - Epoch:[707/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 07:56:51,019 - INFO - Epoch:[707/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 07:56:55,760 - INFO - Epoch:[707/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 07:57:00,702 - INFO - Epoch:[707/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:57:05,396 - INFO - Epoch:[707/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 07:57:09,600 - INFO - Epoch:[707/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 07:57:13,049 - INFO - Epoch:[707/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 07:57:16,276 - INFO - Epoch:[707/805] Step:[90/90] reconstruction_loss: 1.00 loss_vc: 1.28 loss_cvh: 0.81
2025-03-03 07:57:17,201 - INFO - now the learning rate is: 1e-05
2025-03-03 07:57:50,587 - INFO - begin training stage: [708/805]
2025-03-03 07:57:50,587 - INFO - begin training stage: [708/805]
2025-03-03 07:57:54,992 - INFO - Epoch:[708/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 07:57:58,290 - INFO - Epoch:[708/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.13
2025-03-03 07:58:01,619 - INFO - Epoch:[708/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 07:58:05,056 - INFO - Epoch:[708/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:58:08,492 - INFO - Epoch:[708/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 07:58:11,945 - INFO - Epoch:[708/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 07:58:15,409 - INFO - Epoch:[708/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 07:58:18,814 - INFO - Epoch:[708/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 07:58:22,033 - INFO - Epoch:[708/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.18 loss_cvh: 0.67
2025-03-03 07:58:23,070 - INFO - now the learning rate is: 1e-05
2025-03-03 07:58:56,624 - INFO - begin training stage: [709/805]
2025-03-03 07:58:56,625 - INFO - begin training stage: [709/805]
2025-03-03 07:59:00,864 - INFO - Epoch:[709/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 07:59:04,375 - INFO - Epoch:[709/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.05
2025-03-03 07:59:07,792 - INFO - Epoch:[709/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 07:59:11,280 - INFO - Epoch:[709/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 07:59:14,673 - INFO - Epoch:[709/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 07:59:18,074 - INFO - Epoch:[709/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.16
2025-03-03 07:59:21,414 - INFO - Epoch:[709/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 07:59:24,718 - INFO - Epoch:[709/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 07:59:27,843 - INFO - Epoch:[709/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.12 loss_cvh: 0.63
2025-03-03 07:59:28,840 - INFO - now the learning rate is: 1e-05
2025-03-03 08:00:28,463 - INFO - begin training stage: [710/805]
2025-03-03 08:00:28,463 - INFO - begin training stage: [710/805]
2025-03-03 08:00:34,412 - INFO - Epoch:[710/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 08:00:38,833 - INFO - Epoch:[710/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 08:00:43,296 - INFO - Epoch:[710/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 08:00:47,716 - INFO - Epoch:[710/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:00:52,341 - INFO - Epoch:[710/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:00:57,200 - INFO - Epoch:[710/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:01:01,696 - INFO - Epoch:[710/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:01:05,339 - INFO - Epoch:[710/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 08:01:08,331 - INFO - Epoch:[710/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.23 loss_cvh: 0.80
2025-03-03 08:01:09,254 - INFO - now the learning rate is: 1e-05
2025-03-03 08:01:40,836 - INFO - begin training stage: [711/805]
2025-03-03 08:01:40,837 - INFO - eval data number: 45600
2025-03-03 08:01:40,837 - INFO - loading eval data ......
2025-03-03 08:02:12,595 - INFO - retrieval costs: 19.6903133392334
2025-03-03 08:03:25,809 - INFO - hamming distance computation costs: 73.21412491798401
2025-03-03 08:03:31,317 - INFO - hamming ranking costs: 5.508168458938599
2025-03-03 08:03:31,317 - INFO - labels shape: (45600, 239)
2025-03-03 08:04:05,297 - INFO - similarity labels generation costs: 33.98001432418823
2025-03-03 08:04:05,371 - INFO - topK: 5:, map: 0.3475383333333333
2025-03-03 08:04:05,617 - INFO - topK: 20:, map: 0.24843895408658034
2025-03-03 08:04:06,097 - INFO - topK: 40:, map: 0.21386112661991377
2025-03-03 08:04:06,828 - INFO - topK: 60:, map: 0.1934976620862589
2025-03-03 08:04:07,789 - INFO - topK: 80:, map: 0.17822250825058966
2025-03-03 08:04:09,000 - INFO - topK: 100:, map: 0.16606221922340406
2025-03-03 08:04:10,672 - INFO - begin training stage: [711/805]
2025-03-03 08:04:14,856 - INFO - Epoch:[711/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:04:18,131 - INFO - Epoch:[711/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 08:04:21,526 - INFO - Epoch:[711/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:04:24,810 - INFO - Epoch:[711/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:04:28,245 - INFO - Epoch:[711/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:04:31,655 - INFO - Epoch:[711/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 08:04:35,051 - INFO - Epoch:[711/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:04:38,393 - INFO - Epoch:[711/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:04:41,496 - INFO - Epoch:[711/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.18 loss_cvh: 0.76
2025-03-03 08:04:42,427 - INFO - now the learning rate is: 1e-05
2025-03-03 08:05:14,656 - INFO - begin training stage: [712/805]
2025-03-03 08:05:14,656 - INFO - begin training stage: [712/805]
2025-03-03 08:05:18,760 - INFO - Epoch:[712/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 08:05:22,004 - INFO - Epoch:[712/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 08:05:25,254 - INFO - Epoch:[712/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:05:28,570 - INFO - Epoch:[712/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:05:32,058 - INFO - Epoch:[712/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:05:35,317 - INFO - Epoch:[712/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:05:38,606 - INFO - Epoch:[712/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:05:41,928 - INFO - Epoch:[712/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 08:05:44,934 - INFO - Epoch:[712/805] Step:[90/90] reconstruction_loss: 1.04 loss_vc: 1.11 loss_cvh: 0.71
2025-03-03 08:05:45,848 - INFO - now the learning rate is: 1e-05
2025-03-03 08:06:18,103 - INFO - begin training stage: [713/805]
2025-03-03 08:06:18,103 - INFO - begin training stage: [713/805]
2025-03-03 08:06:22,194 - INFO - Epoch:[713/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:06:25,446 - INFO - Epoch:[713/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:06:28,819 - INFO - Epoch:[713/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 08:06:32,177 - INFO - Epoch:[713/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:06:35,598 - INFO - Epoch:[713/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 08:06:38,873 - INFO - Epoch:[713/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 08:06:42,183 - INFO - Epoch:[713/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 08:06:45,508 - INFO - Epoch:[713/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 08:06:48,661 - INFO - Epoch:[713/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.35 loss_cvh: 0.76
2025-03-03 08:06:49,592 - INFO - now the learning rate is: 1e-05
2025-03-03 08:07:21,819 - INFO - begin training stage: [714/805]
2025-03-03 08:07:21,819 - INFO - begin training stage: [714/805]
2025-03-03 08:07:25,920 - INFO - Epoch:[714/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 08:07:29,216 - INFO - Epoch:[714/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 08:07:32,505 - INFO - Epoch:[714/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 08:07:35,814 - INFO - Epoch:[714/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:07:39,213 - INFO - Epoch:[714/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 08:07:42,602 - INFO - Epoch:[714/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:07:45,994 - INFO - Epoch:[714/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 08:07:49,322 - INFO - Epoch:[714/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 08:07:52,372 - INFO - Epoch:[714/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.18 loss_cvh: 0.69
2025-03-03 08:07:53,292 - INFO - now the learning rate is: 1e-05
2025-03-03 08:08:25,316 - INFO - begin training stage: [715/805]
2025-03-03 08:08:25,316 - INFO - begin training stage: [715/805]
2025-03-03 08:08:29,355 - INFO - Epoch:[715/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 08:08:32,618 - INFO - Epoch:[715/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.33 loss_cvh: 3.12
2025-03-03 08:08:35,846 - INFO - Epoch:[715/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:08:39,146 - INFO - Epoch:[715/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 08:08:42,626 - INFO - Epoch:[715/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 08:08:45,970 - INFO - Epoch:[715/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 08:08:49,313 - INFO - Epoch:[715/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 08:08:52,713 - INFO - Epoch:[715/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.32 loss_cvh: 3.08
2025-03-03 08:08:55,884 - INFO - Epoch:[715/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.31 loss_cvh: 0.82
2025-03-03 08:08:56,794 - INFO - now the learning rate is: 1e-05
2025-03-03 08:09:29,157 - INFO - begin training stage: [716/805]
2025-03-03 08:09:29,157 - INFO - begin training stage: [716/805]
2025-03-03 08:09:33,335 - INFO - Epoch:[716/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:09:36,681 - INFO - Epoch:[716/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.09
2025-03-03 08:09:39,990 - INFO - Epoch:[716/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.15
2025-03-03 08:09:43,347 - INFO - Epoch:[716/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 08:09:46,701 - INFO - Epoch:[716/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 08:09:50,038 - INFO - Epoch:[716/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 08:09:53,377 - INFO - Epoch:[716/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 08:09:56,764 - INFO - Epoch:[716/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.19
2025-03-03 08:09:59,898 - INFO - Epoch:[716/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.16 loss_cvh: 0.64
2025-03-03 08:10:00,874 - INFO - now the learning rate is: 1e-05
2025-03-03 08:11:03,598 - INFO - begin training stage: [717/805]
2025-03-03 08:11:03,598 - INFO - begin training stage: [717/805]
2025-03-03 08:11:09,924 - INFO - Epoch:[717/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:11:14,691 - INFO - Epoch:[717/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:11:19,697 - INFO - Epoch:[717/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 08:11:24,413 - INFO - Epoch:[717/805] Step:[40/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 08:11:28,940 - INFO - Epoch:[717/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:11:33,111 - INFO - Epoch:[717/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:11:36,484 - INFO - Epoch:[717/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:11:39,802 - INFO - Epoch:[717/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 08:11:42,854 - INFO - Epoch:[717/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.06 loss_cvh: 0.76
2025-03-03 08:11:43,747 - INFO - now the learning rate is: 1e-05
2025-03-03 08:12:16,368 - INFO - begin training stage: [718/805]
2025-03-03 08:12:16,368 - INFO - begin training stage: [718/805]
2025-03-03 08:12:20,654 - INFO - Epoch:[718/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:12:24,090 - INFO - Epoch:[718/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:12:27,435 - INFO - Epoch:[718/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 08:12:30,837 - INFO - Epoch:[718/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 08:12:34,181 - INFO - Epoch:[718/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 08:12:37,534 - INFO - Epoch:[718/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 08:12:40,857 - INFO - Epoch:[718/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 08:12:44,385 - INFO - Epoch:[718/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 08:12:47,450 - INFO - Epoch:[718/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.14 loss_cvh: 0.74
2025-03-03 08:12:48,416 - INFO - now the learning rate is: 1e-05
2025-03-03 08:13:21,033 - INFO - begin training stage: [719/805]
2025-03-03 08:13:21,033 - INFO - begin training stage: [719/805]
2025-03-03 08:13:25,246 - INFO - Epoch:[719/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 08:13:28,540 - INFO - Epoch:[719/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:13:31,878 - INFO - Epoch:[719/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 08:13:35,219 - INFO - Epoch:[719/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 08:13:38,547 - INFO - Epoch:[719/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 08:13:41,853 - INFO - Epoch:[719/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:13:45,293 - INFO - Epoch:[719/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:13:48,623 - INFO - Epoch:[719/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:13:51,614 - INFO - Epoch:[719/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.28 loss_cvh: 0.71
2025-03-03 08:13:52,547 - INFO - now the learning rate is: 1e-05
2025-03-03 08:14:52,749 - INFO - begin training stage: [720/805]
2025-03-03 08:14:52,750 - INFO - begin training stage: [720/805]
2025-03-03 08:14:58,489 - INFO - Epoch:[720/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 08:15:02,932 - INFO - Epoch:[720/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:15:07,416 - INFO - Epoch:[720/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 08:15:11,816 - INFO - Epoch:[720/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 08:15:16,463 - INFO - Epoch:[720/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 08:15:20,815 - INFO - Epoch:[720/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 08:15:25,324 - INFO - Epoch:[720/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:15:29,850 - INFO - Epoch:[720/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:15:34,463 - INFO - Epoch:[720/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.18 loss_cvh: 0.75
2025-03-03 08:15:35,911 - INFO - now the learning rate is: 1e-05
2025-03-03 08:16:08,292 - INFO - begin training stage: [721/805]
2025-03-03 08:16:08,293 - INFO - eval data number: 45600
2025-03-03 08:16:08,293 - INFO - loading eval data ......
2025-03-03 08:16:38,812 - INFO - retrieval costs: 19.496124267578125
2025-03-03 08:17:50,238 - INFO - hamming distance computation costs: 71.42589855194092
2025-03-03 08:17:56,331 - INFO - hamming ranking costs: 6.09250283241272
2025-03-03 08:17:56,331 - INFO - labels shape: (45600, 239)
2025-03-03 08:18:31,145 - INFO - similarity labels generation costs: 34.81417274475098
2025-03-03 08:18:31,238 - INFO - topK: 5:, map: 0.3366075
2025-03-03 08:18:31,569 - INFO - topK: 20:, map: 0.24438717478922006
2025-03-03 08:18:32,221 - INFO - topK: 40:, map: 0.21058130846607376
2025-03-03 08:18:33,183 - INFO - topK: 60:, map: 0.19006948910862845
2025-03-03 08:18:34,463 - INFO - topK: 80:, map: 0.1750314190595581
2025-03-03 08:18:36,058 - INFO - topK: 100:, map: 0.16303156569748975
2025-03-03 08:18:37,147 - INFO - begin training stage: [721/805]
2025-03-03 08:18:41,462 - INFO - Epoch:[721/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:18:44,780 - INFO - Epoch:[721/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 08:18:48,131 - INFO - Epoch:[721/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 08:18:51,525 - INFO - Epoch:[721/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:18:54,905 - INFO - Epoch:[721/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 08:18:58,390 - INFO - Epoch:[721/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 08:19:01,797 - INFO - Epoch:[721/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 08:19:05,197 - INFO - Epoch:[721/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:19:08,346 - INFO - Epoch:[721/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.23 loss_cvh: 0.91
2025-03-03 08:19:09,356 - INFO - now the learning rate is: 1e-05
2025-03-03 08:19:43,824 - INFO - begin training stage: [722/805]
2025-03-03 08:19:43,824 - INFO - begin training stage: [722/805]
2025-03-03 08:19:48,125 - INFO - Epoch:[722/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 08:19:51,454 - INFO - Epoch:[722/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 08:19:54,799 - INFO - Epoch:[722/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 08:19:58,191 - INFO - Epoch:[722/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 08:20:01,523 - INFO - Epoch:[722/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.06
2025-03-03 08:20:05,087 - INFO - Epoch:[722/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:20:08,463 - INFO - Epoch:[722/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 08:20:11,821 - INFO - Epoch:[722/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 08:20:14,964 - INFO - Epoch:[722/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.11 loss_cvh: 0.70
2025-03-03 08:20:15,921 - INFO - now the learning rate is: 1e-05
2025-03-03 08:20:50,803 - INFO - begin training stage: [723/805]
2025-03-03 08:20:50,803 - INFO - begin training stage: [723/805]
2025-03-03 08:20:55,577 - INFO - Epoch:[723/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 08:20:59,080 - INFO - Epoch:[723/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:21:02,685 - INFO - Epoch:[723/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 08:21:06,246 - INFO - Epoch:[723/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 08:21:09,975 - INFO - Epoch:[723/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 08:21:13,634 - INFO - Epoch:[723/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 08:21:17,131 - INFO - Epoch:[723/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 08:21:20,633 - INFO - Epoch:[723/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 08:21:23,927 - INFO - Epoch:[723/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.32 loss_cvh: 0.69
2025-03-03 08:21:24,924 - INFO - now the learning rate is: 1e-05
2025-03-03 08:21:58,293 - INFO - begin training stage: [724/805]
2025-03-03 08:21:58,294 - INFO - begin training stage: [724/805]
2025-03-03 08:22:02,532 - INFO - Epoch:[724/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 08:22:05,972 - INFO - Epoch:[724/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 08:22:09,369 - INFO - Epoch:[724/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 08:22:12,790 - INFO - Epoch:[724/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:22:16,314 - INFO - Epoch:[724/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:22:19,881 - INFO - Epoch:[724/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:22:23,231 - INFO - Epoch:[724/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 08:22:26,574 - INFO - Epoch:[724/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 08:22:29,733 - INFO - Epoch:[724/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.28 loss_cvh: 0.63
2025-03-03 08:22:30,695 - INFO - now the learning rate is: 1e-05
2025-03-03 08:23:03,629 - INFO - begin training stage: [725/805]
2025-03-03 08:23:03,629 - INFO - begin training stage: [725/805]
2025-03-03 08:23:07,848 - INFO - Epoch:[725/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:23:11,268 - INFO - Epoch:[725/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 08:23:14,611 - INFO - Epoch:[725/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:23:17,990 - INFO - Epoch:[725/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 08:23:21,370 - INFO - Epoch:[725/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.15
2025-03-03 08:23:25,131 - INFO - Epoch:[725/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:23:28,511 - INFO - Epoch:[725/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 08:23:31,899 - INFO - Epoch:[725/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 08:23:35,050 - INFO - Epoch:[725/805] Step:[90/90] reconstruction_loss: 1.23 loss_vc: 1.23 loss_cvh: 0.68
2025-03-03 08:23:36,004 - INFO - now the learning rate is: 1e-05
2025-03-03 08:24:09,584 - INFO - begin training stage: [726/805]
2025-03-03 08:24:09,585 - INFO - begin training stage: [726/805]
2025-03-03 08:24:13,839 - INFO - Epoch:[726/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 08:24:17,270 - INFO - Epoch:[726/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 08:24:20,629 - INFO - Epoch:[726/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 08:24:24,019 - INFO - Epoch:[726/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:24:27,324 - INFO - Epoch:[726/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 08:24:30,918 - INFO - Epoch:[726/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:24:34,333 - INFO - Epoch:[726/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.03
2025-03-03 08:24:37,773 - INFO - Epoch:[726/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.13
2025-03-03 08:24:40,966 - INFO - Epoch:[726/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.28 loss_cvh: 0.73
2025-03-03 08:24:41,963 - INFO - now the learning rate is: 1e-05
2025-03-03 08:25:50,031 - INFO - begin training stage: [727/805]
2025-03-03 08:25:50,032 - INFO - begin training stage: [727/805]
2025-03-03 08:25:55,312 - INFO - Epoch:[727/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 08:25:58,644 - INFO - Epoch:[727/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 08:26:01,963 - INFO - Epoch:[727/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 08:26:05,302 - INFO - Epoch:[727/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:26:08,603 - INFO - Epoch:[727/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 08:26:12,045 - INFO - Epoch:[727/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:26:15,341 - INFO - Epoch:[727/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 08:26:18,674 - INFO - Epoch:[727/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:26:21,775 - INFO - Epoch:[727/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.33 loss_cvh: 0.71
2025-03-03 08:26:22,690 - INFO - now the learning rate is: 1e-05
2025-03-03 08:26:55,452 - INFO - begin training stage: [728/805]
2025-03-03 08:26:55,452 - INFO - begin training stage: [728/805]
2025-03-03 08:26:59,928 - INFO - Epoch:[728/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.17
2025-03-03 08:27:03,324 - INFO - Epoch:[728/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:27:06,680 - INFO - Epoch:[728/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 08:27:10,077 - INFO - Epoch:[728/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 08:27:13,431 - INFO - Epoch:[728/805] Step:[50/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 08:27:16,766 - INFO - Epoch:[728/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:27:20,092 - INFO - Epoch:[728/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.14
2025-03-03 08:27:23,344 - INFO - Epoch:[728/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.02
2025-03-03 08:27:26,395 - INFO - Epoch:[728/805] Step:[90/90] reconstruction_loss: 1.07 loss_vc: 1.29 loss_cvh: 0.95
2025-03-03 08:27:27,329 - INFO - now the learning rate is: 1e-05
2025-03-03 08:27:59,791 - INFO - begin training stage: [729/805]
2025-03-03 08:27:59,792 - INFO - begin training stage: [729/805]
2025-03-03 08:28:04,047 - INFO - Epoch:[729/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 08:28:07,478 - INFO - Epoch:[729/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 08:28:10,705 - INFO - Epoch:[729/805] Step:[30/90] reconstruction_loss: 1.11 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 08:28:13,974 - INFO - Epoch:[729/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:28:17,175 - INFO - Epoch:[729/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 08:28:20,406 - INFO - Epoch:[729/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 08:28:23,676 - INFO - Epoch:[729/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:28:26,887 - INFO - Epoch:[729/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.02
2025-03-03 08:28:29,907 - INFO - Epoch:[729/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.16 loss_cvh: 0.81
2025-03-03 08:28:30,837 - INFO - now the learning rate is: 1e-05
2025-03-03 08:29:36,078 - INFO - begin training stage: [730/805]
2025-03-03 08:29:36,079 - INFO - begin training stage: [730/805]
2025-03-03 08:29:42,088 - INFO - Epoch:[730/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 08:29:46,709 - INFO - Epoch:[730/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 08:29:51,515 - INFO - Epoch:[730/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 08:29:56,027 - INFO - Epoch:[730/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:29:59,497 - INFO - Epoch:[730/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:30:02,661 - INFO - Epoch:[730/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:30:05,850 - INFO - Epoch:[730/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 08:30:09,012 - INFO - Epoch:[730/805] Step:[80/90] reconstruction_loss: 1.11 loss_vc: 4.34 loss_cvh: 3.03
2025-03-03 08:30:11,937 - INFO - Epoch:[730/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.19 loss_cvh: 0.83
2025-03-03 08:30:12,840 - INFO - now the learning rate is: 1e-05
2025-03-03 08:30:44,088 - INFO - begin training stage: [731/805]
2025-03-03 08:30:44,089 - INFO - eval data number: 45600
2025-03-03 08:30:44,089 - INFO - loading eval data ......
2025-03-03 08:31:14,957 - INFO - retrieval costs: 19.3281672000885
2025-03-03 08:32:31,025 - INFO - hamming distance computation costs: 76.0680615901947
2025-03-03 08:32:36,943 - INFO - hamming ranking costs: 5.9181227684021
2025-03-03 08:32:36,943 - INFO - labels shape: (45600, 239)
2025-03-03 08:33:11,919 - INFO - similarity labels generation costs: 34.97530269622803
2025-03-03 08:33:12,078 - INFO - topK: 5:, map: 0.337775
2025-03-03 08:33:12,381 - INFO - topK: 20:, map: 0.24183351425266766
2025-03-03 08:33:12,890 - INFO - topK: 40:, map: 0.2093849713751569
2025-03-03 08:33:13,644 - INFO - topK: 60:, map: 0.18989529860672122
2025-03-03 08:33:14,644 - INFO - topK: 80:, map: 0.17527327015054464
2025-03-03 08:33:15,896 - INFO - topK: 100:, map: 0.16295239058888433
2025-03-03 08:33:17,381 - INFO - begin training stage: [731/805]
2025-03-03 08:33:22,073 - INFO - Epoch:[731/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:33:25,558 - INFO - Epoch:[731/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 08:33:29,151 - INFO - Epoch:[731/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 08:33:32,608 - INFO - Epoch:[731/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 08:33:35,989 - INFO - Epoch:[731/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:33:39,408 - INFO - Epoch:[731/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 08:33:42,844 - INFO - Epoch:[731/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.39 loss_cvh: 3.13
2025-03-03 08:33:46,259 - INFO - Epoch:[731/805] Step:[80/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.16
2025-03-03 08:33:49,376 - INFO - Epoch:[731/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.13 loss_cvh: 0.70
2025-03-03 08:33:50,962 - INFO - now the learning rate is: 1e-05
2025-03-03 08:34:25,494 - INFO - begin training stage: [732/805]
2025-03-03 08:34:25,494 - INFO - begin training stage: [732/805]
2025-03-03 08:34:30,359 - INFO - Epoch:[732/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 08:34:33,989 - INFO - Epoch:[732/805] Step:[20/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:34:37,748 - INFO - Epoch:[732/805] Step:[30/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 08:34:41,255 - INFO - Epoch:[732/805] Step:[40/90] reconstruction_loss: 1.10 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:34:44,800 - INFO - Epoch:[732/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 08:34:48,376 - INFO - Epoch:[732/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.15
2025-03-03 08:34:51,892 - INFO - Epoch:[732/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 08:34:55,435 - INFO - Epoch:[732/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 08:34:58,708 - INFO - Epoch:[732/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.25 loss_cvh: 0.85
2025-03-03 08:35:00,035 - INFO - now the learning rate is: 1e-05
2025-03-03 08:35:34,430 - INFO - begin training stage: [733/805]
2025-03-03 08:35:34,430 - INFO - begin training stage: [733/805]
2025-03-03 08:35:39,550 - INFO - Epoch:[733/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:35:43,126 - INFO - Epoch:[733/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 08:35:46,729 - INFO - Epoch:[733/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:35:50,261 - INFO - Epoch:[733/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:35:53,843 - INFO - Epoch:[733/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:35:57,319 - INFO - Epoch:[733/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 08:36:00,876 - INFO - Epoch:[733/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 08:36:04,452 - INFO - Epoch:[733/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:36:07,735 - INFO - Epoch:[733/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.11 loss_cvh: 0.71
2025-03-03 08:36:09,061 - INFO - now the learning rate is: 1e-05
2025-03-03 08:36:44,329 - INFO - begin training stage: [734/805]
2025-03-03 08:36:44,329 - INFO - begin training stage: [734/805]
2025-03-03 08:36:49,286 - INFO - Epoch:[734/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:36:52,884 - INFO - Epoch:[734/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.03
2025-03-03 08:36:56,452 - INFO - Epoch:[734/805] Step:[30/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:37:00,001 - INFO - Epoch:[734/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 08:37:03,581 - INFO - Epoch:[734/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:37:07,163 - INFO - Epoch:[734/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:37:10,566 - INFO - Epoch:[734/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 08:37:14,052 - INFO - Epoch:[734/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:37:17,306 - INFO - Epoch:[734/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.34 loss_cvh: 0.91
2025-03-03 08:37:18,642 - INFO - now the learning rate is: 1e-05
2025-03-03 08:37:53,642 - INFO - begin training stage: [735/805]
2025-03-03 08:37:53,642 - INFO - begin training stage: [735/805]
2025-03-03 08:37:58,474 - INFO - Epoch:[735/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 08:38:01,979 - INFO - Epoch:[735/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.15
2025-03-03 08:38:05,474 - INFO - Epoch:[735/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 08:38:09,002 - INFO - Epoch:[735/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:38:12,516 - INFO - Epoch:[735/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 08:38:15,974 - INFO - Epoch:[735/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 08:38:19,492 - INFO - Epoch:[735/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 08:38:22,985 - INFO - Epoch:[735/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 08:38:26,106 - INFO - Epoch:[735/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.21 loss_cvh: 0.87
2025-03-03 08:38:27,421 - INFO - now the learning rate is: 1e-05
2025-03-03 08:39:28,549 - INFO - begin training stage: [736/805]
2025-03-03 08:39:28,550 - INFO - begin training stage: [736/805]
2025-03-03 08:39:35,749 - INFO - Epoch:[736/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 08:39:40,734 - INFO - Epoch:[736/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 08:39:45,660 - INFO - Epoch:[736/805] Step:[30/90] reconstruction_loss: 1.10 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 08:39:50,459 - INFO - Epoch:[736/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 08:39:55,819 - INFO - Epoch:[736/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.13
2025-03-03 08:40:01,471 - INFO - Epoch:[736/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 08:40:06,790 - INFO - Epoch:[736/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 08:40:11,507 - INFO - Epoch:[736/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.12
2025-03-03 08:40:15,656 - INFO - Epoch:[736/805] Step:[90/90] reconstruction_loss: 1.37 loss_vc: 1.20 loss_cvh: 0.97
2025-03-03 08:40:16,659 - INFO - now the learning rate is: 1e-05
2025-03-03 08:40:55,584 - INFO - begin training stage: [737/805]
2025-03-03 08:40:55,584 - INFO - begin training stage: [737/805]
2025-03-03 08:41:00,521 - INFO - Epoch:[737/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 08:41:04,497 - INFO - Epoch:[737/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:41:08,528 - INFO - Epoch:[737/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 08:41:12,440 - INFO - Epoch:[737/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:41:16,347 - INFO - Epoch:[737/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 08:41:20,231 - INFO - Epoch:[737/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 08:41:24,163 - INFO - Epoch:[737/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:41:27,998 - INFO - Epoch:[737/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 08:41:31,662 - INFO - Epoch:[737/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.15 loss_cvh: 0.73
2025-03-03 08:41:32,741 - INFO - now the learning rate is: 1e-05
2025-03-03 08:42:02,518 - INFO - begin training stage: [738/805]
2025-03-03 08:42:02,518 - INFO - begin training stage: [738/805]
2025-03-03 08:42:06,501 - INFO - Epoch:[738/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:42:09,463 - INFO - Epoch:[738/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 08:42:12,492 - INFO - Epoch:[738/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 08:42:15,462 - INFO - Epoch:[738/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:42:18,494 - INFO - Epoch:[738/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:42:21,496 - INFO - Epoch:[738/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 08:42:24,474 - INFO - Epoch:[738/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:42:27,459 - INFO - Epoch:[738/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 08:42:30,217 - INFO - Epoch:[738/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.08 loss_cvh: 0.86
2025-03-03 08:42:31,355 - INFO - now the learning rate is: 1e-05
2025-03-03 08:43:01,166 - INFO - begin training stage: [739/805]
2025-03-03 08:43:01,167 - INFO - begin training stage: [739/805]
2025-03-03 08:43:05,172 - INFO - Epoch:[739/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:43:08,164 - INFO - Epoch:[739/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 08:43:11,173 - INFO - Epoch:[739/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.12
2025-03-03 08:43:14,177 - INFO - Epoch:[739/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:43:17,191 - INFO - Epoch:[739/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 08:43:20,197 - INFO - Epoch:[739/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 08:43:23,152 - INFO - Epoch:[739/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 08:43:26,107 - INFO - Epoch:[739/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 08:43:29,184 - INFO - Epoch:[739/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.22 loss_cvh: 0.77
2025-03-03 08:43:30,725 - INFO - now the learning rate is: 1e-05
2025-03-03 08:44:34,975 - INFO - begin training stage: [740/805]
2025-03-03 08:44:34,976 - INFO - begin training stage: [740/805]
2025-03-03 08:44:39,289 - INFO - Epoch:[740/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.31 loss_cvh: 3.06
2025-03-03 08:44:42,557 - INFO - Epoch:[740/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.13
2025-03-03 08:44:45,810 - INFO - Epoch:[740/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 08:44:49,072 - INFO - Epoch:[740/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 08:44:52,336 - INFO - Epoch:[740/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:44:55,613 - INFO - Epoch:[740/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 08:44:58,877 - INFO - Epoch:[740/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 08:45:02,126 - INFO - Epoch:[740/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:45:05,189 - INFO - Epoch:[740/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.28 loss_cvh: 0.65
2025-03-03 08:45:06,242 - INFO - now the learning rate is: 1e-05
2025-03-03 08:45:39,422 - INFO - begin training stage: [741/805]
2025-03-03 08:45:39,423 - INFO - eval data number: 45600
2025-03-03 08:45:39,423 - INFO - loading eval data ......
2025-03-03 08:46:10,883 - INFO - retrieval costs: 19.71890950202942
2025-03-03 08:47:24,635 - INFO - hamming distance computation costs: 73.75178742408752
2025-03-03 08:47:30,716 - INFO - hamming ranking costs: 6.080941438674927
2025-03-03 08:47:30,716 - INFO - labels shape: (45600, 239)
2025-03-03 08:48:05,252 - INFO - similarity labels generation costs: 34.53630566596985
2025-03-03 08:48:05,326 - INFO - topK: 5:, map: 0.33926
2025-03-03 08:48:05,588 - INFO - topK: 20:, map: 0.24264046126302316
2025-03-03 08:48:06,082 - INFO - topK: 40:, map: 0.2093026547997863
2025-03-03 08:48:06,818 - INFO - topK: 60:, map: 0.1891606903101654
2025-03-03 08:48:07,791 - INFO - topK: 80:, map: 0.1740602535355836
2025-03-03 08:48:09,013 - INFO - topK: 100:, map: 0.16210544004383295
2025-03-03 08:48:10,107 - INFO - begin training stage: [741/805]
2025-03-03 08:48:14,600 - INFO - Epoch:[741/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 08:48:18,104 - INFO - Epoch:[741/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.14
2025-03-03 08:48:21,513 - INFO - Epoch:[741/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:48:24,959 - INFO - Epoch:[741/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 08:48:28,292 - INFO - Epoch:[741/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 08:48:31,747 - INFO - Epoch:[741/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 08:48:35,162 - INFO - Epoch:[741/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 08:48:38,511 - INFO - Epoch:[741/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:48:41,661 - INFO - Epoch:[741/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.25 loss_cvh: 0.77
2025-03-03 08:48:42,724 - INFO - now the learning rate is: 1e-05
2025-03-03 08:49:16,713 - INFO - begin training stage: [742/805]
2025-03-03 08:49:16,713 - INFO - begin training stage: [742/805]
2025-03-03 08:49:21,116 - INFO - Epoch:[742/805] Step:[10/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:49:24,582 - INFO - Epoch:[742/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 08:49:28,010 - INFO - Epoch:[742/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 08:49:31,430 - INFO - Epoch:[742/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 08:49:34,788 - INFO - Epoch:[742/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 08:49:38,278 - INFO - Epoch:[742/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 08:49:41,651 - INFO - Epoch:[742/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:49:45,063 - INFO - Epoch:[742/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.05
2025-03-03 08:49:48,230 - INFO - Epoch:[742/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.19 loss_cvh: 0.81
2025-03-03 08:49:49,321 - INFO - now the learning rate is: 1e-05
2025-03-03 08:50:23,357 - INFO - begin training stage: [743/805]
2025-03-03 08:50:23,358 - INFO - begin training stage: [743/805]
2025-03-03 08:50:27,742 - INFO - Epoch:[743/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 08:50:31,116 - INFO - Epoch:[743/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:50:34,486 - INFO - Epoch:[743/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:50:37,895 - INFO - Epoch:[743/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:50:41,285 - INFO - Epoch:[743/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:50:44,602 - INFO - Epoch:[743/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:50:47,987 - INFO - Epoch:[743/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 08:50:51,419 - INFO - Epoch:[743/805] Step:[80/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.03
2025-03-03 08:50:54,572 - INFO - Epoch:[743/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.05 loss_cvh: 0.56
2025-03-03 08:50:55,639 - INFO - now the learning rate is: 1e-05
2025-03-03 08:51:28,973 - INFO - begin training stage: [744/805]
2025-03-03 08:51:28,973 - INFO - begin training stage: [744/805]
2025-03-03 08:51:33,366 - INFO - Epoch:[744/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:51:36,810 - INFO - Epoch:[744/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:51:40,193 - INFO - Epoch:[744/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 08:51:43,591 - INFO - Epoch:[744/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 08:51:46,955 - INFO - Epoch:[744/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 08:51:50,355 - INFO - Epoch:[744/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 08:51:53,915 - INFO - Epoch:[744/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 08:51:57,337 - INFO - Epoch:[744/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:52:00,460 - INFO - Epoch:[744/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.13 loss_cvh: 0.81
2025-03-03 08:52:01,519 - INFO - now the learning rate is: 1e-05
2025-03-03 08:52:34,896 - INFO - begin training stage: [745/805]
2025-03-03 08:52:34,896 - INFO - begin training stage: [745/805]
2025-03-03 08:52:39,280 - INFO - Epoch:[745/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:52:42,698 - INFO - Epoch:[745/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 08:52:46,098 - INFO - Epoch:[745/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 08:52:49,498 - INFO - Epoch:[745/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:52:52,880 - INFO - Epoch:[745/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:52:56,244 - INFO - Epoch:[745/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.10
2025-03-03 08:52:59,489 - INFO - Epoch:[745/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:53:02,753 - INFO - Epoch:[745/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:53:05,794 - INFO - Epoch:[745/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.29 loss_cvh: 0.80
2025-03-03 08:53:06,860 - INFO - now the learning rate is: 1e-05
2025-03-03 08:54:05,679 - INFO - begin training stage: [746/805]
2025-03-03 08:54:05,679 - INFO - begin training stage: [746/805]
2025-03-03 08:54:11,805 - INFO - Epoch:[746/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 08:54:16,062 - INFO - Epoch:[746/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:54:20,509 - INFO - Epoch:[746/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:54:24,920 - INFO - Epoch:[746/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 08:54:29,455 - INFO - Epoch:[746/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:54:33,804 - INFO - Epoch:[746/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:54:38,387 - INFO - Epoch:[746/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 08:54:42,659 - INFO - Epoch:[746/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 08:54:45,688 - INFO - Epoch:[746/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.19 loss_cvh: 0.87
2025-03-03 08:54:46,723 - INFO - now the learning rate is: 1e-05
2025-03-03 08:55:18,964 - INFO - begin training stage: [747/805]
2025-03-03 08:55:18,964 - INFO - begin training stage: [747/805]
2025-03-03 08:55:23,165 - INFO - Epoch:[747/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:55:26,520 - INFO - Epoch:[747/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:55:29,901 - INFO - Epoch:[747/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:55:33,287 - INFO - Epoch:[747/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 08:55:36,665 - INFO - Epoch:[747/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 08:55:40,048 - INFO - Epoch:[747/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 08:55:43,493 - INFO - Epoch:[747/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:55:46,896 - INFO - Epoch:[747/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 08:55:50,100 - INFO - Epoch:[747/805] Step:[90/90] reconstruction_loss: 1.49 loss_vc: 1.13 loss_cvh: 0.82
2025-03-03 08:55:51,193 - INFO - now the learning rate is: 1e-05
2025-03-03 08:56:24,369 - INFO - begin training stage: [748/805]
2025-03-03 08:56:24,369 - INFO - begin training stage: [748/805]
2025-03-03 08:56:28,663 - INFO - Epoch:[748/805] Step:[10/90] reconstruction_loss: 1.17 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 08:56:32,004 - INFO - Epoch:[748/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 08:56:35,262 - INFO - Epoch:[748/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:56:38,554 - INFO - Epoch:[748/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.10
2025-03-03 08:56:41,859 - INFO - Epoch:[748/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 08:56:45,155 - INFO - Epoch:[748/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:56:48,535 - INFO - Epoch:[748/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:56:51,974 - INFO - Epoch:[748/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 08:56:55,204 - INFO - Epoch:[748/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.08 loss_cvh: 0.96
2025-03-03 08:56:56,261 - INFO - now the learning rate is: 1e-05
2025-03-03 08:57:54,537 - INFO - begin training stage: [749/805]
2025-03-03 08:57:54,537 - INFO - begin training stage: [749/805]
2025-03-03 08:58:00,419 - INFO - Epoch:[749/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 08:58:05,409 - INFO - Epoch:[749/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:58:09,875 - INFO - Epoch:[749/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 08:58:14,820 - INFO - Epoch:[749/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 08:58:19,730 - INFO - Epoch:[749/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 08:58:24,137 - INFO - Epoch:[749/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 08:58:29,014 - INFO - Epoch:[749/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 08:58:34,039 - INFO - Epoch:[749/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 08:58:38,298 - INFO - Epoch:[749/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.17 loss_cvh: 0.81
2025-03-03 08:58:39,886 - INFO - now the learning rate is: 1e-05
2025-03-03 08:59:12,947 - INFO - begin training stage: [750/805]
2025-03-03 08:59:12,947 - INFO - begin training stage: [750/805]
2025-03-03 08:59:17,209 - INFO - Epoch:[750/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 08:59:20,542 - INFO - Epoch:[750/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 08:59:23,820 - INFO - Epoch:[750/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 08:59:27,137 - INFO - Epoch:[750/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 08:59:30,378 - INFO - Epoch:[750/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 08:59:33,714 - INFO - Epoch:[750/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 08:59:37,078 - INFO - Epoch:[750/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 08:59:40,320 - INFO - Epoch:[750/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 08:59:43,351 - INFO - Epoch:[750/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.28 loss_cvh: 0.66
2025-03-03 08:59:44,398 - INFO - now the learning rate is: 1e-05
2025-03-03 09:00:16,553 - INFO - begin training stage: [751/805]
2025-03-03 09:00:16,554 - INFO - eval data number: 45600
2025-03-03 09:00:16,554 - INFO - loading eval data ......
2025-03-03 09:00:47,933 - INFO - retrieval costs: 19.161753177642822
2025-03-03 09:01:54,397 - INFO - hamming distance computation costs: 66.46382188796997
2025-03-03 09:02:00,630 - INFO - hamming ranking costs: 6.233185291290283
2025-03-03 09:02:00,630 - INFO - labels shape: (45600, 239)
2025-03-03 09:02:34,886 - INFO - similarity labels generation costs: 34.256057262420654
2025-03-03 09:02:34,958 - INFO - topK: 5:, map: 0.33867583333333334
2025-03-03 09:02:35,202 - INFO - topK: 20:, map: 0.24274198601068905
2025-03-03 09:02:35,677 - INFO - topK: 40:, map: 0.20897241451220447
2025-03-03 09:02:36,405 - INFO - topK: 60:, map: 0.18966664010489737
2025-03-03 09:02:37,373 - INFO - topK: 80:, map: 0.1752581784513219
2025-03-03 09:02:38,571 - INFO - topK: 100:, map: 0.16285871506247557
2025-03-03 09:02:40,077 - INFO - begin training stage: [751/805]
2025-03-03 09:02:44,381 - INFO - Epoch:[751/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.04
2025-03-03 09:02:47,681 - INFO - Epoch:[751/805] Step:[20/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:02:50,931 - INFO - Epoch:[751/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 09:02:54,343 - INFO - Epoch:[751/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 09:02:57,818 - INFO - Epoch:[751/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 09:03:01,100 - INFO - Epoch:[751/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.38 loss_cvh: 3.11
2025-03-03 09:03:04,435 - INFO - Epoch:[751/805] Step:[70/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:03:07,695 - INFO - Epoch:[751/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:03:10,745 - INFO - Epoch:[751/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.26 loss_cvh: 0.90
2025-03-03 09:03:11,804 - INFO - now the learning rate is: 1e-05
2025-03-03 09:03:43,897 - INFO - begin training stage: [752/805]
2025-03-03 09:03:43,898 - INFO - begin training stage: [752/805]
2025-03-03 09:03:48,130 - INFO - Epoch:[752/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:03:51,373 - INFO - Epoch:[752/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 09:03:54,656 - INFO - Epoch:[752/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 09:03:57,988 - INFO - Epoch:[752/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:04:01,331 - INFO - Epoch:[752/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:04:04,594 - INFO - Epoch:[752/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:04:07,901 - INFO - Epoch:[752/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.09
2025-03-03 09:04:11,268 - INFO - Epoch:[752/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.14
2025-03-03 09:04:14,285 - INFO - Epoch:[752/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.23 loss_cvh: 0.84
2025-03-03 09:04:15,339 - INFO - now the learning rate is: 1e-05
2025-03-03 09:04:47,220 - INFO - begin training stage: [753/805]
2025-03-03 09:04:47,220 - INFO - begin training stage: [753/805]
2025-03-03 09:04:51,417 - INFO - Epoch:[753/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.10
2025-03-03 09:04:54,656 - INFO - Epoch:[753/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 09:04:57,938 - INFO - Epoch:[753/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:05:01,192 - INFO - Epoch:[753/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 09:05:04,602 - INFO - Epoch:[753/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:05:07,831 - INFO - Epoch:[753/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:05:11,133 - INFO - Epoch:[753/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:05:14,382 - INFO - Epoch:[753/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 09:05:17,393 - INFO - Epoch:[753/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.28 loss_cvh: 0.62
2025-03-03 09:05:18,463 - INFO - now the learning rate is: 1e-05
2025-03-03 09:05:50,703 - INFO - begin training stage: [754/805]
2025-03-03 09:05:50,703 - INFO - begin training stage: [754/805]
2025-03-03 09:05:54,960 - INFO - Epoch:[754/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 09:05:58,273 - INFO - Epoch:[754/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:06:01,565 - INFO - Epoch:[754/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:06:04,919 - INFO - Epoch:[754/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 09:06:08,204 - INFO - Epoch:[754/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 09:06:11,495 - INFO - Epoch:[754/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 09:06:14,816 - INFO - Epoch:[754/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:06:18,116 - INFO - Epoch:[754/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:06:21,127 - INFO - Epoch:[754/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.29 loss_cvh: 0.89
2025-03-03 09:06:22,197 - INFO - now the learning rate is: 1e-05
2025-03-03 09:06:54,658 - INFO - begin training stage: [755/805]
2025-03-03 09:06:54,658 - INFO - begin training stage: [755/805]
2025-03-03 09:06:58,911 - INFO - Epoch:[755/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 09:07:02,239 - INFO - Epoch:[755/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:07:05,547 - INFO - Epoch:[755/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:07:08,855 - INFO - Epoch:[755/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.13
2025-03-03 09:07:12,195 - INFO - Epoch:[755/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.11
2025-03-03 09:07:15,481 - INFO - Epoch:[755/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 09:07:18,753 - INFO - Epoch:[755/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.14
2025-03-03 09:07:22,064 - INFO - Epoch:[755/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 09:07:25,067 - INFO - Epoch:[755/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.43 loss_cvh: 1.17
2025-03-03 09:07:26,131 - INFO - now the learning rate is: 1e-05
2025-03-03 09:08:28,795 - INFO - begin training stage: [756/805]
2025-03-03 09:08:28,795 - INFO - begin training stage: [756/805]
2025-03-03 09:08:34,829 - INFO - Epoch:[756/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:08:39,383 - INFO - Epoch:[756/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:08:43,007 - INFO - Epoch:[756/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 09:08:46,274 - INFO - Epoch:[756/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 09:08:49,514 - INFO - Epoch:[756/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 09:08:52,725 - INFO - Epoch:[756/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.09
2025-03-03 09:08:55,960 - INFO - Epoch:[756/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:08:59,166 - INFO - Epoch:[756/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:09:02,119 - INFO - Epoch:[756/805] Step:[90/90] reconstruction_loss: 1.29 loss_vc: 1.07 loss_cvh: 0.83
2025-03-03 09:09:03,184 - INFO - now the learning rate is: 1e-05
2025-03-03 09:09:35,152 - INFO - begin training stage: [757/805]
2025-03-03 09:09:35,152 - INFO - begin training stage: [757/805]
2025-03-03 09:09:39,324 - INFO - Epoch:[757/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.15
2025-03-03 09:09:42,543 - INFO - Epoch:[757/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.11
2025-03-03 09:09:45,949 - INFO - Epoch:[757/805] Step:[30/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 09:09:49,188 - INFO - Epoch:[757/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:09:52,509 - INFO - Epoch:[757/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 09:09:55,753 - INFO - Epoch:[757/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 09:09:58,995 - INFO - Epoch:[757/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 09:10:02,287 - INFO - Epoch:[757/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 09:10:05,321 - INFO - Epoch:[757/805] Step:[90/90] reconstruction_loss: 1.04 loss_vc: 1.11 loss_cvh: 0.92
2025-03-03 09:10:06,383 - INFO - now the learning rate is: 1e-05
2025-03-03 09:10:38,513 - INFO - begin training stage: [758/805]
2025-03-03 09:10:38,513 - INFO - begin training stage: [758/805]
2025-03-03 09:10:42,753 - INFO - Epoch:[758/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:10:46,017 - INFO - Epoch:[758/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 09:10:49,321 - INFO - Epoch:[758/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:10:52,606 - INFO - Epoch:[758/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:10:55,882 - INFO - Epoch:[758/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 09:10:59,158 - INFO - Epoch:[758/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 09:11:02,468 - INFO - Epoch:[758/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 09:11:05,718 - INFO - Epoch:[758/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 09:11:08,870 - INFO - Epoch:[758/805] Step:[90/90] reconstruction_loss: 1.02 loss_vc: 1.26 loss_cvh: 0.76
2025-03-03 09:11:09,955 - INFO - now the learning rate is: 1e-05
2025-03-03 09:12:11,569 - INFO - begin training stage: [759/805]
2025-03-03 09:12:11,569 - INFO - begin training stage: [759/805]
2025-03-03 09:12:17,557 - INFO - Epoch:[759/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 09:12:22,058 - INFO - Epoch:[759/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:12:26,817 - INFO - Epoch:[759/805] Step:[30/90] reconstruction_loss: 1.11 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:12:31,583 - INFO - Epoch:[759/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 09:12:36,265 - INFO - Epoch:[759/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 09:12:40,767 - INFO - Epoch:[759/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:12:45,175 - INFO - Epoch:[759/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 09:12:48,381 - INFO - Epoch:[759/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:12:51,330 - INFO - Epoch:[759/805] Step:[90/90] reconstruction_loss: 1.25 loss_vc: 1.13 loss_cvh: 0.63
2025-03-03 09:12:52,372 - INFO - now the learning rate is: 1e-05
2025-03-03 09:13:24,267 - INFO - begin training stage: [760/805]
2025-03-03 09:13:24,267 - INFO - begin training stage: [760/805]
2025-03-03 09:13:28,520 - INFO - Epoch:[760/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 09:13:31,874 - INFO - Epoch:[760/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 09:13:35,147 - INFO - Epoch:[760/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.17
2025-03-03 09:13:38,455 - INFO - Epoch:[760/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:13:41,743 - INFO - Epoch:[760/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 09:13:45,081 - INFO - Epoch:[760/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 09:13:48,421 - INFO - Epoch:[760/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:13:51,676 - INFO - Epoch:[760/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 09:13:54,756 - INFO - Epoch:[760/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.29 loss_cvh: 0.89
2025-03-03 09:13:55,815 - INFO - now the learning rate is: 1e-05
2025-03-03 09:14:27,882 - INFO - begin training stage: [761/805]
2025-03-03 09:14:27,883 - INFO - eval data number: 45600
2025-03-03 09:14:27,883 - INFO - loading eval data ......
2025-03-03 09:14:59,312 - INFO - retrieval costs: 19.38261389732361
2025-03-03 09:16:08,329 - INFO - hamming distance computation costs: 69.01692533493042
2025-03-03 09:16:14,381 - INFO - hamming ranking costs: 6.052217960357666
2025-03-03 09:16:14,381 - INFO - labels shape: (45600, 239)
2025-03-03 09:16:48,443 - INFO - similarity labels generation costs: 34.061580657958984
2025-03-03 09:16:48,514 - INFO - topK: 5:, map: 0.3389691666666667
2025-03-03 09:16:48,766 - INFO - topK: 20:, map: 0.24483344403913723
2025-03-03 09:16:49,261 - INFO - topK: 40:, map: 0.2104432804379722
2025-03-03 09:16:49,981 - INFO - topK: 60:, map: 0.190062849827629
2025-03-03 09:16:50,956 - INFO - topK: 80:, map: 0.17527806228200982
2025-03-03 09:16:52,155 - INFO - topK: 100:, map: 0.16340646841822756
2025-03-03 09:16:53,557 - INFO - begin training stage: [761/805]
2025-03-03 09:16:57,811 - INFO - Epoch:[761/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 09:17:01,039 - INFO - Epoch:[761/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 09:17:04,276 - INFO - Epoch:[761/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 09:17:07,527 - INFO - Epoch:[761/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 09:17:10,764 - INFO - Epoch:[761/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 09:17:14,056 - INFO - Epoch:[761/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 09:17:17,303 - INFO - Epoch:[761/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.16
2025-03-03 09:17:20,572 - INFO - Epoch:[761/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 09:17:23,588 - INFO - Epoch:[761/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.19 loss_cvh: 0.73
2025-03-03 09:17:24,651 - INFO - now the learning rate is: 1e-05
2025-03-03 09:17:56,748 - INFO - begin training stage: [762/805]
2025-03-03 09:17:56,748 - INFO - begin training stage: [762/805]
2025-03-03 09:18:00,951 - INFO - Epoch:[762/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 09:18:04,217 - INFO - Epoch:[762/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:18:07,474 - INFO - Epoch:[762/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:18:10,777 - INFO - Epoch:[762/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:18:14,019 - INFO - Epoch:[762/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 09:18:17,317 - INFO - Epoch:[762/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 09:18:20,639 - INFO - Epoch:[762/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 09:18:23,891 - INFO - Epoch:[762/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 09:18:26,884 - INFO - Epoch:[762/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.31 loss_cvh: 0.85
2025-03-03 09:18:27,935 - INFO - now the learning rate is: 1e-05
2025-03-03 09:19:00,188 - INFO - begin training stage: [763/805]
2025-03-03 09:19:00,188 - INFO - begin training stage: [763/805]
2025-03-03 09:19:04,412 - INFO - Epoch:[763/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.15
2025-03-03 09:19:07,659 - INFO - Epoch:[763/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 09:19:10,912 - INFO - Epoch:[763/805] Step:[30/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.15
2025-03-03 09:19:14,255 - INFO - Epoch:[763/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 09:19:17,506 - INFO - Epoch:[763/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:19:20,843 - INFO - Epoch:[763/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:19:24,158 - INFO - Epoch:[763/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 09:19:27,453 - INFO - Epoch:[763/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 09:19:30,492 - INFO - Epoch:[763/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.37 loss_cvh: 0.83
2025-03-03 09:19:31,568 - INFO - now the learning rate is: 1e-05
2025-03-03 09:20:04,101 - INFO - begin training stage: [764/805]
2025-03-03 09:20:04,101 - INFO - begin training stage: [764/805]
2025-03-03 09:20:08,385 - INFO - Epoch:[764/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.16
2025-03-03 09:20:11,682 - INFO - Epoch:[764/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 09:20:14,943 - INFO - Epoch:[764/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:20:18,318 - INFO - Epoch:[764/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 09:20:21,648 - INFO - Epoch:[764/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.13
2025-03-03 09:20:24,954 - INFO - Epoch:[764/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 09:20:28,293 - INFO - Epoch:[764/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 09:20:31,574 - INFO - Epoch:[764/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 09:20:34,778 - INFO - Epoch:[764/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.16 loss_cvh: 0.85
2025-03-03 09:20:35,853 - INFO - now the learning rate is: 1e-05
2025-03-03 09:21:07,939 - INFO - begin training stage: [765/805]
2025-03-03 09:21:07,940 - INFO - begin training stage: [765/805]
2025-03-03 09:21:12,140 - INFO - Epoch:[765/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:21:15,388 - INFO - Epoch:[765/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 09:21:18,665 - INFO - Epoch:[765/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 09:21:21,942 - INFO - Epoch:[765/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 09:21:25,305 - INFO - Epoch:[765/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:21:28,543 - INFO - Epoch:[765/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 09:21:31,920 - INFO - Epoch:[765/805] Step:[70/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 09:21:35,193 - INFO - Epoch:[765/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 09:21:38,114 - INFO - Epoch:[765/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.33 loss_cvh: 0.69
2025-03-03 09:21:39,198 - INFO - now the learning rate is: 1e-05
2025-03-03 09:22:37,736 - INFO - begin training stage: [766/805]
2025-03-03 09:22:37,736 - INFO - begin training stage: [766/805]
2025-03-03 09:22:43,461 - INFO - Epoch:[766/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 09:22:47,671 - INFO - Epoch:[766/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 09:22:52,028 - INFO - Epoch:[766/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:22:56,677 - INFO - Epoch:[766/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:23:01,170 - INFO - Epoch:[766/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:23:05,551 - INFO - Epoch:[766/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 09:23:09,991 - INFO - Epoch:[766/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 09:23:13,530 - INFO - Epoch:[766/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:23:16,458 - INFO - Epoch:[766/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.17 loss_cvh: 0.72
2025-03-03 09:23:17,497 - INFO - now the learning rate is: 1e-05
2025-03-03 09:23:48,525 - INFO - begin training stage: [767/805]
2025-03-03 09:23:48,525 - INFO - begin training stage: [767/805]
2025-03-03 09:23:52,735 - INFO - Epoch:[767/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 09:23:56,126 - INFO - Epoch:[767/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 09:23:59,384 - INFO - Epoch:[767/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.07
2025-03-03 09:24:02,632 - INFO - Epoch:[767/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:24:05,852 - INFO - Epoch:[767/805] Step:[50/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:24:09,164 - INFO - Epoch:[767/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 09:24:12,531 - INFO - Epoch:[767/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 09:24:15,872 - INFO - Epoch:[767/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 09:24:18,875 - INFO - Epoch:[767/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.29 loss_cvh: 0.87
2025-03-03 09:24:19,926 - INFO - now the learning rate is: 1e-05
2025-03-03 09:24:52,060 - INFO - begin training stage: [768/805]
2025-03-03 09:24:52,060 - INFO - begin training stage: [768/805]
2025-03-03 09:24:56,320 - INFO - Epoch:[768/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 09:24:59,646 - INFO - Epoch:[768/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 09:25:02,947 - INFO - Epoch:[768/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 09:25:06,240 - INFO - Epoch:[768/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:25:09,557 - INFO - Epoch:[768/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.03
2025-03-03 09:25:12,822 - INFO - Epoch:[768/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.33 loss_cvh: 3.06
2025-03-03 09:25:16,197 - INFO - Epoch:[768/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 09:25:19,600 - INFO - Epoch:[768/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 09:25:22,587 - INFO - Epoch:[768/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.33 loss_cvh: 0.78
2025-03-03 09:25:23,680 - INFO - now the learning rate is: 1e-05
2025-03-03 09:26:23,589 - INFO - begin training stage: [769/805]
2025-03-03 09:26:23,589 - INFO - begin training stage: [769/805]
2025-03-03 09:26:29,680 - INFO - Epoch:[769/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:26:34,155 - INFO - Epoch:[769/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 09:26:38,911 - INFO - Epoch:[769/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 09:26:43,592 - INFO - Epoch:[769/805] Step:[40/90] reconstruction_loss: 1.16 loss_vc: 4.38 loss_cvh: 3.03
2025-03-03 09:26:48,385 - INFO - Epoch:[769/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 09:26:53,000 - INFO - Epoch:[769/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.04
2025-03-03 09:26:57,723 - INFO - Epoch:[769/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 09:27:02,335 - INFO - Epoch:[769/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:27:06,465 - INFO - Epoch:[769/805] Step:[90/90] reconstruction_loss: 1.06 loss_vc: 1.38 loss_cvh: 0.69
2025-03-03 09:27:07,966 - INFO - now the learning rate is: 1e-05
2025-03-03 09:27:40,279 - INFO - begin training stage: [770/805]
2025-03-03 09:27:40,279 - INFO - begin training stage: [770/805]
2025-03-03 09:27:44,500 - INFO - Epoch:[770/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 09:27:47,761 - INFO - Epoch:[770/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:27:51,062 - INFO - Epoch:[770/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.32 loss_cvh: 3.07
2025-03-03 09:27:54,329 - INFO - Epoch:[770/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 09:27:57,611 - INFO - Epoch:[770/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:28:00,885 - INFO - Epoch:[770/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.12
2025-03-03 09:28:04,199 - INFO - Epoch:[770/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:28:07,589 - INFO - Epoch:[770/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 09:28:10,616 - INFO - Epoch:[770/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.10 loss_cvh: 0.70
2025-03-03 09:28:11,691 - INFO - now the learning rate is: 1e-05
2025-03-03 09:28:43,903 - INFO - begin training stage: [771/805]
2025-03-03 09:28:43,904 - INFO - eval data number: 45600
2025-03-03 09:28:43,904 - INFO - loading eval data ......
2025-03-03 09:29:15,642 - INFO - retrieval costs: 19.448805332183838
2025-03-03 09:30:21,701 - INFO - hamming distance computation costs: 66.05811071395874
2025-03-03 09:30:27,866 - INFO - hamming ranking costs: 6.1658666133880615
2025-03-03 09:30:27,867 - INFO - labels shape: (45600, 239)
2025-03-03 09:31:02,546 - INFO - similarity labels generation costs: 34.67938780784607
2025-03-03 09:31:02,618 - INFO - topK: 5:, map: 0.34113250000000006
2025-03-03 09:31:02,879 - INFO - topK: 20:, map: 0.2447681067018959
2025-03-03 09:31:03,368 - INFO - topK: 40:, map: 0.21016571422955826
2025-03-03 09:31:04,100 - INFO - topK: 60:, map: 0.19012933239749258
2025-03-03 09:31:05,079 - INFO - topK: 80:, map: 0.17504311153001753
2025-03-03 09:31:06,299 - INFO - topK: 100:, map: 0.16306616959374026
2025-03-03 09:31:07,757 - INFO - begin training stage: [771/805]
2025-03-03 09:31:12,048 - INFO - Epoch:[771/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 09:31:15,292 - INFO - Epoch:[771/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.39 loss_cvh: 3.11
2025-03-03 09:31:18,523 - INFO - Epoch:[771/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:31:21,774 - INFO - Epoch:[771/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:31:24,997 - INFO - Epoch:[771/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.06
2025-03-03 09:31:28,269 - INFO - Epoch:[771/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 09:31:31,546 - INFO - Epoch:[771/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 09:31:34,851 - INFO - Epoch:[771/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:31:37,861 - INFO - Epoch:[771/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.17 loss_cvh: 0.69
2025-03-03 09:31:38,925 - INFO - now the learning rate is: 1e-05
2025-03-03 09:32:11,091 - INFO - begin training stage: [772/805]
2025-03-03 09:32:11,091 - INFO - begin training stage: [772/805]
2025-03-03 09:32:15,287 - INFO - Epoch:[772/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:32:18,491 - INFO - Epoch:[772/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:32:21,686 - INFO - Epoch:[772/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:32:24,921 - INFO - Epoch:[772/805] Step:[40/90] reconstruction_loss: 1.10 loss_vc: 4.38 loss_cvh: 3.06
2025-03-03 09:32:28,182 - INFO - Epoch:[772/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 09:32:31,452 - INFO - Epoch:[772/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:32:34,952 - INFO - Epoch:[772/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:32:38,328 - INFO - Epoch:[772/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:32:41,324 - INFO - Epoch:[772/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.09 loss_cvh: 0.60
2025-03-03 09:32:42,381 - INFO - now the learning rate is: 1e-05
2025-03-03 09:33:14,532 - INFO - begin training stage: [773/805]
2025-03-03 09:33:14,533 - INFO - begin training stage: [773/805]
2025-03-03 09:33:18,780 - INFO - Epoch:[773/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:33:22,025 - INFO - Epoch:[773/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 09:33:25,303 - INFO - Epoch:[773/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 09:33:28,560 - INFO - Epoch:[773/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 09:33:31,829 - INFO - Epoch:[773/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:33:35,090 - INFO - Epoch:[773/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 09:33:38,391 - INFO - Epoch:[773/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 09:33:41,894 - INFO - Epoch:[773/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.14
2025-03-03 09:33:44,911 - INFO - Epoch:[773/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.09 loss_cvh: 0.72
2025-03-03 09:33:45,953 - INFO - now the learning rate is: 1e-05
2025-03-03 09:34:18,908 - INFO - begin training stage: [774/805]
2025-03-03 09:34:18,908 - INFO - begin training stage: [774/805]
2025-03-03 09:34:23,186 - INFO - Epoch:[774/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:34:26,474 - INFO - Epoch:[774/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 09:34:29,733 - INFO - Epoch:[774/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.06
2025-03-03 09:34:32,961 - INFO - Epoch:[774/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 09:34:36,205 - INFO - Epoch:[774/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 09:34:39,463 - INFO - Epoch:[774/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:34:42,803 - INFO - Epoch:[774/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.11
2025-03-03 09:34:46,160 - INFO - Epoch:[774/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 09:34:49,203 - INFO - Epoch:[774/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.13 loss_cvh: 0.53
2025-03-03 09:34:50,305 - INFO - now the learning rate is: 1e-05
2025-03-03 09:35:22,365 - INFO - begin training stage: [775/805]
2025-03-03 09:35:22,365 - INFO - begin training stage: [775/805]
2025-03-03 09:35:26,660 - INFO - Epoch:[775/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 09:35:29,925 - INFO - Epoch:[775/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:35:33,202 - INFO - Epoch:[775/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.15
2025-03-03 09:35:36,458 - INFO - Epoch:[775/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.10
2025-03-03 09:35:39,751 - INFO - Epoch:[775/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:35:42,960 - INFO - Epoch:[775/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:35:46,233 - INFO - Epoch:[775/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:35:49,500 - INFO - Epoch:[775/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 09:35:52,557 - INFO - Epoch:[775/805] Step:[90/90] reconstruction_loss: 1.21 loss_vc: 1.24 loss_cvh: 0.80
2025-03-03 09:35:53,625 - INFO - now the learning rate is: 1e-05
2025-03-03 09:36:30,628 - INFO - begin training stage: [776/805]
2025-03-03 09:36:30,628 - INFO - begin training stage: [776/805]
2025-03-03 09:36:36,908 - INFO - Epoch:[776/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 09:36:41,451 - INFO - Epoch:[776/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 09:36:46,008 - INFO - Epoch:[776/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 09:36:50,419 - INFO - Epoch:[776/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:36:55,123 - INFO - Epoch:[776/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 09:36:59,814 - INFO - Epoch:[776/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.15
2025-03-03 09:37:04,699 - INFO - Epoch:[776/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:37:09,649 - INFO - Epoch:[776/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 09:37:13,996 - INFO - Epoch:[776/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.13 loss_cvh: 0.78
2025-03-03 09:37:15,502 - INFO - now the learning rate is: 1e-05
2025-03-03 09:37:52,982 - INFO - begin training stage: [777/805]
2025-03-03 09:37:52,983 - INFO - begin training stage: [777/805]
2025-03-03 09:37:57,247 - INFO - Epoch:[777/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 09:38:00,536 - INFO - Epoch:[777/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.14
2025-03-03 09:38:03,839 - INFO - Epoch:[777/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 09:38:07,147 - INFO - Epoch:[777/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 09:38:10,436 - INFO - Epoch:[777/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:38:13,834 - INFO - Epoch:[777/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.14
2025-03-03 09:38:17,132 - INFO - Epoch:[777/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 09:38:20,425 - INFO - Epoch:[777/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:38:23,461 - INFO - Epoch:[777/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.24 loss_cvh: 0.89
2025-03-03 09:38:24,527 - INFO - now the learning rate is: 1e-05
2025-03-03 09:38:57,043 - INFO - begin training stage: [778/805]
2025-03-03 09:38:57,043 - INFO - begin training stage: [778/805]
2025-03-03 09:39:01,280 - INFO - Epoch:[778/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 09:39:04,580 - INFO - Epoch:[778/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:39:07,815 - INFO - Epoch:[778/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 09:39:11,118 - INFO - Epoch:[778/805] Step:[40/90] reconstruction_loss: 1.10 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 09:39:14,401 - INFO - Epoch:[778/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:39:17,662 - INFO - Epoch:[778/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.02
2025-03-03 09:39:20,968 - INFO - Epoch:[778/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 09:39:24,372 - INFO - Epoch:[778/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:39:27,415 - INFO - Epoch:[778/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.03 loss_cvh: 0.83
2025-03-03 09:39:28,503 - INFO - now the learning rate is: 1e-05
2025-03-03 09:40:01,293 - INFO - begin training stage: [779/805]
2025-03-03 09:40:01,293 - INFO - begin training stage: [779/805]
2025-03-03 09:40:05,533 - INFO - Epoch:[779/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:40:08,819 - INFO - Epoch:[779/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 09:40:12,119 - INFO - Epoch:[779/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:40:15,421 - INFO - Epoch:[779/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:40:18,711 - INFO - Epoch:[779/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:40:23,039 - INFO - Epoch:[779/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:40:27,600 - INFO - Epoch:[779/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 09:40:32,312 - INFO - Epoch:[779/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 09:40:36,759 - INFO - Epoch:[779/805] Step:[90/90] reconstruction_loss: 1.28 loss_vc: 1.19 loss_cvh: 0.68
2025-03-03 09:40:38,242 - INFO - now the learning rate is: 1e-05
2025-03-03 09:41:34,687 - INFO - begin training stage: [780/805]
2025-03-03 09:41:34,687 - INFO - begin training stage: [780/805]
2025-03-03 09:41:39,027 - INFO - Epoch:[780/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.05
2025-03-03 09:41:42,295 - INFO - Epoch:[780/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 09:41:45,571 - INFO - Epoch:[780/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 09:41:48,823 - INFO - Epoch:[780/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 09:41:52,061 - INFO - Epoch:[780/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 09:41:55,323 - INFO - Epoch:[780/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 09:41:58,593 - INFO - Epoch:[780/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 09:42:01,818 - INFO - Epoch:[780/805] Step:[80/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 09:42:04,807 - INFO - Epoch:[780/805] Step:[90/90] reconstruction_loss: 1.28 loss_vc: 1.26 loss_cvh: 0.89
2025-03-03 09:42:05,831 - INFO - now the learning rate is: 1e-05
2025-03-03 09:42:38,465 - INFO - begin training stage: [781/805]
2025-03-03 09:42:38,466 - INFO - eval data number: 45600
2025-03-03 09:42:38,466 - INFO - loading eval data ......
2025-03-03 09:43:09,763 - INFO - retrieval costs: 19.179620027542114
2025-03-03 09:44:25,945 - INFO - hamming distance computation costs: 76.18136978149414
2025-03-03 09:44:31,916 - INFO - hamming ranking costs: 5.971209287643433
2025-03-03 09:44:31,916 - INFO - labels shape: (45600, 239)
2025-03-03 09:45:06,708 - INFO - similarity labels generation costs: 34.79180645942688
2025-03-03 09:45:06,785 - INFO - topK: 5:, map: 0.33888750000000006
2025-03-03 09:45:07,039 - INFO - topK: 20:, map: 0.24219449333239
2025-03-03 09:45:07,542 - INFO - topK: 40:, map: 0.20869031812704258
2025-03-03 09:45:08,289 - INFO - topK: 60:, map: 0.18939331146679558
2025-03-03 09:45:09,276 - INFO - topK: 80:, map: 0.1747373696015848
2025-03-03 09:45:10,518 - INFO - topK: 100:, map: 0.16249566678721789
2025-03-03 09:45:11,952 - INFO - begin training stage: [781/805]
2025-03-03 09:45:16,305 - INFO - Epoch:[781/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 09:45:19,634 - INFO - Epoch:[781/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:45:22,913 - INFO - Epoch:[781/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 09:45:26,239 - INFO - Epoch:[781/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 09:45:29,557 - INFO - Epoch:[781/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.15
2025-03-03 09:45:32,852 - INFO - Epoch:[781/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.09
2025-03-03 09:45:36,163 - INFO - Epoch:[781/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:45:39,420 - INFO - Epoch:[781/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:45:42,427 - INFO - Epoch:[781/805] Step:[90/90] reconstruction_loss: 1.26 loss_vc: 1.13 loss_cvh: 0.72
2025-03-03 09:45:43,499 - INFO - now the learning rate is: 1e-05
2025-03-03 09:46:16,255 - INFO - begin training stage: [782/805]
2025-03-03 09:46:16,255 - INFO - begin training stage: [782/805]
2025-03-03 09:46:20,561 - INFO - Epoch:[782/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 09:46:23,864 - INFO - Epoch:[782/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 09:46:27,202 - INFO - Epoch:[782/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 09:46:30,623 - INFO - Epoch:[782/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 09:46:33,923 - INFO - Epoch:[782/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:46:37,376 - INFO - Epoch:[782/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 09:46:40,692 - INFO - Epoch:[782/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 09:46:43,968 - INFO - Epoch:[782/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 09:46:47,032 - INFO - Epoch:[782/805] Step:[90/90] reconstruction_loss: 1.17 loss_vc: 1.12 loss_cvh: 0.84
2025-03-03 09:46:48,087 - INFO - now the learning rate is: 1e-05
2025-03-03 09:47:20,829 - INFO - begin training stage: [783/805]
2025-03-03 09:47:20,830 - INFO - begin training stage: [783/805]
2025-03-03 09:47:25,095 - INFO - Epoch:[783/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 09:47:28,439 - INFO - Epoch:[783/805] Step:[20/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 09:47:31,760 - INFO - Epoch:[783/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 09:47:35,067 - INFO - Epoch:[783/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:47:38,357 - INFO - Epoch:[783/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 09:47:41,656 - INFO - Epoch:[783/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 09:47:44,971 - INFO - Epoch:[783/805] Step:[70/90] reconstruction_loss: 1.17 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 09:47:48,259 - INFO - Epoch:[783/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 09:47:51,263 - INFO - Epoch:[783/805] Step:[90/90] reconstruction_loss: 1.10 loss_vc: 1.19 loss_cvh: 0.64
2025-03-03 09:47:52,319 - INFO - now the learning rate is: 1e-05
2025-03-03 09:48:25,747 - INFO - begin training stage: [784/805]
2025-03-03 09:48:25,747 - INFO - begin training stage: [784/805]
2025-03-03 09:48:29,973 - INFO - Epoch:[784/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:48:33,259 - INFO - Epoch:[784/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 09:48:36,513 - INFO - Epoch:[784/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:48:39,783 - INFO - Epoch:[784/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 09:48:43,025 - INFO - Epoch:[784/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.06
2025-03-03 09:48:46,387 - INFO - Epoch:[784/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 09:48:49,689 - INFO - Epoch:[784/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 09:48:52,912 - INFO - Epoch:[784/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 09:48:55,929 - INFO - Epoch:[784/805] Step:[90/90] reconstruction_loss: 0.98 loss_vc: 1.17 loss_cvh: 0.82
2025-03-03 09:48:56,961 - INFO - now the learning rate is: 1e-05
2025-03-03 09:49:30,436 - INFO - begin training stage: [785/805]
2025-03-03 09:49:30,436 - INFO - begin training stage: [785/805]
2025-03-03 09:49:34,972 - INFO - Epoch:[785/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:49:38,371 - INFO - Epoch:[785/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 09:49:41,673 - INFO - Epoch:[785/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.06
2025-03-03 09:49:45,035 - INFO - Epoch:[785/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 09:49:48,343 - INFO - Epoch:[785/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:49:51,689 - INFO - Epoch:[785/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 09:49:54,994 - INFO - Epoch:[785/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:49:58,307 - INFO - Epoch:[785/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 09:50:01,492 - INFO - Epoch:[785/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.13 loss_cvh: 0.62
2025-03-03 09:50:02,564 - INFO - now the learning rate is: 1e-05
2025-03-03 09:50:35,255 - INFO - begin training stage: [786/805]
2025-03-03 09:50:35,256 - INFO - begin training stage: [786/805]
2025-03-03 09:50:39,817 - INFO - Epoch:[786/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:50:43,077 - INFO - Epoch:[786/805] Step:[20/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.17
2025-03-03 09:50:46,369 - INFO - Epoch:[786/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.11
2025-03-03 09:50:49,678 - INFO - Epoch:[786/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:50:53,129 - INFO - Epoch:[786/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:50:56,425 - INFO - Epoch:[786/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 09:50:59,769 - INFO - Epoch:[786/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.13
2025-03-03 09:51:03,086 - INFO - Epoch:[786/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.38 loss_cvh: 3.14
2025-03-03 09:51:06,103 - INFO - Epoch:[786/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.17 loss_cvh: 0.72
2025-03-03 09:51:07,163 - INFO - now the learning rate is: 1e-05
2025-03-03 09:52:11,296 - INFO - begin training stage: [787/805]
2025-03-03 09:52:11,297 - INFO - begin training stage: [787/805]
2025-03-03 09:52:17,366 - INFO - Epoch:[787/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 09:52:22,204 - INFO - Epoch:[787/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 09:52:25,913 - INFO - Epoch:[787/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.11
2025-03-03 09:52:29,174 - INFO - Epoch:[787/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.33 loss_cvh: 3.06
2025-03-03 09:52:32,562 - INFO - Epoch:[787/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 09:52:35,830 - INFO - Epoch:[787/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:52:39,077 - INFO - Epoch:[787/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 09:52:42,336 - INFO - Epoch:[787/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.17
2025-03-03 09:52:45,377 - INFO - Epoch:[787/805] Step:[90/90] reconstruction_loss: 1.12 loss_vc: 1.20 loss_cvh: 0.69
2025-03-03 09:52:46,413 - INFO - now the learning rate is: 1e-05
2025-03-03 09:53:18,825 - INFO - begin training stage: [788/805]
2025-03-03 09:53:18,825 - INFO - begin training stage: [788/805]
2025-03-03 09:53:23,214 - INFO - Epoch:[788/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 09:53:26,539 - INFO - Epoch:[788/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:53:29,824 - INFO - Epoch:[788/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:53:33,154 - INFO - Epoch:[788/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.15
2025-03-03 09:53:36,456 - INFO - Epoch:[788/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:53:39,732 - INFO - Epoch:[788/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 09:53:43,036 - INFO - Epoch:[788/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 09:53:46,405 - INFO - Epoch:[788/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:53:49,449 - INFO - Epoch:[788/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.11 loss_cvh: 0.66
2025-03-03 09:53:50,493 - INFO - now the learning rate is: 1e-05
2025-03-03 09:54:22,998 - INFO - begin training stage: [789/805]
2025-03-03 09:54:22,998 - INFO - begin training stage: [789/805]
2025-03-03 09:54:27,331 - INFO - Epoch:[789/805] Step:[10/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:54:30,625 - INFO - Epoch:[789/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:54:33,893 - INFO - Epoch:[789/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.07
2025-03-03 09:54:37,310 - INFO - Epoch:[789/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 09:54:40,706 - INFO - Epoch:[789/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:54:44,184 - INFO - Epoch:[789/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.38 loss_cvh: 3.10
2025-03-03 09:54:47,699 - INFO - Epoch:[789/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:54:51,115 - INFO - Epoch:[789/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:54:54,228 - INFO - Epoch:[789/805] Step:[90/90] reconstruction_loss: 0.93 loss_vc: 1.24 loss_cvh: 0.80
2025-03-03 09:54:55,308 - INFO - now the learning rate is: 1e-05
2025-03-03 09:55:57,621 - INFO - begin training stage: [790/805]
2025-03-03 09:55:57,622 - INFO - begin training stage: [790/805]
2025-03-03 09:56:03,881 - INFO - Epoch:[790/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:56:08,563 - INFO - Epoch:[790/805] Step:[20/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 09:56:12,990 - INFO - Epoch:[790/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 09:56:16,501 - INFO - Epoch:[790/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.12
2025-03-03 09:56:19,794 - INFO - Epoch:[790/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 09:56:23,029 - INFO - Epoch:[790/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 09:56:26,270 - INFO - Epoch:[790/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 09:56:29,617 - INFO - Epoch:[790/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 09:56:32,628 - INFO - Epoch:[790/805] Step:[90/90] reconstruction_loss: 1.22 loss_vc: 1.22 loss_cvh: 0.82
2025-03-03 09:56:33,672 - INFO - now the learning rate is: 1e-05
2025-03-03 09:57:05,823 - INFO - begin training stage: [791/805]
2025-03-03 09:57:05,824 - INFO - eval data number: 45600
2025-03-03 09:57:05,824 - INFO - loading eval data ......
2025-03-03 09:57:37,170 - INFO - retrieval costs: 19.216500997543335
2025-03-03 09:58:50,738 - INFO - hamming distance computation costs: 73.5675573348999
2025-03-03 09:58:56,804 - INFO - hamming ranking costs: 6.066071271896362
2025-03-03 09:58:56,804 - INFO - labels shape: (45600, 239)
2025-03-03 09:59:31,307 - INFO - similarity labels generation costs: 34.50297927856445
2025-03-03 09:59:31,382 - INFO - topK: 5:, map: 0.34497833333333333
2025-03-03 09:59:31,641 - INFO - topK: 20:, map: 0.24543542179639463
2025-03-03 09:59:32,140 - INFO - topK: 40:, map: 0.21054004636011017
2025-03-03 09:59:32,888 - INFO - topK: 60:, map: 0.19067443260631836
2025-03-03 09:59:33,870 - INFO - topK: 80:, map: 0.1760004195184776
2025-03-03 09:59:35,108 - INFO - topK: 100:, map: 0.1641747997831446
2025-03-03 09:59:36,524 - INFO - begin training stage: [791/805]
2025-03-03 09:59:40,860 - INFO - Epoch:[791/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 09:59:44,319 - INFO - Epoch:[791/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 09:59:47,709 - INFO - Epoch:[791/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 09:59:51,217 - INFO - Epoch:[791/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 09:59:54,578 - INFO - Epoch:[791/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 09:59:57,976 - INFO - Epoch:[791/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 10:00:01,413 - INFO - Epoch:[791/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 10:00:04,714 - INFO - Epoch:[791/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.04
2025-03-03 10:00:07,805 - INFO - Epoch:[791/805] Step:[90/90] reconstruction_loss: 1.11 loss_vc: 1.15 loss_cvh: 0.64
2025-03-03 10:00:08,890 - INFO - now the learning rate is: 1e-05
2025-03-03 10:00:41,622 - INFO - begin training stage: [792/805]
2025-03-03 10:00:41,622 - INFO - begin training stage: [792/805]
2025-03-03 10:00:45,889 - INFO - Epoch:[792/805] Step:[10/90] reconstruction_loss: 1.18 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 10:00:49,296 - INFO - Epoch:[792/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 10:00:52,605 - INFO - Epoch:[792/805] Step:[30/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 10:00:56,046 - INFO - Epoch:[792/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.15
2025-03-03 10:00:59,436 - INFO - Epoch:[792/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 10:01:02,826 - INFO - Epoch:[792/805] Step:[60/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.15
2025-03-03 10:01:06,349 - INFO - Epoch:[792/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 10:01:09,712 - INFO - Epoch:[792/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.10
2025-03-03 10:01:12,775 - INFO - Epoch:[792/805] Step:[90/90] reconstruction_loss: 1.05 loss_vc: 1.22 loss_cvh: 0.77
2025-03-03 10:01:13,853 - INFO - now the learning rate is: 1e-05
2025-03-03 10:01:45,843 - INFO - begin training stage: [793/805]
2025-03-03 10:01:45,843 - INFO - begin training stage: [793/805]
2025-03-03 10:01:50,045 - INFO - Epoch:[793/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 10:01:53,273 - INFO - Epoch:[793/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 10:01:56,529 - INFO - Epoch:[793/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 10:01:59,892 - INFO - Epoch:[793/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.33 loss_cvh: 3.09
2025-03-03 10:02:03,255 - INFO - Epoch:[793/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.09
2025-03-03 10:02:06,542 - INFO - Epoch:[793/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 10:02:09,941 - INFO - Epoch:[793/805] Step:[70/90] reconstruction_loss: 1.11 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 10:02:13,262 - INFO - Epoch:[793/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.05
2025-03-03 10:02:16,353 - INFO - Epoch:[793/805] Step:[90/90] reconstruction_loss: 1.08 loss_vc: 1.20 loss_cvh: 0.87
2025-03-03 10:02:17,437 - INFO - now the learning rate is: 1e-05
2025-03-03 10:02:50,510 - INFO - begin training stage: [794/805]
2025-03-03 10:02:50,510 - INFO - begin training stage: [794/805]
2025-03-03 10:02:54,716 - INFO - Epoch:[794/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 10:02:58,011 - INFO - Epoch:[794/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.15
2025-03-03 10:03:01,271 - INFO - Epoch:[794/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.13
2025-03-03 10:03:04,511 - INFO - Epoch:[794/805] Step:[40/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 10:03:07,724 - INFO - Epoch:[794/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 10:03:10,936 - INFO - Epoch:[794/805] Step:[60/90] reconstruction_loss: 1.17 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 10:03:14,275 - INFO - Epoch:[794/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 10:03:17,473 - INFO - Epoch:[794/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 10:03:20,410 - INFO - Epoch:[794/805] Step:[90/90] reconstruction_loss: 1.19 loss_vc: 1.29 loss_cvh: 0.87
2025-03-03 10:03:21,439 - INFO - now the learning rate is: 1e-05
2025-03-03 10:03:53,578 - INFO - begin training stage: [795/805]
2025-03-03 10:03:53,579 - INFO - begin training stage: [795/805]
2025-03-03 10:03:57,793 - INFO - Epoch:[795/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 10:04:01,042 - INFO - Epoch:[795/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 10:04:04,433 - INFO - Epoch:[795/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 10:04:07,692 - INFO - Epoch:[795/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 10:04:10,917 - INFO - Epoch:[795/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.32 loss_cvh: 3.13
2025-03-03 10:04:14,170 - INFO - Epoch:[795/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 10:04:17,446 - INFO - Epoch:[795/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 10:04:20,691 - INFO - Epoch:[795/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 10:04:23,707 - INFO - Epoch:[795/805] Step:[90/90] reconstruction_loss: 1.24 loss_vc: 1.15 loss_cvh: 0.73
2025-03-03 10:04:24,745 - INFO - now the learning rate is: 1e-05
2025-03-03 10:04:56,890 - INFO - begin training stage: [796/805]
2025-03-03 10:04:56,891 - INFO - begin training stage: [796/805]
2025-03-03 10:05:01,086 - INFO - Epoch:[796/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 10:05:04,352 - INFO - Epoch:[796/805] Step:[20/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.04
2025-03-03 10:05:07,732 - INFO - Epoch:[796/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.02
2025-03-03 10:05:11,008 - INFO - Epoch:[796/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 10:05:14,275 - INFO - Epoch:[796/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 10:05:17,550 - INFO - Epoch:[796/805] Step:[60/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 10:05:20,811 - INFO - Epoch:[796/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.14
2025-03-03 10:05:24,035 - INFO - Epoch:[796/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 10:05:27,002 - INFO - Epoch:[796/805] Step:[90/90] reconstruction_loss: 0.99 loss_vc: 1.01 loss_cvh: 1.02
2025-03-03 10:05:28,059 - INFO - now the learning rate is: 1e-05
2025-03-03 10:06:29,879 - INFO - begin training stage: [797/805]
2025-03-03 10:06:29,880 - INFO - begin training stage: [797/805]
2025-03-03 10:06:36,151 - INFO - Epoch:[797/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 10:06:39,374 - INFO - Epoch:[797/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 10:06:42,508 - INFO - Epoch:[797/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 10:06:45,669 - INFO - Epoch:[797/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 10:06:48,933 - INFO - Epoch:[797/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 10:06:52,053 - INFO - Epoch:[797/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 10:06:55,197 - INFO - Epoch:[797/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 10:06:58,341 - INFO - Epoch:[797/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 10:07:01,213 - INFO - Epoch:[797/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.18 loss_cvh: 0.70
2025-03-03 10:07:02,214 - INFO - now the learning rate is: 1e-05
2025-03-03 10:07:33,893 - INFO - begin training stage: [798/805]
2025-03-03 10:07:33,894 - INFO - begin training stage: [798/805]
2025-03-03 10:07:38,128 - INFO - Epoch:[798/805] Step:[10/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 10:07:41,351 - INFO - Epoch:[798/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.34 loss_cvh: 3.06
2025-03-03 10:07:44,598 - INFO - Epoch:[798/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 10:07:47,846 - INFO - Epoch:[798/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 10:07:51,192 - INFO - Epoch:[798/805] Step:[50/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 10:07:54,407 - INFO - Epoch:[798/805] Step:[60/90] reconstruction_loss: 1.11 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 10:07:57,603 - INFO - Epoch:[798/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.11
2025-03-03 10:08:00,819 - INFO - Epoch:[798/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 10:08:03,787 - INFO - Epoch:[798/805] Step:[90/90] reconstruction_loss: 1.15 loss_vc: 1.35 loss_cvh: 0.80
2025-03-03 10:08:04,849 - INFO - now the learning rate is: 1e-05
2025-03-03 10:08:36,924 - INFO - begin training stage: [799/805]
2025-03-03 10:08:36,925 - INFO - begin training stage: [799/805]
2025-03-03 10:08:41,131 - INFO - Epoch:[799/805] Step:[10/90] reconstruction_loss: 1.11 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 10:08:44,423 - INFO - Epoch:[799/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 10:08:47,795 - INFO - Epoch:[799/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.34 loss_cvh: 3.12
2025-03-03 10:08:51,070 - INFO - Epoch:[799/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.33 loss_cvh: 3.02
2025-03-03 10:08:54,308 - INFO - Epoch:[799/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 10:08:57,570 - INFO - Epoch:[799/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.10
2025-03-03 10:09:00,842 - INFO - Epoch:[799/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.13
2025-03-03 10:09:04,060 - INFO - Epoch:[799/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.15
2025-03-03 10:09:07,058 - INFO - Epoch:[799/805] Step:[90/90] reconstruction_loss: 1.18 loss_vc: 1.02 loss_cvh: 0.62
2025-03-03 10:09:08,112 - INFO - now the learning rate is: 1e-05
2025-03-03 10:09:40,465 - INFO - begin training stage: [800/805]
2025-03-03 10:09:40,465 - INFO - begin training stage: [800/805]
2025-03-03 10:09:44,636 - INFO - Epoch:[800/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.14
2025-03-03 10:09:47,837 - INFO - Epoch:[800/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.32 loss_cvh: 3.03
2025-03-03 10:09:51,040 - INFO - Epoch:[800/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.07
2025-03-03 10:09:54,353 - INFO - Epoch:[800/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.06
2025-03-03 10:09:57,560 - INFO - Epoch:[800/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.09
2025-03-03 10:10:00,745 - INFO - Epoch:[800/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 10:10:03,915 - INFO - Epoch:[800/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 10:10:07,090 - INFO - Epoch:[800/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.33 loss_cvh: 3.08
2025-03-03 10:10:10,009 - INFO - Epoch:[800/805] Step:[90/90] reconstruction_loss: 1.09 loss_vc: 1.01 loss_cvh: 0.82
2025-03-03 10:10:11,040 - INFO - now the learning rate is: 1e-05
2025-03-03 10:10:42,906 - INFO - begin training stage: [801/805]
2025-03-03 10:10:42,907 - INFO - eval data number: 45600
2025-03-03 10:10:42,907 - INFO - loading eval data ......
2025-03-03 10:11:13,733 - INFO - retrieval costs: 18.921624660491943
2025-03-03 10:12:14,069 - INFO - hamming distance computation costs: 60.33544921875
2025-03-03 10:12:20,098 - INFO - hamming ranking costs: 6.028972387313843
2025-03-03 10:12:20,098 - INFO - labels shape: (45600, 239)
2025-03-03 10:12:53,847 - INFO - similarity labels generation costs: 33.748923540115356
2025-03-03 10:12:53,918 - INFO - topK: 5:, map: 0.33956500000000006
2025-03-03 10:12:54,157 - INFO - topK: 20:, map: 0.24455525590739455
2025-03-03 10:12:54,627 - INFO - topK: 40:, map: 0.21086456079706636
2025-03-03 10:12:55,349 - INFO - topK: 60:, map: 0.191132733590687
2025-03-03 10:12:56,303 - INFO - topK: 80:, map: 0.17618252395627979
2025-03-03 10:12:57,485 - INFO - topK: 100:, map: 0.16436285772383658
2025-03-03 10:12:58,860 - INFO - begin training stage: [801/805]
2025-03-03 10:13:03,139 - INFO - Epoch:[801/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 10:13:06,452 - INFO - Epoch:[801/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.11
2025-03-03 10:13:09,655 - INFO - Epoch:[801/805] Step:[30/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 10:13:12,839 - INFO - Epoch:[801/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 10:13:16,006 - INFO - Epoch:[801/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 10:13:19,198 - INFO - Epoch:[801/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 10:13:22,393 - INFO - Epoch:[801/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 10:13:25,564 - INFO - Epoch:[801/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 10:13:28,482 - INFO - Epoch:[801/805] Step:[90/90] reconstruction_loss: 1.13 loss_vc: 1.08 loss_cvh: 0.64
2025-03-03 10:13:29,536 - INFO - now the learning rate is: 1e-05
2025-03-03 10:14:01,012 - INFO - begin training stage: [802/805]
2025-03-03 10:14:01,013 - INFO - begin training stage: [802/805]
2025-03-03 10:14:05,462 - INFO - Epoch:[802/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.05
2025-03-03 10:14:08,927 - INFO - Epoch:[802/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.08
2025-03-03 10:14:12,468 - INFO - Epoch:[802/805] Step:[30/90] reconstruction_loss: 1.12 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 10:14:15,899 - INFO - Epoch:[802/805] Step:[40/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 10:14:19,277 - INFO - Epoch:[802/805] Step:[50/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 10:14:22,748 - INFO - Epoch:[802/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 10:14:26,157 - INFO - Epoch:[802/805] Step:[70/90] reconstruction_loss: 1.16 loss_vc: 4.35 loss_cvh: 3.04
2025-03-03 10:14:29,520 - INFO - Epoch:[802/805] Step:[80/90] reconstruction_loss: 1.12 loss_vc: 4.33 loss_cvh: 3.10
2025-03-03 10:14:32,668 - INFO - Epoch:[802/805] Step:[90/90] reconstruction_loss: 1.16 loss_vc: 1.18 loss_cvh: 0.85
2025-03-03 10:14:33,727 - INFO - now the learning rate is: 1e-05
2025-03-03 10:15:05,210 - INFO - begin training stage: [803/805]
2025-03-03 10:15:05,210 - INFO - begin training stage: [803/805]
2025-03-03 10:15:09,403 - INFO - Epoch:[803/805] Step:[10/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.10
2025-03-03 10:15:12,684 - INFO - Epoch:[803/805] Step:[20/90] reconstruction_loss: 1.13 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 10:15:15,860 - INFO - Epoch:[803/805] Step:[30/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.11
2025-03-03 10:15:19,062 - INFO - Epoch:[803/805] Step:[40/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.14
2025-03-03 10:15:22,210 - INFO - Epoch:[803/805] Step:[50/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 10:15:25,639 - INFO - Epoch:[803/805] Step:[60/90] reconstruction_loss: 1.13 loss_vc: 4.33 loss_cvh: 3.12
2025-03-03 10:15:28,815 - INFO - Epoch:[803/805] Step:[70/90] reconstruction_loss: 1.13 loss_vc: 4.34 loss_cvh: 3.07
2025-03-03 10:15:31,998 - INFO - Epoch:[803/805] Step:[80/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.13
2025-03-03 10:15:34,906 - INFO - Epoch:[803/805] Step:[90/90] reconstruction_loss: 1.14 loss_vc: 1.18 loss_cvh: 0.82
2025-03-03 10:15:35,948 - INFO - now the learning rate is: 1e-05
2025-03-03 10:16:07,450 - INFO - begin training stage: [804/805]
2025-03-03 10:16:07,450 - INFO - begin training stage: [804/805]
2025-03-03 10:16:11,575 - INFO - Epoch:[804/805] Step:[10/90] reconstruction_loss: 1.15 loss_vc: 4.36 loss_cvh: 3.11
2025-03-03 10:16:14,769 - INFO - Epoch:[804/805] Step:[20/90] reconstruction_loss: 1.16 loss_vc: 4.37 loss_cvh: 3.13
2025-03-03 10:16:18,095 - INFO - Epoch:[804/805] Step:[30/90] reconstruction_loss: 1.16 loss_vc: 4.36 loss_cvh: 3.07
2025-03-03 10:16:21,303 - INFO - Epoch:[804/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 10:16:24,448 - INFO - Epoch:[804/805] Step:[50/90] reconstruction_loss: 1.12 loss_vc: 4.37 loss_cvh: 3.04
2025-03-03 10:16:27,614 - INFO - Epoch:[804/805] Step:[60/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.12
2025-03-03 10:16:30,790 - INFO - Epoch:[804/805] Step:[70/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 10:16:33,940 - INFO - Epoch:[804/805] Step:[80/90] reconstruction_loss: 1.14 loss_vc: 4.37 loss_cvh: 3.08
2025-03-03 10:16:36,885 - INFO - Epoch:[804/805] Step:[90/90] reconstruction_loss: 1.29 loss_vc: 1.19 loss_cvh: 0.87
2025-03-03 10:16:37,916 - INFO - now the learning rate is: 1e-05
2025-03-03 10:17:09,392 - INFO - begin training stage: [805/805]
2025-03-03 10:17:09,392 - INFO - begin training stage: [805/805]
2025-03-03 10:17:13,664 - INFO - Epoch:[805/805] Step:[10/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.08
2025-03-03 10:17:16,854 - INFO - Epoch:[805/805] Step:[20/90] reconstruction_loss: 1.14 loss_vc: 4.35 loss_cvh: 3.12
2025-03-03 10:17:20,029 - INFO - Epoch:[805/805] Step:[30/90] reconstruction_loss: 1.13 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 10:17:23,232 - INFO - Epoch:[805/805] Step:[40/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 10:17:26,399 - INFO - Epoch:[805/805] Step:[50/90] reconstruction_loss: 1.14 loss_vc: 4.34 loss_cvh: 3.08
2025-03-03 10:17:29,738 - INFO - Epoch:[805/805] Step:[60/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.10
2025-03-03 10:17:33,067 - INFO - Epoch:[805/805] Step:[70/90] reconstruction_loss: 1.15 loss_vc: 4.35 loss_cvh: 3.09
2025-03-03 10:17:36,395 - INFO - Epoch:[805/805] Step:[80/90] reconstruction_loss: 1.13 loss_vc: 4.37 loss_cvh: 3.17
2025-03-03 10:17:39,487 - INFO - Epoch:[805/805] Step:[90/90] reconstruction_loss: 0.99 loss_vc: 1.38 loss_cvh: 0.91
2025-03-03 10:17:40,543 - INFO - now the learning rate is: 1e-05
